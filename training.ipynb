{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = {\n",
    "    #'dataset': 'IPIN2020_Track3_5F', #['NTU_CSIE_5F', 'DSI', 'IPIN2016_Tutorial', 'IPIN2020_Track3_2F', 'IPIN2020_Track3_3F', 'IPIN2020_Track3_5F']\n",
    "    'dataset':'NTUH_2F',\n",
    "    'method': 'DSAR',#['WKNN', 'RandomForest', 'WiDeep', 'DSAR']\n",
    "}\n",
    "\n",
    "def check_format():\n",
    "    assert config['method'] in ['WKNN', 'RandomForest', 'WiDeep', 'DSAR'], \\\n",
    "        'config method should be [WKNN, RandomForest, WiDeep, DSAR]'\n",
    "    assert config['dataset'] in ['NTUH_2F','NTU_CSIE_5F', 'DSI', 'IPIN2016_Tutorial', 'IPIN2020_Track3_2F', 'IPIN2020_Track3_3F', 'IPIN2020_Track3_5F'], \\\n",
    "        'config dataset should be [NTU_CSIE_5F, DSI, IPIN2016_Tutorial, IPIN2020_Track3_2F, IPIN2020_Track3_3F, IPIN2020_Track3_5F]'\n",
    "\n",
    "\n",
    "\n",
    "def load(dataset):\n",
    "    dir_path = osp.join(os.getcwd(), 'Dataset', dataset)\n",
    "\n",
    "    training_wifi_pos = np.load(osp.join(dir_path, 'training_wifi_pos.npy'))\n",
    "    testing_wifi_pos = np.load(osp.join(dir_path, 'testing_wifi_pos.npy'))\n",
    "\n",
    "    return training_wifi_pos, testing_wifi_pos\n",
    "\n",
    "\n",
    "\n",
    "def normalize_rssi(rssi):\n",
    "    return (rssi + 100) / 100\n",
    "\n",
    "\n",
    "\n",
    "def normalize_pos(pos, boundary):\n",
    "    max_x, min_x, max_y, min_y = boundary\n",
    "    norm_pos = np.zeros_like(pos)\n",
    "    norm_pos[:,0] = (pos[:,0] - min_x) / (max_x - min_x)\n",
    "    norm_pos[:,1] = (pos[:,1] - min_y) / (max_y - min_y)\n",
    "    return norm_pos\n",
    "\n",
    "\n",
    "\n",
    "def restore_pos(norm_pos, boundary):\n",
    "    max_x, min_x, max_y, min_y = boundary\n",
    "    pos = np.zeros_like(norm_pos)\n",
    "    pos[:,0] = norm_pos[:,0] * (max_x - min_x) + min_x\n",
    "    pos[:,1] = norm_pos[:,1] * (max_y - min_y) + min_y\n",
    "    return pos\n",
    "\n",
    "\n",
    "\n",
    "def get_rps(training_wifi_pos):\n",
    "\n",
    "    rps = {}\n",
    "    for i in range(training_wifi_pos.shape[0]):\n",
    "        pos = tuple(training_wifi_pos[i,-2:])\n",
    "        if pos not in rps:\n",
    "            rps[pos] = training_wifi_pos[None,i,:-2]\n",
    "        else:\n",
    "            rps[pos] = np.r_[rps[pos], training_wifi_pos[None,i,:-2]]\n",
    "    return rps\n",
    "        \n",
    "\n",
    "\n",
    "def add_noise(rssi):\n",
    "    noisy_rssi = rssi + torch.normal(0, 0.1, rssi.shape)\n",
    "    noisy_rssi = torch.clip(noisy_rssi, 0, 1)\n",
    "    mask = torch.rand(rssi.shape) < 0.1\n",
    "    noisy_rssi[mask] = 0\n",
    "    return noisy_rssi\n",
    "    \n",
    "\n",
    "\n",
    "def get_boundary(training_pos, testing_pos):\n",
    "    max_x = max(training_pos[:,0].max(), testing_pos[:,0].max())\n",
    "    min_x = min(training_pos[:,0].min(), testing_pos[:,0].min())\n",
    "    max_y = max(training_pos[:,1].max(), testing_pos[:,1].max())\n",
    "    min_y = min(training_pos[:,1].min(), testing_pos[:,1].min())\n",
    "    \n",
    "    return (max_x, min_x, max_y, min_y)\n",
    "\n",
    "\n",
    "\n",
    "def RBF(origin, reconstruction, gamma=16, axis=None):\n",
    "    return np.e**(-gamma * np.linalg.norm(origin - reconstruction, axis=axis)**2)\n",
    "\n",
    "\n",
    "\n",
    "def plot_wifi_pos(dataset, method, training_pos, testing_pos, pred_pos, pred_err):\n",
    "\n",
    "    dir_path = osp.join(os.getcwd(), 'Result', dataset, method)\n",
    "\n",
    "    fig, (axs0, axs1, axs2) = plt.subplots(1, 3, figsize=(20, 5), sharex=True, sharey=True)\n",
    "\n",
    "    axs0.plot(training_pos[:,0], training_pos[:,1], 'ob')\n",
    "    axs0.set_title('Training Points')\n",
    "    axs0.grid()\n",
    "\n",
    "    axs1.plot(testing_pos[:,0], testing_pos[:,1], 'og')\n",
    "    axs1.set_title('Testing Points')\n",
    "    axs1.grid()\n",
    "\n",
    "    axs2.plot(pred_pos[:,0], pred_pos[:,1], 'or')\n",
    "    axs2.set_title('Prediction Points')\n",
    "    axs2.grid()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(osp.join(dir_path, dataset), bbox_inches='tight')\n",
    "    np.save(osp.join(dir_path, 'loc_err.npy'), pred_err)\n",
    "    np.save(osp.join(dir_path, 'pred_pos.npy'), pred_pos)\n",
    "    \n",
    "    \n",
    "def plot_loss(r_losses, reg_losses, v_losses):\n",
    "    x = [i for i in range(len(r_losses))]\n",
    "    \n",
    "    plt.plot(x, r_losses , label = \"rec loss\")\n",
    "    plt.plot(x, reg_losses, label = \"reg loss\")\n",
    "    plt.plot(x, v_losses, label = \"val loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def DSAR_testing(query_wifi_pos, dataset, boundary):\n",
    "\n",
    "    dir_path = osp.join(os.getcwd(), 'Result', dataset, 'DSAR')\n",
    "    inputs = normalize_rssi(query_wifi_pos[:,:-2])\n",
    "    labels = query_wifi_pos[:,-2:]\n",
    "\n",
    "    path = osp.join(dir_path, 'dsar.pth') \n",
    "    network = torch.load(path).to(device) # if u don't have gpu, add map_location='cpu' in load's parameter\n",
    "    network.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.from_numpy(inputs).to(device)\n",
    "        rssi_reconst, pos = network(inputs)\n",
    "        rssi_reconst = rssi_reconst.cpu().numpy()\n",
    "        pred_pos = restore_pos(pos.cpu().numpy(), boundary)\n",
    "        loc_err = np.linalg.norm(pred_pos - labels, axis=1)\n",
    "\n",
    "    return pred_pos, loc_err, rssi_reconst\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DenoisingAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DenoisingAutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, input_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('sigmoid')) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AutoRegression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AutoRegression, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2),\n",
    "        )\n",
    "\n",
    "\n",
    "        for m in self.encoder.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('sigmoid'))\n",
    "        for m in self.decoder.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('sigmoid'))\n",
    "\n",
    "        for m in self.regression.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu')) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        o1 = self.decoder(x)\n",
    "        o2 = self.regression(x)\n",
    "        return (o1, o2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RadioMap(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = torch.from_numpy(inputs)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.inputs[index], self.labels[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def DSAR_training(dataset, training_wifi_pos, boundary):\n",
    "    dir_path = osp.join(os.getcwd(), 'Result', dataset, 'DSAR')\n",
    "    rps = get_rps(training_wifi_pos)\n",
    "\n",
    "    inputs = normalize_rssi(training_wifi_pos[:,:-2])\n",
    "    labels = normalize_pos(training_wifi_pos[:,-2:], boundary)\n",
    "    radio_map = RadioMap(inputs, labels)\n",
    "    loader = DataLoader(dataset=radio_map, shuffle=True, batch_size=16)\n",
    "    \n",
    "    r_losses = []\n",
    "    reg_losses = []\n",
    "    V_losses = []\n",
    "\n",
    "    val_inputs = []\n",
    "    val_labels = []\n",
    "    for rp_pos in rps:\n",
    "        val_inputs.append(np.average(rps[rp_pos], axis=0))\n",
    "        val_labels.append(np.array(rp_pos, dtype=np.float64))\n",
    "\n",
    "    val_inputs = normalize_rssi(np.array(val_inputs, dtype=np.float64))\n",
    "    val_labels = normalize_pos(np.array(val_labels, dtype=np.float64), boundary)\n",
    "    val_radio_map = RadioMap(val_inputs, val_labels)\n",
    "    val_loader = DataLoader(dataset=val_radio_map, shuffle=True, batch_size=8)\n",
    "\n",
    "    epochs = 5000*2\n",
    "    input_size = training_wifi_pos.shape[1] - 2\n",
    "    hidden_size = len(rps)\n",
    "\n",
    "    network = AutoRegression(input_size, hidden_size).to(device)        \n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0, amsgrad=False)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    losses = np.zeros((epochs,3), dtype=np.float64)\n",
    "\n",
    "    network.train()\n",
    "    for epoch in range(epochs):\n",
    "        reconst_losses = 0.0\n",
    "        regression_losses = 0.0\n",
    "\n",
    "        for inputs, labels in loader:\n",
    "\n",
    "            noisy_inputs = add_noise(inputs).to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            reconst_rssi, pos = network(noisy_inputs)\n",
    "\n",
    "            reconst_loss = criterion(inputs, reconst_rssi)\n",
    "            regression_loss = criterion(labels, pos)\n",
    "\n",
    "            loss = reconst_loss + regression_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            reconst_losses += reconst_loss.item()\n",
    "            regression_losses += regression_loss.item()\n",
    "        \n",
    "        losses[epoch,0] = reconst_losses\n",
    "        losses[epoch,1] = regression_losses\n",
    "\n",
    "        network.eval()\n",
    "        val_losses = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                reconst, pos = network(inputs)\n",
    "                val_losses += (labels - pos).pow(2).sum()\n",
    "        \n",
    "        losses[epoch,2] = val_losses\n",
    "\n",
    "        if val_losses < best_val_loss:\n",
    "            best_val_loss = val_losses\n",
    "            torch.save(network, osp.join(dir_path, 'dsar.pth'))\n",
    "        \n",
    "        r_losses.append(reconst_losses)\n",
    "        reg_losses.append(regression_losses)\n",
    "        V_losses.append(val_losses.item())\n",
    "       \n",
    "        print(f'Epoch {epoch}, reconstruction losses: {reconst_losses}, regression losses: {regression_losses}, validation losses: {val_losses}')\n",
    "\n",
    "    np.save(osp.join(dir_path, 'losses.npy'), losses)\n",
    "    \n",
    "    plot_loss(r_losses, reg_losses, V_losses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, reconstruction losses: 0.9941460969139005, regression losses: 3.102871001798125, validation losses: 17.11812954118886\n",
      "Epoch 1, reconstruction losses: 0.8796136767926689, regression losses: 1.4113719572583987, validation losses: 7.397640291521269\n",
      "Epoch 2, reconstruction losses: 0.7704873870905914, regression losses: 0.7054658122759835, validation losses: 5.8709716572156765\n",
      "Epoch 3, reconstruction losses: 0.6857060701185216, regression losses: 0.7257940891010759, validation losses: 6.780281850814774\n",
      "Epoch 4, reconstruction losses: 0.5954536671564281, regression losses: 0.6430973760927573, validation losses: 6.62001412529941\n",
      "Epoch 5, reconstruction losses: 0.5324666182404952, regression losses: 0.8667424136135621, validation losses: 5.9510644997453\n",
      "Epoch 6, reconstruction losses: 0.4499092117867158, regression losses: 0.5999947111973352, validation losses: 5.627028479042272\n",
      "Epoch 7, reconstruction losses: 0.4018788990986508, regression losses: 0.5590843684330044, validation losses: 5.682324708031345\n",
      "Epoch 8, reconstruction losses: 0.3643288750633885, regression losses: 0.6243615138663394, validation losses: 5.668072406371533\n",
      "Epoch 9, reconstruction losses: 0.3117971561645784, regression losses: 0.6160224504266123, validation losses: 5.599551198645214\n",
      "Epoch 10, reconstruction losses: 0.28584111500149234, regression losses: 0.673589558265735, validation losses: 5.5907511032300805\n",
      "Epoch 11, reconstruction losses: 0.25420342043688815, regression losses: 0.5831870883747621, validation losses: 5.63751929401508\n",
      "Epoch 12, reconstruction losses: 0.23298595955646148, regression losses: 0.581831015289672, validation losses: 5.7382645424493\n",
      "Epoch 13, reconstruction losses: 0.20947194135399572, regression losses: 0.6651066200430797, validation losses: 5.716121113725408\n",
      "Epoch 14, reconstruction losses: 0.1851794126242107, regression losses: 0.5682844064567558, validation losses: 5.584611057109758\n",
      "Epoch 15, reconstruction losses: 0.17324501361120817, regression losses: 0.7194499036126687, validation losses: 5.575712476874859\n",
      "Epoch 16, reconstruction losses: 0.1585840613755226, regression losses: 0.7211106574805682, validation losses: 5.583122133607956\n",
      "Epoch 17, reconstruction losses: 0.14828784118275612, regression losses: 0.7292325398358511, validation losses: 5.6112906259248465\n",
      "Epoch 18, reconstruction losses: 0.14082008128614573, regression losses: 0.6530714938014195, validation losses: 5.577998297457267\n",
      "Epoch 19, reconstruction losses: 0.13137563612638142, regression losses: 0.5324150676800055, validation losses: 5.613507643555846\n",
      "Epoch 20, reconstruction losses: 0.12237618478691312, regression losses: 0.6246286674838586, validation losses: 5.586195920196039\n",
      "Epoch 21, reconstruction losses: 0.11330321103991937, regression losses: 0.6058211010730614, validation losses: 5.580179895479957\n",
      "Epoch 22, reconstruction losses: 0.10560871833726845, regression losses: 0.6143842856263829, validation losses: 5.5505496400605345\n",
      "Epoch 23, reconstruction losses: 0.10067601011065953, regression losses: 0.5903455750892311, validation losses: 5.57742325647389\n",
      "Epoch 24, reconstruction losses: 0.09999006225620492, regression losses: 0.6220668676774845, validation losses: 5.64749331892241\n",
      "Epoch 25, reconstruction losses: 0.09114369870194489, regression losses: 0.5662504527980617, validation losses: 5.609701020017824\n",
      "Epoch 26, reconstruction losses: 0.0938882056179983, regression losses: 0.6763470845234218, validation losses: 5.531225684241329\n",
      "Epoch 27, reconstruction losses: 0.08581113369369059, regression losses: 0.6326467709230518, validation losses: 5.596206088683784\n",
      "Epoch 28, reconstruction losses: 0.0854223659921368, regression losses: 0.600883388761849, validation losses: 5.534318755012114\n",
      "Epoch 29, reconstruction losses: 0.08246084331478767, regression losses: 0.6198992616969674, validation losses: 5.5440428010110505\n",
      "Epoch 30, reconstruction losses: 0.08143415562264723, regression losses: 0.7300105245082438, validation losses: 5.538911837717166\n",
      "Epoch 31, reconstruction losses: 0.0791560874928937, regression losses: 0.669796151135627, validation losses: 5.526994588234034\n",
      "Epoch 32, reconstruction losses: 0.07265704889520158, regression losses: 0.6066869233420799, validation losses: 5.531580862352313\n",
      "Epoch 33, reconstruction losses: 0.07527503107588886, regression losses: 0.6050960117398727, validation losses: 5.561086406747501\n",
      "Epoch 34, reconstruction losses: 0.0706373119978111, regression losses: 0.6075503430640974, validation losses: 5.51783671223979\n",
      "Epoch 35, reconstruction losses: 0.06929337091631319, regression losses: 0.58537206975912, validation losses: 5.643067804925934\n",
      "Epoch 36, reconstruction losses: 0.0677856527518705, regression losses: 0.5601771665146756, validation losses: 5.6664048588432845\n",
      "Epoch 37, reconstruction losses: 0.07009986432661791, regression losses: 0.7147710552363452, validation losses: 5.482518129471315\n",
      "Epoch 38, reconstruction losses: 0.0666366204718942, regression losses: 0.5703511958379777, validation losses: 5.589183082031551\n",
      "Epoch 39, reconstruction losses: 0.0711570466484774, regression losses: 0.7160051935718269, validation losses: 5.712936328158685\n",
      "Epoch 40, reconstruction losses: 0.06624115990651656, regression losses: 0.6358418675694114, validation losses: 5.489813139849312\n",
      "Epoch 41, reconstruction losses: 0.062054130114876635, regression losses: 0.6182507093357522, validation losses: 5.6110148373862545\n",
      "Epoch 42, reconstruction losses: 0.06936966031825419, regression losses: 0.6796383264451353, validation losses: 5.525875406701916\n",
      "Epoch 43, reconstruction losses: 0.06497706123969377, regression losses: 0.7396533555961942, validation losses: 5.498161090529809\n",
      "Epoch 44, reconstruction losses: 0.05910059042909635, regression losses: 0.590799351653561, validation losses: 5.463812787002392\n",
      "Epoch 45, reconstruction losses: 0.05983580298779111, regression losses: 0.5678426665054137, validation losses: 5.666760311896702\n",
      "Epoch 46, reconstruction losses: 0.06358501586150243, regression losses: 0.657889392116881, validation losses: 5.706516500372484\n",
      "Epoch 47, reconstruction losses: 0.061659245792361574, regression losses: 0.5891963521884644, validation losses: 5.659551353791535\n",
      "Epoch 48, reconstruction losses: 0.060156480023924055, regression losses: 0.6214511865000653, validation losses: 5.5293424444498\n",
      "Epoch 49, reconstruction losses: 0.057076490928702255, regression losses: 0.6005641957287681, validation losses: 5.468680011086861\n",
      "Epoch 50, reconstruction losses: 0.05618452236847387, regression losses: 0.597351475012474, validation losses: 5.427138441460593\n",
      "Epoch 51, reconstruction losses: 0.061691593166187775, regression losses: 0.6785523395967012, validation losses: 5.468019153257736\n",
      "Epoch 52, reconstruction losses: 0.05492084755939918, regression losses: 0.57651919083349, validation losses: 5.643764770472848\n",
      "Epoch 53, reconstruction losses: 0.05767779152377521, regression losses: 0.603941826956598, validation losses: 5.419799747273707\n",
      "Epoch 54, reconstruction losses: 0.05759237033408039, regression losses: 0.6082487143176595, validation losses: 5.477891668310821\n",
      "Epoch 55, reconstruction losses: 0.05898080551766615, regression losses: 0.6290904923880164, validation losses: 5.398095575636801\n",
      "Epoch 56, reconstruction losses: 0.05419852802315912, regression losses: 0.5540828529584909, validation losses: 5.4891706751393565\n",
      "Epoch 57, reconstruction losses: 0.05571160738123585, regression losses: 0.6204364419695906, validation losses: 5.409322583441114\n",
      "Epoch 58, reconstruction losses: 0.06269876627827134, regression losses: 0.6380613189410924, validation losses: 5.4840074976888085\n",
      "Epoch 59, reconstruction losses: 0.053181405464786245, regression losses: 0.6276250462995991, validation losses: 5.5337678170745805\n",
      "Epoch 60, reconstruction losses: 0.05260602783406001, regression losses: 0.5868413449269249, validation losses: 5.39305506119921\n",
      "Epoch 61, reconstruction losses: 0.05499070026361341, regression losses: 0.6262243048219165, validation losses: 5.572987171525923\n",
      "Epoch 62, reconstruction losses: 0.06183753567617982, regression losses: 0.6504741571650826, validation losses: 5.36938228623913\n",
      "Epoch 63, reconstruction losses: 0.05628853060748218, regression losses: 0.5521043822956745, validation losses: 5.508114986330559\n",
      "Epoch 64, reconstruction losses: 0.05670548845631742, regression losses: 0.6745008710559521, validation losses: 5.555800751779333\n",
      "Epoch 65, reconstruction losses: 0.05640316093327722, regression losses: 0.6170565314464431, validation losses: 5.355805039148765\n",
      "Epoch 66, reconstruction losses: 0.05677845482740649, regression losses: 0.642114568147979, validation losses: 5.528299959690115\n",
      "Epoch 67, reconstruction losses: 0.05303372325567946, regression losses: 0.7436790270546593, validation losses: 5.3592681143847924\n",
      "Epoch 68, reconstruction losses: 0.05531021696400378, regression losses: 0.6653434848673118, validation losses: 5.5352620058195106\n",
      "Epoch 69, reconstruction losses: 0.052281810439416515, regression losses: 0.583580241405135, validation losses: 5.45361711799248\n",
      "Epoch 70, reconstruction losses: 0.05072658527857157, regression losses: 0.6011180043507127, validation losses: 5.376399367083098\n",
      "Epoch 71, reconstruction losses: 0.05226756883133025, regression losses: 0.5170306201162226, validation losses: 5.369387428207778\n",
      "Epoch 72, reconstruction losses: 0.05222060759430003, regression losses: 0.6169333951857632, validation losses: 5.344978819768378\n",
      "Epoch 73, reconstruction losses: 0.05148975210029483, regression losses: 0.5335731576541222, validation losses: 5.3496905248228055\n",
      "Epoch 74, reconstruction losses: 0.0610150491375558, regression losses: 0.6886816934950831, validation losses: 5.376889607605233\n",
      "Epoch 75, reconstruction losses: 0.05351003315134283, regression losses: 0.5974974291378282, validation losses: 5.333440075162084\n",
      "Epoch 76, reconstruction losses: 0.05083791609629884, regression losses: 0.5692173011761577, validation losses: 5.426279600634064\n",
      "Epoch 77, reconstruction losses: 0.054832496117363176, regression losses: 0.6899413036790794, validation losses: 5.4940570583311406\n",
      "Epoch 78, reconstruction losses: 0.04951104852698993, regression losses: 0.5668618699404354, validation losses: 5.51279903189926\n",
      "Epoch 79, reconstruction losses: 0.0502780255740866, regression losses: 0.5711365624410774, validation losses: 5.429375780050751\n",
      "Epoch 80, reconstruction losses: 0.0587375769581062, regression losses: 0.6689507846332462, validation losses: 5.328166682199588\n",
      "Epoch 81, reconstruction losses: 0.049354719268491866, regression losses: 0.5813305467962464, validation losses: 5.297364609312787\n",
      "Epoch 82, reconstruction losses: 0.050622149287228774, regression losses: 0.5771274114296712, validation losses: 5.2994420400378335\n",
      "Epoch 83, reconstruction losses: 0.050499964549589396, regression losses: 0.5509580626690631, validation losses: 5.379570701114189\n",
      "Epoch 84, reconstruction losses: 0.05368904779390116, regression losses: 0.7111083987157539, validation losses: 5.278248680166175\n",
      "Epoch 85, reconstruction losses: 0.050599287484216444, regression losses: 0.5596585102422293, validation losses: 5.477354897215067\n",
      "Epoch 86, reconstruction losses: 0.05232945676007902, regression losses: 0.5648260419537374, validation losses: 5.7140397861644825\n",
      "Epoch 87, reconstruction losses: 0.04958532079301322, regression losses: 0.6453640725365029, validation losses: 5.360869785714458\n",
      "Epoch 88, reconstruction losses: 0.05289200433814233, regression losses: 0.7050496243359801, validation losses: 5.29234498743452\n",
      "Epoch 89, reconstruction losses: 0.05919046854656382, regression losses: 0.6219960300556155, validation losses: 5.2520107687239515\n",
      "Epoch 90, reconstruction losses: 0.0500866920496829, regression losses: 0.624534397358847, validation losses: 5.333255927173759\n",
      "Epoch 91, reconstruction losses: 0.05346468238556834, regression losses: 0.6491775293165427, validation losses: 5.223265712407837\n",
      "Epoch 92, reconstruction losses: 0.0543269749173863, regression losses: 0.5950514931837168, validation losses: 5.407090708582084\n",
      "Epoch 93, reconstruction losses: 0.04974265331217408, regression losses: 0.5298658088314359, validation losses: 5.49353480867133\n",
      "Epoch 94, reconstruction losses: 0.05410452792214542, regression losses: 0.6818004954831448, validation losses: 5.2705340273410695\n",
      "Epoch 95, reconstruction losses: 0.0508199407484756, regression losses: 0.5667618567650569, validation losses: 5.2837593481620875\n",
      "Epoch 96, reconstruction losses: 0.05106326150102848, regression losses: 0.584693903448018, validation losses: 5.299785299771611\n",
      "Epoch 97, reconstruction losses: 0.05220459196515195, regression losses: 0.591322969275117, validation losses: 5.287205138930373\n",
      "Epoch 98, reconstruction losses: 0.05188848083023179, regression losses: 0.7290837038356082, validation losses: 5.322362232124534\n",
      "Epoch 99, reconstruction losses: 0.048119650329620955, regression losses: 0.602859978953358, validation losses: 5.26017784069337\n",
      "Epoch 100, reconstruction losses: 0.05196923349423639, regression losses: 0.552281537666928, validation losses: 5.200543477217044\n",
      "Epoch 101, reconstruction losses: 0.04811121717916356, regression losses: 0.5197255162332506, validation losses: 5.209781976096916\n",
      "Epoch 102, reconstruction losses: 0.04901493563602747, regression losses: 0.5187834712210815, validation losses: 5.214903872886443\n",
      "Epoch 103, reconstruction losses: 0.053848658579207224, regression losses: 0.6324776185838248, validation losses: 5.170717497915451\n",
      "Epoch 104, reconstruction losses: 0.0502290648462117, regression losses: 0.5942898154043599, validation losses: 5.341283660867697\n",
      "Epoch 105, reconstruction losses: 0.05727102481957492, regression losses: 0.623463371321295, validation losses: 5.18990785144213\n",
      "Epoch 106, reconstruction losses: 0.05841777181236871, regression losses: 0.638273585711831, validation losses: 5.395964890013527\n",
      "Epoch 107, reconstruction losses: 0.048748167067777855, regression losses: 0.579717734688423, validation losses: 5.404661661520612\n",
      "Epoch 108, reconstruction losses: 0.053675655315685175, regression losses: 0.6111301381608771, validation losses: 5.1390772164903575\n",
      "Epoch 109, reconstruction losses: 0.050068201992518095, regression losses: 0.6087057972837809, validation losses: 5.281286203179348\n",
      "Epoch 110, reconstruction losses: 0.0522674597223012, regression losses: 0.677399298499076, validation losses: 5.276489580477488\n",
      "Epoch 111, reconstruction losses: 0.05025663105607887, regression losses: 0.5661846687129779, validation losses: 5.392933222834335\n",
      "Epoch 112, reconstruction losses: 0.04978083211247627, regression losses: 0.5621767403223903, validation losses: 5.353287105421444\n",
      "Epoch 113, reconstruction losses: 0.05435040709503356, regression losses: 0.6095897661029208, validation losses: 5.255478306618129\n",
      "Epoch 114, reconstruction losses: 0.056222161002792925, regression losses: 0.6731901619988399, validation losses: 5.2211099014824285\n",
      "Epoch 115, reconstruction losses: 0.04928494139019358, regression losses: 0.6065732470521319, validation losses: 5.414841381849812\n",
      "Epoch 116, reconstruction losses: 0.049355009947062586, regression losses: 0.5530442408560232, validation losses: 5.127962266546409\n",
      "Epoch 117, reconstruction losses: 0.04756256994477938, regression losses: 0.5116374455161968, validation losses: 5.128924579598763\n",
      "Epoch 118, reconstruction losses: 0.05188280034089059, regression losses: 0.6163554964145673, validation losses: 5.182660835684065\n",
      "Epoch 119, reconstruction losses: 0.047946036762991466, regression losses: 0.49308472123555597, validation losses: 5.122320553461114\n",
      "Epoch 120, reconstruction losses: 0.05061845979520369, regression losses: 0.6006000001287954, validation losses: 5.120397554464093\n",
      "Epoch 121, reconstruction losses: 0.051913925559065766, regression losses: 0.6324165602436307, validation losses: 5.069646226078337\n",
      "Epoch 122, reconstruction losses: 0.05231474594759814, regression losses: 0.5981274342461813, validation losses: 5.08187030713425\n",
      "Epoch 123, reconstruction losses: 0.04871945575694948, regression losses: 0.5193641275743933, validation losses: 5.178245275315382\n",
      "Epoch 124, reconstruction losses: 0.05336858033336346, regression losses: 0.6131397314064411, validation losses: 5.15377912615464\n",
      "Epoch 125, reconstruction losses: 0.04714415069444362, regression losses: 0.5528441401822695, validation losses: 5.1142568366647\n",
      "Epoch 126, reconstruction losses: 0.050682485830831694, regression losses: 0.547584129733393, validation losses: 5.104190898465754\n",
      "Epoch 127, reconstruction losses: 0.0476111952758668, regression losses: 0.5433650019701269, validation losses: 5.1174535108861425\n",
      "Epoch 128, reconstruction losses: 0.049660300967241944, regression losses: 0.7104464273868187, validation losses: 5.071245634942372\n",
      "Epoch 129, reconstruction losses: 0.05035001507313496, regression losses: 0.5235992541183536, validation losses: 5.185305203653009\n",
      "Epoch 130, reconstruction losses: 0.04879509664514086, regression losses: 0.6340534308421416, validation losses: 5.336341075698598\n",
      "Epoch 131, reconstruction losses: 0.0518129983198162, regression losses: 0.6296267845995611, validation losses: 5.013461722545157\n",
      "Epoch 132, reconstruction losses: 0.051930424132709686, regression losses: 0.5646950691075326, validation losses: 5.332411771340474\n",
      "Epoch 133, reconstruction losses: 0.054721869838871846, regression losses: 0.6574577015427464, validation losses: 5.407433296132761\n",
      "Epoch 134, reconstruction losses: 0.050018790732790766, regression losses: 0.635681155324183, validation losses: 5.140842373136307\n",
      "Epoch 135, reconstruction losses: 0.052325528735626285, regression losses: 0.5230862251976802, validation losses: 5.141083510524458\n",
      "Epoch 136, reconstruction losses: 0.059153091304544984, regression losses: 0.6511838552516004, validation losses: 5.460493484045653\n",
      "Epoch 137, reconstruction losses: 0.04912518424386681, regression losses: 0.5642869661675385, validation losses: 5.169223688077711\n",
      "Epoch 138, reconstruction losses: 0.047603754109391494, regression losses: 0.5761718128492729, validation losses: 4.976807563876868\n",
      "Epoch 139, reconstruction losses: 0.05365486918566121, regression losses: 0.5777536425499257, validation losses: 5.0682344750594845\n",
      "Epoch 140, reconstruction losses: 0.04905046964398744, regression losses: 0.5534442870469097, validation losses: 4.989272595314869\n",
      "Epoch 141, reconstruction losses: 0.05787634514385073, regression losses: 0.661559844584974, validation losses: 4.941655971064893\n",
      "Epoch 142, reconstruction losses: 0.04679516637302552, regression losses: 0.5533628844341923, validation losses: 4.951293256656428\n",
      "Epoch 143, reconstruction losses: 0.04985832351352522, regression losses: 0.5620095532000365, validation losses: 4.926108382626836\n",
      "Epoch 144, reconstruction losses: 0.047026536759726886, regression losses: 0.4810528304323743, validation losses: 5.01408322238031\n",
      "Epoch 145, reconstruction losses: 0.04792140258477464, regression losses: 0.5248747623264706, validation losses: 4.990782801836489\n",
      "Epoch 146, reconstruction losses: 0.05314929253283088, regression losses: 0.6869793155783948, validation losses: 4.928099244359307\n",
      "Epoch 147, reconstruction losses: 0.048079985602746164, regression losses: 0.5278125482252265, validation losses: 4.932625169265141\n",
      "Epoch 148, reconstruction losses: 0.04736113405356751, regression losses: 0.5277947636509454, validation losses: 5.169737453983068\n",
      "Epoch 149, reconstruction losses: 0.0595089442842275, regression losses: 0.6673172465711779, validation losses: 5.006813863770075\n",
      "Epoch 150, reconstruction losses: 0.05807311785171832, regression losses: 0.60879520735872, validation losses: 4.9745341670755145\n",
      "Epoch 151, reconstruction losses: 0.0479502666079442, regression losses: 0.5264474973325125, validation losses: 5.11517755978748\n",
      "Epoch 152, reconstruction losses: 0.0515560202520525, regression losses: 0.6630522385114531, validation losses: 4.9532815543443895\n",
      "Epoch 153, reconstruction losses: 0.04640030625211056, regression losses: 0.5379793593003864, validation losses: 4.983643988388572\n",
      "Epoch 154, reconstruction losses: 0.05126459931974463, regression losses: 0.5334863440267797, validation losses: 5.340812960820133\n",
      "Epoch 155, reconstruction losses: 0.05538878137895076, regression losses: 0.6579536688730556, validation losses: 5.30333590456737\n",
      "Epoch 156, reconstruction losses: 0.04716289790333714, regression losses: 0.544785681406284, validation losses: 4.978083961756785\n",
      "Epoch 157, reconstruction losses: 0.05063603895186465, regression losses: 0.5659440347557384, validation losses: 4.893334830563749\n",
      "Epoch 158, reconstruction losses: 0.04676127513661557, regression losses: 0.5017040055708822, validation losses: 4.944354549490011\n",
      "Epoch 159, reconstruction losses: 0.04935581739545409, regression losses: 0.5550816020953653, validation losses: 4.8883117467290145\n",
      "Epoch 160, reconstruction losses: 0.05278622229062838, regression losses: 0.617046093480309, validation losses: 4.8257773395639605\n",
      "Epoch 161, reconstruction losses: 0.04803803099685548, regression losses: 0.5414284439703554, validation losses: 4.908077713371408\n",
      "Epoch 162, reconstruction losses: 0.05136860758435873, regression losses: 0.5650052020829863, validation losses: 5.102323969688042\n",
      "Epoch 163, reconstruction losses: 0.04924607046516962, regression losses: 0.578975485092336, validation losses: 4.916059950902276\n",
      "Epoch 164, reconstruction losses: 0.052382286560530185, regression losses: 0.639924891983316, validation losses: 4.913137010237638\n",
      "Epoch 165, reconstruction losses: 0.0526582837887634, regression losses: 0.5458164522105791, validation losses: 4.780113841183374\n",
      "Epoch 166, reconstruction losses: 0.051159163281057705, regression losses: 0.5813438060165861, validation losses: 4.842693620358984\n",
      "Epoch 167, reconstruction losses: 0.0542270379770968, regression losses: 0.6192150437739233, validation losses: 4.8338313975261125\n",
      "Epoch 168, reconstruction losses: 0.047635451705905364, regression losses: 0.5518390679927978, validation losses: 4.973799223749873\n",
      "Epoch 169, reconstruction losses: 0.05769650178427402, regression losses: 0.6129301607108903, validation losses: 4.809575156426794\n",
      "Epoch 170, reconstruction losses: 0.04807738229311756, regression losses: 0.48392232075233854, validation losses: 4.758774660590377\n",
      "Epoch 171, reconstruction losses: 0.047897121212284746, regression losses: 0.5534843858854606, validation losses: 4.728991660715661\n",
      "Epoch 172, reconstruction losses: 0.05205772636416438, regression losses: 0.6269918577744146, validation losses: 4.798570977433915\n",
      "Epoch 173, reconstruction losses: 0.04776226477503856, regression losses: 0.5211095260425932, validation losses: 4.886175724748643\n",
      "Epoch 174, reconstruction losses: 0.04644096045872162, regression losses: 0.5196592577620962, validation losses: 4.861451250198053\n",
      "Epoch 175, reconstruction losses: 0.04926406000630097, regression losses: 0.5577865965681711, validation losses: 4.763681187548894\n",
      "Epoch 176, reconstruction losses: 0.04936730613857303, regression losses: 0.6283622171549482, validation losses: 4.8601019349051136\n",
      "Epoch 177, reconstruction losses: 0.047521050586843847, regression losses: 0.5189838490701444, validation losses: 5.122688920912232\n",
      "Epoch 178, reconstruction losses: 0.04808442064938924, regression losses: 0.5706697262292284, validation losses: 4.682054154586332\n",
      "Epoch 179, reconstruction losses: 0.04989428827720026, regression losses: 0.713791387827782, validation losses: 4.859956149055216\n",
      "Epoch 180, reconstruction losses: 0.04932352051335833, regression losses: 0.6546982897820077, validation losses: 4.673308760633521\n",
      "Epoch 181, reconstruction losses: 0.05283717356141045, regression losses: 0.6926158249629262, validation losses: 5.166448667596045\n",
      "Epoch 182, reconstruction losses: 0.05283364053692402, regression losses: 0.6651542917584544, validation losses: 4.714811735542308\n",
      "Epoch 183, reconstruction losses: 0.05020176504070702, regression losses: 0.5588807749715659, validation losses: 4.886609774274127\n",
      "Epoch 184, reconstruction losses: 0.04911971385033021, regression losses: 0.5266055195799162, validation losses: 4.69946810396846\n",
      "Epoch 185, reconstruction losses: 0.0496974308707998, regression losses: 0.6811222745813829, validation losses: 4.648117403304753\n",
      "Epoch 186, reconstruction losses: 0.050195864301759575, regression losses: 0.4933557280836313, validation losses: 5.100005282082924\n",
      "Epoch 187, reconstruction losses: 0.047830149375894325, regression losses: 0.5983299008134757, validation losses: 4.703453161629069\n",
      "Epoch 188, reconstruction losses: 0.0465776070414891, regression losses: 0.4578669467377131, validation losses: 4.779147805404733\n",
      "Epoch 189, reconstruction losses: 0.05205808868742493, regression losses: 0.6118168263152606, validation losses: 4.852543848578553\n",
      "Epoch 190, reconstruction losses: 0.05244058616257926, regression losses: 0.5644033243444342, validation losses: 4.709495706665411\n",
      "Epoch 191, reconstruction losses: 0.05942773800215889, regression losses: 0.6305551304238075, validation losses: 4.569166166546664\n",
      "Epoch 192, reconstruction losses: 0.052190540970133585, regression losses: 0.5671535812439368, validation losses: 4.67413989456189\n",
      "Epoch 193, reconstruction losses: 0.049601119856257286, regression losses: 0.513304090932322, validation losses: 4.73230182153621\n",
      "Epoch 194, reconstruction losses: 0.05198182900142584, regression losses: 0.6623765036004419, validation losses: 4.562897338702028\n",
      "Epoch 195, reconstruction losses: 0.04900688612797618, regression losses: 0.5132020344405289, validation losses: 4.582424678940716\n",
      "Epoch 196, reconstruction losses: 0.05057681756589943, regression losses: 0.5292330029445911, validation losses: 4.754525635875826\n",
      "Epoch 197, reconstruction losses: 0.05003960508279176, regression losses: 0.5512205714949677, validation losses: 4.626466106907805\n",
      "Epoch 198, reconstruction losses: 0.046214268851419146, regression losses: 0.5411482919626595, validation losses: 4.523526295591322\n",
      "Epoch 199, reconstruction losses: 0.05105321669970211, regression losses: 0.536172122812846, validation losses: 4.475947887395072\n",
      "Epoch 200, reconstruction losses: 0.05009346464741003, regression losses: 0.5675743237684681, validation losses: 4.620526772047928\n",
      "Epoch 201, reconstruction losses: 0.046460089791392885, regression losses: 0.4807464615648599, validation losses: 4.524536410004083\n",
      "Epoch 202, reconstruction losses: 0.04669432230016563, regression losses: 0.4807877994981292, validation losses: 4.621376552864488\n",
      "Epoch 203, reconstruction losses: 0.04629502084563639, regression losses: 0.46212639437471503, validation losses: 4.462879993324224\n",
      "Epoch 204, reconstruction losses: 0.04955542341226033, regression losses: 0.5241948218556782, validation losses: 4.485200368737047\n",
      "Epoch 205, reconstruction losses: 0.05673358363706246, regression losses: 0.5341303900714949, validation losses: 4.458764378989893\n",
      "Epoch 206, reconstruction losses: 0.052420510371851324, regression losses: 0.66581420155493, validation losses: 4.573831221094702\n",
      "Epoch 207, reconstruction losses: 0.04924173131115622, regression losses: 0.6143089260365746, validation losses: 4.395006387724997\n",
      "Epoch 208, reconstruction losses: 0.047789539070685345, regression losses: 0.520750235808364, validation losses: 4.445919337844668\n",
      "Epoch 209, reconstruction losses: 0.04883115387435258, regression losses: 0.5175838002597071, validation losses: 4.4058105268342755\n",
      "Epoch 210, reconstruction losses: 0.04701180988550258, regression losses: 0.5102314527588439, validation losses: 4.3714609357407666\n",
      "Epoch 211, reconstruction losses: 0.05297438972517866, regression losses: 0.5957306623554519, validation losses: 4.422976993335299\n",
      "Epoch 212, reconstruction losses: 0.04585743581898159, regression losses: 0.49841243626370163, validation losses: 4.711217767451523\n",
      "Epoch 213, reconstruction losses: 0.0498034045383211, regression losses: 0.5094241831148684, validation losses: 4.4635942107490685\n",
      "Epoch 214, reconstruction losses: 0.04573265285722057, regression losses: 0.4737643831477458, validation losses: 4.380952957626592\n",
      "Epoch 215, reconstruction losses: 0.04873064289868979, regression losses: 0.4994104189295018, validation losses: 4.312339307877066\n",
      "Epoch 216, reconstruction losses: 0.059603897975679776, regression losses: 0.5907666934266473, validation losses: 4.422388590367331\n",
      "Epoch 217, reconstruction losses: 0.04730070701396526, regression losses: 0.44992636814922116, validation losses: 4.469175659228893\n",
      "Epoch 218, reconstruction losses: 0.04889308370210167, regression losses: 0.509802548977511, validation losses: 4.325165092286515\n",
      "Epoch 219, reconstruction losses: 0.04543632067749806, regression losses: 0.4876220070947243, validation losses: 4.553458932616303\n",
      "Epoch 220, reconstruction losses: 0.04785829898529213, regression losses: 0.5078282700217203, validation losses: 4.506673377482179\n",
      "Epoch 221, reconstruction losses: 0.047234605792858084, regression losses: 0.5055849530418968, validation losses: 4.380082037793127\n",
      "Epoch 222, reconstruction losses: 0.048503911567030183, regression losses: 0.4850369811182513, validation losses: 4.349352031181949\n",
      "Epoch 223, reconstruction losses: 0.04941057587213826, regression losses: 0.49436097311382965, validation losses: 4.297585776437923\n",
      "Epoch 224, reconstruction losses: 0.05245934974239841, regression losses: 0.5293348834442367, validation losses: 4.276915691574053\n",
      "Epoch 225, reconstruction losses: 0.04802113195188308, regression losses: 0.4928915572092461, validation losses: 4.453692622093299\n",
      "Epoch 226, reconstruction losses: 0.052606496358687235, regression losses: 0.5500293752314568, validation losses: 4.456136386146039\n",
      "Epoch 227, reconstruction losses: 0.04615813523445261, regression losses: 0.4621134551228622, validation losses: 4.316431274809124\n",
      "Epoch 228, reconstruction losses: 0.050679287213155004, regression losses: 0.5204075013689167, validation losses: 4.453397520281347\n",
      "Epoch 229, reconstruction losses: 0.04923063472886878, regression losses: 0.608368556909334, validation losses: 4.286519540882291\n",
      "Epoch 230, reconstruction losses: 0.05020944609171094, regression losses: 0.4552575344972511, validation losses: 4.230264367744424\n",
      "Epoch 231, reconstruction losses: 0.04747200170556316, regression losses: 0.44046855620689196, validation losses: 4.21629748779276\n",
      "Epoch 232, reconstruction losses: 0.04553676893001476, regression losses: 0.4878166000839869, validation losses: 4.14979885600826\n",
      "Epoch 233, reconstruction losses: 0.04901622949284545, regression losses: 0.4676128649517015, validation losses: 4.474906818349784\n",
      "Epoch 234, reconstruction losses: 0.04889150525426148, regression losses: 0.48667186710641824, validation losses: 4.331145112265652\n",
      "Epoch 235, reconstruction losses: 0.05065121279057392, regression losses: 0.5218826612399057, validation losses: 4.094446976195797\n",
      "Epoch 236, reconstruction losses: 0.05087893054271778, regression losses: 0.5569746472910291, validation losses: 4.211053570748504\n",
      "Epoch 237, reconstruction losses: 0.047413248285966506, regression losses: 0.4223416714624507, validation losses: 4.067102667945243\n",
      "Epoch 238, reconstruction losses: 0.0528493359917231, regression losses: 0.5115084605594159, validation losses: 4.127061073709615\n",
      "Epoch 239, reconstruction losses: 0.04730287257818084, regression losses: 0.49220571842072813, validation losses: 4.254107958258845\n",
      "Epoch 240, reconstruction losses: 0.04672130745447165, regression losses: 0.4645095702461456, validation losses: 4.151194127548591\n",
      "Epoch 241, reconstruction losses: 0.04717039910245881, regression losses: 0.42702606884076577, validation losses: 4.059028514245457\n",
      "Epoch 242, reconstruction losses: 0.048648272606784365, regression losses: 0.45823205497103137, validation losses: 4.083613813317806\n",
      "Epoch 243, reconstruction losses: 0.047406169123398595, regression losses: 0.41133721033916487, validation losses: 4.100575963541262\n",
      "Epoch 244, reconstruction losses: 0.0458495265209705, regression losses: 0.48773431862940564, validation losses: 3.987144611293688\n",
      "Epoch 245, reconstruction losses: 0.046146565255170885, regression losses: 0.4108867312062204, validation losses: 4.116639817537853\n",
      "Epoch 246, reconstruction losses: 0.05315918044311299, regression losses: 0.5353558107682074, validation losses: 4.097163234423268\n",
      "Epoch 247, reconstruction losses: 0.05077888917995534, regression losses: 0.4992044037827669, validation losses: 4.017842774105744\n",
      "Epoch 248, reconstruction losses: 0.04722816235315414, regression losses: 0.4470157880040799, validation losses: 4.076055901446773\n",
      "Epoch 249, reconstruction losses: 0.05382176397049183, regression losses: 0.47712490004975194, validation losses: 3.9743053568401385\n",
      "Epoch 250, reconstruction losses: 0.05361762162203336, regression losses: 0.47011359670223896, validation losses: 3.9464493166361327\n",
      "Epoch 251, reconstruction losses: 0.05005858416490659, regression losses: 0.46595709219803616, validation losses: 3.988438826620603\n",
      "Epoch 252, reconstruction losses: 0.04950873077602524, regression losses: 0.46117658674889334, validation losses: 4.037522266648722\n",
      "Epoch 253, reconstruction losses: 0.05102735177147796, regression losses: 0.4351340893022994, validation losses: 3.984511779996805\n",
      "Epoch 254, reconstruction losses: 0.0490807046579556, regression losses: 0.4383198872456347, validation losses: 3.8768425873430274\n",
      "Epoch 255, reconstruction losses: 0.04960123275676151, regression losses: 0.47176239400593506, validation losses: 3.842458076198628\n",
      "Epoch 256, reconstruction losses: 0.04790521307816657, regression losses: 0.4648409248976689, validation losses: 3.9027316960721166\n",
      "Epoch 257, reconstruction losses: 0.05276281518315243, regression losses: 0.4611540441674443, validation losses: 3.8151311357429734\n",
      "Epoch 258, reconstruction losses: 0.048107075593251676, regression losses: 0.42042647796312044, validation losses: 4.0205584056149055\n",
      "Epoch 259, reconstruction losses: 0.0515579550444003, regression losses: 0.5088160056014972, validation losses: 3.874789192591441\n",
      "Epoch 260, reconstruction losses: 0.04802238794651402, regression losses: 0.4482024609456978, validation losses: 3.9828864081905677\n",
      "Epoch 261, reconstruction losses: 0.052984566309323036, regression losses: 0.5387053315477931, validation losses: 4.057414338096483\n",
      "Epoch 262, reconstruction losses: 0.05578794106978889, regression losses: 0.503805069520031, validation losses: 3.84918375895829\n",
      "Epoch 263, reconstruction losses: 0.05098724166993948, regression losses: 0.466486929966514, validation losses: 3.772919286706237\n",
      "Epoch 264, reconstruction losses: 0.05022927864795233, regression losses: 0.4645295115749097, validation losses: 3.7600022161876803\n",
      "Epoch 265, reconstruction losses: 0.04756458465918283, regression losses: 0.48174603778669134, validation losses: 3.7138289381375595\n",
      "Epoch 266, reconstruction losses: 0.05130080254019048, regression losses: 0.5332347557577504, validation losses: 3.7344130061017804\n",
      "Epoch 267, reconstruction losses: 0.047269802168950444, regression losses: 0.4001568801308504, validation losses: 3.7193820048437765\n",
      "Epoch 268, reconstruction losses: 0.04618161777251814, regression losses: 0.40502148389713577, validation losses: 3.6997169917602806\n",
      "Epoch 269, reconstruction losses: 0.048468557335904376, regression losses: 0.43029317137579587, validation losses: 3.65952884630715\n",
      "Epoch 270, reconstruction losses: 0.046728262742641635, regression losses: 0.451132798844292, validation losses: 3.61561275907207\n",
      "Epoch 271, reconstruction losses: 0.05911423899606551, regression losses: 0.4775100775422922, validation losses: 3.6516429374192247\n",
      "Epoch 272, reconstruction losses: 0.04601282121113713, regression losses: 0.4531890513708844, validation losses: 3.648772372691288\n",
      "Epoch 273, reconstruction losses: 0.04763351680229716, regression losses: 0.4454884395084876, validation losses: 3.6272831308178572\n",
      "Epoch 274, reconstruction losses: 0.0519623289400469, regression losses: 0.4998971371054678, validation losses: 3.6711960173454568\n",
      "Epoch 275, reconstruction losses: 0.05216584938270088, regression losses: 0.4767312800810789, validation losses: 3.8451195751368665\n",
      "Epoch 276, reconstruction losses: 0.05115355472715896, regression losses: 0.5082172383041751, validation losses: 3.850452565061858\n",
      "Epoch 277, reconstruction losses: 0.059894839962915364, regression losses: 0.5458823689911542, validation losses: 3.658307935219417\n",
      "Epoch 278, reconstruction losses: 0.04961208523854275, regression losses: 0.46006807997454724, validation losses: 3.634324652557448\n",
      "Epoch 279, reconstruction losses: 0.051896437368765085, regression losses: 0.5151982493015537, validation losses: 3.5266502019796033\n",
      "Epoch 280, reconstruction losses: 0.0519085155169433, regression losses: 0.46101864763372385, validation losses: 3.589055298571367\n",
      "Epoch 281, reconstruction losses: 0.050247045655979046, regression losses: 0.4112002555746733, validation losses: 3.4693360560508975\n",
      "Epoch 282, reconstruction losses: 0.05090992076881907, regression losses: 0.5030978560537743, validation losses: 3.6252454222797703\n",
      "Epoch 283, reconstruction losses: 0.0508382139279105, regression losses: 0.4956494242991033, validation losses: 3.570378299254944\n",
      "Epoch 284, reconstruction losses: 0.049289578309776996, regression losses: 0.4966192306563093, validation losses: 3.9592312623420427\n",
      "Epoch 285, reconstruction losses: 0.046751296876016334, regression losses: 0.43073218247787426, validation losses: 3.3891618307199334\n",
      "Epoch 286, reconstruction losses: 0.0475858526997555, regression losses: 0.3675342460654776, validation losses: 3.3849533050205407\n",
      "Epoch 287, reconstruction losses: 0.058227198848556594, regression losses: 0.47179358331105314, validation losses: 3.36634566279322\n",
      "Epoch 288, reconstruction losses: 0.04667646779106826, regression losses: 0.42038261323359477, validation losses: 3.4055410726223867\n",
      "Epoch 289, reconstruction losses: 0.053336481252906666, regression losses: 0.4781159066909861, validation losses: 3.4664128265216547\n",
      "Epoch 290, reconstruction losses: 0.04777917650719856, regression losses: 0.4375499014592302, validation losses: 3.3136192230141535\n",
      "Epoch 291, reconstruction losses: 0.05039099249369088, regression losses: 0.4516746101114536, validation losses: 3.3271696555918115\n",
      "Epoch 292, reconstruction losses: 0.04983561729038677, regression losses: 0.4576351251627374, validation losses: 3.477684258809091\n",
      "Epoch 293, reconstruction losses: 0.05063050817755697, regression losses: 0.49113441321123164, validation losses: 3.3770371269612767\n",
      "Epoch 294, reconstruction losses: 0.048938931533610244, regression losses: 0.403894605535298, validation losses: 3.261273545466546\n",
      "Epoch 295, reconstruction losses: 0.052354187498137195, regression losses: 0.44682680211332926, validation losses: 3.2696479311210123\n",
      "Epoch 296, reconstruction losses: 0.05254351222220202, regression losses: 0.47792335087881427, validation losses: 3.2243782518003767\n",
      "Epoch 297, reconstruction losses: 0.05804186935835927, regression losses: 0.5136672532929267, validation losses: 3.313651394914325\n",
      "Epoch 298, reconstruction losses: 0.047424543133004295, regression losses: 0.3959761793446085, validation losses: 3.2436202045175255\n",
      "Epoch 299, reconstruction losses: 0.04991393596322276, regression losses: 0.4239472350392824, validation losses: 3.215608802176587\n",
      "Epoch 300, reconstruction losses: 0.05205888087317336, regression losses: 0.44894473237036037, validation losses: 3.250496094906188\n",
      "Epoch 301, reconstruction losses: 0.048960827756694095, regression losses: 0.416790921058237, validation losses: 3.1522792033778733\n",
      "Epoch 302, reconstruction losses: 0.0474120091194449, regression losses: 0.3684436834281279, validation losses: 3.2393227800791\n",
      "Epoch 303, reconstruction losses: 0.057884354664709, regression losses: 0.47127848994656907, validation losses: 3.216792414563799\n",
      "Epoch 304, reconstruction losses: 0.05250083076608237, regression losses: 0.47457576409897184, validation losses: 3.1285061832518744\n",
      "Epoch 305, reconstruction losses: 0.050019430790452825, regression losses: 0.4154749205196377, validation losses: 3.44844402598359\n",
      "Epoch 306, reconstruction losses: 0.052265072808547, regression losses: 0.4469305600855239, validation losses: 3.185985605875888\n",
      "Epoch 307, reconstruction losses: 0.046902309684559926, regression losses: 0.37928697205986633, validation losses: 3.23761788892005\n",
      "Epoch 308, reconstruction losses: 0.04870018682990494, regression losses: 0.39137886458024207, validation losses: 3.179569846636929\n",
      "Epoch 309, reconstruction losses: 0.049314809455373795, regression losses: 0.3885175481172522, validation losses: 3.0339807641020924\n",
      "Epoch 310, reconstruction losses: 0.05050789575351807, regression losses: 0.40545217997929034, validation losses: 3.03696016337018\n",
      "Epoch 311, reconstruction losses: 0.04685176289966408, regression losses: 0.4016953781965011, validation losses: 3.0170452354139856\n",
      "Epoch 312, reconstruction losses: 0.04585514511271488, regression losses: 0.39047825809370995, validation losses: 3.151532592597381\n",
      "Epoch 313, reconstruction losses: 0.058416980611701946, regression losses: 0.47805892444253384, validation losses: 2.959214907421683\n",
      "Epoch 314, reconstruction losses: 0.04866858871988727, regression losses: 0.42007608255727613, validation losses: 2.974133601123076\n",
      "Epoch 315, reconstruction losses: 0.04759361612795451, regression losses: 0.3389364107729574, validation losses: 2.9378714636949557\n",
      "Epoch 316, reconstruction losses: 0.04586486190863766, regression losses: 0.3590321626339703, validation losses: 2.92007900625614\n",
      "Epoch 317, reconstruction losses: 0.059261167648856014, regression losses: 0.46638101864765247, validation losses: 2.884875488917369\n",
      "Epoch 318, reconstruction losses: 0.04908269103970402, regression losses: 0.34115740881955414, validation losses: 2.9214028322194108\n",
      "Epoch 319, reconstruction losses: 0.05327022559166524, regression losses: 0.34730904767113224, validation losses: 2.93077144106202\n",
      "Epoch 320, reconstruction losses: 0.05067512532773362, regression losses: 0.43619211896203713, validation losses: 2.8648025745906804\n",
      "Epoch 321, reconstruction losses: 0.04634142067763756, regression losses: 0.3696167004770431, validation losses: 2.838752284411707\n",
      "Epoch 322, reconstruction losses: 0.046844587324647566, regression losses: 0.394435494734351, validation losses: 2.800719625847438\n",
      "Epoch 323, reconstruction losses: 0.05868405588496113, regression losses: 0.5164776852342303, validation losses: 2.9881378138050563\n",
      "Epoch 324, reconstruction losses: 0.048026964586844724, regression losses: 0.3432744125018676, validation losses: 2.780195088366759\n",
      "Epoch 325, reconstruction losses: 0.057665400248269404, regression losses: 0.4054502688393523, validation losses: 2.920204683425909\n",
      "Epoch 326, reconstruction losses: 0.05838398332754523, regression losses: 0.3798144374817604, validation losses: 2.8515353734139506\n",
      "Epoch 327, reconstruction losses: 0.049851578154865905, regression losses: 0.3903506127293335, validation losses: 2.8073068659386227\n",
      "Epoch 328, reconstruction losses: 0.047626722869415314, regression losses: 0.33768069814791035, validation losses: 2.7766797535335335\n",
      "Epoch 329, reconstruction losses: 0.04814533309152765, regression losses: 0.44066674360149033, validation losses: 2.72415890951437\n",
      "Epoch 330, reconstruction losses: 0.0485987320267057, regression losses: 0.367860003376047, validation losses: 3.153822289110172\n",
      "Epoch 331, reconstruction losses: 0.04713396121083737, regression losses: 0.37804497527612235, validation losses: 2.626040774488114\n",
      "Epoch 332, reconstruction losses: 0.058335044442617626, regression losses: 0.3665576788576133, validation losses: 2.5973213528986383\n",
      "Epoch 333, reconstruction losses: 0.05838962404529009, regression losses: 0.34994284801565767, validation losses: 2.7025336015586183\n",
      "Epoch 334, reconstruction losses: 0.05342032636768618, regression losses: 0.457803366458039, validation losses: 2.6458340921764565\n",
      "Epoch 335, reconstruction losses: 0.048766552879093476, regression losses: 0.35456290412136504, validation losses: 2.676591863805267\n",
      "Epoch 336, reconstruction losses: 0.05026233091144665, regression losses: 0.4409786745955511, validation losses: 2.6079982432673074\n",
      "Epoch 337, reconstruction losses: 0.0477637502415911, regression losses: 0.31317144371455286, validation losses: 2.687589919076316\n",
      "Epoch 338, reconstruction losses: 0.04610461974441429, regression losses: 0.38812788637053974, validation losses: 2.564336450701865\n",
      "Epoch 339, reconstruction losses: 0.050489033457557335, regression losses: 0.342957801473685, validation losses: 2.679754284154205\n",
      "Epoch 340, reconstruction losses: 0.048903776248337374, regression losses: 0.4275170246781439, validation losses: 2.564152068327203\n",
      "Epoch 341, reconstruction losses: 0.049776147663589926, regression losses: 0.4026217772299586, validation losses: 2.541434703784243\n",
      "Epoch 342, reconstruction losses: 0.04564692827647891, regression losses: 0.3313835867593581, validation losses: 2.5849079930724126\n",
      "Epoch 343, reconstruction losses: 0.05222171186028818, regression losses: 0.4212266854715863, validation losses: 2.845473254723544\n",
      "Epoch 344, reconstruction losses: 0.05183103661504549, regression losses: 0.4282951614153968, validation losses: 2.5321284379592317\n",
      "Epoch 345, reconstruction losses: 0.04922772202497817, regression losses: 0.32350855391260586, validation losses: 2.377937883240837\n",
      "Epoch 346, reconstruction losses: 0.04813823289059766, regression losses: 0.3118499081312777, validation losses: 2.409372856421105\n",
      "Epoch 347, reconstruction losses: 0.04762244684219842, regression losses: 0.36113740646298903, validation losses: 2.351435437064843\n",
      "Epoch 348, reconstruction losses: 0.048869851928756286, regression losses: 0.5092937764641272, validation losses: 2.4333643487395316\n",
      "Epoch 349, reconstruction losses: 0.050227369137960956, regression losses: 0.377696374560616, validation losses: 2.591641392063857\n",
      "Epoch 350, reconstruction losses: 0.05274538477356054, regression losses: 0.46696864501084434, validation losses: 2.6560270359654385\n",
      "Epoch 351, reconstruction losses: 0.04888786373238313, regression losses: 0.3521088525057501, validation losses: 2.5700783034341015\n",
      "Epoch 352, reconstruction losses: 0.049483245341084274, regression losses: 0.5341455798068622, validation losses: 2.329412564719142\n",
      "Epoch 353, reconstruction losses: 0.045884112706593726, regression losses: 0.40804084186364586, validation losses: 2.635203145129285\n",
      "Epoch 354, reconstruction losses: 0.04920882469574941, regression losses: 0.308361751428449, validation losses: 2.261741961982394\n",
      "Epoch 355, reconstruction losses: 0.046041172372649125, regression losses: 0.28495214114979117, validation losses: 2.28748417127525\n",
      "Epoch 356, reconstruction losses: 0.04868392797946859, regression losses: 0.4267200108782585, validation losses: 2.212313472376529\n",
      "Epoch 357, reconstruction losses: 0.04661388111739338, regression losses: 0.3257113700858289, validation losses: 2.435872654235617\n",
      "Epoch 358, reconstruction losses: 0.05238847373107075, regression losses: 0.3146837657601975, validation losses: 2.203648298753645\n",
      "Epoch 359, reconstruction losses: 0.05245013479727259, regression losses: 0.30370483069729254, validation losses: 2.3567513665659883\n",
      "Epoch 360, reconstruction losses: 0.04754632488898694, regression losses: 0.2878712147965108, validation losses: 2.198006149978255\n",
      "Epoch 361, reconstruction losses: 0.048431773962143126, regression losses: 0.3798454740162306, validation losses: 2.2268262161158283\n",
      "Epoch 362, reconstruction losses: 0.05318516657219896, regression losses: 0.5040367917333122, validation losses: 2.290905467224698\n",
      "Epoch 363, reconstruction losses: 0.04900678315653237, regression losses: 0.3441594319715671, validation losses: 2.2158996755652134\n",
      "Epoch 364, reconstruction losses: 0.04775408785611212, regression losses: 0.33807988156236024, validation losses: 2.1832672435451403\n",
      "Epoch 365, reconstruction losses: 0.04872777727809169, regression losses: 0.3533777487200129, validation losses: 2.369269965005124\n",
      "Epoch 366, reconstruction losses: 0.04841545442606066, regression losses: 0.32888241914522787, validation losses: 2.345114490617879\n",
      "Epoch 367, reconstruction losses: 0.048445295091349094, regression losses: 0.29155122819131274, validation losses: 2.0692484871918797\n",
      "Epoch 368, reconstruction losses: 0.04888728798631383, regression losses: 0.3529395013456389, validation losses: 2.0717974618711743\n",
      "Epoch 369, reconstruction losses: 0.0468088498809324, regression losses: 0.25710556415443875, validation losses: 2.015698063741515\n",
      "Epoch 370, reconstruction losses: 0.050804792563580406, regression losses: 0.3082600609523159, validation losses: 1.9798292347103987\n",
      "Epoch 371, reconstruction losses: 0.0517886153350573, regression losses: 0.32134821540581854, validation losses: 2.085799638177542\n",
      "Epoch 372, reconstruction losses: 0.0546359444334871, regression losses: 0.424913431990683, validation losses: 2.1776688200793304\n",
      "Epoch 373, reconstruction losses: 0.05330796683382962, regression losses: 0.27640318605981967, validation losses: 2.020004740502644\n",
      "Epoch 374, reconstruction losses: 0.05244676308547998, regression losses: 0.4102872568867495, validation losses: 1.9329780248279333\n",
      "Epoch 375, reconstruction losses: 0.051613141267123575, regression losses: 0.25941658720214616, validation losses: 2.395004767139424\n",
      "Epoch 376, reconstruction losses: 0.04816876115348101, regression losses: 0.3111968287429972, validation losses: 2.0541862913408964\n",
      "Epoch 377, reconstruction losses: 0.0554815540316837, regression losses: 0.43028855146044065, validation losses: 1.895863432423948\n",
      "Epoch 378, reconstruction losses: 0.04931082511788361, regression losses: 0.29087418754690075, validation losses: 2.045324612592978\n",
      "Epoch 379, reconstruction losses: 0.05308094306142761, regression losses: 0.2699648315263873, validation losses: 1.933900351678327\n",
      "Epoch 380, reconstruction losses: 0.047982625244966375, regression losses: 0.24950381213111497, validation losses: 1.9050130063310853\n",
      "Epoch 381, reconstruction losses: 0.05298467872304951, regression losses: 0.3694359682016145, validation losses: 1.8628172906067557\n",
      "Epoch 382, reconstruction losses: 0.051611063877765054, regression losses: 0.2734098051458653, validation losses: 1.959226569572725\n",
      "Epoch 383, reconstruction losses: 0.05100378660654217, regression losses: 0.2637712035594083, validation losses: 1.8942575665302488\n",
      "Epoch 384, reconstruction losses: 0.05753583088888181, regression losses: 0.3182917058438178, validation losses: 1.842195289496006\n",
      "Epoch 385, reconstruction losses: 0.04872246652448361, regression losses: 0.27978708738919633, validation losses: 1.936180566282232\n",
      "Epoch 386, reconstruction losses: 0.049383391918222816, regression losses: 0.28847098958491346, validation losses: 1.8453246745756848\n",
      "Epoch 387, reconstruction losses: 0.05039506233752395, regression losses: 0.3106202835398375, validation losses: 1.7639265089195044\n",
      "Epoch 388, reconstruction losses: 0.05358209150704657, regression losses: 0.31685732943527517, validation losses: 1.7905712321975193\n",
      "Epoch 389, reconstruction losses: 0.04647433299452968, regression losses: 0.2876726751224433, validation losses: 1.8701496545043674\n",
      "Epoch 390, reconstruction losses: 0.04789348264033558, regression losses: 0.2688827536226192, validation losses: 1.7146474109903689\n",
      "Epoch 391, reconstruction losses: 0.051080550470415466, regression losses: 0.24384640883036074, validation losses: 1.6888923722816718\n",
      "Epoch 392, reconstruction losses: 0.05135720365054575, regression losses: 0.25303002754231874, validation losses: 1.6645506757791677\n",
      "Epoch 393, reconstruction losses: 0.05008249658679201, regression losses: 0.23333268503653667, validation losses: 1.6047038895263384\n",
      "Epoch 394, reconstruction losses: 0.046726559448708856, regression losses: 0.3104821191752855, validation losses: 1.6685476880973193\n",
      "Epoch 395, reconstruction losses: 0.05245858018574677, regression losses: 0.3025632614775558, validation losses: 2.008230909501509\n",
      "Epoch 396, reconstruction losses: 0.04863795728550893, regression losses: 0.3876297303531145, validation losses: 1.7759944821713476\n",
      "Epoch 397, reconstruction losses: 0.0474026325590665, regression losses: 0.23265001048216113, validation losses: 1.8721852251653275\n",
      "Epoch 398, reconstruction losses: 0.05210461819483524, regression losses: 0.3411112363448693, validation losses: 1.5575073283516159\n",
      "Epoch 399, reconstruction losses: 0.051071458751280344, regression losses: 0.23334528163183332, validation losses: 2.0827416957431666\n",
      "Epoch 400, reconstruction losses: 0.046258124846520206, regression losses: 0.279268554425804, validation losses: 1.65431330147768\n",
      "Epoch 401, reconstruction losses: 0.05413671361059525, regression losses: 0.31952596137586226, validation losses: 1.499811428245966\n",
      "Epoch 402, reconstruction losses: 0.0494509706370077, regression losses: 0.2365823762685209, validation losses: 1.5565106360767829\n",
      "Epoch 403, reconstruction losses: 0.046679929416789986, regression losses: 0.3998432352180512, validation losses: 1.5366844582576744\n",
      "Epoch 404, reconstruction losses: 0.04888829988792102, regression losses: 0.27022506112321465, validation losses: 2.1563760533125995\n",
      "Epoch 405, reconstruction losses: 0.049251608580578, regression losses: 0.20608222687935748, validation losses: 1.5597158528024304\n",
      "Epoch 406, reconstruction losses: 0.04579600820391242, regression losses: 0.22729898782890334, validation losses: 1.4526274596738362\n",
      "Epoch 407, reconstruction losses: 0.049515359403234004, regression losses: 0.272533732347933, validation losses: 1.4378090762494964\n",
      "Epoch 408, reconstruction losses: 0.05096724472490701, regression losses: 0.23294576941857376, validation losses: 1.4730802055638708\n",
      "Epoch 409, reconstruction losses: 0.04699325707478948, regression losses: 0.25728325228471577, validation losses: 1.4967105090170703\n",
      "Epoch 410, reconstruction losses: 0.04699403672219566, regression losses: 0.24986776173713138, validation losses: 1.4146049524659177\n",
      "Epoch 411, reconstruction losses: 0.047494786863275754, regression losses: 0.2193030993888403, validation losses: 1.4417279939894982\n",
      "Epoch 412, reconstruction losses: 0.05169645444416182, regression losses: 0.25097025440129317, validation losses: 1.4361616407418194\n",
      "Epoch 413, reconstruction losses: 0.05384232349098096, regression losses: 0.28394323541712424, validation losses: 1.4054510642873639\n",
      "Epoch 414, reconstruction losses: 0.054523163317494475, regression losses: 0.3449691741133186, validation losses: 1.3823014719031042\n",
      "Epoch 415, reconstruction losses: 0.04872813928379888, regression losses: 0.3513077896031739, validation losses: 1.6613712992437761\n",
      "Epoch 416, reconstruction losses: 0.051094060717676304, regression losses: 0.37498572072487085, validation losses: 1.3899856368720036\n",
      "Epoch 417, reconstruction losses: 0.047572190021053194, regression losses: 0.23014355992797056, validation losses: 1.551053416604027\n",
      "Epoch 418, reconstruction losses: 0.049030907084809325, regression losses: 0.19600036808153323, validation losses: 1.3154752626044155\n",
      "Epoch 419, reconstruction losses: 0.04867643997340008, regression losses: 0.2565303558783113, validation losses: 1.3244416807585127\n",
      "Epoch 420, reconstruction losses: 0.05758241147584907, regression losses: 0.2869480170790595, validation losses: 1.4040256633775947\n",
      "Epoch 421, reconstruction losses: 0.04711364216654312, regression losses: 0.2731686346252909, validation losses: 1.289310358602625\n",
      "Epoch 422, reconstruction losses: 0.0482413689891447, regression losses: 0.22410253364869834, validation losses: 1.2765953943682518\n",
      "Epoch 423, reconstruction losses: 0.052715237580011905, regression losses: 0.22585598965551984, validation losses: 1.405247276010546\n",
      "Epoch 424, reconstruction losses: 0.050298731038482945, regression losses: 0.26389371100620784, validation losses: 1.6561215145881292\n",
      "Epoch 425, reconstruction losses: 0.0471122636196578, regression losses: 0.24729231809150537, validation losses: 1.2412267081345956\n",
      "Epoch 426, reconstruction losses: 0.050643845339046686, regression losses: 0.45368431655728564, validation losses: 1.2353772334404072\n",
      "Epoch 427, reconstruction losses: 0.04650131958208415, regression losses: 0.2398174521605193, validation losses: 1.994734886334438\n",
      "Epoch 428, reconstruction losses: 0.05565970905156299, regression losses: 0.31263758535521596, validation losses: 1.3423426028900522\n",
      "Epoch 429, reconstruction losses: 0.049520462170603574, regression losses: 0.2605179014200191, validation losses: 1.3030234909603893\n",
      "Epoch 430, reconstruction losses: 0.04701894917469086, regression losses: 0.2517645573827135, validation losses: 1.3823677812055883\n",
      "Epoch 431, reconstruction losses: 0.051023390969367616, regression losses: 0.27437696982246873, validation losses: 1.3286358348691614\n",
      "Epoch 432, reconstruction losses: 0.046041349111080314, regression losses: 0.24253464318442935, validation losses: 1.2935330331610464\n",
      "Epoch 433, reconstruction losses: 0.04730054780771454, regression losses: 0.2230696781838018, validation losses: 1.202458800010642\n",
      "Epoch 434, reconstruction losses: 0.04942221073118841, regression losses: 0.22734942707943392, validation losses: 1.30803682249674\n",
      "Epoch 435, reconstruction losses: 0.04833204973995315, regression losses: 0.266249628181247, validation losses: 1.2466838159303637\n",
      "Epoch 436, reconstruction losses: 0.05075993457459914, regression losses: 0.24107834661201072, validation losses: 1.219043615531188\n",
      "Epoch 437, reconstruction losses: 0.05307566147046529, regression losses: 0.2981135289385948, validation losses: 1.1676961425313013\n",
      "Epoch 438, reconstruction losses: 0.04596326112799051, regression losses: 0.24052731700823207, validation losses: 1.5669898369887387\n",
      "Epoch 439, reconstruction losses: 0.0504674956588425, regression losses: 0.30754075978532536, validation losses: 1.809408478446564\n",
      "Epoch 440, reconstruction losses: 0.05264455658291899, regression losses: 0.4023498204585525, validation losses: 1.3966295864865967\n",
      "Epoch 441, reconstruction losses: 0.04523459490566191, regression losses: 0.2099912901122771, validation losses: 1.4637389902891849\n",
      "Epoch 442, reconstruction losses: 0.04557791003162295, regression losses: 0.2530680545041404, validation losses: 1.1636766933740292\n",
      "Epoch 443, reconstruction losses: 0.04788742287257207, regression losses: 0.215703028264444, validation losses: 1.1291215159595227\n",
      "Epoch 444, reconstruction losses: 0.0494764886013496, regression losses: 0.2190228365143588, validation losses: 1.1047860326448629\n",
      "Epoch 445, reconstruction losses: 0.05785534467971388, regression losses: 0.20934888535243276, validation losses: 1.1204220626862615\n",
      "Epoch 446, reconstruction losses: 0.05280902296355933, regression losses: 0.24163072538381344, validation losses: 1.121826461397307\n",
      "Epoch 447, reconstruction losses: 0.04982587100800305, regression losses: 0.2416943244429557, validation losses: 1.1948467935070466\n",
      "Epoch 448, reconstruction losses: 0.0510680526772298, regression losses: 0.2611153985714698, validation losses: 1.1321843917984622\n",
      "Epoch 449, reconstruction losses: 0.0484961067704825, regression losses: 0.22531386797731703, validation losses: 1.0888092824139257\n",
      "Epoch 450, reconstruction losses: 0.04569061920913103, regression losses: 0.2137943321966612, validation losses: 1.0519126707412259\n",
      "Epoch 451, reconstruction losses: 0.05263425309171326, regression losses: 0.25644703873663877, validation losses: 1.1148031467272068\n",
      "Epoch 452, reconstruction losses: 0.051923840625162324, regression losses: 0.2730560192413492, validation losses: 1.3840451541501804\n",
      "Epoch 453, reconstruction losses: 0.04835558252546313, regression losses: 0.2104795532192562, validation losses: 1.021571447835108\n",
      "Epoch 454, reconstruction losses: 0.05228478623409716, regression losses: 0.18628495971687303, validation losses: 1.0459853395750491\n",
      "Epoch 455, reconstruction losses: 0.0488030380623223, regression losses: 0.2221688184818767, validation losses: 1.0097423508475396\n",
      "Epoch 456, reconstruction losses: 0.05009749624487162, regression losses: 0.1893577420916396, validation losses: 1.1329857260203016\n",
      "Epoch 457, reconstruction losses: 0.048159762239050594, regression losses: 0.2594112338449435, validation losses: 1.0500941574894562\n",
      "Epoch 458, reconstruction losses: 0.051873477040227045, regression losses: 0.19522692801490185, validation losses: 1.059647434157263\n",
      "Epoch 459, reconstruction losses: 0.04592072523193677, regression losses: 0.22346760907339325, validation losses: 1.0379440986177078\n",
      "Epoch 460, reconstruction losses: 0.05205758550734614, regression losses: 0.2598836964676173, validation losses: 1.362913597794789\n",
      "Epoch 461, reconstruction losses: 0.045648912571926034, regression losses: 0.2117586121602027, validation losses: 1.2312660275416287\n",
      "Epoch 462, reconstruction losses: 0.04930660050720019, regression losses: 0.20911473257222277, validation losses: 1.056336496945026\n",
      "Epoch 463, reconstruction losses: 0.049368320081612016, regression losses: 0.22183325549013266, validation losses: 0.9739816147058479\n",
      "Epoch 464, reconstruction losses: 0.04722464716694763, regression losses: 0.16997794157997603, validation losses: 1.353157272209188\n",
      "Epoch 465, reconstruction losses: 0.05258487605487206, regression losses: 0.21548821271491186, validation losses: 1.1532471481547257\n",
      "Epoch 466, reconstruction losses: 0.05703643239020956, regression losses: 0.21177329930110342, validation losses: 0.9574112655640311\n",
      "Epoch 467, reconstruction losses: 0.04805223382770391, regression losses: 0.20934608073015482, validation losses: 0.9431242838575771\n",
      "Epoch 468, reconstruction losses: 0.047496805549259793, regression losses: 0.24019827503780766, validation losses: 1.076056803664362\n",
      "Epoch 469, reconstruction losses: 0.05420692486320339, regression losses: 0.2363192859216521, validation losses: 1.0571883749625108\n",
      "Epoch 470, reconstruction losses: 0.04682268035829068, regression losses: 0.19090682760255817, validation losses: 1.0101949515269244\n",
      "Epoch 471, reconstruction losses: 0.047354807390687995, regression losses: 0.21274927589582648, validation losses: 0.9526608974811263\n",
      "Epoch 472, reconstruction losses: 0.05256491988771625, regression losses: 0.29367085808681, validation losses: 1.018163148468441\n",
      "Epoch 473, reconstruction losses: 0.059517500699566975, regression losses: 0.18909202580462184, validation losses: 1.070519859147992\n",
      "Epoch 474, reconstruction losses: 0.05150884025437989, regression losses: 0.3293532440667071, validation losses: 0.8706398696645196\n",
      "Epoch 475, reconstruction losses: 0.04910030721983106, regression losses: 0.3828954947268662, validation losses: 1.6179692456702115\n",
      "Epoch 476, reconstruction losses: 0.04983481465406943, regression losses: 0.26088609237142396, validation losses: 1.2277851429549684\n",
      "Epoch 477, reconstruction losses: 0.0580018994219917, regression losses: 0.18723720165742297, validation losses: 0.978125751330509\n",
      "Epoch 478, reconstruction losses: 0.046147315907723814, regression losses: 0.21863385301370036, validation losses: 1.1387008472039444\n",
      "Epoch 479, reconstruction losses: 0.04965576889190605, regression losses: 0.19905144805483982, validation losses: 1.194980037294867\n",
      "Epoch 480, reconstruction losses: 0.04974912781146047, regression losses: 0.22382082267989697, validation losses: 1.0603205664886652\n",
      "Epoch 481, reconstruction losses: 0.04864517500403542, regression losses: 0.2007352339151588, validation losses: 0.8971627607903105\n",
      "Epoch 482, reconstruction losses: 0.04650144417680803, regression losses: 0.20398439338595065, validation losses: 1.054802145082361\n",
      "Epoch 483, reconstruction losses: 0.052059211170881955, regression losses: 0.20569037394892345, validation losses: 1.420125244001193\n",
      "Epoch 484, reconstruction losses: 0.05049771295574397, regression losses: 0.20197779246683736, validation losses: 1.2081800509703349\n",
      "Epoch 485, reconstruction losses: 0.04666202243682345, regression losses: 0.23977727795625836, validation losses: 0.9248391486448063\n",
      "Epoch 486, reconstruction losses: 0.04915509028020509, regression losses: 0.18036568496371333, validation losses: 1.0207251745026218\n",
      "Epoch 487, reconstruction losses: 0.04954290023235842, regression losses: 0.17720670789690635, validation losses: 0.8805396632139904\n",
      "Epoch 488, reconstruction losses: 0.05219901735615193, regression losses: 0.24294165690673356, validation losses: 0.8936748928836845\n",
      "Epoch 489, reconstruction losses: 0.04732598182355789, regression losses: 0.2141631733158408, validation losses: 1.313180077128366\n",
      "Epoch 490, reconstruction losses: 0.04886833754253836, regression losses: 0.18469652566131017, validation losses: 1.0029261575765382\n",
      "Epoch 491, reconstruction losses: 0.04961606086723581, regression losses: 0.17708290456080553, validation losses: 0.7930923669977958\n",
      "Epoch 492, reconstruction losses: 0.0466658558943626, regression losses: 0.19047343896638388, validation losses: 0.8305282880933403\n",
      "Epoch 493, reconstruction losses: 0.049783584111221836, regression losses: 0.19342659497563672, validation losses: 0.8793586584979736\n",
      "Epoch 494, reconstruction losses: 0.047139550662335265, regression losses: 0.21644641461764835, validation losses: 0.8282457753284075\n",
      "Epoch 495, reconstruction losses: 0.047597454775643075, regression losses: 0.16899110861781444, validation losses: 0.768863503631804\n",
      "Epoch 496, reconstruction losses: 0.05001386625190288, regression losses: 0.17787643397939998, validation losses: 0.8090506998397834\n",
      "Epoch 497, reconstruction losses: 0.04633008623473484, regression losses: 0.18832084249854114, validation losses: 0.8795827071180166\n",
      "Epoch 498, reconstruction losses: 0.0476760699950263, regression losses: 0.16487226631370014, validation losses: 0.7900271683432966\n",
      "Epoch 499, reconstruction losses: 0.05952012394764758, regression losses: 0.16499257805742873, validation losses: 0.8166159215698392\n",
      "Epoch 500, reconstruction losses: 0.051076571004719476, regression losses: 0.17546486729590702, validation losses: 0.7643868477852568\n",
      "Epoch 501, reconstruction losses: 0.0494695526658621, regression losses: 0.17234640187540465, validation losses: 0.896501513950293\n",
      "Epoch 502, reconstruction losses: 0.04744966079816752, regression losses: 0.19044601244028192, validation losses: 0.8550670538208293\n",
      "Epoch 503, reconstruction losses: 0.049203450392227344, regression losses: 0.24857024590604299, validation losses: 0.7737422545200753\n",
      "Epoch 504, reconstruction losses: 0.0510978025473817, regression losses: 0.1648412338329276, validation losses: 0.9947331010525773\n",
      "Epoch 505, reconstruction losses: 0.048265473571695174, regression losses: 0.16614264685679003, validation losses: 0.806831217126397\n",
      "Epoch 506, reconstruction losses: 0.05589894469145086, regression losses: 0.18165728186164085, validation losses: 0.7792273113616691\n",
      "Epoch 507, reconstruction losses: 0.046932900040683, regression losses: 0.20538088813464447, validation losses: 0.7174634521744526\n",
      "Epoch 508, reconstruction losses: 0.047887961144649244, regression losses: 0.20303623701138523, validation losses: 0.7747931179077545\n",
      "Epoch 509, reconstruction losses: 0.04855196199295363, regression losses: 0.19998864214038756, validation losses: 0.7199354777096995\n",
      "Epoch 510, reconstruction losses: 0.05230356099563922, regression losses: 0.23087598883503302, validation losses: 0.7647964356053136\n",
      "Epoch 511, reconstruction losses: 0.05196004143296285, regression losses: 0.20584359001247693, validation losses: 0.7294758526039709\n",
      "Epoch 512, reconstruction losses: 0.05194397062150078, regression losses: 0.23674977349873563, validation losses: 0.6905254715093571\n",
      "Epoch 513, reconstruction losses: 0.05207865286594188, regression losses: 0.16016128076969122, validation losses: 1.1113532097243417\n",
      "Epoch 514, reconstruction losses: 0.05365048120683078, regression losses: 0.21334201239755146, validation losses: 0.8006825095930911\n",
      "Epoch 515, reconstruction losses: 0.051287062408316646, regression losses: 0.20272157236573268, validation losses: 0.7370081738044644\n",
      "Epoch 516, reconstruction losses: 0.05079121864961316, regression losses: 0.17481863335838949, validation losses: 0.7531569807334446\n",
      "Epoch 517, reconstruction losses: 0.04928144088152702, regression losses: 0.19490716061158353, validation losses: 0.8686777077203592\n",
      "Epoch 518, reconstruction losses: 0.04860350050387126, regression losses: 0.19763305592239366, validation losses: 0.688193511992405\n",
      "Epoch 519, reconstruction losses: 0.04671942835647347, regression losses: 0.1834198168594078, validation losses: 1.0057399741133706\n",
      "Epoch 520, reconstruction losses: 0.04699001917721279, regression losses: 0.16602147214201532, validation losses: 0.8490787185004316\n",
      "Epoch 521, reconstruction losses: 0.045134376614426236, regression losses: 0.24559548643815854, validation losses: 0.7451715354794057\n",
      "Epoch 522, reconstruction losses: 0.04729133765139862, regression losses: 0.17011033947902038, validation losses: 0.9188935371083002\n",
      "Epoch 523, reconstruction losses: 0.05106674828082454, regression losses: 0.22172601979870846, validation losses: 0.6834132282495001\n",
      "Epoch 524, reconstruction losses: 0.04717474768865607, regression losses: 0.1685915603578968, validation losses: 0.6843066995174502\n",
      "Epoch 525, reconstruction losses: 0.05044655054966401, regression losses: 0.1959118575391919, validation losses: 0.8700190946200861\n",
      "Epoch 526, reconstruction losses: 0.04741137556189128, regression losses: 0.22523182775913977, validation losses: 1.03104840044615\n",
      "Epoch 527, reconstruction losses: 0.05294510897169706, regression losses: 0.26202229335409055, validation losses: 0.6730330714530576\n",
      "Epoch 528, reconstruction losses: 0.0480226471085953, regression losses: 0.18801199939391464, validation losses: 0.7342429895119615\n",
      "Epoch 529, reconstruction losses: 0.048577754838239694, regression losses: 0.1859280212823197, validation losses: 0.8220306588971333\n",
      "Epoch 530, reconstruction losses: 0.0485875598902449, regression losses: 0.18607024612554593, validation losses: 0.8969283330838451\n",
      "Epoch 531, reconstruction losses: 0.05357326790089021, regression losses: 0.17762598642576227, validation losses: 0.6632376590656763\n",
      "Epoch 532, reconstruction losses: 0.04922524027781054, regression losses: 0.3522898367336219, validation losses: 0.6324553138094607\n",
      "Epoch 533, reconstruction losses: 0.049038817842383516, regression losses: 0.1737648197521715, validation losses: 1.0751794074012904\n",
      "Epoch 534, reconstruction losses: 0.04738923802842818, regression losses: 0.17040978654617456, validation losses: 0.7136346685099125\n",
      "Epoch 535, reconstruction losses: 0.053275121034878345, regression losses: 0.236053404193574, validation losses: 0.7410040599134111\n",
      "Epoch 536, reconstruction losses: 0.048762613969160463, regression losses: 0.15098875220759772, validation losses: 0.6902648493918176\n",
      "Epoch 537, reconstruction losses: 0.046371497545676606, regression losses: 0.188763251463701, validation losses: 0.6754868744402176\n",
      "Epoch 538, reconstruction losses: 0.04778332511958879, regression losses: 0.17918513824026938, validation losses: 1.0460163932621582\n",
      "Epoch 539, reconstruction losses: 0.05269193956139597, regression losses: 0.16741512372584763, validation losses: 0.794844045530009\n",
      "Epoch 540, reconstruction losses: 0.04825512578939533, regression losses: 0.18517852289494477, validation losses: 0.6241506137866848\n",
      "Epoch 541, reconstruction losses: 0.05639107160176657, regression losses: 0.17565983737439114, validation losses: 0.6479090122693267\n",
      "Epoch 542, reconstruction losses: 0.04883933090027121, regression losses: 0.1804871687441902, validation losses: 0.6347797346244982\n",
      "Epoch 543, reconstruction losses: 0.048428635883348385, regression losses: 0.1734570956110349, validation losses: 0.6721653807827576\n",
      "Epoch 544, reconstruction losses: 0.047491839886820916, regression losses: 0.16666336556441363, validation losses: 0.7022350190102126\n",
      "Epoch 545, reconstruction losses: 0.0456365877808634, regression losses: 0.21940750047157281, validation losses: 0.710765666331771\n",
      "Epoch 546, reconstruction losses: 0.04889419505974874, regression losses: 0.26182214038395923, validation losses: 0.8529305362159316\n",
      "Epoch 547, reconstruction losses: 0.047177865283574726, regression losses: 0.1963667025089663, validation losses: 1.1714971511939511\n",
      "Epoch 548, reconstruction losses: 0.05302332277304583, regression losses: 0.218803842805611, validation losses: 0.6204221213072549\n",
      "Epoch 549, reconstruction losses: 0.05256141206453253, regression losses: 0.2928001656147028, validation losses: 1.0345176020504876\n",
      "Epoch 550, reconstruction losses: 0.051374050353161047, regression losses: 0.21354525464158353, validation losses: 1.2323123411066763\n",
      "Epoch 551, reconstruction losses: 0.0454912963410543, regression losses: 0.2054131755246534, validation losses: 0.8678443170386386\n",
      "Epoch 552, reconstruction losses: 0.04527715633091045, regression losses: 0.16299173966108216, validation losses: 0.705561014806852\n",
      "Epoch 553, reconstruction losses: 0.04942148562429417, regression losses: 0.19580927113966584, validation losses: 0.6222425994313329\n",
      "Epoch 554, reconstruction losses: 0.0495472080296146, regression losses: 0.1722282924864138, validation losses: 0.9986153126183792\n",
      "Epoch 555, reconstruction losses: 0.04565105837132173, regression losses: 0.18578416609289966, validation losses: 0.8355386225402865\n",
      "Epoch 556, reconstruction losses: 0.05863360463586664, regression losses: 0.15258724339419605, validation losses: 0.7438420084485544\n",
      "Epoch 557, reconstruction losses: 0.0459023651813129, regression losses: 0.16204397630668838, validation losses: 0.5819648908190417\n",
      "Epoch 558, reconstruction losses: 0.049662929173349336, regression losses: 0.26080194551458735, validation losses: 0.7842371203752083\n",
      "Epoch 559, reconstruction losses: 0.04746794480636577, regression losses: 0.15563398157721747, validation losses: 0.6599461838894994\n",
      "Epoch 560, reconstruction losses: 0.04725893385020951, regression losses: 0.19820983592942296, validation losses: 0.6030810805993158\n",
      "Epoch 561, reconstruction losses: 0.049641531089449936, regression losses: 0.204885319657245, validation losses: 0.688837869175601\n",
      "Epoch 562, reconstruction losses: 0.04840043573195701, regression losses: 0.18010300253059153, validation losses: 0.841872067345575\n",
      "Epoch 563, reconstruction losses: 0.04988608922857588, regression losses: 0.15709778126310045, validation losses: 0.7489253204236166\n",
      "Epoch 564, reconstruction losses: 0.04812913215847131, regression losses: 0.1251704543543892, validation losses: 0.7768528563077586\n",
      "Epoch 565, reconstruction losses: 0.04795506386751719, regression losses: 0.16020501666319512, validation losses: 0.8305946199588647\n",
      "Epoch 566, reconstruction losses: 0.048834850193089814, regression losses: 0.14201754177449263, validation losses: 0.6639554864201371\n",
      "Epoch 567, reconstruction losses: 0.04933683834491484, regression losses: 0.18944503767923374, validation losses: 0.5968526444190778\n",
      "Epoch 568, reconstruction losses: 0.0470408850801457, regression losses: 0.1892029299690939, validation losses: 0.5729613947897478\n",
      "Epoch 569, reconstruction losses: 0.047460735063426365, regression losses: 0.1675819237685775, validation losses: 0.7665432836482249\n",
      "Epoch 570, reconstruction losses: 0.05228378731329761, regression losses: 0.17672111333564242, validation losses: 0.8486607234371578\n",
      "Epoch 571, reconstruction losses: 0.04849289611534731, regression losses: 0.3262121321335519, validation losses: 0.8366923071793844\n",
      "Epoch 572, reconstruction losses: 0.0522875967465388, regression losses: 0.2594584837098089, validation losses: 0.7319295612410373\n",
      "Epoch 573, reconstruction losses: 0.054492913082127586, regression losses: 0.16282956952728794, validation losses: 0.8606602009030282\n",
      "Epoch 574, reconstruction losses: 0.045740405096727325, regression losses: 0.216509943867847, validation losses: 0.857387510929609\n",
      "Epoch 575, reconstruction losses: 0.05150724490105668, regression losses: 0.16390261417986007, validation losses: 0.9070925396964491\n",
      "Epoch 576, reconstruction losses: 0.04647634640084614, regression losses: 0.21535925904055234, validation losses: 0.5716182903162953\n",
      "Epoch 577, reconstruction losses: 0.054571853078166976, regression losses: 0.2763723296207164, validation losses: 1.0340044643963162\n",
      "Epoch 578, reconstruction losses: 0.050000856866383746, regression losses: 0.20444632224562356, validation losses: 0.795587738066865\n",
      "Epoch 579, reconstruction losses: 0.05742397545482544, regression losses: 0.1641109602247282, validation losses: 0.8249825482205035\n",
      "Epoch 580, reconstruction losses: 0.05273936970414471, regression losses: 0.22630963362317624, validation losses: 0.6712283098144706\n",
      "Epoch 581, reconstruction losses: 0.048946014496927565, regression losses: 0.278015624277663, validation losses: 1.0258266927111297\n",
      "Epoch 582, reconstruction losses: 0.05089364599037299, regression losses: 0.168775058659603, validation losses: 0.6527543450228399\n",
      "Epoch 583, reconstruction losses: 0.05175123171162047, regression losses: 0.16323671409053866, validation losses: 0.5537469845593448\n",
      "Epoch 584, reconstruction losses: 0.049449135959965126, regression losses: 0.2418004150462713, validation losses: 0.5975564259908646\n",
      "Epoch 585, reconstruction losses: 0.04873927415425305, regression losses: 0.13142677405828054, validation losses: 1.0282410367422752\n",
      "Epoch 586, reconstruction losses: 0.05244825410127279, regression losses: 0.1815987224452116, validation losses: 0.5680219606474551\n",
      "Epoch 587, reconstruction losses: 0.049421397309456334, regression losses: 0.21129184578881316, validation losses: 0.6060270137534455\n",
      "Epoch 588, reconstruction losses: 0.04693311350704295, regression losses: 0.1764033644319658, validation losses: 0.7521488303309534\n",
      "Epoch 589, reconstruction losses: 0.0579548064960823, regression losses: 0.18338376612388876, validation losses: 0.647144446723056\n",
      "Epoch 590, reconstruction losses: 0.04553234815025912, regression losses: 0.1439690871076371, validation losses: 0.6680461381794686\n",
      "Epoch 591, reconstruction losses: 0.048899595731343566, regression losses: 0.15384402292477026, validation losses: 0.6182301008337578\n",
      "Epoch 592, reconstruction losses: 0.046377211468534435, regression losses: 0.13563707851695567, validation losses: 0.5661709509695033\n",
      "Epoch 593, reconstruction losses: 0.045919655804392154, regression losses: 0.15827449519789605, validation losses: 0.6661358016885021\n",
      "Epoch 594, reconstruction losses: 0.05122961428202287, regression losses: 0.17069381379362927, validation losses: 0.7174696012504594\n",
      "Epoch 595, reconstruction losses: 0.04583778263928393, regression losses: 0.13730970906726056, validation losses: 0.6015608236437249\n",
      "Epoch 596, reconstruction losses: 0.056520885008876684, regression losses: 0.19814910425580978, validation losses: 0.6276444385770891\n",
      "Epoch 597, reconstruction losses: 0.046320914513647185, regression losses: 0.15904009907917963, validation losses: 0.7047436508380781\n",
      "Epoch 598, reconstruction losses: 0.04965994745727284, regression losses: 0.25953632487090694, validation losses: 0.7404936013035792\n",
      "Epoch 599, reconstruction losses: 0.052749785805862974, regression losses: 0.18241916138800834, validation losses: 0.6593548918271518\n",
      "Epoch 600, reconstruction losses: 0.05317615339479512, regression losses: 0.15726410781026662, validation losses: 0.7316331737818899\n",
      "Epoch 601, reconstruction losses: 0.04964267620785656, regression losses: 0.13785431213970856, validation losses: 0.7616842784358395\n",
      "Epoch 602, reconstruction losses: 0.04904178355330551, regression losses: 0.2040552103030261, validation losses: 0.7279088274876457\n",
      "Epoch 603, reconstruction losses: 0.05227080746569037, regression losses: 0.16061519626922088, validation losses: 0.7236803874721058\n",
      "Epoch 604, reconstruction losses: 0.045612009016424045, regression losses: 0.22075479711289425, validation losses: 0.6357846277621346\n",
      "Epoch 605, reconstruction losses: 0.05892247022528613, regression losses: 0.18172394558725766, validation losses: 1.0496098084330028\n",
      "Epoch 606, reconstruction losses: 0.0481958451553117, regression losses: 0.17613741819588338, validation losses: 0.635452385927386\n",
      "Epoch 607, reconstruction losses: 0.0490063615853615, regression losses: 0.20342167727359223, validation losses: 0.8257337697936161\n",
      "Epoch 608, reconstruction losses: 0.04829892467551064, regression losses: 0.1718243902930578, validation losses: 0.7198978759382615\n",
      "Epoch 609, reconstruction losses: 0.051617365385644334, regression losses: 0.18711508346247185, validation losses: 0.6013188331121002\n",
      "Epoch 610, reconstruction losses: 0.05579910836736556, regression losses: 0.29844468423462156, validation losses: 0.7532706329582359\n",
      "Epoch 611, reconstruction losses: 0.04853829302879974, regression losses: 0.19752856767557903, validation losses: 0.7600412036168058\n",
      "Epoch 612, reconstruction losses: 0.05139658775942972, regression losses: 0.15629669049352446, validation losses: 0.7076648061357407\n",
      "Epoch 613, reconstruction losses: 0.049179167532155475, regression losses: 0.15103506280894918, validation losses: 0.7312725102743755\n",
      "Epoch 614, reconstruction losses: 0.05014313677208476, regression losses: 0.15847801554347568, validation losses: 0.6199427139868323\n",
      "Epoch 615, reconstruction losses: 0.04689198898957954, regression losses: 0.16033231178239332, validation losses: 0.5436166599769743\n",
      "Epoch 616, reconstruction losses: 0.05035413233269065, regression losses: 0.14197474012376984, validation losses: 0.5942005296304551\n",
      "Epoch 617, reconstruction losses: 0.04793428127529693, regression losses: 0.1499918366295268, validation losses: 0.6326257777883703\n",
      "Epoch 618, reconstruction losses: 0.046796613821568356, regression losses: 0.1902239615827751, validation losses: 0.5643746630195924\n",
      "Epoch 619, reconstruction losses: 0.048043779060908544, regression losses: 0.1688869947577406, validation losses: 0.6139843785998005\n",
      "Epoch 620, reconstruction losses: 0.04652340290195026, regression losses: 0.1482392249326415, validation losses: 0.8203092733395815\n",
      "Epoch 621, reconstruction losses: 0.048007466323867085, regression losses: 0.19542435996196023, validation losses: 0.612023652350209\n",
      "Epoch 622, reconstruction losses: 0.05791436288756527, regression losses: 0.13445296700325118, validation losses: 0.6288143577048454\n",
      "Epoch 623, reconstruction losses: 0.048512958070307054, regression losses: 0.16443633442807684, validation losses: 0.5510182095769776\n",
      "Epoch 624, reconstruction losses: 0.04721833366401014, regression losses: 0.25070656167537, validation losses: 0.6915896043493018\n",
      "Epoch 625, reconstruction losses: 0.053034443278374616, regression losses: 0.17881844054622134, validation losses: 0.558370036958862\n",
      "Epoch 626, reconstruction losses: 0.04719625007971441, regression losses: 0.16624471782221983, validation losses: 0.489009648153968\n",
      "Epoch 627, reconstruction losses: 0.04681359749269716, regression losses: 0.19061202115270137, validation losses: 0.6488708806204123\n",
      "Epoch 628, reconstruction losses: 0.05190689919438885, regression losses: 0.16415450128521483, validation losses: 0.7878492590769476\n",
      "Epoch 629, reconstruction losses: 0.04594832375741557, regression losses: 0.142196466950304, validation losses: 0.5888749589642682\n",
      "Epoch 630, reconstruction losses: 0.0479653451627241, regression losses: 0.14934148691660393, validation losses: 0.5648752195652964\n",
      "Epoch 631, reconstruction losses: 0.045737038744990285, regression losses: 0.1296846514497036, validation losses: 0.5801521362104197\n",
      "Epoch 632, reconstruction losses: 0.04751268746297396, regression losses: 0.17626321939871542, validation losses: 0.5220197020733439\n",
      "Epoch 633, reconstruction losses: 0.050970195880678394, regression losses: 0.1483424488852324, validation losses: 0.5092837887938608\n",
      "Epoch 634, reconstruction losses: 0.047000195159484885, regression losses: 0.1513505854917658, validation losses: 0.6175190272230335\n",
      "Epoch 635, reconstruction losses: 0.0486466385200088, regression losses: 0.3070004607113278, validation losses: 0.6728015271891034\n",
      "Epoch 636, reconstruction losses: 0.04783823019992751, regression losses: 0.17412970272909134, validation losses: 0.8066691751467975\n",
      "Epoch 637, reconstruction losses: 0.049666202529851204, regression losses: 0.21819904133736878, validation losses: 0.6597802261111148\n",
      "Epoch 638, reconstruction losses: 0.051308443774221384, regression losses: 0.1724095391470493, validation losses: 1.1271444019932981\n",
      "Epoch 639, reconstruction losses: 0.05012136594513095, regression losses: 0.2760249337890158, validation losses: 0.7258330405653024\n",
      "Epoch 640, reconstruction losses: 0.050118556878741685, regression losses: 0.2154382414977416, validation losses: 0.996179496578252\n",
      "Epoch 641, reconstruction losses: 0.04852020703805349, regression losses: 0.20070663752259998, validation losses: 0.5219058894852998\n",
      "Epoch 642, reconstruction losses: 0.04676995710693122, regression losses: 0.18820701715711932, validation losses: 0.6339291311780628\n",
      "Epoch 643, reconstruction losses: 0.04672817375774448, regression losses: 0.15177793856211835, validation losses: 0.5763457671812346\n",
      "Epoch 644, reconstruction losses: 0.05864650861984104, regression losses: 0.10965172614823099, validation losses: 0.5028783102297059\n",
      "Epoch 645, reconstruction losses: 0.046102459852180366, regression losses: 0.16545936805347286, validation losses: 0.5085419391489651\n",
      "Epoch 646, reconstruction losses: 0.047514104927689094, regression losses: 0.18926803267256606, validation losses: 0.5669468199012057\n",
      "Epoch 647, reconstruction losses: 0.04641841398352166, regression losses: 0.12500484968697123, validation losses: 0.8194217393818025\n",
      "Epoch 648, reconstruction losses: 0.04702978891964753, regression losses: 0.23152102972457234, validation losses: 0.4948858550023625\n",
      "Epoch 649, reconstruction losses: 0.05029024584293037, regression losses: 0.44162113754828836, validation losses: 0.5280155106880587\n",
      "Epoch 650, reconstruction losses: 0.053149325522254175, regression losses: 0.18150853897084082, validation losses: 1.1013609157149356\n",
      "Epoch 651, reconstruction losses: 0.05256328750155764, regression losses: 0.17020098790574079, validation losses: 0.7439711105472375\n",
      "Epoch 652, reconstruction losses: 0.04856888745381202, regression losses: 0.1590786427038372, validation losses: 0.7064290432363758\n",
      "Epoch 653, reconstruction losses: 0.05215139385614042, regression losses: 0.1947194379911842, validation losses: 0.5368982901263795\n",
      "Epoch 654, reconstruction losses: 0.04937503456826339, regression losses: 0.2879479269041242, validation losses: 0.6342673716515516\n",
      "Epoch 655, reconstruction losses: 0.04808825655622368, regression losses: 0.1754488406577815, validation losses: 1.3355053790899005\n",
      "Epoch 656, reconstruction losses: 0.050630177109854235, regression losses: 0.2369418021255431, validation losses: 0.5897526810592407\n",
      "Epoch 657, reconstruction losses: 0.0529480111532026, regression losses: 0.17331198986801755, validation losses: 0.6338478209644194\n",
      "Epoch 658, reconstruction losses: 0.04835366563714641, regression losses: 0.1810744440128735, validation losses: 0.6706435594970259\n",
      "Epoch 659, reconstruction losses: 0.05054872166887314, regression losses: 0.4826986703094974, validation losses: 0.5979436875236753\n",
      "Epoch 660, reconstruction losses: 0.04617613137639591, regression losses: 0.18458670276524164, validation losses: 1.2624226251296298\n",
      "Epoch 661, reconstruction losses: 0.053528154156522484, regression losses: 0.20646895315814898, validation losses: 0.6814254502868318\n",
      "Epoch 662, reconstruction losses: 0.04745525345333549, regression losses: 0.19784546795419572, validation losses: 0.8745678141587601\n",
      "Epoch 663, reconstruction losses: 0.04932043365229816, regression losses: 0.16167857981907072, validation losses: 0.5423264193502546\n",
      "Epoch 664, reconstruction losses: 0.05234671530341223, regression losses: 0.19117909267762084, validation losses: 0.5879375778386379\n",
      "Epoch 665, reconstruction losses: 0.04767430707808384, regression losses: 0.1615652807765066, validation losses: 1.1627368454726572\n",
      "Epoch 666, reconstruction losses: 0.04650319349088108, regression losses: 0.15837861956902827, validation losses: 0.5088590428499941\n",
      "Epoch 667, reconstruction losses: 0.04965359068222145, regression losses: 0.20395205507912065, validation losses: 0.5336293842699545\n",
      "Epoch 668, reconstruction losses: 0.05090939293401895, regression losses: 0.18769708391239492, validation losses: 0.7207319479784354\n",
      "Epoch 669, reconstruction losses: 0.05404390243052351, regression losses: 0.15336117822430748, validation losses: 0.5767362429819494\n",
      "Epoch 670, reconstruction losses: 0.04691131036470312, regression losses: 0.16572905390394774, validation losses: 0.5091937615532541\n",
      "Epoch 671, reconstruction losses: 0.05211827273308381, regression losses: 0.16137303736676917, validation losses: 0.7051310023393124\n",
      "Epoch 672, reconstruction losses: 0.04534373189449667, regression losses: 0.1547539174543648, validation losses: 0.8303944950934643\n",
      "Epoch 673, reconstruction losses: 0.04794751271274847, regression losses: 0.15333851388835842, validation losses: 0.6998149696124788\n",
      "Epoch 674, reconstruction losses: 0.04646228198668573, regression losses: 0.15570006531279681, validation losses: 0.6895747749427745\n",
      "Epoch 675, reconstruction losses: 0.04882199821678178, regression losses: 0.2280782956789088, validation losses: 0.5151011755460189\n",
      "Epoch 676, reconstruction losses: 0.04651838116519303, regression losses: 0.19130618354135848, validation losses: 0.5812592093789661\n",
      "Epoch 677, reconstruction losses: 0.048141916587406214, regression losses: 0.21993095420142075, validation losses: 0.5802168282258994\n",
      "Epoch 678, reconstruction losses: 0.05318938617231427, regression losses: 0.1370057059714578, validation losses: 0.7526105445701111\n",
      "Epoch 679, reconstruction losses: 0.04984932839224122, regression losses: 0.17922297346192842, validation losses: 0.5450116343182542\n",
      "Epoch 680, reconstruction losses: 0.048857984253582086, regression losses: 0.3109363893732655, validation losses: 0.6034119219627552\n",
      "Epoch 681, reconstruction losses: 0.04565052260355571, regression losses: 0.16975459791000713, validation losses: 0.8960755694243265\n",
      "Epoch 682, reconstruction losses: 0.05064115809569514, regression losses: 0.16773592178544386, validation losses: 0.4849036382804855\n",
      "Epoch 683, reconstruction losses: 0.04764534027438751, regression losses: 0.16608220766762485, validation losses: 0.800331412895932\n",
      "Epoch 684, reconstruction losses: 0.05307299173212377, regression losses: 0.2051011069354858, validation losses: 0.7272026421272514\n",
      "Epoch 685, reconstruction losses: 0.04955919476311813, regression losses: 0.16598691133647506, validation losses: 0.5026456586886053\n",
      "Epoch 686, reconstruction losses: 0.048751182374649246, regression losses: 0.18577616392146276, validation losses: 0.5650095356396616\n",
      "Epoch 687, reconstruction losses: 0.04713504286213241, regression losses: 0.1759088987248744, validation losses: 0.7090323507677896\n",
      "Epoch 688, reconstruction losses: 0.0482389054996206, regression losses: 0.15458999717843366, validation losses: 0.6927376656825189\n",
      "Epoch 689, reconstruction losses: 0.04895150243605743, regression losses: 0.14032453734866168, validation losses: 0.5722962561997442\n",
      "Epoch 690, reconstruction losses: 0.047475295270836576, regression losses: 0.15415927106029315, validation losses: 0.6183028194532214\n",
      "Epoch 691, reconstruction losses: 0.057845415420360535, regression losses: 0.14950811001700165, validation losses: 0.5239405607514436\n",
      "Epoch 692, reconstruction losses: 0.049275899801029685, regression losses: 0.1464460898102075, validation losses: 0.5967275026581293\n",
      "Epoch 693, reconstruction losses: 0.0503262556955201, regression losses: 0.15352878640842935, validation losses: 0.5639151806551675\n",
      "Epoch 694, reconstruction losses: 0.04927924164652733, regression losses: 0.16649761066246352, validation losses: 0.7437700436317936\n",
      "Epoch 695, reconstruction losses: 0.04881695351383471, regression losses: 0.15223674369111348, validation losses: 0.6399650203138323\n",
      "Epoch 696, reconstruction losses: 0.04762398593041853, regression losses: 0.12855709754433153, validation losses: 0.4950049612299807\n",
      "Epoch 697, reconstruction losses: 0.04852963507039768, regression losses: 0.136657680105979, validation losses: 0.5008957197157523\n",
      "Epoch 698, reconstruction losses: 0.0470314974554961, regression losses: 0.14204416434849662, validation losses: 0.705728153826647\n",
      "Epoch 699, reconstruction losses: 0.05103678200978631, regression losses: 0.15285828480107416, validation losses: 0.5641692024228417\n",
      "Epoch 700, reconstruction losses: 0.04888362089673704, regression losses: 0.14793546894643358, validation losses: 0.4770605598870897\n",
      "Epoch 701, reconstruction losses: 0.055688429082307755, regression losses: 0.12069342801542125, validation losses: 0.6156304043156184\n",
      "Epoch 702, reconstruction losses: 0.04771412929454523, regression losses: 0.199671027439812, validation losses: 0.6753011128782849\n",
      "Epoch 703, reconstruction losses: 0.04769634448511245, regression losses: 0.12984270579639579, validation losses: 0.538802238376369\n",
      "Epoch 704, reconstruction losses: 0.052759591651989214, regression losses: 0.19685402339985567, validation losses: 0.5035028491343516\n",
      "Epoch 705, reconstruction losses: 0.05223383955525969, regression losses: 0.19074643083104165, validation losses: 0.8741619767849494\n",
      "Epoch 706, reconstruction losses: 0.051423169053690994, regression losses: 0.1479019379384051, validation losses: 0.4878041946169685\n",
      "Epoch 707, reconstruction losses: 0.0589580092528731, regression losses: 0.17969548890309198, validation losses: 0.5064989413201586\n",
      "Epoch 708, reconstruction losses: 0.04695397631120639, regression losses: 0.15330461300556583, validation losses: 0.6031832346952699\n",
      "Epoch 709, reconstruction losses: 0.05068415121081728, regression losses: 0.3886558792031237, validation losses: 0.5815610767267185\n",
      "Epoch 710, reconstruction losses: 0.048049418886967676, regression losses: 0.33258750382165836, validation losses: 1.0324450720260447\n",
      "Epoch 711, reconstruction losses: 0.04815436314260597, regression losses: 0.16661868207263675, validation losses: 0.9219836323339345\n",
      "Epoch 712, reconstruction losses: 0.04633856396574673, regression losses: 0.16542415130446858, validation losses: 0.49620898466059243\n",
      "Epoch 713, reconstruction losses: 0.059142192663684943, regression losses: 0.15499995603647929, validation losses: 0.838531415428918\n",
      "Epoch 714, reconstruction losses: 0.052259478463696565, regression losses: 0.17050792139243692, validation losses: 0.6610705598382\n",
      "Epoch 715, reconstruction losses: 0.04926735993445995, regression losses: 0.15749920011097587, validation losses: 0.7123306140803446\n",
      "Epoch 716, reconstruction losses: 0.04772730013903888, regression losses: 0.18047759854268142, validation losses: 0.4975519858561176\n",
      "Epoch 717, reconstruction losses: 0.046699599550103915, regression losses: 0.1592197584702325, validation losses: 0.7971094576966447\n",
      "Epoch 718, reconstruction losses: 0.05793506391047323, regression losses: 0.15608295193985697, validation losses: 0.6746565543902254\n",
      "Epoch 719, reconstruction losses: 0.04976264208231159, regression losses: 0.27346051040718344, validation losses: 0.6522186513444732\n",
      "Epoch 720, reconstruction losses: 0.046598102478159265, regression losses: 0.22008864005619153, validation losses: 0.7935342404979497\n",
      "Epoch 721, reconstruction losses: 0.047029428208441346, regression losses: 0.1867536839718451, validation losses: 0.6039735272738366\n",
      "Epoch 722, reconstruction losses: 0.04860394007830778, regression losses: 0.1243482529873597, validation losses: 0.60425599189099\n",
      "Epoch 723, reconstruction losses: 0.048317478497328537, regression losses: 0.14098005600533256, validation losses: 0.7102489766892428\n",
      "Epoch 724, reconstruction losses: 0.05301712538512677, regression losses: 0.1835113237368199, validation losses: 0.6827725794275332\n",
      "Epoch 725, reconstruction losses: 0.057618472027330184, regression losses: 0.1957868646768319, validation losses: 0.7749801071440358\n",
      "Epoch 726, reconstruction losses: 0.054605961543182015, regression losses: 0.15234910380013653, validation losses: 0.664307960331786\n",
      "Epoch 727, reconstruction losses: 0.04801129456414843, regression losses: 0.19817122473476292, validation losses: 0.5301236576588599\n",
      "Epoch 728, reconstruction losses: 0.04792640311674453, regression losses: 0.2031389448682107, validation losses: 0.5734956223469376\n",
      "Epoch 729, reconstruction losses: 0.04865020659819785, regression losses: 0.156679904460682, validation losses: 0.5952955775989508\n",
      "Epoch 730, reconstruction losses: 0.05308145536409007, regression losses: 0.16274819123871365, validation losses: 0.4986120301124307\n",
      "Epoch 731, reconstruction losses: 0.0474492896466325, regression losses: 0.1545521815960411, validation losses: 0.49396728121882694\n",
      "Epoch 732, reconstruction losses: 0.047925442049590705, regression losses: 0.12813878161446954, validation losses: 0.5882338407596537\n",
      "Epoch 733, reconstruction losses: 0.047982748775542414, regression losses: 0.13870351091738373, validation losses: 0.6950311408745142\n",
      "Epoch 734, reconstruction losses: 0.04949933596997561, regression losses: 0.1880588336039904, validation losses: 0.5531572329320124\n",
      "Epoch 735, reconstruction losses: 0.05236759520522552, regression losses: 0.19453653667451945, validation losses: 0.6693002480334356\n",
      "Epoch 736, reconstruction losses: 0.05509197386364139, regression losses: 0.15099182796190355, validation losses: 0.7656734803289205\n",
      "Epoch 737, reconstruction losses: 0.04768370728812749, regression losses: 0.1638693650644434, validation losses: 0.5787431668780962\n",
      "Epoch 738, reconstruction losses: 0.05152235106239266, regression losses: 0.14635791460338096, validation losses: 0.6026392736976248\n",
      "Epoch 739, reconstruction losses: 0.046862702821282846, regression losses: 0.19738648798689973, validation losses: 0.7418068365571261\n",
      "Epoch 740, reconstruction losses: 0.05200131414824795, regression losses: 0.13529214487707947, validation losses: 0.9769397146583831\n",
      "Epoch 741, reconstruction losses: 0.04679483254659668, regression losses: 0.2141366252205745, validation losses: 0.6369382605607234\n",
      "Epoch 742, reconstruction losses: 0.0580908294151395, regression losses: 0.14934302824797663, validation losses: 0.6140917583239319\n",
      "Epoch 743, reconstruction losses: 0.05353837308526938, regression losses: 0.16309405266076482, validation losses: 0.6966719649809365\n",
      "Epoch 744, reconstruction losses: 0.049029982622496505, regression losses: 0.1523033790679116, validation losses: 0.49607917553017794\n",
      "Epoch 745, reconstruction losses: 0.04911260173317909, regression losses: 0.17591121650433905, validation losses: 0.5095829810856911\n",
      "Epoch 746, reconstruction losses: 0.04748880484187659, regression losses: 0.17861979730190755, validation losses: 0.5923727190238465\n",
      "Epoch 747, reconstruction losses: 0.047153632546932445, regression losses: 0.15190113618214432, validation losses: 0.8567518208473958\n",
      "Epoch 748, reconstruction losses: 0.04868638275125721, regression losses: 0.15709882781139126, validation losses: 0.7281915355796065\n",
      "Epoch 749, reconstruction losses: 0.05262860636998841, regression losses: 0.1673271135937316, validation losses: 0.5368819036456812\n",
      "Epoch 750, reconstruction losses: 0.0493212614694599, regression losses: 0.14338315533748208, validation losses: 0.6083585774946982\n",
      "Epoch 751, reconstruction losses: 0.05054186067204566, regression losses: 0.16732170851416356, validation losses: 0.7948448192952602\n",
      "Epoch 752, reconstruction losses: 0.05282162664010085, regression losses: 0.13714480900273768, validation losses: 0.6396543309820616\n",
      "Epoch 753, reconstruction losses: 0.04867154311408918, regression losses: 0.16226034481149584, validation losses: 0.5209194459101762\n",
      "Epoch 754, reconstruction losses: 0.046354875511584924, regression losses: 0.16590584504311007, validation losses: 0.5605175210245346\n",
      "Epoch 755, reconstruction losses: 0.05251255243317764, regression losses: 0.14324996670456033, validation losses: 0.517277535394261\n",
      "Epoch 756, reconstruction losses: 0.05300021833435718, regression losses: 0.1443455825941686, validation losses: 0.5498298466430385\n",
      "Epoch 757, reconstruction losses: 0.050913784349098656, regression losses: 0.20442962462773484, validation losses: 0.6572407881482927\n",
      "Epoch 758, reconstruction losses: 0.04715079263538814, regression losses: 0.13582001459429907, validation losses: 0.8156270202358448\n",
      "Epoch 759, reconstruction losses: 0.049490043641111245, regression losses: 0.1734283698626231, validation losses: 0.51785960806312\n",
      "Epoch 760, reconstruction losses: 0.05244818688386304, regression losses: 0.20055899605829058, validation losses: 0.5436787856502346\n",
      "Epoch 761, reconstruction losses: 0.05907932456719475, regression losses: 0.14284629414583622, validation losses: 0.7203171651490969\n",
      "Epoch 762, reconstruction losses: 0.05186514107767383, regression losses: 0.14764297230344897, validation losses: 0.7053296182642704\n",
      "Epoch 763, reconstruction losses: 0.048034858008524486, regression losses: 0.17903077394293487, validation losses: 0.6171550516894263\n",
      "Epoch 764, reconstruction losses: 0.047639023560211144, regression losses: 0.14732054069957876, validation losses: 0.6494597812396727\n",
      "Epoch 765, reconstruction losses: 0.04580808637055218, regression losses: 0.19585296514803824, validation losses: 0.5911240946635815\n",
      "Epoch 766, reconstruction losses: 0.04753106210154014, regression losses: 0.17423443300098493, validation losses: 0.7909811478638868\n",
      "Epoch 767, reconstruction losses: 0.04565841243781933, regression losses: 0.15825692003909075, validation losses: 0.5553003678802753\n",
      "Epoch 768, reconstruction losses: 0.0508376277279385, regression losses: 0.144788573317228, validation losses: 0.5681382733074561\n",
      "Epoch 769, reconstruction losses: 0.05270265329364403, regression losses: 0.18234011803379513, validation losses: 0.5133806802812074\n",
      "Epoch 770, reconstruction losses: 0.045533026409536236, regression losses: 0.14605919107918477, validation losses: 0.8219024128652893\n",
      "Epoch 771, reconstruction losses: 0.049419136859592594, regression losses: 0.21270546593112408, validation losses: 0.6868181640594642\n",
      "Epoch 772, reconstruction losses: 0.05346186325820768, regression losses: 0.19679119068425183, validation losses: 0.5312198922020696\n",
      "Epoch 773, reconstruction losses: 0.04895436846563314, regression losses: 0.21889028032959548, validation losses: 0.546353831305281\n",
      "Epoch 774, reconstruction losses: 0.04821425548930238, regression losses: 0.16466489047534483, validation losses: 1.1439510635758232\n",
      "Epoch 775, reconstruction losses: 0.04639342084938948, regression losses: 0.2905674122507932, validation losses: 0.7443421222618152\n",
      "Epoch 776, reconstruction losses: 0.050907782944256595, regression losses: 0.20004664138815484, validation losses: 0.7480992514365986\n",
      "Epoch 777, reconstruction losses: 0.055722242473916064, regression losses: 0.12906814257627414, validation losses: 0.684323630298047\n",
      "Epoch 778, reconstruction losses: 0.04715835052459533, regression losses: 0.21941707051972173, validation losses: 0.6699486177170642\n",
      "Epoch 779, reconstruction losses: 0.04612980002300346, regression losses: 0.19089763247833572, validation losses: 0.8543669612550877\n",
      "Epoch 780, reconstruction losses: 0.058332637498977685, regression losses: 0.15962806718477773, validation losses: 0.59335880932755\n",
      "Epoch 781, reconstruction losses: 0.04733951271310377, regression losses: 0.2672116517030558, validation losses: 0.5430148829858694\n",
      "Epoch 782, reconstruction losses: 0.04735835315808883, regression losses: 0.17350614255654417, validation losses: 0.9300765195801928\n",
      "Epoch 783, reconstruction losses: 0.0515985469537699, regression losses: 0.16329811538500288, validation losses: 0.7163510028562784\n",
      "Epoch 784, reconstruction losses: 0.04646116407447263, regression losses: 0.17658027566644163, validation losses: 0.5789945197634949\n",
      "Epoch 785, reconstruction losses: 0.058472196515003766, regression losses: 0.16859744759807654, validation losses: 0.5193992300150417\n",
      "Epoch 786, reconstruction losses: 0.050495068966661165, regression losses: 0.1553952726858547, validation losses: 0.645542010939893\n",
      "Epoch 787, reconstruction losses: 0.05549454421315907, regression losses: 0.15001729446948522, validation losses: 0.7178609387660247\n",
      "Epoch 788, reconstruction losses: 0.053385319721230874, regression losses: 0.1695498265894129, validation losses: 0.5857551712258849\n",
      "Epoch 789, reconstruction losses: 0.046057372146388435, regression losses: 0.1576200861905318, validation losses: 0.7184856898075336\n",
      "Epoch 790, reconstruction losses: 0.04628994194115541, regression losses: 0.15220655697652918, validation losses: 0.5873486439182031\n",
      "Epoch 791, reconstruction losses: 0.05871443812807968, regression losses: 0.1380570620774492, validation losses: 0.5363433538053756\n",
      "Epoch 792, reconstruction losses: 0.04834478701345258, regression losses: 0.14864607414955933, validation losses: 0.5139956941714623\n",
      "Epoch 793, reconstruction losses: 0.046003070301516354, regression losses: 0.15408589466081837, validation losses: 0.6525603736635559\n",
      "Epoch 794, reconstruction losses: 0.04601387408383926, regression losses: 0.14168455190156692, validation losses: 0.6654535497676203\n",
      "Epoch 795, reconstruction losses: 0.04702460364857027, regression losses: 0.16559987804406573, validation losses: 0.5600617245228985\n",
      "Epoch 796, reconstruction losses: 0.05311397275580433, regression losses: 0.1484580183594826, validation losses: 0.5670283843158677\n",
      "Epoch 797, reconstruction losses: 0.04534768406979629, regression losses: 0.15677031056236457, validation losses: 0.5161083195494441\n",
      "Epoch 798, reconstruction losses: 0.04908839844560648, regression losses: 0.19740472078037108, validation losses: 0.5196892874116723\n",
      "Epoch 799, reconstruction losses: 0.047341277849139954, regression losses: 0.14658954242416422, validation losses: 0.7166768837210451\n",
      "Epoch 800, reconstruction losses: 0.0492988889903534, regression losses: 0.17137606367783578, validation losses: 0.6610886430981492\n",
      "Epoch 801, reconstruction losses: 0.04971437744160146, regression losses: 0.1444245251271276, validation losses: 0.5677854514575198\n",
      "Epoch 802, reconstruction losses: 0.04763559853387982, regression losses: 0.15624800385343046, validation losses: 0.601114438337975\n",
      "Epoch 803, reconstruction losses: 0.04696358769737618, regression losses: 0.219607909461692, validation losses: 0.6713642094930996\n",
      "Epoch 804, reconstruction losses: 0.048990319501396665, regression losses: 0.149378083906434, validation losses: 0.6420384853819212\n",
      "Epoch 805, reconstruction losses: 0.059108264002832964, regression losses: 0.1844684803297628, validation losses: 0.5842704496936972\n",
      "Epoch 806, reconstruction losses: 0.050380854295731504, regression losses: 0.33828175866866506, validation losses: 0.7645792370367221\n",
      "Epoch 807, reconstruction losses: 0.052944624916444465, regression losses: 0.19535806664300281, validation losses: 0.8055441238900516\n",
      "Epoch 808, reconstruction losses: 0.05112943856127468, regression losses: 0.16757696667038383, validation losses: 0.7251033820229063\n",
      "Epoch 809, reconstruction losses: 0.04900077223582992, regression losses: 0.1899413983307161, validation losses: 0.5301165419944435\n",
      "Epoch 810, reconstruction losses: 0.04928526158717514, regression losses: 0.1500087780294249, validation losses: 0.6395149730564473\n",
      "Epoch 811, reconstruction losses: 0.04962077232327067, regression losses: 0.16217212653913082, validation losses: 0.5614972810777252\n",
      "Epoch 812, reconstruction losses: 0.04582615498096451, regression losses: 0.1562143229871327, validation losses: 0.601559440813499\n",
      "Epoch 813, reconstruction losses: 0.052919948000998376, regression losses: 0.25527505868454137, validation losses: 0.6708426917673405\n",
      "Epoch 814, reconstruction losses: 0.04667811084733856, regression losses: 0.2576629188544599, validation losses: 0.6237347635384607\n",
      "Epoch 815, reconstruction losses: 0.04588268671934502, regression losses: 0.17895024153428568, validation losses: 0.9228538919655953\n",
      "Epoch 816, reconstruction losses: 0.04630923547260112, regression losses: 0.21849820222024996, validation losses: 1.1691590564385137\n",
      "Epoch 817, reconstruction losses: 0.0482313167511044, regression losses: 0.2212751284124066, validation losses: 0.5134216191548344\n",
      "Epoch 818, reconstruction losses: 0.04603903404479079, regression losses: 0.17613786804774448, validation losses: 0.7309987993273004\n",
      "Epoch 819, reconstruction losses: 0.04889432692509977, regression losses: 0.2056483409076525, validation losses: 0.6835775997245469\n",
      "Epoch 820, reconstruction losses: 0.05295730877198736, regression losses: 0.18691411541770067, validation losses: 0.5232358912069693\n",
      "Epoch 821, reconstruction losses: 0.04909354903611392, regression losses: 0.2694692816639256, validation losses: 0.816998084876061\n",
      "Epoch 822, reconstruction losses: 0.052989556863189985, regression losses: 0.21593099402906943, validation losses: 0.7379815677852354\n",
      "Epoch 823, reconstruction losses: 0.05922430081755642, regression losses: 0.1802703681340988, validation losses: 0.6090255083879796\n",
      "Epoch 824, reconstruction losses: 0.04630674019407271, regression losses: 0.1748233715492393, validation losses: 0.5180774535524284\n",
      "Epoch 825, reconstruction losses: 0.05182025185536887, regression losses: 0.12860554918973535, validation losses: 0.721889373186802\n",
      "Epoch 826, reconstruction losses: 0.05723901314664534, regression losses: 0.1500249877570565, validation losses: 0.6090059327642837\n",
      "Epoch 827, reconstruction losses: 0.051391436021377204, regression losses: 0.13199815051247998, validation losses: 0.5686975424942698\n",
      "Epoch 828, reconstruction losses: 0.052336667063773774, regression losses: 0.12449774854369423, validation losses: 0.5621232234223158\n",
      "Epoch 829, reconstruction losses: 0.04848314064029396, regression losses: 0.14426804411288058, validation losses: 0.5443935996292334\n",
      "Epoch 830, reconstruction losses: 0.04765464209955023, regression losses: 0.13957031469280357, validation losses: 0.6298697829172168\n",
      "Epoch 831, reconstruction losses: 0.05107800325929482, regression losses: 0.1364520029336632, validation losses: 0.5958194457523328\n",
      "Epoch 832, reconstruction losses: 0.0489430772468665, regression losses: 0.17240539608065472, validation losses: 0.5741759114090417\n",
      "Epoch 833, reconstruction losses: 0.05131165524747024, regression losses: 0.15136519339259125, validation losses: 0.5831976750717622\n",
      "Epoch 834, reconstruction losses: 0.0463794213617527, regression losses: 0.1559493175827889, validation losses: 0.5991424167554698\n",
      "Epoch 835, reconstruction losses: 0.058061819757048536, regression losses: 0.16967235203272535, validation losses: 0.5628046065597395\n",
      "Epoch 836, reconstruction losses: 0.045517492690880255, regression losses: 0.15066880695641233, validation losses: 0.5190380056560285\n",
      "Epoch 837, reconstruction losses: 0.05224216861138563, regression losses: 0.1483063911685999, validation losses: 0.5332285742410612\n",
      "Epoch 838, reconstruction losses: 0.05194493706044006, regression losses: 0.13949033579353193, validation losses: 0.5218313664646245\n",
      "Epoch 839, reconstruction losses: 0.04907093931378227, regression losses: 0.1872293673369979, validation losses: 0.6102280887877348\n",
      "Epoch 840, reconstruction losses: 0.04666892100447568, regression losses: 0.1673922437467401, validation losses: 0.6392090669361503\n",
      "Epoch 841, reconstruction losses: 0.04845679948387992, regression losses: 0.1430566667569281, validation losses: 0.5780384621862676\n",
      "Epoch 842, reconstruction losses: 0.04751906356319956, regression losses: 0.16837534544733462, validation losses: 0.6115827776717071\n",
      "Epoch 843, reconstruction losses: 0.046379356362027155, regression losses: 0.16521382705914522, validation losses: 0.8855108895736268\n",
      "Epoch 844, reconstruction losses: 0.05024249454525386, regression losses: 0.13976292022477058, validation losses: 0.5354143786045994\n",
      "Epoch 845, reconstruction losses: 0.05253250842807393, regression losses: 0.15697545635917054, validation losses: 0.5173074919029634\n",
      "Epoch 846, reconstruction losses: 0.048102569592145324, regression losses: 0.2129331205542605, validation losses: 0.5944708654651507\n",
      "Epoch 847, reconstruction losses: 0.045771970714408375, regression losses: 0.15189942670116904, validation losses: 0.6014408414398679\n",
      "Epoch 848, reconstruction losses: 0.04955504256224992, regression losses: 0.1942700046199297, validation losses: 0.641869958973442\n",
      "Epoch 849, reconstruction losses: 0.047640331614243234, regression losses: 0.15642767456015205, validation losses: 0.8566467793630538\n",
      "Epoch 850, reconstruction losses: 0.045789394141286195, regression losses: 0.18705933643685885, validation losses: 0.666023049984628\n",
      "Epoch 851, reconstruction losses: 0.04568771790368695, regression losses: 0.16745072446703801, validation losses: 0.6063991357339303\n",
      "Epoch 852, reconstruction losses: 0.04693345833423284, regression losses: 0.15416486045557484, validation losses: 0.69939758764723\n",
      "Epoch 853, reconstruction losses: 0.05040242853665182, regression losses: 0.42298376756733336, validation losses: 0.8624584063357092\n",
      "Epoch 854, reconstruction losses: 0.05288379794557874, regression losses: 0.192801033398449, validation losses: 0.8192750808243491\n",
      "Epoch 855, reconstruction losses: 0.04595520944922987, regression losses: 0.15887053739099394, validation losses: 0.6141090618542703\n",
      "Epoch 856, reconstruction losses: 0.05691244303756485, regression losses: 0.16736285930436173, validation losses: 0.5934687635467611\n",
      "Epoch 857, reconstruction losses: 0.049448688829247515, regression losses: 0.15557743852460193, validation losses: 0.5552307143497758\n",
      "Epoch 858, reconstruction losses: 0.04719551962956403, regression losses: 0.16305590775150708, validation losses: 0.7621645303629105\n",
      "Epoch 859, reconstruction losses: 0.05064584190271481, regression losses: 0.15198550592540402, validation losses: 0.6737970605031601\n",
      "Epoch 860, reconstruction losses: 0.049340245312059716, regression losses: 0.16161088876311167, validation losses: 0.6848654806397287\n",
      "Epoch 861, reconstruction losses: 0.0476794113384497, regression losses: 0.17790370254039942, validation losses: 0.5255528905719384\n",
      "Epoch 862, reconstruction losses: 0.04568000084422982, regression losses: 0.21749014842263267, validation losses: 0.6496542100119852\n",
      "Epoch 863, reconstruction losses: 0.046650339012909985, regression losses: 0.1606074649500521, validation losses: 0.8472496583704794\n",
      "Epoch 864, reconstruction losses: 0.049013211307971837, regression losses: 0.1435512603089106, validation losses: 0.5416623838215672\n",
      "Epoch 865, reconstruction losses: 0.045677409279496727, regression losses: 0.13153095510812549, validation losses: 0.5709889825965674\n",
      "Epoch 866, reconstruction losses: 0.04613220022152117, regression losses: 0.15275326126319316, validation losses: 0.5436906994511959\n",
      "Epoch 867, reconstruction losses: 0.04603840090773996, regression losses: 0.16518556097636666, validation losses: 0.5597014052727045\n",
      "Epoch 868, reconstruction losses: 0.050808319340835476, regression losses: 0.1357916318692154, validation losses: 0.7235767893424232\n",
      "Epoch 869, reconstruction losses: 0.05043958653882611, regression losses: 0.3767935373996004, validation losses: 0.5858629986689519\n",
      "Epoch 870, reconstruction losses: 0.04600252696033873, regression losses: 0.24825214267016976, validation losses: 0.6000447416747045\n",
      "Epoch 871, reconstruction losses: 0.05388078087017229, regression losses: 0.17338330071460267, validation losses: 0.6424251387129525\n",
      "Epoch 872, reconstruction losses: 0.050236003127893225, regression losses: 0.415774169993316, validation losses: 0.5170470148322435\n",
      "Epoch 873, reconstruction losses: 0.04525864822535942, regression losses: 0.16255817759554397, validation losses: 1.3977922622171866\n",
      "Epoch 874, reconstruction losses: 0.045707541496576014, regression losses: 0.21148182014858424, validation losses: 1.2313512686188304\n",
      "Epoch 875, reconstruction losses: 0.049089129540616463, regression losses: 0.15576836812997258, validation losses: 0.6911501502987816\n",
      "Epoch 876, reconstruction losses: 0.05061162594565846, regression losses: 0.18383668150108268, validation losses: 0.5516438033067202\n",
      "Epoch 877, reconstruction losses: 0.054510198716933626, regression losses: 0.19079607690513073, validation losses: 0.5221391480094741\n",
      "Epoch 878, reconstruction losses: 0.04554822193141957, regression losses: 0.1749251245587281, validation losses: 0.715102458484421\n",
      "Epoch 879, reconstruction losses: 0.04847292263267418, regression losses: 0.13823348680712785, validation losses: 1.0070365776334478\n",
      "Epoch 880, reconstruction losses: 0.047126887218094035, regression losses: 0.14843726232114604, validation losses: 0.5053864753246852\n",
      "Epoch 881, reconstruction losses: 0.04597101354447916, regression losses: 0.13380598544474953, validation losses: 0.5110235864539736\n",
      "Epoch 882, reconstruction losses: 0.051408126371552475, regression losses: 0.16203670797162723, validation losses: 0.5520643336531337\n",
      "Epoch 883, reconstruction losses: 0.051841357636967844, regression losses: 0.1332696978735178, validation losses: 0.6842346744088655\n",
      "Epoch 884, reconstruction losses: 0.051565978252673, regression losses: 0.11542119626856974, validation losses: 0.564490749039972\n",
      "Epoch 885, reconstruction losses: 0.0468419689288207, regression losses: 0.15359111573306872, validation losses: 0.7406590738548497\n",
      "Epoch 886, reconstruction losses: 0.06016288716689994, regression losses: 0.1723068606788792, validation losses: 0.7655185222646361\n",
      "Epoch 887, reconstruction losses: 0.05809705939599974, regression losses: 0.17002633033072279, validation losses: 0.5797538909110324\n",
      "Epoch 888, reconstruction losses: 0.053021065014080465, regression losses: 0.17252445286237653, validation losses: 0.6799853640524758\n",
      "Epoch 889, reconstruction losses: 0.049613082713341694, regression losses: 0.22265747492195598, validation losses: 0.566472113118314\n",
      "Epoch 890, reconstruction losses: 0.046078424128197355, regression losses: 0.16802012502726155, validation losses: 0.6776554441166293\n",
      "Epoch 891, reconstruction losses: 0.05087196861334681, regression losses: 0.16718184993157673, validation losses: 0.5021659189041888\n",
      "Epoch 892, reconstruction losses: 0.051364317916796305, regression losses: 0.1922520365893858, validation losses: 0.5649451526876841\n",
      "Epoch 893, reconstruction losses: 0.047547723790351916, regression losses: 0.16262148000746895, validation losses: 0.5743838945834754\n",
      "Epoch 894, reconstruction losses: 0.04984462097444834, regression losses: 0.17787565512482706, validation losses: 0.8004059644148926\n",
      "Epoch 895, reconstruction losses: 0.05209701072322727, regression losses: 0.15738868432140427, validation losses: 0.5259965647769039\n",
      "Epoch 896, reconstruction losses: 0.048600093481246165, regression losses: 0.1201391303310482, validation losses: 0.5008783609730199\n",
      "Epoch 897, reconstruction losses: 0.04957560443867547, regression losses: 0.17083879414071684, validation losses: 0.5399893290415629\n",
      "Epoch 898, reconstruction losses: 0.051824419313529956, regression losses: 0.1455520697785436, validation losses: 0.847991629091725\n",
      "Epoch 899, reconstruction losses: 0.049124136263514875, regression losses: 0.316537023385135, validation losses: 0.5869372766776784\n",
      "Epoch 900, reconstruction losses: 0.05123795663255799, regression losses: 0.2038091819298227, validation losses: 0.8419523429937923\n",
      "Epoch 901, reconstruction losses: 0.050488278562097186, regression losses: 0.17205722838052578, validation losses: 0.6076467179590567\n",
      "Epoch 902, reconstruction losses: 0.04927301384156395, regression losses: 0.14907294835341833, validation losses: 0.6869434747676002\n",
      "Epoch 903, reconstruction losses: 0.04733599582352601, regression losses: 0.2139323081656584, validation losses: 0.48410284563152095\n",
      "Epoch 904, reconstruction losses: 0.053023117905581535, regression losses: 0.15509078475058466, validation losses: 0.6483759635408598\n",
      "Epoch 905, reconstruction losses: 0.04903325063662176, regression losses: 0.14438749692506228, validation losses: 0.5524333016443701\n",
      "Epoch 906, reconstruction losses: 0.0455767789444507, regression losses: 0.1555127343398274, validation losses: 0.8235385769963116\n",
      "Epoch 907, reconstruction losses: 0.046047616027506164, regression losses: 0.12043345644003793, validation losses: 0.6937421433721425\n",
      "Epoch 908, reconstruction losses: 0.047450529562200264, regression losses: 0.19124151343777268, validation losses: 0.6036798643904608\n",
      "Epoch 909, reconstruction losses: 0.04537217479403759, regression losses: 0.14963841846369072, validation losses: 0.6076182044037097\n",
      "Epoch 910, reconstruction losses: 0.04798291557683241, regression losses: 0.15977878363980483, validation losses: 0.5265254419458988\n",
      "Epoch 911, reconstruction losses: 0.05227541483959902, regression losses: 0.1485867263509747, validation losses: 0.6242292640430542\n",
      "Epoch 912, reconstruction losses: 0.04782711893381518, regression losses: 0.15187392797618, validation losses: 0.5641322006906926\n",
      "Epoch 913, reconstruction losses: 0.05052412690973527, regression losses: 0.1388288531808205, validation losses: 0.520780945275038\n",
      "Epoch 914, reconstruction losses: 0.04890622203147865, regression losses: 0.1203070015858303, validation losses: 0.5067255389294509\n",
      "Epoch 915, reconstruction losses: 0.04678482951181873, regression losses: 0.11192368453014671, validation losses: 0.5652668025801668\n",
      "Epoch 916, reconstruction losses: 0.04672266402336167, regression losses: 0.1294895045149327, validation losses: 0.6524579274268831\n",
      "Epoch 917, reconstruction losses: 0.05159892534184053, regression losses: 0.1524764173072004, validation losses: 0.5665001102539159\n",
      "Epoch 918, reconstruction losses: 0.046442254248947774, regression losses: 0.16532917887791698, validation losses: 0.5601732813821696\n",
      "Epoch 919, reconstruction losses: 0.04957578312684284, regression losses: 0.1610609084215106, validation losses: 0.6547377210953473\n",
      "Epoch 920, reconstruction losses: 0.058382282370815594, regression losses: 0.1975185192998946, validation losses: 0.7116933494087652\n",
      "Epoch 921, reconstruction losses: 0.04855378448274497, regression losses: 0.14983517728559825, validation losses: 0.6215301054457046\n",
      "Epoch 922, reconstruction losses: 0.05040314632901681, regression losses: 0.45739454893763165, validation losses: 0.5611189837600794\n",
      "Epoch 923, reconstruction losses: 0.047979661305911685, regression losses: 0.22380108706084484, validation losses: 1.4962548305932721\n",
      "Epoch 924, reconstruction losses: 0.05194456765362833, regression losses: 0.22039756394091675, validation losses: 0.8918796797871672\n",
      "Epoch 925, reconstruction losses: 0.047674120328202035, regression losses: 0.23641489913080138, validation losses: 0.7904557137226966\n",
      "Epoch 926, reconstruction losses: 0.05209749840930099, regression losses: 0.15603607973155237, validation losses: 0.723173288352161\n",
      "Epoch 927, reconstruction losses: 0.045731479198215, regression losses: 0.1419157364909835, validation losses: 0.5958051516391107\n",
      "Epoch 928, reconstruction losses: 0.0478675890993968, regression losses: 0.19133129543977348, validation losses: 0.5568072331143235\n",
      "Epoch 929, reconstruction losses: 0.050456885179969393, regression losses: 0.40263360011474464, validation losses: 0.6000602710980537\n",
      "Epoch 930, reconstruction losses: 0.047837765712736006, regression losses: 0.14050538289996892, validation losses: 0.9892567304966078\n",
      "Epoch 931, reconstruction losses: 0.04645795068549939, regression losses: 0.16100132380404975, validation losses: 0.6462449055667473\n",
      "Epoch 932, reconstruction losses: 0.052073060249673946, regression losses: 0.1560750562184557, validation losses: 0.6511112265146574\n",
      "Epoch 933, reconstruction losses: 0.0474732568713326, regression losses: 0.21035116492774647, validation losses: 0.6340099001139182\n",
      "Epoch 934, reconstruction losses: 0.046337164111330105, regression losses: 0.19047335309436017, validation losses: 0.7604448893475062\n",
      "Epoch 935, reconstruction losses: 0.050504864392703616, regression losses: 0.31919141517242017, validation losses: 0.9973313251456428\n",
      "Epoch 936, reconstruction losses: 0.052142697164399926, regression losses: 0.3355333098171914, validation losses: 0.8580392324158561\n",
      "Epoch 937, reconstruction losses: 0.057771693147646935, regression losses: 0.1396015516146477, validation losses: 1.081201260427148\n",
      "Epoch 938, reconstruction losses: 0.04732777608163902, regression losses: 0.16644202497098615, validation losses: 0.6080901477947422\n",
      "Epoch 939, reconstruction losses: 0.04801538141243436, regression losses: 0.13418152393037158, validation losses: 0.5738568162869488\n",
      "Epoch 940, reconstruction losses: 0.046063803160667195, regression losses: 0.132965499006527, validation losses: 0.5254448279426931\n",
      "Epoch 941, reconstruction losses: 0.05142899403557493, regression losses: 0.16704238385182824, validation losses: 0.7593188612863154\n",
      "Epoch 942, reconstruction losses: 0.04902180544617182, regression losses: 0.15743410001930863, validation losses: 0.8284068604908632\n",
      "Epoch 943, reconstruction losses: 0.04683292611486527, regression losses: 0.1743946096650391, validation losses: 0.5009224117098245\n",
      "Epoch 944, reconstruction losses: 0.04881217391154702, regression losses: 0.15334911694421588, validation losses: 0.7564319989751501\n",
      "Epoch 945, reconstruction losses: 0.04765938578715148, regression losses: 0.15031250429101575, validation losses: 0.551775440729648\n",
      "Epoch 946, reconstruction losses: 0.04608649331650383, regression losses: 0.1462097581984949, validation losses: 0.5834381052896881\n",
      "Epoch 947, reconstruction losses: 0.0470406117753062, regression losses: 0.16377793233435456, validation losses: 0.580516596269307\n",
      "Epoch 948, reconstruction losses: 0.04732707825518224, regression losses: 0.1562209342010756, validation losses: 0.49159966599223703\n",
      "Epoch 949, reconstruction losses: 0.050161470543683195, regression losses: 0.15109379554400038, validation losses: 0.5106309477343645\n",
      "Epoch 950, reconstruction losses: 0.0476234661196361, regression losses: 0.15175723295829374, validation losses: 0.5506908485268911\n",
      "Epoch 951, reconstruction losses: 0.053197296855317, regression losses: 0.16657498115065297, validation losses: 0.5795692173492799\n",
      "Epoch 952, reconstruction losses: 0.047519737083833904, regression losses: 0.16056614887032794, validation losses: 0.505342226806336\n",
      "Epoch 953, reconstruction losses: 0.04628996543819806, regression losses: 0.1478675167753396, validation losses: 0.6531329470874201\n",
      "Epoch 954, reconstruction losses: 0.0471721378690185, regression losses: 0.1493199176121635, validation losses: 0.5621778492614311\n",
      "Epoch 955, reconstruction losses: 0.046869423348448805, regression losses: 0.18788131590867585, validation losses: 0.5879057315388349\n",
      "Epoch 956, reconstruction losses: 0.0468772973508192, regression losses: 0.13354264211604158, validation losses: 0.704249257427376\n",
      "Epoch 957, reconstruction losses: 0.04761999347600236, regression losses: 0.15536121281907952, validation losses: 0.49216924332096795\n",
      "Epoch 958, reconstruction losses: 0.04668129030681577, regression losses: 0.13284581283073882, validation losses: 0.5302187232939012\n",
      "Epoch 959, reconstruction losses: 0.04968136501208146, regression losses: 0.11727388041827942, validation losses: 0.7997654952679916\n",
      "Epoch 960, reconstruction losses: 0.04836361215391021, regression losses: 0.12819708306077082, validation losses: 0.6098014559047256\n",
      "Epoch 961, reconstruction losses: 0.05243553152316854, regression losses: 0.18559764234056034, validation losses: 0.5929918402395898\n",
      "Epoch 962, reconstruction losses: 0.04786026292952157, regression losses: 0.21027296682790014, validation losses: 0.6432649623124653\n",
      "Epoch 963, reconstruction losses: 0.04812256183293613, regression losses: 0.2371350985100845, validation losses: 0.49260155664031097\n",
      "Epoch 964, reconstruction losses: 0.047155485998248675, regression losses: 0.17007569689784058, validation losses: 0.886181837150958\n",
      "Epoch 965, reconstruction losses: 0.0522468534412044, regression losses: 0.16511856039169467, validation losses: 0.5501099236149201\n",
      "Epoch 966, reconstruction losses: 0.050594848249625075, regression losses: 0.3627243621996047, validation losses: 1.0154002527011092\n",
      "Epoch 967, reconstruction losses: 0.04875091704555022, regression losses: 0.24945128229481864, validation losses: 1.0591541949826357\n",
      "Epoch 968, reconstruction losses: 0.04729596435463365, regression losses: 0.1538432481723628, validation losses: 0.6150422303070032\n",
      "Epoch 969, reconstruction losses: 0.05228610101555177, regression losses: 0.14190148718817241, validation losses: 0.7475542999415317\n",
      "Epoch 970, reconstruction losses: 0.054667015251393565, regression losses: 0.16866748550174093, validation losses: 0.5341968609006142\n",
      "Epoch 971, reconstruction losses: 0.04565085336874091, regression losses: 0.1638659605706906, validation losses: 0.7223221577355973\n",
      "Epoch 972, reconstruction losses: 0.04541661365215389, regression losses: 0.12739006759023166, validation losses: 0.5902142424484429\n",
      "Epoch 973, reconstruction losses: 0.049982620522362915, regression losses: 0.1456562856589828, validation losses: 0.5582941798224986\n",
      "Epoch 974, reconstruction losses: 0.05930277236284387, regression losses: 0.15095479305218096, validation losses: 0.4992399171098497\n",
      "Epoch 975, reconstruction losses: 0.055231388096113665, regression losses: 0.24579003522636375, validation losses: 0.5690692486288353\n",
      "Epoch 976, reconstruction losses: 0.05204936624881465, regression losses: 0.21107252899608048, validation losses: 0.8356476254658273\n",
      "Epoch 977, reconstruction losses: 0.04772420546813168, regression losses: 0.14751171956812684, validation losses: 0.9799983375716277\n",
      "Epoch 978, reconstruction losses: 0.046794889823210326, regression losses: 0.1793636203917689, validation losses: 0.518582088288378\n",
      "Epoch 979, reconstruction losses: 0.052108340100864625, regression losses: 0.1631403047349171, validation losses: 0.5260986651005973\n",
      "Epoch 980, reconstruction losses: 0.04994186913756547, regression losses: 0.1326879459850478, validation losses: 0.7411351631359998\n",
      "Epoch 981, reconstruction losses: 0.05168952056653562, regression losses: 0.13198385834679324, validation losses: 0.640469147474077\n",
      "Epoch 982, reconstruction losses: 0.04708258709109682, regression losses: 0.20714668468895792, validation losses: 0.5035665345226917\n",
      "Epoch 983, reconstruction losses: 0.04897898180667981, regression losses: 0.14356628947698058, validation losses: 0.6267962804933357\n",
      "Epoch 984, reconstruction losses: 0.04655452891245784, regression losses: 0.14440022386187976, validation losses: 0.5109943296353447\n",
      "Epoch 985, reconstruction losses: 0.048909109724534314, regression losses: 0.1378862533692043, validation losses: 0.6071020335415166\n",
      "Epoch 986, reconstruction losses: 0.049972559292132894, regression losses: 0.13985511974166928, validation losses: 0.6309587888745306\n",
      "Epoch 987, reconstruction losses: 0.04617044483446063, regression losses: 0.15135632967234441, validation losses: 0.5795122686066395\n",
      "Epoch 988, reconstruction losses: 0.04863879907127376, regression losses: 0.12379231292153471, validation losses: 0.5882251993957575\n",
      "Epoch 989, reconstruction losses: 0.05306475357840566, regression losses: 0.17400816412654657, validation losses: 0.6066291941251618\n",
      "Epoch 990, reconstruction losses: 0.048123160713054405, regression losses: 0.16548954574213498, validation losses: 0.603632271043368\n",
      "Epoch 991, reconstruction losses: 0.048350946436880336, regression losses: 0.16700864862070158, validation losses: 0.6114133993855024\n",
      "Epoch 992, reconstruction losses: 0.046457549108280094, regression losses: 0.13257321053401036, validation losses: 0.5760323460726636\n",
      "Epoch 993, reconstruction losses: 0.047159045518158076, regression losses: 0.17390720945852728, validation losses: 0.5575147591372052\n",
      "Epoch 994, reconstruction losses: 0.04693971372712254, regression losses: 0.17029667218879063, validation losses: 0.6709327989958693\n",
      "Epoch 995, reconstruction losses: 0.048713250782169065, regression losses: 0.12705219364695977, validation losses: 0.4832779307025845\n",
      "Epoch 996, reconstruction losses: 0.046616425577829426, regression losses: 0.22311247935940992, validation losses: 0.5605079664873862\n",
      "Epoch 997, reconstruction losses: 0.053047285738118295, regression losses: 0.17365339314672554, validation losses: 0.9139372667990217\n",
      "Epoch 998, reconstruction losses: 0.05349737510511543, regression losses: 0.14467474157694052, validation losses: 0.7514567920136679\n",
      "Epoch 999, reconstruction losses: 0.04861093533399888, regression losses: 0.13960649462525992, validation losses: 0.5153337555566059\n",
      "Epoch 1000, reconstruction losses: 0.04641930032919205, regression losses: 0.1365808118506198, validation losses: 0.5472507375698217\n",
      "Epoch 1001, reconstruction losses: 0.04833325796798603, regression losses: 0.12944088096915127, validation losses: 0.6411973626514865\n",
      "Epoch 1002, reconstruction losses: 0.04780734060678658, regression losses: 0.1100967286320782, validation losses: 0.5684749911054068\n",
      "Epoch 1003, reconstruction losses: 0.04703728489281737, regression losses: 0.14838275203506196, validation losses: 0.5413211093120803\n",
      "Epoch 1004, reconstruction losses: 0.05299189030278941, regression losses: 0.185626252354959, validation losses: 0.5276741732765363\n",
      "Epoch 1005, reconstruction losses: 0.04908582894903014, regression losses: 0.1403986004597368, validation losses: 0.5881364900685071\n",
      "Epoch 1006, reconstruction losses: 0.04884556726757263, regression losses: 0.16755134210754646, validation losses: 0.5362545497121538\n",
      "Epoch 1007, reconstruction losses: 0.050689040391428714, regression losses: 0.10833485210935889, validation losses: 0.8043410617030191\n",
      "Epoch 1008, reconstruction losses: 0.04607478038130438, regression losses: 0.19101319700879826, validation losses: 0.5552176156797675\n",
      "Epoch 1009, reconstruction losses: 0.046224086405901726, regression losses: 0.16258387606526783, validation losses: 0.7406700490943471\n",
      "Epoch 1010, reconstruction losses: 0.05112680352279198, regression losses: 0.1595491263293914, validation losses: 0.5471619754786929\n",
      "Epoch 1011, reconstruction losses: 0.049160257970856394, regression losses: 0.15116206224249212, validation losses: 0.5203708365472302\n",
      "Epoch 1012, reconstruction losses: 0.051839592690294985, regression losses: 0.10959088256735171, validation losses: 0.5704422045996819\n",
      "Epoch 1013, reconstruction losses: 0.04613398387059457, regression losses: 0.15082236143453093, validation losses: 0.5234522619577868\n",
      "Epoch 1014, reconstruction losses: 0.05559544362456581, regression losses: 0.15545309651815567, validation losses: 0.48522836568875527\n",
      "Epoch 1015, reconstruction losses: 0.04827925317207896, regression losses: 0.15381752692149836, validation losses: 0.48829985670447096\n",
      "Epoch 1016, reconstruction losses: 0.05002652715140318, regression losses: 0.16507545788666939, validation losses: 0.6677773610388876\n",
      "Epoch 1017, reconstruction losses: 0.04683142104913556, regression losses: 0.23652717763937225, validation losses: 0.5969623029366462\n",
      "Epoch 1018, reconstruction losses: 0.046278417053956064, regression losses: 0.1415348940486768, validation losses: 0.6480830193412608\n",
      "Epoch 1019, reconstruction losses: 0.05051014025918274, regression losses: 0.1706665262473724, validation losses: 0.5327968482040859\n",
      "Epoch 1020, reconstruction losses: 0.047881403941123585, regression losses: 0.11532751658301708, validation losses: 0.6067894525913426\n",
      "Epoch 1021, reconstruction losses: 0.05637882116529475, regression losses: 0.13123948792458018, validation losses: 0.526510423823505\n",
      "Epoch 1022, reconstruction losses: 0.04577820786144114, regression losses: 0.1413047560136735, validation losses: 0.5714765434971955\n",
      "Epoch 1023, reconstruction losses: 0.04784816232292355, regression losses: 0.13454640153383737, validation losses: 0.6795961162026051\n",
      "Epoch 1024, reconstruction losses: 0.050382922123533645, regression losses: 0.15285635487512214, validation losses: 0.6234260019553272\n",
      "Epoch 1025, reconstruction losses: 0.04774103801828902, regression losses: 0.19289288293868276, validation losses: 0.48487173437955616\n",
      "Epoch 1026, reconstruction losses: 0.051875937920057714, regression losses: 0.153761778033269, validation losses: 0.5278411631276164\n",
      "Epoch 1027, reconstruction losses: 0.04567228835091552, regression losses: 0.15116736528848246, validation losses: 0.712118166634423\n",
      "Epoch 1028, reconstruction losses: 0.05847629290460753, regression losses: 0.14634944879919298, validation losses: 0.5310187445064964\n",
      "Epoch 1029, reconstruction losses: 0.05772573762416916, regression losses: 0.16003750919255136, validation losses: 0.5117801191570116\n",
      "Epoch 1030, reconstruction losses: 0.05101650408921689, regression losses: 0.1561581283955358, validation losses: 0.6075773841192214\n",
      "Epoch 1031, reconstruction losses: 0.05481678889660059, regression losses: 0.15736837257052752, validation losses: 0.6084905267692441\n",
      "Epoch 1032, reconstruction losses: 0.04931229295021749, regression losses: 0.11743775109778667, validation losses: 0.5751918102780512\n",
      "Epoch 1033, reconstruction losses: 0.04839633391476479, regression losses: 0.1307387224483948, validation losses: 0.5149308248148989\n",
      "Epoch 1034, reconstruction losses: 0.04752008842725428, regression losses: 0.16529634875736243, validation losses: 0.568081162376357\n",
      "Epoch 1035, reconstruction losses: 0.0556851425035614, regression losses: 0.13923034324459263, validation losses: 0.5997022812183133\n",
      "Epoch 1036, reconstruction losses: 0.048416874644125314, regression losses: 0.1477693815082572, validation losses: 0.5270779496069427\n",
      "Epoch 1037, reconstruction losses: 0.05098607754437752, regression losses: 0.1467826867849146, validation losses: 0.6642488778066346\n",
      "Epoch 1038, reconstruction losses: 0.04622295654307805, regression losses: 0.21816126308222036, validation losses: 0.544034477434933\n",
      "Epoch 1039, reconstruction losses: 0.05149269856965532, regression losses: 0.1547544854165164, validation losses: 0.6039205767416812\n",
      "Epoch 1040, reconstruction losses: 0.04892829358624928, regression losses: 0.15360967053420013, validation losses: 0.6249937931001569\n",
      "Epoch 1041, reconstruction losses: 0.04676479066730539, regression losses: 0.15775988168854393, validation losses: 0.6540812585584316\n",
      "Epoch 1042, reconstruction losses: 0.05166809877715074, regression losses: 0.1509500255336655, validation losses: 0.4765622647664988\n",
      "Epoch 1043, reconstruction losses: 0.05004810282568732, regression losses: 0.16106328063182215, validation losses: 0.5075512856290104\n",
      "Epoch 1044, reconstruction losses: 0.047912654965202986, regression losses: 0.16471649437880154, validation losses: 0.9102367294371791\n",
      "Epoch 1045, reconstruction losses: 0.05296351303664054, regression losses: 0.17099822312332508, validation losses: 0.5404209273927463\n",
      "Epoch 1046, reconstruction losses: 0.05107942664987299, regression losses: 0.1354665504719933, validation losses: 0.6011707342990247\n",
      "Epoch 1047, reconstruction losses: 0.04580450002566109, regression losses: 0.12859050467273464, validation losses: 0.6011884145017122\n",
      "Epoch 1048, reconstruction losses: 0.05133864418081999, regression losses: 0.2114919422950693, validation losses: 0.6871406234837093\n",
      "Epoch 1049, reconstruction losses: 0.05258513399653635, regression losses: 0.15226299820462474, validation losses: 0.5377317766552526\n",
      "Epoch 1050, reconstruction losses: 0.048422291385328324, regression losses: 0.15422079704790004, validation losses: 0.613901587118594\n",
      "Epoch 1051, reconstruction losses: 0.048995145436492735, regression losses: 0.1603874071662938, validation losses: 0.5898528074940816\n",
      "Epoch 1052, reconstruction losses: 0.047072032298224695, regression losses: 0.16336271021298426, validation losses: 0.6616179872094538\n",
      "Epoch 1053, reconstruction losses: 0.0519085827786706, regression losses: 0.1597286581903482, validation losses: 0.47814956180550244\n",
      "Epoch 1054, reconstruction losses: 0.05080093731250073, regression losses: 0.1775583571242354, validation losses: 0.643689784648274\n",
      "Epoch 1055, reconstruction losses: 0.051900219327358624, regression losses: 0.1805987093321258, validation losses: 0.6823358562799393\n",
      "Epoch 1056, reconstruction losses: 0.04826177582367807, regression losses: 0.11786041761637762, validation losses: 0.4637310460459049\n",
      "Epoch 1057, reconstruction losses: 0.04678374570016778, regression losses: 0.15971711608654918, validation losses: 0.6276034150068475\n",
      "Epoch 1058, reconstruction losses: 0.059945501784436535, regression losses: 0.22877364641489273, validation losses: 0.620845290228642\n",
      "Epoch 1059, reconstruction losses: 0.047710561484651956, regression losses: 0.17197908065263837, validation losses: 0.5559518861746406\n",
      "Epoch 1060, reconstruction losses: 0.04957259374490704, regression losses: 0.16648980575791805, validation losses: 0.53694803806837\n",
      "Epoch 1061, reconstruction losses: 0.05728464490069526, regression losses: 0.14481090941156324, validation losses: 0.799382616410639\n",
      "Epoch 1062, reconstruction losses: 0.04738893859680572, regression losses: 0.15588253465796778, validation losses: 0.4774374313330012\n",
      "Epoch 1063, reconstruction losses: 0.04908918681809859, regression losses: 0.44612039337537146, validation losses: 0.5204528874025834\n",
      "Epoch 1064, reconstruction losses: 0.04689513039453238, regression losses: 0.20688390737179752, validation losses: 1.3842432755956815\n",
      "Epoch 1065, reconstruction losses: 0.04576500322475802, regression losses: 0.2394426671356205, validation losses: 0.6122867034266849\n",
      "Epoch 1066, reconstruction losses: 0.047679788281308755, regression losses: 0.2940603871651869, validation losses: 1.3584047651477222\n",
      "Epoch 1067, reconstruction losses: 0.04702657649867758, regression losses: 0.1822203593288585, validation losses: 0.8231731995471043\n",
      "Epoch 1068, reconstruction losses: 0.050535217778917646, regression losses: 0.17807373422739736, validation losses: 0.5180355583156465\n",
      "Epoch 1069, reconstruction losses: 0.054813596164348125, regression losses: 0.18048207695127527, validation losses: 0.5509594157078811\n",
      "Epoch 1070, reconstruction losses: 0.04827389796953632, regression losses: 0.13451293847907114, validation losses: 0.7076767692641327\n",
      "Epoch 1071, reconstruction losses: 0.04748848979870944, regression losses: 0.17695365859969364, validation losses: 0.5244626275268215\n",
      "Epoch 1072, reconstruction losses: 0.048593866546920224, regression losses: 0.1670125428444751, validation losses: 0.6234967809580404\n",
      "Epoch 1073, reconstruction losses: 0.04772199164242064, regression losses: 0.2962923644475174, validation losses: 0.5732651637671465\n",
      "Epoch 1074, reconstruction losses: 0.04984141107146849, regression losses: 0.13767525757366803, validation losses: 0.5768901705698917\n",
      "Epoch 1075, reconstruction losses: 0.04827946042399652, regression losses: 0.17923239729752316, validation losses: 0.5231510384392897\n",
      "Epoch 1076, reconstruction losses: 0.04740703742746326, regression losses: 0.159552791294789, validation losses: 0.7047501322655176\n",
      "Epoch 1077, reconstruction losses: 0.05764149083397803, regression losses: 0.14622093547817383, validation losses: 0.5601707125467585\n",
      "Epoch 1078, reconstruction losses: 0.0470130572879596, regression losses: 0.14012719218091138, validation losses: 0.5789890837443505\n",
      "Epoch 1079, reconstruction losses: 0.04679700876628493, regression losses: 0.14613643956623917, validation losses: 0.653535014836029\n",
      "Epoch 1080, reconstruction losses: 0.051366484510926694, regression losses: 0.1397546388122517, validation losses: 0.5079584659168003\n",
      "Epoch 1081, reconstruction losses: 0.058367389543326105, regression losses: 0.13980312385712604, validation losses: 0.5144856458316137\n",
      "Epoch 1082, reconstruction losses: 0.048077321299246634, regression losses: 0.26331217761778275, validation losses: 0.5971222016177908\n",
      "Epoch 1083, reconstruction losses: 0.0529017540371557, regression losses: 0.15367586281547718, validation losses: 0.7497129205197901\n",
      "Epoch 1084, reconstruction losses: 0.04919842282698425, regression losses: 0.14822288721984525, validation losses: 0.49008289344451983\n",
      "Epoch 1085, reconstruction losses: 0.04914210314412923, regression losses: 0.12776473363150892, validation losses: 0.4623113735264358\n",
      "Epoch 1086, reconstruction losses: 0.04748003352815088, regression losses: 0.14178236401915795, validation losses: 0.5399225053568917\n",
      "Epoch 1087, reconstruction losses: 0.04988499544027547, regression losses: 0.10986227215227806, validation losses: 0.5567993636629083\n",
      "Epoch 1088, reconstruction losses: 0.048868187545866096, regression losses: 0.14746978927003734, validation losses: 0.5155922437074416\n",
      "Epoch 1089, reconstruction losses: 0.05232395856151162, regression losses: 0.2279725611903649, validation losses: 0.5051271244881118\n",
      "Epoch 1090, reconstruction losses: 0.049685569720097834, regression losses: 0.18482349477518292, validation losses: 0.5575780713904612\n",
      "Epoch 1091, reconstruction losses: 0.04914297993852355, regression losses: 0.14054130988249974, validation losses: 0.8907233484061683\n",
      "Epoch 1092, reconstruction losses: 0.05195806421052637, regression losses: 0.18653336628874276, validation losses: 0.5363009097880482\n",
      "Epoch 1093, reconstruction losses: 0.046486518507271826, regression losses: 0.18218099232892201, validation losses: 0.4862677069602057\n",
      "Epoch 1094, reconstruction losses: 0.04921584018651107, regression losses: 0.14161112761915293, validation losses: 0.8951337821054713\n",
      "Epoch 1095, reconstruction losses: 0.05527952350602775, regression losses: 0.16542232423959308, validation losses: 0.5213137143417645\n",
      "Epoch 1096, reconstruction losses: 0.04795806534808593, regression losses: 0.1473343900323528, validation losses: 0.5441844451900922\n",
      "Epoch 1097, reconstruction losses: 0.05037511678884441, regression losses: 0.1720386356520679, validation losses: 0.4675758102524476\n",
      "Epoch 1098, reconstruction losses: 0.054911104471745395, regression losses: 0.15307319926563526, validation losses: 0.713126816661915\n",
      "Epoch 1099, reconstruction losses: 0.05227490764426655, regression losses: 0.12385622391887116, validation losses: 0.5893901281635744\n",
      "Epoch 1100, reconstruction losses: 0.05021368988853805, regression losses: 0.1610514955621397, validation losses: 0.6251380472676159\n",
      "Epoch 1101, reconstruction losses: 0.05299679790805242, regression losses: 0.21863483462026068, validation losses: 0.6403223377358958\n",
      "Epoch 1102, reconstruction losses: 0.04922562051972272, regression losses: 0.17595441732595152, validation losses: 0.49669712020586443\n",
      "Epoch 1103, reconstruction losses: 0.058736601723877194, regression losses: 0.20551643556393837, validation losses: 0.6257615981994913\n",
      "Epoch 1104, reconstruction losses: 0.04829905646104182, regression losses: 0.16804862495354056, validation losses: 0.8182804930487086\n",
      "Epoch 1105, reconstruction losses: 0.047853297879376824, regression losses: 0.16098073401481358, validation losses: 0.4664311658027519\n",
      "Epoch 1106, reconstruction losses: 0.05869108726949891, regression losses: 0.248856990515932, validation losses: 0.5029549610020293\n",
      "Epoch 1107, reconstruction losses: 0.04843915253278114, regression losses: 0.14464264319989428, validation losses: 0.4840436272967512\n",
      "Epoch 1108, reconstruction losses: 0.057079027826654645, regression losses: 0.16598546329360966, validation losses: 0.560875020836562\n",
      "Epoch 1109, reconstruction losses: 0.05045314551317216, regression losses: 0.3210737031724439, validation losses: 0.6185254099754396\n",
      "Epoch 1110, reconstruction losses: 0.0549871113922904, regression losses: 0.1791668992105959, validation losses: 0.9757380623944196\n",
      "Epoch 1111, reconstruction losses: 0.04665306164470812, regression losses: 0.16426270650663125, validation losses: 0.7579644887117212\n",
      "Epoch 1112, reconstruction losses: 0.050950311686676866, regression losses: 0.17246562202531784, validation losses: 0.554911543267673\n",
      "Epoch 1113, reconstruction losses: 0.05295826540492195, regression losses: 0.15480785172758058, validation losses: 0.600404720402382\n",
      "Epoch 1114, reconstruction losses: 0.04692886848377365, regression losses: 0.2069661539439353, validation losses: 0.813734826654712\n",
      "Epoch 1115, reconstruction losses: 0.049351858137128723, regression losses: 0.23896535853410467, validation losses: 0.712321755083009\n",
      "Epoch 1116, reconstruction losses: 0.05269957575674227, regression losses: 0.16591530969515794, validation losses: 0.8783774279733686\n",
      "Epoch 1117, reconstruction losses: 0.04995676078356017, regression losses: 0.1840819415385886, validation losses: 0.5279999871915524\n",
      "Epoch 1118, reconstruction losses: 0.05877126348682406, regression losses: 0.11718199387755496, validation losses: 0.6600309004700488\n",
      "Epoch 1119, reconstruction losses: 0.05722745425231731, regression losses: 0.16874809527912188, validation losses: 0.5282998211106678\n",
      "Epoch 1120, reconstruction losses: 0.046911957690625714, regression losses: 0.1342393867154685, validation losses: 0.49866594176654155\n",
      "Epoch 1121, reconstruction losses: 0.05507445635860549, regression losses: 0.14614036212910583, validation losses: 0.6162627604432347\n",
      "Epoch 1122, reconstruction losses: 0.04702434018348726, regression losses: 0.15243117111847557, validation losses: 0.5265589619698392\n",
      "Epoch 1123, reconstruction losses: 0.048182944944470396, regression losses: 0.16237893939333375, validation losses: 0.523352897457268\n",
      "Epoch 1124, reconstruction losses: 0.05143650715364165, regression losses: 0.1707251197660012, validation losses: 0.5418686225410161\n",
      "Epoch 1125, reconstruction losses: 0.05134706932945951, regression losses: 0.18931191737175704, validation losses: 0.8380474484097397\n",
      "Epoch 1126, reconstruction losses: 0.05250956439244106, regression losses: 0.16480069614035908, validation losses: 0.4957599316437852\n",
      "Epoch 1127, reconstruction losses: 0.046610206621045494, regression losses: 0.1844665572055804, validation losses: 0.5429526631208752\n",
      "Epoch 1128, reconstruction losses: 0.05903179055223086, regression losses: 0.17707439253461424, validation losses: 0.7304883330974407\n",
      "Epoch 1129, reconstruction losses: 0.048062314032931, regression losses: 0.2499455898252896, validation losses: 0.6620799321689048\n",
      "Epoch 1130, reconstruction losses: 0.050559770568494165, regression losses: 0.19073886098792303, validation losses: 0.8723923674904356\n",
      "Epoch 1131, reconstruction losses: 0.04863630999990024, regression losses: 0.18239828555754808, validation losses: 0.6355124986706364\n",
      "Epoch 1132, reconstruction losses: 0.046120825657388856, regression losses: 0.21894189724021956, validation losses: 1.0150825524555898\n",
      "Epoch 1133, reconstruction losses: 0.04957143191719458, regression losses: 0.17341514537325753, validation losses: 0.6953984257543808\n",
      "Epoch 1134, reconstruction losses: 0.051898188724628175, regression losses: 0.1392060773143922, validation losses: 0.4683013204784686\n",
      "Epoch 1135, reconstruction losses: 0.050703564186014835, regression losses: 0.13672645351480242, validation losses: 0.5120600695357255\n",
      "Epoch 1136, reconstruction losses: 0.04781469855814569, regression losses: 0.18879033841231013, validation losses: 0.5868652618269249\n",
      "Epoch 1137, reconstruction losses: 0.04983206935442862, regression losses: 0.14840179582157006, validation losses: 0.570944544426783\n",
      "Epoch 1138, reconstruction losses: 0.04915425970395543, regression losses: 0.17767703193219103, validation losses: 0.5369986515705225\n",
      "Epoch 1139, reconstruction losses: 0.048939113696630905, regression losses: 0.1760828103461082, validation losses: 0.5626204202716607\n",
      "Epoch 1140, reconstruction losses: 0.04720854093380613, regression losses: 0.14511098833783587, validation losses: 0.6636387206431204\n",
      "Epoch 1141, reconstruction losses: 0.049063283364863555, regression losses: 0.1465805650304341, validation losses: 0.46611727356200944\n",
      "Epoch 1142, reconstruction losses: 0.05310487443788597, regression losses: 0.19050075245376705, validation losses: 0.47133828136525147\n",
      "Epoch 1143, reconstruction losses: 0.04718390823347825, regression losses: 0.1595150327655651, validation losses: 0.5053647492161566\n",
      "Epoch 1144, reconstruction losses: 0.04754271166878776, regression losses: 0.14511995892442403, validation losses: 0.6299500007453195\n",
      "Epoch 1145, reconstruction losses: 0.05282535292780627, regression losses: 0.15030981473793512, validation losses: 0.4629970052333526\n",
      "Epoch 1146, reconstruction losses: 0.056871445056448144, regression losses: 0.21118971959302008, validation losses: 0.4822886104058346\n",
      "Epoch 1147, reconstruction losses: 0.05240565480784705, regression losses: 0.1823530083244113, validation losses: 1.0348977772967094\n",
      "Epoch 1148, reconstruction losses: 0.052754337769530646, regression losses: 0.15395496289331734, validation losses: 0.8538721116880632\n",
      "Epoch 1149, reconstruction losses: 0.051135102600688695, regression losses: 0.12186077377882776, validation losses: 0.5085343665354571\n",
      "Epoch 1150, reconstruction losses: 0.051408638699853064, regression losses: 0.11911429830124193, validation losses: 0.4689562109933664\n",
      "Epoch 1151, reconstruction losses: 0.05119839641479029, regression losses: 0.12409361103953276, validation losses: 0.5552320455388462\n",
      "Epoch 1152, reconstruction losses: 0.05054842496956578, regression losses: 0.4124010884872586, validation losses: 0.6828573768899122\n",
      "Epoch 1153, reconstruction losses: 0.04771326840310012, regression losses: 0.2631381673261677, validation losses: 0.8594214782825226\n",
      "Epoch 1154, reconstruction losses: 0.04865799785756944, regression losses: 0.2887494678927482, validation losses: 1.157292630982314\n",
      "Epoch 1155, reconstruction losses: 0.049718306802631757, regression losses: 0.2485923769169755, validation losses: 0.6384137325853063\n",
      "Epoch 1156, reconstruction losses: 0.04780039315765276, regression losses: 0.19702033116767467, validation losses: 0.861841224685223\n",
      "Epoch 1157, reconstruction losses: 0.04872686581578454, regression losses: 0.26561232337663715, validation losses: 0.9039876978054013\n",
      "Epoch 1158, reconstruction losses: 0.04928159989258453, regression losses: 0.1886168872544674, validation losses: 0.9975855782057568\n",
      "Epoch 1159, reconstruction losses: 0.05240874653137412, regression losses: 0.13540149750001498, validation losses: 0.49308816647840686\n",
      "Epoch 1160, reconstruction losses: 0.04953340783410288, regression losses: 0.1874483990613782, validation losses: 0.5773332849557983\n",
      "Epoch 1161, reconstruction losses: 0.04890969692543382, regression losses: 0.14074606264415232, validation losses: 0.9315546239399426\n",
      "Epoch 1162, reconstruction losses: 0.05067900639561528, regression losses: 0.1637603192993087, validation losses: 0.5931387246752464\n",
      "Epoch 1163, reconstruction losses: 0.055669334885374, regression losses: 0.14198763288102176, validation losses: 0.5199941298928863\n",
      "Epoch 1164, reconstruction losses: 0.04949449723955006, regression losses: 0.17475785450190154, validation losses: 0.5469840224576933\n",
      "Epoch 1165, reconstruction losses: 0.05025969427112788, regression losses: 0.19833847327528492, validation losses: 0.8308988409343387\n",
      "Epoch 1166, reconstruction losses: 0.05695627190158699, regression losses: 0.17519147992765607, validation losses: 0.64173749435457\n",
      "Epoch 1167, reconstruction losses: 0.055119619790133814, regression losses: 0.15707331518863438, validation losses: 0.5679672293079732\n",
      "Epoch 1168, reconstruction losses: 0.05228312801282122, regression losses: 0.17198003054383984, validation losses: 0.6115589959525717\n",
      "Epoch 1169, reconstruction losses: 0.04697111946054418, regression losses: 0.1842903032366528, validation losses: 0.8886810926406267\n",
      "Epoch 1170, reconstruction losses: 0.04766629913902361, regression losses: 0.23613470428513567, validation losses: 0.62408317510518\n",
      "Epoch 1171, reconstruction losses: 0.04896645864929054, regression losses: 0.187810296554613, validation losses: 0.5405989873444522\n",
      "Epoch 1172, reconstruction losses: 0.052333203235141894, regression losses: 0.13139640112642734, validation losses: 0.7081072467298535\n",
      "Epoch 1173, reconstruction losses: 0.04852701772429086, regression losses: 0.13051957203370693, validation losses: 0.5734401797694244\n",
      "Epoch 1174, reconstruction losses: 0.048034410205504946, regression losses: 0.1644267459801557, validation losses: 0.5290770108327947\n",
      "Epoch 1175, reconstruction losses: 0.049409970881321805, regression losses: 0.19115033072980692, validation losses: 0.6155765106780388\n",
      "Epoch 1176, reconstruction losses: 0.04916509491006685, regression losses: 0.15821935686982924, validation losses: 0.6248386750316473\n",
      "Epoch 1177, reconstruction losses: 0.0486439722379913, regression losses: 0.14312610526371977, validation losses: 0.4616131955971879\n",
      "Epoch 1178, reconstruction losses: 0.053030324537611806, regression losses: 0.20639996476859176, validation losses: 0.5052631935017295\n",
      "Epoch 1179, reconstruction losses: 0.05302202640033396, regression losses: 0.12566097976574112, validation losses: 0.4680130627868244\n",
      "Epoch 1180, reconstruction losses: 0.04614218867338198, regression losses: 0.12464730957950972, validation losses: 0.690969391743244\n",
      "Epoch 1181, reconstruction losses: 0.04784291604650797, regression losses: 0.17438001487093924, validation losses: 0.5725206226767173\n",
      "Epoch 1182, reconstruction losses: 0.04718599186828368, regression losses: 0.14493156699998327, validation losses: 0.4675783497362911\n",
      "Epoch 1183, reconstruction losses: 0.04948820523757308, regression losses: 0.12932493890081487, validation losses: 0.5184582023751856\n",
      "Epoch 1184, reconstruction losses: 0.04869684360774488, regression losses: 0.23495979167995723, validation losses: 0.5342808315544715\n",
      "Epoch 1185, reconstruction losses: 0.048150386541489835, regression losses: 0.1638243569242702, validation losses: 0.8511403362822335\n",
      "Epoch 1186, reconstruction losses: 0.04707887587072743, regression losses: 0.16055688265774157, validation losses: 0.451968350152359\n",
      "Epoch 1187, reconstruction losses: 0.046387158636050266, regression losses: 0.19269323969841157, validation losses: 0.5485315293591321\n",
      "Epoch 1188, reconstruction losses: 0.05115899880455706, regression losses: 0.1554219117661292, validation losses: 0.6132163504935151\n",
      "Epoch 1189, reconstruction losses: 0.05022918661575974, regression losses: 0.3335412197507497, validation losses: 0.5464595591276048\n",
      "Epoch 1190, reconstruction losses: 0.053914945979026144, regression losses: 0.19957407351605508, validation losses: 0.9934457521515316\n",
      "Epoch 1191, reconstruction losses: 0.05940367208475683, regression losses: 0.21819553080743936, validation losses: 0.6806501783805816\n",
      "Epoch 1192, reconstruction losses: 0.048441190662268804, regression losses: 0.23857381193234245, validation losses: 0.6208392967099983\n",
      "Epoch 1193, reconstruction losses: 0.04677095811487865, regression losses: 0.3347571063785015, validation losses: 0.5691793629617297\n",
      "Epoch 1194, reconstruction losses: 0.058655630214322546, regression losses: 0.17110185742200784, validation losses: 1.1554418181235067\n",
      "Epoch 1195, reconstruction losses: 0.055698072142255015, regression losses: 0.144587321790283, validation losses: 0.7842452105395503\n",
      "Epoch 1196, reconstruction losses: 0.04615968311875292, regression losses: 0.1346522179487394, validation losses: 0.612136149392515\n",
      "Epoch 1197, reconstruction losses: 0.0480315515364088, regression losses: 0.15884217292265312, validation losses: 0.8367511339517337\n",
      "Epoch 1198, reconstruction losses: 0.04908926712268477, regression losses: 0.16045126416171812, validation losses: 0.6505423776385126\n",
      "Epoch 1199, reconstruction losses: 0.052235144509216604, regression losses: 0.10286520124210759, validation losses: 0.5111465354883876\n",
      "Epoch 1200, reconstruction losses: 0.05240468880074644, regression losses: 0.14796336201789095, validation losses: 0.6034891206941974\n",
      "Epoch 1201, reconstruction losses: 0.04882186289336883, regression losses: 0.1578928342450156, validation losses: 0.49830917353967547\n",
      "Epoch 1202, reconstruction losses: 0.050829778838442294, regression losses: 0.14463253951581415, validation losses: 0.47857191111018405\n",
      "Epoch 1203, reconstruction losses: 0.04762886796623568, regression losses: 0.21228305977661577, validation losses: 0.5719889956169131\n",
      "Epoch 1204, reconstruction losses: 0.047812503284958695, regression losses: 0.15679098255922172, validation losses: 0.5655294273019293\n",
      "Epoch 1205, reconstruction losses: 0.047441032503520136, regression losses: 0.2039142974981714, validation losses: 0.46928187049628894\n",
      "Epoch 1206, reconstruction losses: 0.04896986730056015, regression losses: 0.1275447408552965, validation losses: 0.6569397282059718\n",
      "Epoch 1207, reconstruction losses: 0.0503994539025671, regression losses: 0.13679736401780587, validation losses: 0.5393891605328409\n",
      "Epoch 1208, reconstruction losses: 0.04676895276527094, regression losses: 0.15182635418564452, validation losses: 0.4891984286785538\n",
      "Epoch 1209, reconstruction losses: 0.04851104548328494, regression losses: 0.16482640188196662, validation losses: 0.6689202693823514\n",
      "Epoch 1210, reconstruction losses: 0.04804496052024883, regression losses: 0.14406844048042766, validation losses: 0.6561936178423109\n",
      "Epoch 1211, reconstruction losses: 0.052340050073676, regression losses: 0.2502262561956733, validation losses: 0.6065270056951715\n",
      "Epoch 1212, reconstruction losses: 0.0454633912519421, regression losses: 0.14834680384048157, validation losses: 0.9932241077740273\n",
      "Epoch 1213, reconstruction losses: 0.04882762274665401, regression losses: 0.17492807638785687, validation losses: 0.5019305202957346\n",
      "Epoch 1214, reconstruction losses: 0.048811477083126095, regression losses: 0.13853050859374255, validation losses: 0.48571090617138923\n",
      "Epoch 1215, reconstruction losses: 0.047511366642955244, regression losses: 0.15399002421161143, validation losses: 0.4725032311824955\n",
      "Epoch 1216, reconstruction losses: 0.0501110621921936, regression losses: 0.4175444439135194, validation losses: 0.7848102757695117\n",
      "Epoch 1217, reconstruction losses: 0.04831037457546858, regression losses: 0.1934276627208955, validation losses: 1.2135350246103462\n",
      "Epoch 1218, reconstruction losses: 0.05823877971566942, regression losses: 0.23357596543344117, validation losses: 0.7584486479619503\n",
      "Epoch 1219, reconstruction losses: 0.05863230905886262, regression losses: 0.14220737720963952, validation losses: 0.6740275859482244\n",
      "Epoch 1220, reconstruction losses: 0.04733855412051682, regression losses: 0.19547773146974143, validation losses: 0.5130549666881056\n",
      "Epoch 1221, reconstruction losses: 0.05300563585544679, regression losses: 0.18399316714158456, validation losses: 0.7211013128115193\n",
      "Epoch 1222, reconstruction losses: 0.047443171907415004, regression losses: 0.17607250377379122, validation losses: 0.8112054364729884\n",
      "Epoch 1223, reconstruction losses: 0.04585886007254996, regression losses: 0.18126221815586435, validation losses: 0.7321330147637591\n",
      "Epoch 1224, reconstruction losses: 0.048408170095211825, regression losses: 0.16109841325521473, validation losses: 0.4782398907697244\n",
      "Epoch 1225, reconstruction losses: 0.0482148841232492, regression losses: 0.13051977324178077, validation losses: 0.6058931080762865\n",
      "Epoch 1226, reconstruction losses: 0.04901966292394815, regression losses: 0.13970193438689346, validation losses: 0.7174597657744003\n",
      "Epoch 1227, reconstruction losses: 0.04738290533693643, regression losses: 0.14603808982077124, validation losses: 0.5408480124926068\n",
      "Epoch 1228, reconstruction losses: 0.04997719833591951, regression losses: 0.16066751873641577, validation losses: 0.47158946388846923\n",
      "Epoch 1229, reconstruction losses: 0.049806216636230395, regression losses: 0.14315832242967294, validation losses: 0.48240974590039604\n",
      "Epoch 1230, reconstruction losses: 0.05177418398603891, regression losses: 0.13198447842308325, validation losses: 0.5523188446756205\n",
      "Epoch 1231, reconstruction losses: 0.051215185923996265, regression losses: 0.16922647831984097, validation losses: 0.5161730677461408\n",
      "Epoch 1232, reconstruction losses: 0.04834879284969218, regression losses: 0.16781013557174818, validation losses: 0.5142575694826126\n",
      "Epoch 1233, reconstruction losses: 0.05062858621067708, regression losses: 0.1753729141515837, validation losses: 0.49621984192521046\n",
      "Epoch 1234, reconstruction losses: 0.046472518260730324, regression losses: 0.14544377482214468, validation losses: 0.601736991349793\n",
      "Epoch 1235, reconstruction losses: 0.05234227430161806, regression losses: 0.16864570143221477, validation losses: 0.6778119435969235\n",
      "Epoch 1236, reconstruction losses: 0.046288098568957776, regression losses: 0.17261868287023185, validation losses: 0.6279949686138004\n",
      "Epoch 1237, reconstruction losses: 0.05270654577496515, regression losses: 0.1564865710735481, validation losses: 0.45584842993056435\n",
      "Epoch 1238, reconstruction losses: 0.05111926241905768, regression losses: 0.13494560170528744, validation losses: 0.4586015685723786\n",
      "Epoch 1239, reconstruction losses: 0.04695455706551385, regression losses: 0.14388479195143564, validation losses: 0.6118406884744083\n",
      "Epoch 1240, reconstruction losses: 0.051835907612311244, regression losses: 0.14376314273595445, validation losses: 0.6605566960587236\n",
      "Epoch 1241, reconstruction losses: 0.046097164750227744, regression losses: 0.1452194929844089, validation losses: 0.6003931713590649\n",
      "Epoch 1242, reconstruction losses: 0.04678500878361263, regression losses: 0.14338576801403094, validation losses: 0.5459287522430359\n",
      "Epoch 1243, reconstruction losses: 0.05648151112232924, regression losses: 0.15950007263311022, validation losses: 0.5351071174314813\n",
      "Epoch 1244, reconstruction losses: 0.0476201480369066, regression losses: 0.21020750725976106, validation losses: 0.6095516224628694\n",
      "Epoch 1245, reconstruction losses: 0.04562727294944626, regression losses: 0.16642386123130087, validation losses: 0.6849667895828238\n",
      "Epoch 1246, reconstruction losses: 0.04764148483956928, regression losses: 0.1175479090011491, validation losses: 0.6113566913612138\n",
      "Epoch 1247, reconstruction losses: 0.05308671813439978, regression losses: 0.19706676875655857, validation losses: 0.6240556109261427\n",
      "Epoch 1248, reconstruction losses: 0.04623075340850642, regression losses: 0.16584260198581474, validation losses: 0.5630065101329681\n",
      "Epoch 1249, reconstruction losses: 0.046905801099819566, regression losses: 0.14376630346452487, validation losses: 0.4877689504631341\n",
      "Epoch 1250, reconstruction losses: 0.046777080089477466, regression losses: 0.1433179018497779, validation losses: 0.4645760582453314\n",
      "Epoch 1251, reconstruction losses: 0.04932673114724165, regression losses: 0.12608778857813419, validation losses: 0.6769383222252149\n",
      "Epoch 1252, reconstruction losses: 0.05276896805593592, regression losses: 0.166872586819697, validation losses: 0.547670960708502\n",
      "Epoch 1253, reconstruction losses: 0.05703468538753771, regression losses: 0.207741452964912, validation losses: 0.5773374398044862\n",
      "Epoch 1254, reconstruction losses: 0.04757989747412532, regression losses: 0.21522707689546994, validation losses: 0.5775704855789747\n",
      "Epoch 1255, reconstruction losses: 0.04777495690424033, regression losses: 0.1524986261342804, validation losses: 0.7228510623928386\n",
      "Epoch 1256, reconstruction losses: 0.051172550426829354, regression losses: 0.15445288910367994, validation losses: 0.9493474596453516\n",
      "Epoch 1257, reconstruction losses: 0.055424916725942006, regression losses: 0.17213644713928147, validation losses: 0.6367874102164214\n",
      "Epoch 1258, reconstruction losses: 0.04876057094368562, regression losses: 0.14536366429878822, validation losses: 0.4947215659270921\n",
      "Epoch 1259, reconstruction losses: 0.04802312749418173, regression losses: 0.17698164608116176, validation losses: 0.4982475294883015\n",
      "Epoch 1260, reconstruction losses: 0.04813324457349038, regression losses: 0.14763943464297793, validation losses: 0.6637777492309025\n",
      "Epoch 1261, reconstruction losses: 0.047963685252835016, regression losses: 0.16405023060245746, validation losses: 0.6432586610504298\n",
      "Epoch 1262, reconstruction losses: 0.04559217937209412, regression losses: 0.15669107267709884, validation losses: 0.5305759506060744\n",
      "Epoch 1263, reconstruction losses: 0.048285303692250446, regression losses: 0.14994343082993897, validation losses: 0.5357858455273252\n",
      "Epoch 1264, reconstruction losses: 0.047132384251833054, regression losses: 0.23099658298333742, validation losses: 0.6894669060900913\n",
      "Epoch 1265, reconstruction losses: 0.04639986574174231, regression losses: 0.14247940576105028, validation losses: 0.4835084049087012\n",
      "Epoch 1266, reconstruction losses: 0.05039920785835866, regression losses: 0.13607794980374854, validation losses: 0.5864467511638451\n",
      "Epoch 1267, reconstruction losses: 0.059065323608326704, regression losses: 0.1737338019369695, validation losses: 0.5895315784236959\n",
      "Epoch 1268, reconstruction losses: 0.047116097338286436, regression losses: 0.196775810638331, validation losses: 0.48531358277072234\n",
      "Epoch 1269, reconstruction losses: 0.047656480817915486, regression losses: 0.18537921445023134, validation losses: 0.5721014542312377\n",
      "Epoch 1270, reconstruction losses: 0.04738185513922175, regression losses: 0.12019196014523646, validation losses: 0.6376264397092537\n",
      "Epoch 1271, reconstruction losses: 0.051301169863125114, regression losses: 0.1169280313933868, validation losses: 0.5862354205497988\n",
      "Epoch 1272, reconstruction losses: 0.045258756270220885, regression losses: 0.14755423661804182, validation losses: 0.5205469487768802\n",
      "Epoch 1273, reconstruction losses: 0.056682242849033185, regression losses: 0.14808514460222744, validation losses: 0.5480659808076438\n",
      "Epoch 1274, reconstruction losses: 0.056414783955486755, regression losses: 0.17177577308609854, validation losses: 0.5278255886754669\n",
      "Epoch 1275, reconstruction losses: 0.05171621905619012, regression losses: 0.10776030557213433, validation losses: 0.6778125895717806\n",
      "Epoch 1276, reconstruction losses: 0.04923196098766796, regression losses: 0.1320430473078993, validation losses: 0.5522438520176177\n",
      "Epoch 1277, reconstruction losses: 0.05158189975769831, regression losses: 0.12673973189177665, validation losses: 0.5107585862390144\n",
      "Epoch 1278, reconstruction losses: 0.04825805404784277, regression losses: 0.1501138430337357, validation losses: 0.5256031797248378\n",
      "Epoch 1279, reconstruction losses: 0.04653615461553947, regression losses: 0.13199858544244403, validation losses: 0.5536502713558342\n",
      "Epoch 1280, reconstruction losses: 0.04868208376331754, regression losses: 0.15284275450481227, validation losses: 0.5066731475530833\n",
      "Epoch 1281, reconstruction losses: 0.04999514692127244, regression losses: 0.11350680654385342, validation losses: 0.6041574092626383\n",
      "Epoch 1282, reconstruction losses: 0.05102483876646136, regression losses: 0.13431029799340924, validation losses: 0.5798813849736919\n",
      "Epoch 1283, reconstruction losses: 0.0473069410612576, regression losses: 0.13805780724108468, validation losses: 0.5282319143242531\n",
      "Epoch 1284, reconstruction losses: 0.04929601561620487, regression losses: 0.13482168557059762, validation losses: 0.4796274335188895\n",
      "Epoch 1285, reconstruction losses: 0.05361846920002858, regression losses: 0.17216061030652574, validation losses: 0.5589001386646482\n",
      "Epoch 1286, reconstruction losses: 0.047810538478028, regression losses: 0.15493267782426176, validation losses: 0.5037820879718891\n",
      "Epoch 1287, reconstruction losses: 0.04572121231395407, regression losses: 0.11628527043779344, validation losses: 0.5552427801707973\n",
      "Epoch 1288, reconstruction losses: 0.04772719158155212, regression losses: 0.13137151010577683, validation losses: 0.5399199338152325\n",
      "Epoch 1289, reconstruction losses: 0.05006449679628309, regression losses: 0.1513337661766179, validation losses: 0.568452166863103\n",
      "Epoch 1290, reconstruction losses: 0.04845971306626765, regression losses: 0.28101949685571725, validation losses: 0.48012846297529305\n",
      "Epoch 1291, reconstruction losses: 0.052030365193760135, regression losses: 0.20866926065957553, validation losses: 0.5237133617026036\n",
      "Epoch 1292, reconstruction losses: 0.048409590925270106, regression losses: 0.13299399315131868, validation losses: 0.7112832736656901\n",
      "Epoch 1293, reconstruction losses: 0.046971691653838236, regression losses: 0.14504931206636107, validation losses: 0.8382722689480993\n",
      "Epoch 1294, reconstruction losses: 0.04684124856533195, regression losses: 0.13568067878837886, validation losses: 0.5239972548763256\n",
      "Epoch 1295, reconstruction losses: 0.047510497686608574, regression losses: 0.17971361021776303, validation losses: 0.5003618378285102\n",
      "Epoch 1296, reconstruction losses: 0.04798725453374991, regression losses: 0.18726508667540254, validation losses: 0.5784185788434866\n",
      "Epoch 1297, reconstruction losses: 0.04822461163812092, regression losses: 0.22586026936952308, validation losses: 0.8048369658705306\n",
      "Epoch 1298, reconstruction losses: 0.05469662558970022, regression losses: 0.1805740687109165, validation losses: 0.47645295575573804\n",
      "Epoch 1299, reconstruction losses: 0.057811999486891585, regression losses: 0.14459558141108664, validation losses: 0.7310836137687995\n",
      "Epoch 1300, reconstruction losses: 0.04707489317883544, regression losses: 0.15645331199477264, validation losses: 0.7069945500243613\n",
      "Epoch 1301, reconstruction losses: 0.04810375316179064, regression losses: 0.26702956289994406, validation losses: 0.516595269539528\n",
      "Epoch 1302, reconstruction losses: 0.04575687311256138, regression losses: 0.19033773546244823, validation losses: 0.7791800376433308\n",
      "Epoch 1303, reconstruction losses: 0.05578719493142614, regression losses: 0.15857930393058672, validation losses: 0.5367959523798153\n",
      "Epoch 1304, reconstruction losses: 0.04758618231879549, regression losses: 0.14335716190124034, validation losses: 0.8115584329624296\n",
      "Epoch 1305, reconstruction losses: 0.05030132949584396, regression losses: 0.17495489080035376, validation losses: 0.7579899635484698\n",
      "Epoch 1306, reconstruction losses: 0.049312270657587254, regression losses: 0.15729676937066525, validation losses: 0.5594885127637518\n",
      "Epoch 1307, reconstruction losses: 0.05313942842019665, regression losses: 0.21323807983299908, validation losses: 0.5520578866118937\n",
      "Epoch 1308, reconstruction losses: 0.04805940355737518, regression losses: 0.1651076041891381, validation losses: 0.9738357309337374\n",
      "Epoch 1309, reconstruction losses: 0.05289682871632419, regression losses: 0.2505119877607972, validation losses: 0.6362723091928897\n",
      "Epoch 1310, reconstruction losses: 0.04895490796163991, regression losses: 0.15802927173040482, validation losses: 0.8432435130104577\n",
      "Epoch 1311, reconstruction losses: 0.047627697787269975, regression losses: 0.19915399430082067, validation losses: 0.48669922836323104\n",
      "Epoch 1312, reconstruction losses: 0.050779965411115104, regression losses: 0.15919423325199092, validation losses: 0.8872096748920975\n",
      "Epoch 1313, reconstruction losses: 0.046887645153402026, regression losses: 0.18315568577536623, validation losses: 0.653662306463043\n",
      "Epoch 1314, reconstruction losses: 0.046840652932039366, regression losses: 0.11942029844733675, validation losses: 0.6181989481440084\n",
      "Epoch 1315, reconstruction losses: 0.05316851989104279, regression losses: 0.25559604187432916, validation losses: 0.4658424428667977\n",
      "Epoch 1316, reconstruction losses: 0.04847032703111623, regression losses: 0.19572510748334462, validation losses: 1.0799210612393804\n",
      "Epoch 1317, reconstruction losses: 0.04860459661186501, regression losses: 0.1585173392837245, validation losses: 0.5287142580148417\n",
      "Epoch 1318, reconstruction losses: 0.05331891183595585, regression losses: 0.14236831918516044, validation losses: 0.5886213503289052\n",
      "Epoch 1319, reconstruction losses: 0.04753576611793494, regression losses: 0.1557549007023666, validation losses: 0.5933214593491881\n",
      "Epoch 1320, reconstruction losses: 0.04563504767158621, regression losses: 0.18127464648092845, validation losses: 0.5313878018963633\n",
      "Epoch 1321, reconstruction losses: 0.045813776741242894, regression losses: 0.11381829554703776, validation losses: 0.6657465818852201\n",
      "Epoch 1322, reconstruction losses: 0.047591892678404996, regression losses: 0.15616982313685612, validation losses: 0.4984008577398423\n",
      "Epoch 1323, reconstruction losses: 0.057476897174724054, regression losses: 0.12736367952190825, validation losses: 0.45445643253230184\n",
      "Epoch 1324, reconstruction losses: 0.04763269501983886, regression losses: 0.12894619956618855, validation losses: 0.563932268520945\n",
      "Epoch 1325, reconstruction losses: 0.04836990865217465, regression losses: 0.11538120150060127, validation losses: 0.7244091898423286\n",
      "Epoch 1326, reconstruction losses: 0.04690329947425666, regression losses: 0.1486159092978779, validation losses: 0.49641236406517986\n",
      "Epoch 1327, reconstruction losses: 0.05233044510530796, regression losses: 0.20629770176227769, validation losses: 0.6354828426854476\n",
      "Epoch 1328, reconstruction losses: 0.05226543095598065, regression losses: 0.1649592830308045, validation losses: 0.6944826490273663\n",
      "Epoch 1329, reconstruction losses: 0.04731769770578217, regression losses: 0.15190353610278376, validation losses: 0.7661225527594262\n",
      "Epoch 1330, reconstruction losses: 0.052532290548677675, regression losses: 0.1347226851159798, validation losses: 0.6879196970917335\n",
      "Epoch 1331, reconstruction losses: 0.053786758328414674, regression losses: 0.11672304793095913, validation losses: 0.45281399822596113\n",
      "Epoch 1332, reconstruction losses: 0.045998839106967386, regression losses: 0.14468937255981862, validation losses: 0.4654637387587553\n",
      "Epoch 1333, reconstruction losses: 0.04893601366410507, regression losses: 0.15491005191021892, validation losses: 0.8253809445698261\n",
      "Epoch 1334, reconstruction losses: 0.0472606747352829, regression losses: 0.14411685620236372, validation losses: 0.4850261036140856\n",
      "Epoch 1335, reconstruction losses: 0.04576542982999829, regression losses: 0.1453817174294007, validation losses: 0.5193061817117288\n",
      "Epoch 1336, reconstruction losses: 0.05030453757476576, regression losses: 0.27570864575176063, validation losses: 0.7367409890013894\n",
      "Epoch 1337, reconstruction losses: 0.04855880651863743, regression losses: 0.16808806926255795, validation losses: 0.8704263994642356\n",
      "Epoch 1338, reconstruction losses: 0.049710221491995575, regression losses: 0.1722175368128303, validation losses: 0.5213354590263282\n",
      "Epoch 1339, reconstruction losses: 0.0527055430856467, regression losses: 0.13055051349397376, validation losses: 0.490546124409277\n",
      "Epoch 1340, reconstruction losses: 0.051999453858771846, regression losses: 0.16442095619511135, validation losses: 0.46653362283358374\n",
      "Epoch 1341, reconstruction losses: 0.0588416058650477, regression losses: 0.1698636538120054, validation losses: 0.5270069665304309\n",
      "Epoch 1342, reconstruction losses: 0.05186863097282102, regression losses: 0.11894337693494073, validation losses: 0.5134502330565238\n",
      "Epoch 1343, reconstruction losses: 0.050879016852834455, regression losses: 0.1574581101910153, validation losses: 0.4601570290943996\n",
      "Epoch 1344, reconstruction losses: 0.048800821048265906, regression losses: 0.1894349323155711, validation losses: 0.48845469627651106\n",
      "Epoch 1345, reconstruction losses: 0.04708856923156465, regression losses: 0.16603527386014177, validation losses: 0.6017958096224443\n",
      "Epoch 1346, reconstruction losses: 0.04628316646942045, regression losses: 0.24020260995320158, validation losses: 0.6937076163756364\n",
      "Epoch 1347, reconstruction losses: 0.04584324070191863, regression losses: 0.1798249262602152, validation losses: 0.921321134512775\n",
      "Epoch 1348, reconstruction losses: 0.04673261093755865, regression losses: 0.19050321908150272, validation losses: 0.7334608386875844\n",
      "Epoch 1349, reconstruction losses: 0.04598571475894188, regression losses: 0.1863422730502022, validation losses: 0.5501092743035199\n",
      "Epoch 1350, reconstruction losses: 0.0479996909628717, regression losses: 0.1893584621484168, validation losses: 0.6452619709786583\n",
      "Epoch 1351, reconstruction losses: 0.044937073128143656, regression losses: 0.18538051016122686, validation losses: 0.5293502358235302\n",
      "Epoch 1352, reconstruction losses: 0.05018581697136589, regression losses: 0.3639453811581211, validation losses: 1.0591334262321097\n",
      "Epoch 1353, reconstruction losses: 0.047620148033393636, regression losses: 0.23518539516136025, validation losses: 0.9943744118875967\n",
      "Epoch 1354, reconstruction losses: 0.04692052165929849, regression losses: 0.16684919472424875, validation losses: 0.7793809607586912\n",
      "Epoch 1355, reconstruction losses: 0.04860383443010102, regression losses: 0.1862775331704403, validation losses: 0.6937091821667131\n",
      "Epoch 1356, reconstruction losses: 0.04800092062508992, regression losses: 0.17914277236417986, validation losses: 0.4893553924981884\n",
      "Epoch 1357, reconstruction losses: 0.052007981847793226, regression losses: 0.1483156252678062, validation losses: 0.7620313947072792\n",
      "Epoch 1358, reconstruction losses: 0.04803722177194081, regression losses: 0.31764092930999077, validation losses: 0.643622178735247\n",
      "Epoch 1359, reconstruction losses: 0.051612886976499454, regression losses: 0.1860900125299166, validation losses: 0.6876017996300182\n",
      "Epoch 1360, reconstruction losses: 0.04644243675736634, regression losses: 0.11908346944076942, validation losses: 0.4518532296658682\n",
      "Epoch 1361, reconstruction losses: 0.047122839043377676, regression losses: 0.16033822990631852, validation losses: 0.696688481213418\n",
      "Epoch 1362, reconstruction losses: 0.04943496232976476, regression losses: 0.20017241360827132, validation losses: 0.7501655371644665\n",
      "Epoch 1363, reconstruction losses: 0.050138242897705985, regression losses: 0.11413247190310233, validation losses: 0.6376769610116818\n",
      "Epoch 1364, reconstruction losses: 0.05002843077031551, regression losses: 0.16058246507488724, validation losses: 0.45755527766574816\n",
      "Epoch 1365, reconstruction losses: 0.048729507651062674, regression losses: 0.1480691705342944, validation losses: 0.5694111853552459\n",
      "Epoch 1366, reconstruction losses: 0.05154114920180343, regression losses: 0.15525809623233933, validation losses: 0.7172805832960751\n",
      "Epoch 1367, reconstruction losses: 0.04973737429189157, regression losses: 0.14205140181841727, validation losses: 0.5989695314593502\n",
      "Epoch 1368, reconstruction losses: 0.04870273972624956, regression losses: 0.2438528754631669, validation losses: 0.4779905571910166\n",
      "Epoch 1369, reconstruction losses: 0.04702093262101046, regression losses: 0.18662501596999623, validation losses: 0.6623507134202057\n",
      "Epoch 1370, reconstruction losses: 0.04935568248465535, regression losses: 0.1232727407323037, validation losses: 0.6151026523733246\n",
      "Epoch 1371, reconstruction losses: 0.04945833559017913, regression losses: 0.26950795200115335, validation losses: 0.6818511546400776\n",
      "Epoch 1372, reconstruction losses: 0.048286401710183904, regression losses: 0.17398231933741862, validation losses: 0.8324140207610056\n",
      "Epoch 1373, reconstruction losses: 0.04907956037446112, regression losses: 0.16743896931762894, validation losses: 0.4582242559782575\n",
      "Epoch 1374, reconstruction losses: 0.04766220624112436, regression losses: 0.1550894944810986, validation losses: 0.5232798761932944\n",
      "Epoch 1375, reconstruction losses: 0.05063790586899851, regression losses: 0.14046228961879165, validation losses: 0.8505292907097348\n",
      "Epoch 1376, reconstruction losses: 0.0530396801191591, regression losses: 0.16406717050435343, validation losses: 0.5776733661696003\n",
      "Epoch 1377, reconstruction losses: 0.048286739619433416, regression losses: 0.16644978578888986, validation losses: 0.48213717252222527\n",
      "Epoch 1378, reconstruction losses: 0.05127158067440784, regression losses: 0.14563170929780123, validation losses: 0.4796799338300022\n",
      "Epoch 1379, reconstruction losses: 0.047174291551914535, regression losses: 0.16757292802151988, validation losses: 0.610453032661774\n",
      "Epoch 1380, reconstruction losses: 0.04723040894984362, regression losses: 0.13948004314129145, validation losses: 0.6401087497944853\n",
      "Epoch 1381, reconstruction losses: 0.04983655928377643, regression losses: 0.12553274012991536, validation losses: 0.590250468413607\n",
      "Epoch 1382, reconstruction losses: 0.05962107156446875, regression losses: 0.13175551937704708, validation losses: 0.5153659457155505\n",
      "Epoch 1383, reconstruction losses: 0.04689514800072262, regression losses: 0.1552362980102229, validation losses: 0.45942024997663206\n",
      "Epoch 1384, reconstruction losses: 0.04760139299486887, regression losses: 0.1408573079297112, validation losses: 0.5735057977578706\n",
      "Epoch 1385, reconstruction losses: 0.04616962513426724, regression losses: 0.14900524349011127, validation losses: 0.6011256432347194\n",
      "Epoch 1386, reconstruction losses: 0.051929144892475944, regression losses: 0.1714001849695308, validation losses: 0.7170925039350358\n",
      "Epoch 1387, reconstruction losses: 0.05629765455727366, regression losses: 0.1613807107294473, validation losses: 0.7646823282952109\n",
      "Epoch 1388, reconstruction losses: 0.04595123651782228, regression losses: 0.16792220375884093, validation losses: 0.5168876612443246\n",
      "Epoch 1389, reconstruction losses: 0.053061217189429355, regression losses: 0.15132108733808158, validation losses: 0.47072146142648136\n",
      "Epoch 1390, reconstruction losses: 0.04685654026033436, regression losses: 0.21075031386896664, validation losses: 0.5609758683210062\n",
      "Epoch 1391, reconstruction losses: 0.05752403879044311, regression losses: 0.15001808369123334, validation losses: 0.5657493157832749\n",
      "Epoch 1392, reconstruction losses: 0.04701162832031418, regression losses: 0.16076811875323904, validation losses: 0.464257368798922\n",
      "Epoch 1393, reconstruction losses: 0.048775458851477785, regression losses: 0.15180014626622845, validation losses: 0.647519605455771\n",
      "Epoch 1394, reconstruction losses: 0.04553004629614263, regression losses: 0.1395266135061513, validation losses: 0.5160234829276846\n",
      "Epoch 1395, reconstruction losses: 0.04800271751018321, regression losses: 0.13835780584003027, validation losses: 0.5269738206721067\n",
      "Epoch 1396, reconstruction losses: 0.04683503211789622, regression losses: 0.15177349933131956, validation losses: 0.6250260995924899\n",
      "Epoch 1397, reconstruction losses: 0.04916850598585181, regression losses: 0.15074321870389376, validation losses: 0.6025035153071143\n",
      "Epoch 1398, reconstruction losses: 0.04625911260432524, regression losses: 0.13617521233210117, validation losses: 0.5196889904732713\n",
      "Epoch 1399, reconstruction losses: 0.04704667226720656, regression losses: 0.15015558260166462, validation losses: 0.4867327715115107\n",
      "Epoch 1400, reconstruction losses: 0.046850806230954424, regression losses: 0.13557321615166523, validation losses: 0.6113896851886456\n",
      "Epoch 1401, reconstruction losses: 0.052595500999592495, regression losses: 0.12349848210299899, validation losses: 0.541182437051513\n",
      "Epoch 1402, reconstruction losses: 0.04700469923518167, regression losses: 0.16504051418862598, validation losses: 0.4705490835656422\n",
      "Epoch 1403, reconstruction losses: 0.04536773757987097, regression losses: 0.18273803960092735, validation losses: 0.6609764863568324\n",
      "Epoch 1404, reconstruction losses: 0.04580409402192845, regression losses: 0.18177496691346764, validation losses: 0.7063887992952077\n",
      "Epoch 1405, reconstruction losses: 0.045376886623626225, regression losses: 0.21519293916314552, validation losses: 0.6476720567259227\n",
      "Epoch 1406, reconstruction losses: 0.0528229720657808, regression losses: 0.14612859962201033, validation losses: 0.5410266818296213\n",
      "Epoch 1407, reconstruction losses: 0.04508196423167237, regression losses: 0.12641011960422752, validation losses: 0.4878678614011488\n",
      "Epoch 1408, reconstruction losses: 0.04926922985972429, regression losses: 0.14315737184529884, validation losses: 0.7524671901231245\n",
      "Epoch 1409, reconstruction losses: 0.05150480562281007, regression losses: 0.12963537103681155, validation losses: 0.710165234514285\n",
      "Epoch 1410, reconstruction losses: 0.05072564773838212, regression losses: 0.16611098884470982, validation losses: 0.5334620091980723\n",
      "Epoch 1411, reconstruction losses: 0.049704298291778776, regression losses: 0.14371276300981298, validation losses: 0.5176854849106023\n",
      "Epoch 1412, reconstruction losses: 0.046169256736407024, regression losses: 0.13033643648126006, validation losses: 0.5286609438695976\n",
      "Epoch 1413, reconstruction losses: 0.050183383178214046, regression losses: 0.13614119609732264, validation losses: 0.5372918644133491\n",
      "Epoch 1414, reconstruction losses: 0.04866577135710751, regression losses: 0.14264888366187461, validation losses: 0.5197593879175308\n",
      "Epoch 1415, reconstruction losses: 0.05712690141972222, regression losses: 0.1391156848718323, validation losses: 0.5392025664073461\n",
      "Epoch 1416, reconstruction losses: 0.05238736614583756, regression losses: 0.17415581498632665, validation losses: 0.4929769119911459\n",
      "Epoch 1417, reconstruction losses: 0.05206953011323809, regression losses: 0.11415771115887155, validation losses: 0.4598707877771163\n",
      "Epoch 1418, reconstruction losses: 0.047065045332489966, regression losses: 0.13859544284944877, validation losses: 0.4957747010624412\n",
      "Epoch 1419, reconstruction losses: 0.04871361467780818, regression losses: 0.1553241477872993, validation losses: 0.44844839816388116\n",
      "Epoch 1420, reconstruction losses: 0.04798023779565985, regression losses: 0.12399493792178086, validation losses: 0.5814928746038611\n",
      "Epoch 1421, reconstruction losses: 0.049748269051459126, regression losses: 0.1360051804416418, validation losses: 0.5837651148324257\n",
      "Epoch 1422, reconstruction losses: 0.04657054827224803, regression losses: 0.14613088871506835, validation losses: 0.6125128402843935\n",
      "Epoch 1423, reconstruction losses: 0.05095119007402242, regression losses: 0.15140950684326654, validation losses: 0.45605550146750096\n",
      "Epoch 1424, reconstruction losses: 0.04972648343114626, regression losses: 0.22909500135398483, validation losses: 0.47336368075257085\n",
      "Epoch 1425, reconstruction losses: 0.05272195057593063, regression losses: 0.13292482988292273, validation losses: 0.8632056913383381\n",
      "Epoch 1426, reconstruction losses: 0.05033087562043978, regression losses: 0.14561072161703706, validation losses: 0.4681414471532718\n",
      "Epoch 1427, reconstruction losses: 0.04798490438194217, regression losses: 0.14743207447026843, validation losses: 0.5210423581171593\n",
      "Epoch 1428, reconstruction losses: 0.04961248882775201, regression losses: 0.13599479956473715, validation losses: 0.6177546692293588\n",
      "Epoch 1429, reconstruction losses: 0.04640105544739204, regression losses: 0.1729663924562228, validation losses: 0.7626210317064998\n",
      "Epoch 1430, reconstruction losses: 0.04665049163936801, regression losses: 0.16386094404615978, validation losses: 0.5138013264083313\n",
      "Epoch 1431, reconstruction losses: 0.052770986964625795, regression losses: 0.15715583098246394, validation losses: 0.506749339458603\n",
      "Epoch 1432, reconstruction losses: 0.04620130582282382, regression losses: 0.288237354148804, validation losses: 0.4997759314490441\n",
      "Epoch 1433, reconstruction losses: 0.05233583706875379, regression losses: 0.18854790467887267, validation losses: 1.4520090311810145\n",
      "Epoch 1434, reconstruction losses: 0.047909057986810756, regression losses: 0.2265866238500834, validation losses: 0.670166071978691\n",
      "Epoch 1435, reconstruction losses: 0.0518765899502701, regression losses: 0.17933240802904502, validation losses: 0.6104751490603731\n",
      "Epoch 1436, reconstruction losses: 0.04918723828403387, regression losses: 0.138562238348127, validation losses: 0.4738531323712455\n",
      "Epoch 1437, reconstruction losses: 0.0471023937276682, regression losses: 0.13902809977467184, validation losses: 0.7202490313155773\n",
      "Epoch 1438, reconstruction losses: 0.048963045491414406, regression losses: 0.2139788453057427, validation losses: 0.5419815860457338\n",
      "Epoch 1439, reconstruction losses: 0.04545094943935206, regression losses: 0.1479315927194021, validation losses: 0.6732881526845079\n",
      "Epoch 1440, reconstruction losses: 0.04915166939663799, regression losses: 0.15633971646895495, validation losses: 0.4778380629798953\n",
      "Epoch 1441, reconstruction losses: 0.04777269404915643, regression losses: 0.18517645714229464, validation losses: 0.636574164334711\n",
      "Epoch 1442, reconstruction losses: 0.04780031538563394, regression losses: 0.1716301133680226, validation losses: 0.5415822012964561\n",
      "Epoch 1443, reconstruction losses: 0.046798575399187026, regression losses: 0.14555916487451953, validation losses: 0.5397717883364465\n",
      "Epoch 1444, reconstruction losses: 0.048949365558259024, regression losses: 0.14416589288699655, validation losses: 0.5201289744505737\n",
      "Epoch 1445, reconstruction losses: 0.051849609570817905, regression losses: 0.167148417672984, validation losses: 0.759086949426719\n",
      "Epoch 1446, reconstruction losses: 0.04790150144211783, regression losses: 0.14141792062785918, validation losses: 0.48065663452508545\n",
      "Epoch 1447, reconstruction losses: 0.049228763339367584, regression losses: 0.1390939005535105, validation losses: 0.4683813303822878\n",
      "Epoch 1448, reconstruction losses: 0.047287847741745694, regression losses: 0.14039809226836075, validation losses: 0.5406647217536975\n",
      "Epoch 1449, reconstruction losses: 0.055913014346610834, regression losses: 0.134840764060025, validation losses: 0.6114388827476547\n",
      "Epoch 1450, reconstruction losses: 0.04669261872354463, regression losses: 0.131645740256453, validation losses: 0.4763057487868517\n",
      "Epoch 1451, reconstruction losses: 0.05074465969811408, regression losses: 0.1413216646911935, validation losses: 0.5125100959896493\n",
      "Epoch 1452, reconstruction losses: 0.0507845744522121, regression losses: 0.2128006387473253, validation losses: 0.46325262650154286\n",
      "Epoch 1453, reconstruction losses: 0.050019688102658985, regression losses: 0.17836907552268444, validation losses: 0.5290227420339643\n",
      "Epoch 1454, reconstruction losses: 0.047793181073922726, regression losses: 0.1545187364075723, validation losses: 0.7043782021425068\n",
      "Epoch 1455, reconstruction losses: 0.04756841810931795, regression losses: 0.20061207140897905, validation losses: 0.5556423142058363\n",
      "Epoch 1456, reconstruction losses: 0.05877817776296154, regression losses: 0.13097241204647425, validation losses: 0.4872323519968841\n",
      "Epoch 1457, reconstruction losses: 0.05553592295552366, regression losses: 0.1390496863817121, validation losses: 0.5106167086346225\n",
      "Epoch 1458, reconstruction losses: 0.052286256642863335, regression losses: 0.14529514846420877, validation losses: 0.7562201680524311\n",
      "Epoch 1459, reconstruction losses: 0.05811256312281676, regression losses: 0.17257211385182308, validation losses: 0.5790276717530848\n",
      "Epoch 1460, reconstruction losses: 0.046050538358941004, regression losses: 0.1560692464020026, validation losses: 0.5152703763902001\n",
      "Epoch 1461, reconstruction losses: 0.04604553366255067, regression losses: 0.1015689766853341, validation losses: 0.6303728801893539\n",
      "Epoch 1462, reconstruction losses: 0.052411741851809655, regression losses: 0.17637263490688135, validation losses: 0.7452742304075918\n",
      "Epoch 1463, reconstruction losses: 0.04711324603504635, regression losses: 0.24481358416442556, validation losses: 1.1741097403242227\n",
      "Epoch 1464, reconstruction losses: 0.04924372872790982, regression losses: 0.21144245528408182, validation losses: 0.7358684236624548\n",
      "Epoch 1465, reconstruction losses: 0.04649939174032376, regression losses: 0.18492856052289558, validation losses: 0.517237325937527\n",
      "Epoch 1466, reconstruction losses: 0.052438231550839064, regression losses: 0.16257102876182958, validation losses: 0.5256079715388869\n",
      "Epoch 1467, reconstruction losses: 0.04736499413640631, regression losses: 0.12579252318115275, validation losses: 0.5066396731424193\n",
      "Epoch 1468, reconstruction losses: 0.048038241336541075, regression losses: 0.14653268971974925, validation losses: 0.674264309551653\n",
      "Epoch 1469, reconstruction losses: 0.047757719452488016, regression losses: 0.14773728493772242, validation losses: 0.49121757207391586\n",
      "Epoch 1470, reconstruction losses: 0.04719609833548085, regression losses: 0.15061973438080217, validation losses: 0.45957677642768835\n",
      "Epoch 1471, reconstruction losses: 0.04830693304962699, regression losses: 0.16891024084646267, validation losses: 0.616430281365851\n",
      "Epoch 1472, reconstruction losses: 0.044890438507591016, regression losses: 0.1687478055446879, validation losses: 0.6821130748735056\n",
      "Epoch 1473, reconstruction losses: 0.05015849247227307, regression losses: 0.3445211589501273, validation losses: 0.6929911834049572\n",
      "Epoch 1474, reconstruction losses: 0.05014227981816273, regression losses: 0.21005930816811447, validation losses: 0.9311543904063858\n",
      "Epoch 1475, reconstruction losses: 0.047758219631570585, regression losses: 0.14883362481081971, validation losses: 0.5945168900774422\n",
      "Epoch 1476, reconstruction losses: 0.04835459564463698, regression losses: 0.16179750094761824, validation losses: 0.5149582630100105\n",
      "Epoch 1477, reconstruction losses: 0.04814258533483628, regression losses: 0.1218771001363258, validation losses: 0.6763941335091614\n",
      "Epoch 1478, reconstruction losses: 0.049045903815098095, regression losses: 0.20924006974557427, validation losses: 0.5833221399635377\n",
      "Epoch 1479, reconstruction losses: 0.052831314479856034, regression losses: 0.17273397981061522, validation losses: 0.7205957438156587\n",
      "Epoch 1480, reconstruction losses: 0.04634391126603045, regression losses: 0.1513717726512518, validation losses: 0.49682592841223755\n",
      "Epoch 1481, reconstruction losses: 0.04892735431966689, regression losses: 0.1404638894945857, validation losses: 0.5357953590923267\n",
      "Epoch 1482, reconstruction losses: 0.04574317327819896, regression losses: 0.1421044654857926, validation losses: 0.6805257059385686\n",
      "Epoch 1483, reconstruction losses: 0.047254294688823605, regression losses: 0.13529921784239515, validation losses: 0.5096555868102466\n",
      "Epoch 1484, reconstruction losses: 0.048052486429791916, regression losses: 0.17730391911589624, validation losses: 0.46859598863016283\n",
      "Epoch 1485, reconstruction losses: 0.046153223304574116, regression losses: 0.17318516780905918, validation losses: 0.6473728083863354\n",
      "Epoch 1486, reconstruction losses: 0.04797737489229098, regression losses: 0.12480346039404114, validation losses: 0.5340395802584064\n",
      "Epoch 1487, reconstruction losses: 0.052401857413775475, regression losses: 0.16438435762430806, validation losses: 0.6088360832521773\n",
      "Epoch 1488, reconstruction losses: 0.047416225590824784, regression losses: 0.1586474797910809, validation losses: 0.6868329686817461\n",
      "Epoch 1489, reconstruction losses: 0.04841342247602645, regression losses: 0.12354975357775355, validation losses: 0.4731735881833904\n",
      "Epoch 1490, reconstruction losses: 0.05126584782841797, regression losses: 0.1307874885112059, validation losses: 0.5102642191895832\n",
      "Epoch 1491, reconstruction losses: 0.05111359872852506, regression losses: 0.16945352692360074, validation losses: 0.6493941666076274\n",
      "Epoch 1492, reconstruction losses: 0.047276649422198995, regression losses: 0.19584891443971827, validation losses: 0.6563822616052852\n",
      "Epoch 1493, reconstruction losses: 0.048292995373660476, regression losses: 0.23430497399550826, validation losses: 0.45581907349631245\n",
      "Epoch 1494, reconstruction losses: 0.050986564601645995, regression losses: 0.13990316009607623, validation losses: 0.7870173747666641\n",
      "Epoch 1495, reconstruction losses: 0.05050876656662273, regression losses: 0.1702198868441482, validation losses: 0.8279495077759418\n",
      "Epoch 1496, reconstruction losses: 0.049711226403851234, regression losses: 0.2320028968010251, validation losses: 0.7544837439613703\n",
      "Epoch 1497, reconstruction losses: 0.045889843865305126, regression losses: 0.16768710912727713, validation losses: 0.5548584523330887\n",
      "Epoch 1498, reconstruction losses: 0.04697647464837471, regression losses: 0.1525205191302784, validation losses: 0.6443051391637128\n",
      "Epoch 1499, reconstruction losses: 0.04730559203601841, regression losses: 0.14998463649888533, validation losses: 0.663212106076408\n",
      "Epoch 1500, reconstruction losses: 0.04828505411309989, regression losses: 0.13157844608047647, validation losses: 0.6263323166863438\n",
      "Epoch 1501, reconstruction losses: 0.048633082271316276, regression losses: 0.17238336543601143, validation losses: 0.49000030580006\n",
      "Epoch 1502, reconstruction losses: 0.04725639982859659, regression losses: 0.1423438561032955, validation losses: 0.46893345312259094\n",
      "Epoch 1503, reconstruction losses: 0.04545889133479621, regression losses: 0.17330918123546174, validation losses: 0.6895733038222113\n",
      "Epoch 1504, reconstruction losses: 0.05035193942646326, regression losses: 0.6257910397029174, validation losses: 0.511552300083268\n",
      "Epoch 1505, reconstruction losses: 0.04894318194578238, regression losses: 0.26154226749765797, validation losses: 0.8781127103230485\n",
      "Epoch 1506, reconstruction losses: 0.04774501355462794, regression losses: 0.1287982950570443, validation losses: 0.782514788986949\n",
      "Epoch 1507, reconstruction losses: 0.04843360159970907, regression losses: 0.17914927410096754, validation losses: 0.7187142984625725\n",
      "Epoch 1508, reconstruction losses: 0.048263397020511425, regression losses: 0.1281590432093403, validation losses: 0.476203064619468\n",
      "Epoch 1509, reconstruction losses: 0.045778675425346145, regression losses: 0.15587789575793543, validation losses: 0.5406682238179424\n",
      "Epoch 1510, reconstruction losses: 0.05123480873129742, regression losses: 0.16204016420720585, validation losses: 0.6838958778250526\n",
      "Epoch 1511, reconstruction losses: 0.04612724997511817, regression losses: 0.14798534222414592, validation losses: 0.6762653234400291\n",
      "Epoch 1512, reconstruction losses: 0.049005202831423615, regression losses: 0.17507904512470704, validation losses: 0.48964022995424716\n",
      "Epoch 1513, reconstruction losses: 0.04893397116575569, regression losses: 0.18799461354935842, validation losses: 0.6626029282199599\n",
      "Epoch 1514, reconstruction losses: 0.04704023096106209, regression losses: 0.1696300094063819, validation losses: 0.58646263404602\n",
      "Epoch 1515, reconstruction losses: 0.04838379870764163, regression losses: 0.12799678214995078, validation losses: 0.5442714576460834\n",
      "Epoch 1516, reconstruction losses: 0.053555661489318535, regression losses: 0.20791694827703033, validation losses: 0.5473821550586104\n",
      "Epoch 1517, reconstruction losses: 0.04629228505325279, regression losses: 0.11641864760144036, validation losses: 0.5232492154203179\n",
      "Epoch 1518, reconstruction losses: 0.046893514745962726, regression losses: 0.14110818965253977, validation losses: 0.4485723273129475\n",
      "Epoch 1519, reconstruction losses: 0.04680843848681421, regression losses: 0.245883109764836, validation losses: 0.6419219815226306\n",
      "Epoch 1520, reconstruction losses: 0.055790655738970574, regression losses: 0.13859280973586566, validation losses: 0.5591551818520248\n",
      "Epoch 1521, reconstruction losses: 0.050719910817558896, regression losses: 0.12769766960363166, validation losses: 0.4473758427072597\n",
      "Epoch 1522, reconstruction losses: 0.055034967081275796, regression losses: 0.1271925359946234, validation losses: 0.4516875290165799\n",
      "Epoch 1523, reconstruction losses: 0.049755355625049964, regression losses: 0.13752358941962936, validation losses: 0.46326730723929455\n",
      "Epoch 1524, reconstruction losses: 0.04700251151544862, regression losses: 0.14333131657566733, validation losses: 0.49025471553902944\n",
      "Epoch 1525, reconstruction losses: 0.04903100968887096, regression losses: 0.12784326420805203, validation losses: 0.5458378653889607\n",
      "Epoch 1526, reconstruction losses: 0.0504537818445817, regression losses: 0.12532951171355983, validation losses: 0.5539031037159952\n",
      "Epoch 1527, reconstruction losses: 0.046837140210350584, regression losses: 0.11810616932768171, validation losses: 0.4873538235997248\n",
      "Epoch 1528, reconstruction losses: 0.05916098601433693, regression losses: 0.1278621213197519, validation losses: 0.5920219596733265\n",
      "Epoch 1529, reconstruction losses: 0.04616529511081842, regression losses: 0.1466463799211534, validation losses: 0.535232204216117\n",
      "Epoch 1530, reconstruction losses: 0.04808304064538909, regression losses: 0.24590776233099193, validation losses: 0.6252752633720928\n",
      "Epoch 1531, reconstruction losses: 0.050159742418920364, regression losses: 0.1648679568371244, validation losses: 0.6291019283315025\n",
      "Epoch 1532, reconstruction losses: 0.05142706623078489, regression losses: 0.17347691860760142, validation losses: 0.6276317386332645\n",
      "Epoch 1533, reconstruction losses: 0.04735571790365554, regression losses: 0.14171498994044537, validation losses: 0.6194079405485767\n",
      "Epoch 1534, reconstruction losses: 0.049648293701107224, regression losses: 0.14982479931427922, validation losses: 0.5622126454658003\n",
      "Epoch 1535, reconstruction losses: 0.04688891386914968, regression losses: 0.14094089821917585, validation losses: 0.6617112794605549\n",
      "Epoch 1536, reconstruction losses: 0.04523991359855541, regression losses: 0.18821258036267985, validation losses: 0.6029476163868398\n",
      "Epoch 1537, reconstruction losses: 0.04657658657644936, regression losses: 0.2743275711426648, validation losses: 0.8208366500922984\n",
      "Epoch 1538, reconstruction losses: 0.04633121201213393, regression losses: 0.14352180337954729, validation losses: 0.7610008252901073\n",
      "Epoch 1539, reconstruction losses: 0.04828602317962856, regression losses: 0.19356777149422452, validation losses: 0.5095007666658001\n",
      "Epoch 1540, reconstruction losses: 0.04489368206920418, regression losses: 0.21042098415957722, validation losses: 0.7239583408817751\n",
      "Epoch 1541, reconstruction losses: 0.047696693101736895, regression losses: 0.17917091341156166, validation losses: 1.2608163375707406\n",
      "Epoch 1542, reconstruction losses: 0.04850983345368937, regression losses: 0.19725437779132002, validation losses: 0.7362742132027835\n",
      "Epoch 1543, reconstruction losses: 0.04857549983087568, regression losses: 0.1625122933100219, validation losses: 0.7688672050063071\n",
      "Epoch 1544, reconstruction losses: 0.048463954969847955, regression losses: 0.18794864554125026, validation losses: 0.5034357434840685\n",
      "Epoch 1545, reconstruction losses: 0.04608464606845371, regression losses: 0.15728996300608525, validation losses: 0.5611567597491302\n",
      "Epoch 1546, reconstruction losses: 0.047060421819509875, regression losses: 0.17862264346789955, validation losses: 0.4781218662138956\n",
      "Epoch 1547, reconstruction losses: 0.04983491918653217, regression losses: 0.1999946803896463, validation losses: 0.6258741359575465\n",
      "Epoch 1548, reconstruction losses: 0.04727597522844072, regression losses: 0.14840086612583744, validation losses: 0.5472851735109698\n",
      "Epoch 1549, reconstruction losses: 0.0471291410157444, regression losses: 0.13353475005381282, validation losses: 0.5537058737392075\n",
      "Epoch 1550, reconstruction losses: 0.054905313464114675, regression losses: 0.22252530479372992, validation losses: 0.5513851666217258\n",
      "Epoch 1551, reconstruction losses: 0.04618474302354021, regression losses: 0.1657447461585189, validation losses: 0.43978457865606213\n",
      "Epoch 1552, reconstruction losses: 0.055402567869952776, regression losses: 0.13867174309571356, validation losses: 0.6408994802052034\n",
      "Epoch 1553, reconstruction losses: 0.05184777732546331, regression losses: 0.18413523086417516, validation losses: 0.7665419760195373\n",
      "Epoch 1554, reconstruction losses: 0.048081344938406725, regression losses: 0.1830656996205676, validation losses: 0.5294289616740144\n",
      "Epoch 1555, reconstruction losses: 0.0472696784217548, regression losses: 0.12027174392970708, validation losses: 0.5616749954391191\n",
      "Epoch 1556, reconstruction losses: 0.058921023483297086, regression losses: 0.18413593749449225, validation losses: 0.5458213507451763\n",
      "Epoch 1557, reconstruction losses: 0.0458951670236126, regression losses: 0.1729232746559384, validation losses: 0.5462939552589587\n",
      "Epoch 1558, reconstruction losses: 0.052352546361640245, regression losses: 0.20529032154461901, validation losses: 0.5014249615464939\n",
      "Epoch 1559, reconstruction losses: 0.052629748248476715, regression losses: 0.27653320931564385, validation losses: 0.5673134065849313\n",
      "Epoch 1560, reconstruction losses: 0.05033570391035914, regression losses: 0.12801417726950806, validation losses: 0.5141019144365637\n",
      "Epoch 1561, reconstruction losses: 0.051935285301126566, regression losses: 0.25944933814116516, validation losses: 0.5679972289916335\n",
      "Epoch 1562, reconstruction losses: 0.04632900367617992, regression losses: 0.2191286555643945, validation losses: 1.2556325340618262\n",
      "Epoch 1563, reconstruction losses: 0.047458277325227914, regression losses: 0.17733643396607576, validation losses: 0.6338259153267789\n",
      "Epoch 1564, reconstruction losses: 0.047615312022571514, regression losses: 0.30797552261839856, validation losses: 0.4655602183674486\n",
      "Epoch 1565, reconstruction losses: 0.04545924095602527, regression losses: 0.2143288700167872, validation losses: 0.7378508316891366\n",
      "Epoch 1566, reconstruction losses: 0.0486688758070993, regression losses: 0.15680858366494269, validation losses: 0.5171640673698731\n",
      "Epoch 1567, reconstruction losses: 0.04600593558159586, regression losses: 0.14122505172243618, validation losses: 0.715369740838558\n",
      "Epoch 1568, reconstruction losses: 0.05457603039287349, regression losses: 0.21272905113529483, validation losses: 0.6342893648887662\n",
      "Epoch 1569, reconstruction losses: 0.045892904560772226, regression losses: 0.14817304558535097, validation losses: 0.5121903180398666\n",
      "Epoch 1570, reconstruction losses: 0.04571042182589847, regression losses: 0.1628070195290365, validation losses: 0.525094431651627\n",
      "Epoch 1571, reconstruction losses: 0.058254837531131455, regression losses: 0.11823321507285343, validation losses: 0.6782874881206861\n",
      "Epoch 1572, reconstruction losses: 0.045886046701470166, regression losses: 0.198652894794321, validation losses: 0.5661686359211331\n",
      "Epoch 1573, reconstruction losses: 0.051522105116384505, regression losses: 0.24006483775492685, validation losses: 0.5290454295280136\n",
      "Epoch 1574, reconstruction losses: 0.058662933866279396, regression losses: 0.13384816094587462, validation losses: 0.7067436370987071\n",
      "Epoch 1575, reconstruction losses: 0.05026224810788966, regression losses: 0.15767073100801282, validation losses: 0.5733984160433339\n",
      "Epoch 1576, reconstruction losses: 0.04566052751600995, regression losses: 0.15649612309395497, validation losses: 0.5803740607749999\n",
      "Epoch 1577, reconstruction losses: 0.0454924039966388, regression losses: 0.16640384439690367, validation losses: 0.5896317459712465\n",
      "Epoch 1578, reconstruction losses: 0.04724578906220851, regression losses: 0.11834217166751043, validation losses: 0.7566385728098051\n",
      "Epoch 1579, reconstruction losses: 0.0449259701858064, regression losses: 0.16926615100264353, validation losses: 0.5317802911080719\n",
      "Epoch 1580, reconstruction losses: 0.051574660332960674, regression losses: 0.1892994325575995, validation losses: 0.5105209606937308\n",
      "Epoch 1581, reconstruction losses: 0.04942497558749642, regression losses: 0.20269487187811625, validation losses: 0.5382454307935979\n",
      "Epoch 1582, reconstruction losses: 0.045590444504531105, regression losses: 0.13499117770504138, validation losses: 0.5750498562352124\n",
      "Epoch 1583, reconstruction losses: 0.047705664227148684, regression losses: 0.34337262274470126, validation losses: 0.6494904619394083\n",
      "Epoch 1584, reconstruction losses: 0.051519141148597895, regression losses: 0.15787010832823542, validation losses: 0.6656584355738846\n",
      "Epoch 1585, reconstruction losses: 0.04835053576966496, regression losses: 0.14440399105414994, validation losses: 0.5305984991618412\n",
      "Epoch 1586, reconstruction losses: 0.057416179993872773, regression losses: 0.1760350102683106, validation losses: 0.7352231464455408\n",
      "Epoch 1587, reconstruction losses: 0.04900101839063622, regression losses: 0.16295271811333056, validation losses: 0.48398441938583586\n",
      "Epoch 1588, reconstruction losses: 0.04782944572697592, regression losses: 0.17153510858285914, validation losses: 0.4752130341802096\n",
      "Epoch 1589, reconstruction losses: 0.04873236890973503, regression losses: 0.18372605640342946, validation losses: 0.47938808673736705\n",
      "Epoch 1590, reconstruction losses: 0.04678983393104581, regression losses: 0.14635146012056183, validation losses: 0.5734697754081526\n",
      "Epoch 1591, reconstruction losses: 0.045550934339814414, regression losses: 0.2594800676961593, validation losses: 0.4687401228168433\n",
      "Epoch 1592, reconstruction losses: 0.05864821442378691, regression losses: 0.1489888587719391, validation losses: 0.9309641287660004\n",
      "Epoch 1593, reconstruction losses: 0.0479705504451636, regression losses: 0.1821948942102405, validation losses: 0.6200732029164262\n",
      "Epoch 1594, reconstruction losses: 0.04528245715939034, regression losses: 0.1714983678695528, validation losses: 0.7107873096376959\n",
      "Epoch 1595, reconstruction losses: 0.046436869150811855, regression losses: 0.17853162659494307, validation losses: 0.47776176392280983\n",
      "Epoch 1596, reconstruction losses: 0.04942920463342709, regression losses: 0.15547230897388642, validation losses: 0.5771173399114086\n",
      "Epoch 1597, reconstruction losses: 0.05002640911720253, regression losses: 0.15906010812313034, validation losses: 0.8074707397141393\n",
      "Epoch 1598, reconstruction losses: 0.057995240139895085, regression losses: 0.19525697704316786, validation losses: 0.5753326320445388\n",
      "Epoch 1599, reconstruction losses: 0.04815845317674787, regression losses: 0.13538455742620673, validation losses: 0.460900654040322\n",
      "Epoch 1600, reconstruction losses: 0.04842170457407434, regression losses: 0.13636682605585254, validation losses: 0.5561046812938248\n",
      "Epoch 1601, reconstruction losses: 0.04801368034838948, regression losses: 0.18025329944621044, validation losses: 0.6128358170876\n",
      "Epoch 1602, reconstruction losses: 0.04815427681114352, regression losses: 0.17606504020940023, validation losses: 0.43705069741541264\n",
      "Epoch 1603, reconstruction losses: 0.05028916743126341, regression losses: 0.12863501458477053, validation losses: 0.48169617649062213\n",
      "Epoch 1604, reconstruction losses: 0.04770536390741187, regression losses: 0.16503403965126587, validation losses: 0.5010323411212358\n",
      "Epoch 1605, reconstruction losses: 0.052893014437473, regression losses: 0.1436174228873352, validation losses: 0.6960919940988441\n",
      "Epoch 1606, reconstruction losses: 0.04759104117171287, regression losses: 0.16207309378028179, validation losses: 0.547731250575334\n",
      "Epoch 1607, reconstruction losses: 0.04692066632885699, regression losses: 0.1391597519922806, validation losses: 0.6918030945752581\n",
      "Epoch 1608, reconstruction losses: 0.04808329814405563, regression losses: 0.22240361026250044, validation losses: 0.47679050893466357\n",
      "Epoch 1609, reconstruction losses: 0.045292442603981166, regression losses: 0.11328377241730476, validation losses: 0.5415174970253359\n",
      "Epoch 1610, reconstruction losses: 0.04800614324679381, regression losses: 0.15873103835115449, validation losses: 0.4649284351523691\n",
      "Epoch 1611, reconstruction losses: 0.046136181189576464, regression losses: 0.1409218777642714, validation losses: 0.5495924751857761\n",
      "Epoch 1612, reconstruction losses: 0.04619529572580205, regression losses: 0.15125775412382853, validation losses: 0.5179653510459354\n",
      "Epoch 1613, reconstruction losses: 0.04723329027346772, regression losses: 0.12627675406635291, validation losses: 0.46847866847575403\n",
      "Epoch 1614, reconstruction losses: 0.045258303634083785, regression losses: 0.16285461720021216, validation losses: 0.5447794698832293\n",
      "Epoch 1615, reconstruction losses: 0.04699995950355356, regression losses: 0.1654767875171259, validation losses: 0.45025698250158086\n",
      "Epoch 1616, reconstruction losses: 0.0466016286322006, regression losses: 0.13689976140282714, validation losses: 0.5254330722216898\n",
      "Epoch 1617, reconstruction losses: 0.04787730446272795, regression losses: 0.14535027609424042, validation losses: 0.5992322757537997\n",
      "Epoch 1618, reconstruction losses: 0.05304487285991792, regression losses: 0.17967127685338777, validation losses: 0.5283787319586948\n",
      "Epoch 1619, reconstruction losses: 0.04761916731097338, regression losses: 0.151751687853541, validation losses: 0.4722979727762226\n",
      "Epoch 1620, reconstruction losses: 0.05211994258792901, regression losses: 0.1390789845366526, validation losses: 0.6259351095164771\n",
      "Epoch 1621, reconstruction losses: 0.05082126785022832, regression losses: 0.29570944509153874, validation losses: 0.6664579636255672\n",
      "Epoch 1622, reconstruction losses: 0.048425074791512576, regression losses: 0.21142816978027262, validation losses: 0.8328703862688439\n",
      "Epoch 1623, reconstruction losses: 0.046190077267312564, regression losses: 0.1373485199976427, validation losses: 0.4887751084476196\n",
      "Epoch 1624, reconstruction losses: 0.048354933158156976, regression losses: 0.1742576691188536, validation losses: 0.7131268313389576\n",
      "Epoch 1625, reconstruction losses: 0.04875035710076002, regression losses: 0.17044305851118588, validation losses: 0.5631782225745161\n",
      "Epoch 1626, reconstruction losses: 0.05290501364188774, regression losses: 0.16199727506019157, validation losses: 0.6384988183865666\n",
      "Epoch 1627, reconstruction losses: 0.04648286343624006, regression losses: 0.12193491340482264, validation losses: 0.45047000514778196\n",
      "Epoch 1628, reconstruction losses: 0.04671663450549678, regression losses: 0.1250024105675219, validation losses: 0.4392746782215581\n",
      "Epoch 1629, reconstruction losses: 0.04831514741745527, regression losses: 0.21173344977876773, validation losses: 0.5283533595084411\n",
      "Epoch 1630, reconstruction losses: 0.05228031323944993, regression losses: 0.17598433644061418, validation losses: 0.5852942550608667\n",
      "Epoch 1631, reconstruction losses: 0.051782663094750755, regression losses: 0.12647829453419035, validation losses: 0.7098665556008967\n",
      "Epoch 1632, reconstruction losses: 0.04813961073904984, regression losses: 0.15755702041400688, validation losses: 0.5359731595592591\n",
      "Epoch 1633, reconstruction losses: 0.04848463032187592, regression losses: 0.15398323857588184, validation losses: 0.6175197617791686\n",
      "Epoch 1634, reconstruction losses: 0.04863131269772409, regression losses: 0.13988988690331375, validation losses: 0.44685920023848974\n",
      "Epoch 1635, reconstruction losses: 0.04979775190846516, regression losses: 0.14184946940560142, validation losses: 0.48541463005972874\n",
      "Epoch 1636, reconstruction losses: 0.045577667881677976, regression losses: 0.12350219915098128, validation losses: 0.6793409744883409\n",
      "Epoch 1637, reconstruction losses: 0.04612003293725036, regression losses: 0.11361322506430999, validation losses: 0.6811912615320798\n",
      "Epoch 1638, reconstruction losses: 0.04926078660560676, regression losses: 0.19410620323950067, validation losses: 0.5722944498863705\n",
      "Epoch 1639, reconstruction losses: 0.048125469325952006, regression losses: 0.144036922364507, validation losses: 0.702825803465008\n",
      "Epoch 1640, reconstruction losses: 0.05133095058756178, regression losses: 0.11706618411410694, validation losses: 0.49771761645108914\n",
      "Epoch 1641, reconstruction losses: 0.05130930127598305, regression losses: 0.1564483236195918, validation losses: 0.4576960721902878\n",
      "Epoch 1642, reconstruction losses: 0.046107735393193454, regression losses: 0.13039915617087763, validation losses: 0.5472630566273244\n",
      "Epoch 1643, reconstruction losses: 0.04775819693111499, regression losses: 0.14373668226493724, validation losses: 0.5477293295943654\n",
      "Epoch 1644, reconstruction losses: 0.04510977891809301, regression losses: 0.14255955353894542, validation losses: 0.6028498108409033\n",
      "Epoch 1645, reconstruction losses: 0.05113688908731799, regression losses: 0.13485294498689707, validation losses: 0.5317120363747401\n",
      "Epoch 1646, reconstruction losses: 0.04638505726429894, regression losses: 0.12663540733017617, validation losses: 0.5771333298550947\n",
      "Epoch 1647, reconstruction losses: 0.045965592234992046, regression losses: 0.17195826162894096, validation losses: 0.595108936253527\n",
      "Epoch 1648, reconstruction losses: 0.045281941490136764, regression losses: 0.1789068473083499, validation losses: 0.6457334087443841\n",
      "Epoch 1649, reconstruction losses: 0.05019541737569922, regression losses: 0.12672980105943674, validation losses: 0.6505549055643791\n",
      "Epoch 1650, reconstruction losses: 0.052337806564963216, regression losses: 0.13618641129997994, validation losses: 0.4760218770934528\n",
      "Epoch 1651, reconstruction losses: 0.04836820839471025, regression losses: 0.1382163597604067, validation losses: 0.4541803754140876\n",
      "Epoch 1652, reconstruction losses: 0.05178575111264663, regression losses: 0.11660318665522865, validation losses: 0.5436222211184579\n",
      "Epoch 1653, reconstruction losses: 0.0511652538422388, regression losses: 0.15496208106153186, validation losses: 0.6431926202667132\n",
      "Epoch 1654, reconstruction losses: 0.0488705349052414, regression losses: 0.17246738894265262, validation losses: 0.664886618863695\n",
      "Epoch 1655, reconstruction losses: 0.04679742797990245, regression losses: 0.1918613533952305, validation losses: 0.6931741444823876\n",
      "Epoch 1656, reconstruction losses: 0.05034324806959345, regression losses: 0.1829471920893498, validation losses: 0.5488989137848926\n",
      "Epoch 1657, reconstruction losses: 0.045112413374525144, regression losses: 0.17090851354387726, validation losses: 0.5902024294942512\n",
      "Epoch 1658, reconstruction losses: 0.047464202724417814, regression losses: 0.1401546681797247, validation losses: 0.6963571948074233\n",
      "Epoch 1659, reconstruction losses: 0.04507661892783337, regression losses: 0.13721759395728128, validation losses: 0.5573318625432312\n",
      "Epoch 1660, reconstruction losses: 0.04472178999815918, regression losses: 0.20642381848479296, validation losses: 0.46996316840574076\n",
      "Epoch 1661, reconstruction losses: 0.053413775262299575, regression losses: 0.18926154759528185, validation losses: 0.4893874194744873\n",
      "Epoch 1662, reconstruction losses: 0.04669541801188355, regression losses: 0.15390398737915328, validation losses: 0.6057309568240066\n",
      "Epoch 1663, reconstruction losses: 0.04825978161124368, regression losses: 0.15370421557987415, validation losses: 0.45416399311315936\n",
      "Epoch 1664, reconstruction losses: 0.04958237434163601, regression losses: 0.10650316617402299, validation losses: 0.5370887925357088\n",
      "Epoch 1665, reconstruction losses: 0.04768171067267532, regression losses: 0.1515480719463422, validation losses: 0.6045913825321352\n",
      "Epoch 1666, reconstruction losses: 0.04807407508151892, regression losses: 0.13705536792730913, validation losses: 0.5273801139139889\n",
      "Epoch 1667, reconstruction losses: 0.05098059881727347, regression losses: 0.14408245123936522, validation losses: 0.47394350351435216\n",
      "Epoch 1668, reconstruction losses: 0.05180600616182932, regression losses: 0.1292340986068468, validation losses: 0.5169503347100753\n",
      "Epoch 1669, reconstruction losses: 0.051255466922530094, regression losses: 0.18573656993165283, validation losses: 0.5079336069108449\n",
      "Epoch 1670, reconstruction losses: 0.04901533105202163, regression losses: 0.1520887816003192, validation losses: 0.5146528447856009\n",
      "Epoch 1671, reconstruction losses: 0.047439881212714086, regression losses: 0.22762224850092294, validation losses: 0.6769694674678077\n",
      "Epoch 1672, reconstruction losses: 0.04700854570678914, regression losses: 0.15940692921296498, validation losses: 0.5990057008027578\n",
      "Epoch 1673, reconstruction losses: 0.045933846849702045, regression losses: 0.13408034275534542, validation losses: 0.47846896443671627\n",
      "Epoch 1674, reconstruction losses: 0.048657711371057864, regression losses: 0.16610319880498062, validation losses: 0.6547992202712405\n",
      "Epoch 1675, reconstruction losses: 0.04646388207305066, regression losses: 0.18175989503341597, validation losses: 0.5767675592433454\n",
      "Epoch 1676, reconstruction losses: 0.05210657381165813, regression losses: 0.1265823438918553, validation losses: 0.5153917332980601\n",
      "Epoch 1677, reconstruction losses: 0.049126796254814635, regression losses: 0.15581097050757003, validation losses: 0.4946615766664322\n",
      "Epoch 1678, reconstruction losses: 0.04696365843302243, regression losses: 0.14310250837200536, validation losses: 0.5865746054107497\n",
      "Epoch 1679, reconstruction losses: 0.04921369742638516, regression losses: 0.19367418015428478, validation losses: 0.4846913412368795\n",
      "Epoch 1680, reconstruction losses: 0.04754923255998657, regression losses: 0.1297719071672507, validation losses: 0.592830258876556\n",
      "Epoch 1681, reconstruction losses: 0.05161607691097079, regression losses: 0.1677367005289176, validation losses: 0.45815684850628324\n",
      "Epoch 1682, reconstruction losses: 0.051213711476263295, regression losses: 0.1615694184239009, validation losses: 0.674991251346782\n",
      "Epoch 1683, reconstruction losses: 0.04699536916737279, regression losses: 0.1607580989258224, validation losses: 0.7301038776127895\n",
      "Epoch 1684, reconstruction losses: 0.046569877604902846, regression losses: 0.1535959221887749, validation losses: 0.5202217339090449\n",
      "Epoch 1685, reconstruction losses: 0.04807909183843093, regression losses: 0.1837360907633745, validation losses: 0.4458530819412966\n",
      "Epoch 1686, reconstruction losses: 0.047359194019042684, regression losses: 0.12612209131261407, validation losses: 0.6448361362957732\n",
      "Epoch 1687, reconstruction losses: 0.05606893420820678, regression losses: 0.1889353603079632, validation losses: 0.49855687180380953\n",
      "Epoch 1688, reconstruction losses: 0.05168987277439941, regression losses: 0.22942655533192105, validation losses: 0.6244779668554827\n",
      "Epoch 1689, reconstruction losses: 0.05199172465157406, regression losses: 0.18423617898838704, validation losses: 0.7698636287236285\n",
      "Epoch 1690, reconstruction losses: 0.04935337450052209, regression losses: 0.11389011457171444, validation losses: 0.46674556503717474\n",
      "Epoch 1691, reconstruction losses: 0.04800650804529365, regression losses: 0.17476724069156338, validation losses: 0.45188979849624905\n",
      "Epoch 1692, reconstruction losses: 0.046773726293808056, regression losses: 0.1294167466468441, validation losses: 0.5544813651662046\n",
      "Epoch 1693, reconstruction losses: 0.058994845444537536, regression losses: 0.14078755550940927, validation losses: 0.5394303494335495\n",
      "Epoch 1694, reconstruction losses: 0.04868833102557939, regression losses: 0.15155741245206183, validation losses: 0.49449893767513636\n",
      "Epoch 1695, reconstruction losses: 0.05116551276690459, regression losses: 0.12102740108516195, validation losses: 0.47994786084423074\n",
      "Epoch 1696, reconstruction losses: 0.0464696621108386, regression losses: 0.15073338680484089, validation losses: 0.48368352434617634\n",
      "Epoch 1697, reconstruction losses: 0.04769845500198246, regression losses: 0.21587773698194113, validation losses: 0.4565966172387018\n",
      "Epoch 1698, reconstruction losses: 0.04786028575520789, regression losses: 0.1266825603959448, validation losses: 0.5777738924749362\n",
      "Epoch 1699, reconstruction losses: 0.046764427013116554, regression losses: 0.138600553568105, validation losses: 0.4664834961718297\n",
      "Epoch 1700, reconstruction losses: 0.05414421782268196, regression losses: 0.15302605470044073, validation losses: 0.45708647142486303\n",
      "Epoch 1701, reconstruction losses: 0.04825167141834677, regression losses: 0.17259204900108838, validation losses: 0.4713229016340905\n",
      "Epoch 1702, reconstruction losses: 0.05152434188620712, regression losses: 0.2348757897600145, validation losses: 0.8626228903169639\n",
      "Epoch 1703, reconstruction losses: 0.05068373256380779, regression losses: 0.18215311669865344, validation losses: 1.0695622261865132\n",
      "Epoch 1704, reconstruction losses: 0.04828424686769719, regression losses: 0.1605942142654457, validation losses: 0.5139135473815396\n",
      "Epoch 1705, reconstruction losses: 0.050362576241176724, regression losses: 0.14653064503978716, validation losses: 0.5310128406222109\n",
      "Epoch 1706, reconstruction losses: 0.052546015530425705, regression losses: 0.16578644275454282, validation losses: 0.4875210586149519\n",
      "Epoch 1707, reconstruction losses: 0.04931095158040964, regression losses: 0.22565940623629743, validation losses: 0.697755853848986\n",
      "Epoch 1708, reconstruction losses: 0.046533496881364766, regression losses: 0.1997196468204998, validation losses: 0.5100284239451838\n",
      "Epoch 1709, reconstruction losses: 0.046800062433224765, regression losses: 0.14083867981025414, validation losses: 0.6507619024566095\n",
      "Epoch 1710, reconstruction losses: 0.048214208134819234, regression losses: 0.20193711438393924, validation losses: 0.639296481993044\n",
      "Epoch 1711, reconstruction losses: 0.04912666167521188, regression losses: 0.18759807721700167, validation losses: 0.6274422767786215\n",
      "Epoch 1712, reconstruction losses: 0.04522111245808054, regression losses: 0.15445844451605573, validation losses: 0.4604796824012511\n",
      "Epoch 1713, reconstruction losses: 0.046951397895902684, regression losses: 0.1649131040268581, validation losses: 0.5196493038349213\n",
      "Epoch 1714, reconstruction losses: 0.05737807316975052, regression losses: 0.13778435925991894, validation losses: 0.5092250928960282\n",
      "Epoch 1715, reconstruction losses: 0.0492800340922019, regression losses: 0.11939960707041881, validation losses: 0.5365242804401956\n",
      "Epoch 1716, reconstruction losses: 0.047432129509022015, regression losses: 0.12321628173660377, validation losses: 0.4947066747794125\n",
      "Epoch 1717, reconstruction losses: 0.052412755663397356, regression losses: 0.12302843453906359, validation losses: 0.4899775558455762\n",
      "Epoch 1718, reconstruction losses: 0.04764137283800504, regression losses: 0.1203429975547095, validation losses: 0.4518503655421182\n",
      "Epoch 1719, reconstruction losses: 0.051869845150609106, regression losses: 0.1765963792565242, validation losses: 0.5314434484888335\n",
      "Epoch 1720, reconstruction losses: 0.05250066425537571, regression losses: 0.1428437850963637, validation losses: 0.4669125198727053\n",
      "Epoch 1721, reconstruction losses: 0.048438018710765626, regression losses: 0.12172882834342656, validation losses: 0.5779782906625086\n",
      "Epoch 1722, reconstruction losses: 0.051550533796374816, regression losses: 0.12541782895817058, validation losses: 0.5906208548917921\n",
      "Epoch 1723, reconstruction losses: 0.047345877996237955, regression losses: 0.11486645151584128, validation losses: 0.4598019377356263\n",
      "Epoch 1724, reconstruction losses: 0.04740995867515443, regression losses: 0.15241229085647337, validation losses: 0.5061056722150801\n",
      "Epoch 1725, reconstruction losses: 0.04770816905262976, regression losses: 0.13799087869720456, validation losses: 0.612516349935624\n",
      "Epoch 1726, reconstruction losses: 0.0471744118896268, regression losses: 0.1848581741417982, validation losses: 0.7699376355257297\n",
      "Epoch 1727, reconstruction losses: 0.051398317871028346, regression losses: 0.13704191980016067, validation losses: 0.4818500298787528\n",
      "Epoch 1728, reconstruction losses: 0.05170262935273081, regression losses: 0.15586855339732197, validation losses: 0.4630319326231268\n",
      "Epoch 1729, reconstruction losses: 0.0518322516265077, regression losses: 0.19554224846328885, validation losses: 0.5183725078148712\n",
      "Epoch 1730, reconstruction losses: 0.051430226323654814, regression losses: 0.15658746498897158, validation losses: 0.49924925543370813\n",
      "Epoch 1731, reconstruction losses: 0.05096180261336474, regression losses: 0.13389010182830866, validation losses: 0.4790735640467477\n",
      "Epoch 1732, reconstruction losses: 0.048783892085383924, regression losses: 0.2304249980534958, validation losses: 0.5170952920512879\n",
      "Epoch 1733, reconstruction losses: 0.046898886026542706, regression losses: 0.20116290267857945, validation losses: 0.59785869934624\n",
      "Epoch 1734, reconstruction losses: 0.050799059926945375, regression losses: 0.12890263354123313, validation losses: 0.6097094928382522\n",
      "Epoch 1735, reconstruction losses: 0.04861343523118312, regression losses: 0.18492197923929526, validation losses: 0.5664152291567657\n",
      "Epoch 1736, reconstruction losses: 0.050868986548724196, regression losses: 0.13667381122168729, validation losses: 0.5832258209312036\n",
      "Epoch 1737, reconstruction losses: 0.04905619403924713, regression losses: 0.16411381746240267, validation losses: 0.4662234512099273\n",
      "Epoch 1738, reconstruction losses: 0.04711800054916477, regression losses: 0.12924948635245395, validation losses: 0.5004097066588793\n",
      "Epoch 1739, reconstruction losses: 0.04929980353641363, regression losses: 0.13110704679724947, validation losses: 0.48758984418206475\n",
      "Epoch 1740, reconstruction losses: 0.05023380971195757, regression losses: 0.1286333795306735, validation losses: 0.5661239872548418\n",
      "Epoch 1741, reconstruction losses: 0.05084836827218575, regression losses: 0.1478097195885439, validation losses: 0.5208295174124693\n",
      "Epoch 1742, reconstruction losses: 0.049399194374257833, regression losses: 0.12560850851784405, validation losses: 0.7450277607287806\n",
      "Epoch 1743, reconstruction losses: 0.05056044101938466, regression losses: 0.16887121033075317, validation losses: 0.5304241278059425\n",
      "Epoch 1744, reconstruction losses: 0.04633025886002201, regression losses: 0.1670441144197345, validation losses: 0.5139073914133454\n",
      "Epoch 1745, reconstruction losses: 0.053146072888906146, regression losses: 0.1306720684883909, validation losses: 0.6608748669664197\n",
      "Epoch 1746, reconstruction losses: 0.04643579955095879, regression losses: 0.2648178379375692, validation losses: 0.6066336278551148\n",
      "Epoch 1747, reconstruction losses: 0.052001553237624176, regression losses: 0.16919995549952707, validation losses: 0.6290372732899701\n",
      "Epoch 1748, reconstruction losses: 0.05163730252980645, regression losses: 0.1602155448978268, validation losses: 0.5292125462638562\n",
      "Epoch 1749, reconstruction losses: 0.0464490383479981, regression losses: 0.184896623756265, validation losses: 0.5710445035828631\n",
      "Epoch 1750, reconstruction losses: 0.04967451292470257, regression losses: 0.1185948274528263, validation losses: 0.6009130825831511\n",
      "Epoch 1751, reconstruction losses: 0.04901534015722566, regression losses: 0.15103559521570248, validation losses: 0.5650671676562541\n",
      "Epoch 1752, reconstruction losses: 0.05286786626888504, regression losses: 0.13905834458614036, validation losses: 0.6914313020443725\n",
      "Epoch 1753, reconstruction losses: 0.04669615822197325, regression losses: 0.14669346248215245, validation losses: 0.4404693066736781\n",
      "Epoch 1754, reconstruction losses: 0.04523099262627729, regression losses: 0.1370159919015377, validation losses: 0.5160083784649789\n",
      "Epoch 1755, reconstruction losses: 0.048266908184871865, regression losses: 0.14219146271937247, validation losses: 0.7278434723281971\n",
      "Epoch 1756, reconstruction losses: 0.052287324826871526, regression losses: 0.14309288137975318, validation losses: 0.6174888201439334\n",
      "Epoch 1757, reconstruction losses: 0.04781322241444348, regression losses: 0.1371588112588836, validation losses: 0.4526223112863329\n",
      "Epoch 1758, reconstruction losses: 0.0485320661820028, regression losses: 0.11842956725388085, validation losses: 0.4733868889775362\n",
      "Epoch 1759, reconstruction losses: 0.05189215364959246, regression losses: 0.14162827744490394, validation losses: 0.5492661767678955\n",
      "Epoch 1760, reconstruction losses: 0.0569525044092192, regression losses: 0.14103599163561775, validation losses: 0.5756881589845112\n",
      "Epoch 1761, reconstruction losses: 0.04738377600424139, regression losses: 0.17552272077874098, validation losses: 0.5639499177514311\n",
      "Epoch 1762, reconstruction losses: 0.05136106426211057, regression losses: 0.15355396807608743, validation losses: 0.5890733274225487\n",
      "Epoch 1763, reconstruction losses: 0.0487145007589574, regression losses: 0.14527033968841205, validation losses: 0.7481583725033311\n",
      "Epoch 1764, reconstruction losses: 0.04752449572910606, regression losses: 0.1742706121062104, validation losses: 0.4326016593875486\n",
      "Epoch 1765, reconstruction losses: 0.04722667255285228, regression losses: 0.1486776208733348, validation losses: 0.42755432735650967\n",
      "Epoch 1766, reconstruction losses: 0.046657288293343785, regression losses: 0.17549723339942622, validation losses: 0.4887089630005397\n",
      "Epoch 1767, reconstruction losses: 0.04653549022237116, regression losses: 0.16087982917185864, validation losses: 0.5554954195306974\n",
      "Epoch 1768, reconstruction losses: 0.04868898923295571, regression losses: 0.12642229403324104, validation losses: 0.7002121103054393\n",
      "Epoch 1769, reconstruction losses: 0.047115337221609634, regression losses: 0.13532755105381644, validation losses: 0.5391988713394251\n",
      "Epoch 1770, reconstruction losses: 0.04747020526859958, regression losses: 0.13666230473421334, validation losses: 0.4442574352212198\n",
      "Epoch 1771, reconstruction losses: 0.04691957617534631, regression losses: 0.15405319972532522, validation losses: 0.46057629434824077\n",
      "Epoch 1772, reconstruction losses: 0.04802181299298106, regression losses: 0.11207918695261794, validation losses: 0.49495580693602864\n",
      "Epoch 1773, reconstruction losses: 0.0463865002184397, regression losses: 0.1212800269730389, validation losses: 0.4777252179241211\n",
      "Epoch 1774, reconstruction losses: 0.047113036582019215, regression losses: 0.14094359535151804, validation losses: 0.5398208638640314\n",
      "Epoch 1775, reconstruction losses: 0.04824415059484435, regression losses: 0.143720369934478, validation losses: 0.5130523423257443\n",
      "Epoch 1776, reconstruction losses: 0.05243246468491133, regression losses: 0.14051930606917357, validation losses: 0.45632932126151565\n",
      "Epoch 1777, reconstruction losses: 0.04525480391019041, regression losses: 0.13564440390319218, validation losses: 0.5090015161625876\n",
      "Epoch 1778, reconstruction losses: 0.05161277283055757, regression losses: 0.18941030838281253, validation losses: 0.5926593488213876\n",
      "Epoch 1779, reconstruction losses: 0.048240623933659896, regression losses: 0.13936989129095148, validation losses: 0.6732397598196627\n",
      "Epoch 1780, reconstruction losses: 0.0448195126123547, regression losses: 0.15608496796211246, validation losses: 0.5585802244368918\n",
      "Epoch 1781, reconstruction losses: 0.04522315948319294, regression losses: 0.19469864889231958, validation losses: 0.647703655446962\n",
      "Epoch 1782, reconstruction losses: 0.05809477343415004, regression losses: 0.14645094100639544, validation losses: 0.6713088830799192\n",
      "Epoch 1783, reconstruction losses: 0.05043729156530659, regression losses: 0.12417495848217082, validation losses: 0.5628081349971363\n",
      "Epoch 1784, reconstruction losses: 0.04712858075978067, regression losses: 0.14384113753458022, validation losses: 0.5666457711093942\n",
      "Epoch 1785, reconstruction losses: 0.04824116190240428, regression losses: 0.18160611794524928, validation losses: 0.7040717715213515\n",
      "Epoch 1786, reconstruction losses: 0.05723872338567046, regression losses: 0.13942868269876527, validation losses: 0.47277527047236906\n",
      "Epoch 1787, reconstruction losses: 0.056170619805991695, regression losses: 0.15676022720071314, validation losses: 0.4525514771370926\n",
      "Epoch 1788, reconstruction losses: 0.045216243639098395, regression losses: 0.1649224845410251, validation losses: 0.5982947931861153\n",
      "Epoch 1789, reconstruction losses: 0.049522151082289516, regression losses: 0.13982647100941495, validation losses: 0.6623580811490092\n",
      "Epoch 1790, reconstruction losses: 0.05008261460397055, regression losses: 0.13156284696074147, validation losses: 0.44040804298777203\n",
      "Epoch 1791, reconstruction losses: 0.046881700655546206, regression losses: 0.14217663023091975, validation losses: 0.5584542351559368\n",
      "Epoch 1792, reconstruction losses: 0.04782048109471097, regression losses: 0.15436731676068793, validation losses: 0.4764570197951609\n",
      "Epoch 1793, reconstruction losses: 0.0540638185089186, regression losses: 0.1622022609657326, validation losses: 0.5011332117417919\n",
      "Epoch 1794, reconstruction losses: 0.04587539507134712, regression losses: 0.15248407105730055, validation losses: 0.5813224929253353\n",
      "Epoch 1795, reconstruction losses: 0.05030285173007925, regression losses: 0.1385907106877644, validation losses: 0.6999872206153569\n",
      "Epoch 1796, reconstruction losses: 0.0457041852083051, regression losses: 0.13484853776800595, validation losses: 0.5502651247801985\n",
      "Epoch 1797, reconstruction losses: 0.05181575592468168, regression losses: 0.1431739557954638, validation losses: 0.43758653742524806\n",
      "Epoch 1798, reconstruction losses: 0.04705458049464278, regression losses: 0.1903503907467528, validation losses: 0.4700101058454582\n",
      "Epoch 1799, reconstruction losses: 0.055974411052969894, regression losses: 0.15942890244462804, validation losses: 0.4955473235872185\n",
      "Epoch 1800, reconstruction losses: 0.049575722557381616, regression losses: 0.1377721068555583, validation losses: 0.4334787767801997\n",
      "Epoch 1801, reconstruction losses: 0.047657238854368504, regression losses: 0.3068123609487232, validation losses: 0.6066157050510832\n",
      "Epoch 1802, reconstruction losses: 0.05137179248192272, regression losses: 0.25947352388915473, validation losses: 0.8207708289711456\n",
      "Epoch 1803, reconstruction losses: 0.04695523896025538, regression losses: 0.1574048152369468, validation losses: 0.6723490092595338\n",
      "Epoch 1804, reconstruction losses: 0.04865718363813974, regression losses: 0.14870250075285565, validation losses: 0.5494837221309792\n",
      "Epoch 1805, reconstruction losses: 0.0491156305184362, regression losses: 0.12918335175371748, validation losses: 0.4657706375151166\n",
      "Epoch 1806, reconstruction losses: 0.055171065971696714, regression losses: 0.18075686750830822, validation losses: 0.5077502173888838\n",
      "Epoch 1807, reconstruction losses: 0.05189220672197144, regression losses: 0.15816711388655735, validation losses: 0.47399559181243905\n",
      "Epoch 1808, reconstruction losses: 0.04765413742991598, regression losses: 0.16789016304491608, validation losses: 0.5137492668075856\n",
      "Epoch 1809, reconstruction losses: 0.05736328972357112, regression losses: 0.1335386324655801, validation losses: 0.49188968880506506\n",
      "Epoch 1810, reconstruction losses: 0.052906856380264156, regression losses: 0.1384529223395587, validation losses: 0.4478837433068012\n",
      "Epoch 1811, reconstruction losses: 0.05228546179279157, regression losses: 0.15781232887597885, validation losses: 0.5062791647797117\n",
      "Epoch 1812, reconstruction losses: 0.046485778396903675, regression losses: 0.12606293641738872, validation losses: 0.6309708719493857\n",
      "Epoch 1813, reconstruction losses: 0.050206233795487436, regression losses: 0.17165961736753124, validation losses: 0.49659031604510784\n",
      "Epoch 1814, reconstruction losses: 0.05164716622765464, regression losses: 0.1360980018677454, validation losses: 0.48528270114016686\n",
      "Epoch 1815, reconstruction losses: 0.045644773431103174, regression losses: 0.1336195533702831, validation losses: 0.5402579872666335\n",
      "Epoch 1816, reconstruction losses: 0.048667858322689904, regression losses: 0.1553286969627484, validation losses: 0.596517868326554\n",
      "Epoch 1817, reconstruction losses: 0.04663248937770676, regression losses: 0.13857829773008454, validation losses: 0.4749771169407709\n",
      "Epoch 1818, reconstruction losses: 0.04519627011412423, regression losses: 0.17319817262670226, validation losses: 0.4810813018682701\n",
      "Epoch 1819, reconstruction losses: 0.04622693976700013, regression losses: 0.12316287728894303, validation losses: 0.7103560650887011\n",
      "Epoch 1820, reconstruction losses: 0.04691206410039224, regression losses: 0.14377192904441607, validation losses: 0.4917074715677483\n",
      "Epoch 1821, reconstruction losses: 0.053079478761533766, regression losses: 0.1344139856801343, validation losses: 0.5587199719310223\n",
      "Epoch 1822, reconstruction losses: 0.048204461865204884, regression losses: 0.14910164693418534, validation losses: 0.4863639383609708\n",
      "Epoch 1823, reconstruction losses: 0.05073268714738039, regression losses: 0.15442978351997377, validation losses: 0.8747819935534122\n",
      "Epoch 1824, reconstruction losses: 0.05024335954189798, regression losses: 0.13254464089586426, validation losses: 0.8242678628066757\n",
      "Epoch 1825, reconstruction losses: 0.04612709234607554, regression losses: 0.15145523607926778, validation losses: 0.5338205050140479\n",
      "Epoch 1826, reconstruction losses: 0.046959001959589255, regression losses: 0.13545374113841616, validation losses: 0.44402109039350246\n",
      "Epoch 1827, reconstruction losses: 0.04629880756800925, regression losses: 0.23337653787960122, validation losses: 0.5742971986377285\n",
      "Epoch 1828, reconstruction losses: 0.051466755094575475, regression losses: 0.1374498964680573, validation losses: 1.0162529516860652\n",
      "Epoch 1829, reconstruction losses: 0.04574039848727715, regression losses: 0.2284436067557809, validation losses: 0.6663375698620967\n",
      "Epoch 1830, reconstruction losses: 0.04830431786965612, regression losses: 0.16100778312071004, validation losses: 0.5643627686174814\n",
      "Epoch 1831, reconstruction losses: 0.05209482079449207, regression losses: 0.14260186393560978, validation losses: 0.45332803874909283\n",
      "Epoch 1832, reconstruction losses: 0.0476738873191237, regression losses: 0.12404223643350648, validation losses: 0.5589057255254815\n",
      "Epoch 1833, reconstruction losses: 0.04661533106208838, regression losses: 0.13092365950198903, validation losses: 0.6412441852723273\n",
      "Epoch 1834, reconstruction losses: 0.046882681995780995, regression losses: 0.1839377623877594, validation losses: 0.5370431788774147\n",
      "Epoch 1835, reconstruction losses: 0.04454301683247495, regression losses: 0.14497763045182954, validation losses: 0.5127957705273058\n",
      "Epoch 1836, reconstruction losses: 0.045845043917835566, regression losses: 0.2091317834906049, validation losses: 0.8454470881629885\n",
      "Epoch 1837, reconstruction losses: 0.05618759922460309, regression losses: 0.16498055046875149, validation losses: 0.696947407481694\n",
      "Epoch 1838, reconstruction losses: 0.04589133764937392, regression losses: 0.1196027938191071, validation losses: 0.48805244653600977\n",
      "Epoch 1839, reconstruction losses: 0.04883185494003601, regression losses: 0.18677823114833167, validation losses: 0.533717680104509\n",
      "Epoch 1840, reconstruction losses: 0.051098857690040946, regression losses: 0.14835624268913117, validation losses: 0.8767950856473501\n",
      "Epoch 1841, reconstruction losses: 0.048076621666129735, regression losses: 0.17830341653869966, validation losses: 0.5227813795496755\n",
      "Epoch 1842, reconstruction losses: 0.04875818278433517, regression losses: 0.15556079585900515, validation losses: 0.4459565076848118\n",
      "Epoch 1843, reconstruction losses: 0.04648043458541739, regression losses: 0.14816320618590798, validation losses: 0.5593702075040993\n",
      "Epoch 1844, reconstruction losses: 0.05135166205509894, regression losses: 0.19305662478506014, validation losses: 0.5538060148130102\n",
      "Epoch 1845, reconstruction losses: 0.04603847713040361, regression losses: 0.13290193594722594, validation losses: 0.4943493376329598\n",
      "Epoch 1846, reconstruction losses: 0.05392643860158369, regression losses: 0.13464118400590588, validation losses: 0.45496223496842847\n",
      "Epoch 1847, reconstruction losses: 0.047427438004476616, regression losses: 0.13315767623641742, validation losses: 0.5374058872208628\n",
      "Epoch 1848, reconstruction losses: 0.04939209108296287, regression losses: 0.1302116570628211, validation losses: 0.5434838719468202\n",
      "Epoch 1849, reconstruction losses: 0.0464818426426551, regression losses: 0.12938451451873853, validation losses: 0.7177323854320188\n",
      "Epoch 1850, reconstruction losses: 0.04624190768975272, regression losses: 0.221688863843117, validation losses: 0.556203569324644\n",
      "Epoch 1851, reconstruction losses: 0.051475742656717546, regression losses: 0.15166985432938793, validation losses: 0.9284775192789727\n",
      "Epoch 1852, reconstruction losses: 0.058306817974694454, regression losses: 0.12891672735988877, validation losses: 0.6075120365810027\n",
      "Epoch 1853, reconstruction losses: 0.05008405952181265, regression losses: 0.12900779106935942, validation losses: 0.5711377283246897\n",
      "Epoch 1854, reconstruction losses: 0.04811211433102374, regression losses: 0.13815613842098792, validation losses: 0.45770148760472673\n",
      "Epoch 1855, reconstruction losses: 0.04764532258984937, regression losses: 0.12540707274101698, validation losses: 0.6506176614401362\n",
      "Epoch 1856, reconstruction losses: 0.04813132148287626, regression losses: 0.12355339934418563, validation losses: 0.5560471263511653\n",
      "Epoch 1857, reconstruction losses: 0.05194194048004094, regression losses: 0.1389677249790299, validation losses: 0.4587704701602886\n",
      "Epoch 1858, reconstruction losses: 0.049755396735172895, regression losses: 0.14390399257521125, validation losses: 0.5100802628428865\n",
      "Epoch 1859, reconstruction losses: 0.05140185613603112, regression losses: 0.1452231656038562, validation losses: 0.6567210176559144\n",
      "Epoch 1860, reconstruction losses: 0.04619886730397826, regression losses: 0.15421663140802633, validation losses: 0.48387540223468045\n",
      "Epoch 1861, reconstruction losses: 0.05740724462554195, regression losses: 0.1386724457185112, validation losses: 0.45328794943065265\n",
      "Epoch 1862, reconstruction losses: 0.04639866748537221, regression losses: 0.12822896844356013, validation losses: 0.5239104266457472\n",
      "Epoch 1863, reconstruction losses: 0.05536603627388294, regression losses: 0.12753317138084763, validation losses: 0.4804704762613256\n",
      "Epoch 1864, reconstruction losses: 0.048018426904809244, regression losses: 0.18228361016197298, validation losses: 0.4612731112810323\n",
      "Epoch 1865, reconstruction losses: 0.04749639671180079, regression losses: 0.12189255003950383, validation losses: 0.6973809868782392\n",
      "Epoch 1866, reconstruction losses: 0.04942902058996345, regression losses: 0.11980027114423206, validation losses: 0.576333896545958\n",
      "Epoch 1867, reconstruction losses: 0.04940493002338393, regression losses: 0.12989285171370488, validation losses: 0.4456563902566479\n",
      "Epoch 1868, reconstruction losses: 0.05025536543715423, regression losses: 0.19095661532393868, validation losses: 0.4704020296015872\n",
      "Epoch 1869, reconstruction losses: 0.05825132323007665, regression losses: 0.15217854515381593, validation losses: 0.8989515517281605\n",
      "Epoch 1870, reconstruction losses: 0.04626909756844852, regression losses: 0.1611019828661894, validation losses: 0.5170659266441453\n",
      "Epoch 1871, reconstruction losses: 0.04469783917792597, regression losses: 0.16313481404420185, validation losses: 0.46675235604442794\n",
      "Epoch 1872, reconstruction losses: 0.050370577845047726, regression losses: 0.17004362806426843, validation losses: 0.4794428811838707\n",
      "Epoch 1873, reconstruction losses: 0.045129628349840224, regression losses: 0.15015978353980955, validation losses: 0.526051226427148\n",
      "Epoch 1874, reconstruction losses: 0.04997976295477121, regression losses: 0.1259863132323821, validation losses: 0.5318879271447664\n",
      "Epoch 1875, reconstruction losses: 0.05227459167653911, regression losses: 0.13297606393325528, validation losses: 0.4970751977644847\n",
      "Epoch 1876, reconstruction losses: 0.051548960516126854, regression losses: 0.13515308780772073, validation losses: 0.5570851347518736\n",
      "Epoch 1877, reconstruction losses: 0.04958946393736663, regression losses: 0.11790951883165735, validation losses: 0.5856744567289695\n",
      "Epoch 1878, reconstruction losses: 0.049430071965026356, regression losses: 0.14189174763315637, validation losses: 0.4404080940379311\n",
      "Epoch 1879, reconstruction losses: 0.04937413135345022, regression losses: 0.2734555130092644, validation losses: 0.5091549763977022\n",
      "Epoch 1880, reconstruction losses: 0.0473193366079398, regression losses: 0.1400375905208737, validation losses: 0.979631863318529\n",
      "Epoch 1881, reconstruction losses: 0.04520264150448574, regression losses: 0.19331884338833288, validation losses: 0.6219724492346641\n",
      "Epoch 1882, reconstruction losses: 0.04559900234270362, regression losses: 0.11667722304102274, validation losses: 0.6023580404534373\n",
      "Epoch 1883, reconstruction losses: 0.04486688621234698, regression losses: 0.17056948176662687, validation losses: 0.45368516867670083\n",
      "Epoch 1884, reconstruction losses: 0.04617104359900725, regression losses: 0.11703059764846155, validation losses: 0.5160517080285931\n",
      "Epoch 1885, reconstruction losses: 0.0490948680895426, regression losses: 0.1521326881131762, validation losses: 0.5696268481079207\n",
      "Epoch 1886, reconstruction losses: 0.04591723909400261, regression losses: 0.1479582872725999, validation losses: 0.47244578669346954\n",
      "Epoch 1887, reconstruction losses: 0.05018788635154252, regression losses: 0.1589716927637681, validation losses: 0.46802572839200846\n",
      "Epoch 1888, reconstruction losses: 0.04706566931404203, regression losses: 0.15909990067435564, validation losses: 0.746669704745701\n",
      "Epoch 1889, reconstruction losses: 0.049489932581757295, regression losses: 0.15201686014161092, validation losses: 0.5672662858525549\n",
      "Epoch 1890, reconstruction losses: 0.04794674769208533, regression losses: 0.13333120414153005, validation losses: 0.5381989833428529\n",
      "Epoch 1891, reconstruction losses: 0.04824070788060358, regression losses: 0.19429387231337064, validation losses: 0.4962804323175969\n",
      "Epoch 1892, reconstruction losses: 0.04496668354112842, regression losses: 0.15562784169134003, validation losses: 0.5432337989210803\n",
      "Epoch 1893, reconstruction losses: 0.04665246856006808, regression losses: 0.20945009658943417, validation losses: 0.47825499545450856\n",
      "Epoch 1894, reconstruction losses: 0.04503761461297775, regression losses: 0.12407132783095091, validation losses: 0.7322494578805305\n",
      "Epoch 1895, reconstruction losses: 0.049961962987689, regression losses: 0.1544852195723074, validation losses: 0.5777476822714865\n",
      "Epoch 1896, reconstruction losses: 0.04704200580516181, regression losses: 0.11796085919467157, validation losses: 0.4679055147662057\n",
      "Epoch 1897, reconstruction losses: 0.0519341934986698, regression losses: 0.12480761864464786, validation losses: 0.46862958596534643\n",
      "Epoch 1898, reconstruction losses: 0.04904674606222226, regression losses: 0.14684480745201375, validation losses: 0.5052295264573566\n",
      "Epoch 1899, reconstruction losses: 0.05164839789939612, regression losses: 0.12252177600889982, validation losses: 0.524189411885828\n",
      "Epoch 1900, reconstruction losses: 0.04648879862938374, regression losses: 0.11980868918752273, validation losses: 0.49903057440744575\n",
      "Epoch 1901, reconstruction losses: 0.0508614349824853, regression losses: 0.14628257254555987, validation losses: 0.5418128996745651\n",
      "Epoch 1902, reconstruction losses: 0.05458556011903804, regression losses: 0.14192284721355825, validation losses: 0.5246775435033142\n",
      "Epoch 1903, reconstruction losses: 0.046869082040101095, regression losses: 0.13569819168376437, validation losses: 0.4471870520588491\n",
      "Epoch 1904, reconstruction losses: 0.050614487321526486, regression losses: 0.15364545128386622, validation losses: 0.49523733855746904\n",
      "Epoch 1905, reconstruction losses: 0.05144095293028807, regression losses: 0.13992750658540132, validation losses: 0.5834390565008059\n",
      "Epoch 1906, reconstruction losses: 0.046956387362587386, regression losses: 0.14465752303210913, validation losses: 0.5164093999949744\n",
      "Epoch 1907, reconstruction losses: 0.04756370751031793, regression losses: 0.17414989225063596, validation losses: 0.4620637564302632\n",
      "Epoch 1908, reconstruction losses: 0.049982423789528344, regression losses: 0.13593567545345023, validation losses: 0.6117900231495127\n",
      "Epoch 1909, reconstruction losses: 0.04774882654924017, regression losses: 0.15266962661705966, validation losses: 0.5881181774250448\n",
      "Epoch 1910, reconstruction losses: 0.045455468448893664, regression losses: 0.2429543197654626, validation losses: 0.5910173407951861\n",
      "Epoch 1911, reconstruction losses: 0.05147103669119444, regression losses: 0.16601442913487807, validation losses: 0.7636245409026494\n",
      "Epoch 1912, reconstruction losses: 0.045699628261447106, regression losses: 0.19092572914033856, validation losses: 0.4960488963708731\n",
      "Epoch 1913, reconstruction losses: 0.047208499411433555, regression losses: 0.1525906125921489, validation losses: 0.7020124294660012\n",
      "Epoch 1914, reconstruction losses: 0.04881120194465318, regression losses: 0.21183919564424022, validation losses: 0.6317287119017891\n",
      "Epoch 1915, reconstruction losses: 0.049916359459491494, regression losses: 0.19349560145461853, validation losses: 0.809943217318242\n",
      "Epoch 1916, reconstruction losses: 0.045966421595237755, regression losses: 0.1404300867086797, validation losses: 0.49044080839576465\n",
      "Epoch 1917, reconstruction losses: 0.0448671610046443, regression losses: 0.12114808727291629, validation losses: 0.5236754385308497\n",
      "Epoch 1918, reconstruction losses: 0.05023685836893157, regression losses: 0.1334870735331272, validation losses: 0.6223139132037685\n",
      "Epoch 1919, reconstruction losses: 0.04684259800105972, regression losses: 0.14548894018825187, validation losses: 0.593475290163478\n",
      "Epoch 1920, reconstruction losses: 0.048913497598064015, regression losses: 0.15699115971692781, validation losses: 0.5282732322810966\n",
      "Epoch 1921, reconstruction losses: 0.0455441458910823, regression losses: 0.22762975530479923, validation losses: 0.4931103223829177\n",
      "Epoch 1922, reconstruction losses: 0.05539567324367172, regression losses: 0.16978551574569953, validation losses: 0.9900074736410914\n",
      "Epoch 1923, reconstruction losses: 0.049298230449146475, regression losses: 0.16727274498236686, validation losses: 0.6629967667425032\n",
      "Epoch 1924, reconstruction losses: 0.0514563526114846, regression losses: 0.14945217621841903, validation losses: 0.55563915364091\n",
      "Epoch 1925, reconstruction losses: 0.05162054474210855, regression losses: 0.15364890460886843, validation losses: 0.4509045140083718\n",
      "Epoch 1926, reconstruction losses: 0.04558722955305107, regression losses: 0.13208340472980987, validation losses: 0.5056013474874487\n",
      "Epoch 1927, reconstruction losses: 0.04910161884999507, regression losses: 0.13949839287455493, validation losses: 0.6860309718969331\n",
      "Epoch 1928, reconstruction losses: 0.047403968236342076, regression losses: 0.1435439593024096, validation losses: 0.6394245442245297\n",
      "Epoch 1929, reconstruction losses: 0.04961497340384153, regression losses: 0.13256966877840554, validation losses: 0.46469749171404073\n",
      "Epoch 1930, reconstruction losses: 0.04650020479407343, regression losses: 0.19094100744172599, validation losses: 0.6578230170974086\n",
      "Epoch 1931, reconstruction losses: 0.049180798519140465, regression losses: 0.17966005902479898, validation losses: 0.7779922331764186\n",
      "Epoch 1932, reconstruction losses: 0.050089669457719393, regression losses: 0.15698031739111515, validation losses: 0.6674563372410076\n",
      "Epoch 1933, reconstruction losses: 0.04751337024153926, regression losses: 0.1604922972215051, validation losses: 0.5167487950569803\n",
      "Epoch 1934, reconstruction losses: 0.05333256270188267, regression losses: 0.11019386261617184, validation losses: 0.47636952848476255\n",
      "Epoch 1935, reconstruction losses: 0.045551978857755894, regression losses: 0.13620891647968913, validation losses: 0.573897594016936\n",
      "Epoch 1936, reconstruction losses: 0.05206839466830662, regression losses: 0.13941964559661574, validation losses: 0.5498558575342676\n",
      "Epoch 1937, reconstruction losses: 0.048640149645492764, regression losses: 0.14099566158693358, validation losses: 0.4545109947757083\n",
      "Epoch 1938, reconstruction losses: 0.05725584423437349, regression losses: 0.1568909800378207, validation losses: 0.5251574090347316\n",
      "Epoch 1939, reconstruction losses: 0.047189202219246926, regression losses: 0.13710787013021167, validation losses: 0.5113067451615103\n",
      "Epoch 1940, reconstruction losses: 0.04675834879265724, regression losses: 0.154857506593392, validation losses: 0.5048486027817498\n",
      "Epoch 1941, reconstruction losses: 0.04708882369791458, regression losses: 0.19650923849868662, validation losses: 0.6098187341083224\n",
      "Epoch 1942, reconstruction losses: 0.046050279203817254, regression losses: 0.18636829532184654, validation losses: 0.49994065131650467\n",
      "Epoch 1943, reconstruction losses: 0.0568240248452558, regression losses: 0.20611322711282132, validation losses: 0.5808622883439706\n",
      "Epoch 1944, reconstruction losses: 0.04649378434535405, regression losses: 0.19784642865329277, validation losses: 0.7594400324619243\n",
      "Epoch 1945, reconstruction losses: 0.051784411210872155, regression losses: 0.13655955416193097, validation losses: 0.574732042804211\n",
      "Epoch 1946, reconstruction losses: 0.04943361167904525, regression losses: 0.13231957327092278, validation losses: 0.4670351173071602\n",
      "Epoch 1947, reconstruction losses: 0.057891392942940476, regression losses: 0.18832490865794518, validation losses: 0.564300099158043\n",
      "Epoch 1948, reconstruction losses: 0.04654911505281503, regression losses: 0.18192402801137683, validation losses: 0.5318185837925851\n",
      "Epoch 1949, reconstruction losses: 0.04707335864026782, regression losses: 0.20599257253956887, validation losses: 0.5546655941372274\n",
      "Epoch 1950, reconstruction losses: 0.05070455461624479, regression losses: 0.1494571596633476, validation losses: 0.5316695683574385\n",
      "Epoch 1951, reconstruction losses: 0.04640006841490399, regression losses: 0.18154493040388792, validation losses: 0.4511655715836836\n",
      "Epoch 1952, reconstruction losses: 0.05169475285684233, regression losses: 0.14803261736718373, validation losses: 0.5335100140497628\n",
      "Epoch 1953, reconstruction losses: 0.047967390139181755, regression losses: 0.12591483638990184, validation losses: 0.5453916123740429\n",
      "Epoch 1954, reconstruction losses: 0.049405253628170026, regression losses: 0.11224996893417477, validation losses: 0.5175169001593517\n",
      "Epoch 1955, reconstruction losses: 0.053352596659951255, regression losses: 0.12357210995224202, validation losses: 0.5323373195724199\n",
      "Epoch 1956, reconstruction losses: 0.049308154217909864, regression losses: 0.13924528966330146, validation losses: 0.6351407874483599\n",
      "Epoch 1957, reconstruction losses: 0.047570980408556354, regression losses: 0.1723273115078971, validation losses: 0.4652676393188801\n",
      "Epoch 1958, reconstruction losses: 0.04632173029225174, regression losses: 0.12547857315104727, validation losses: 0.43170909738143637\n",
      "Epoch 1959, reconstruction losses: 0.04663901597164685, regression losses: 0.1362500197992269, validation losses: 0.5313301475820744\n",
      "Epoch 1960, reconstruction losses: 0.050542226376435365, regression losses: 0.155130514103954, validation losses: 0.6058413526768585\n",
      "Epoch 1961, reconstruction losses: 0.050764075273104156, regression losses: 0.12442490718985112, validation losses: 0.5007105984238899\n",
      "Epoch 1962, reconstruction losses: 0.04521448082274632, regression losses: 0.11146436069235162, validation losses: 0.4587749324586564\n",
      "Epoch 1963, reconstruction losses: 0.04821323090647825, regression losses: 0.2683347810804854, validation losses: 0.6171440053717241\n",
      "Epoch 1964, reconstruction losses: 0.044699295111093475, regression losses: 0.2725864086943887, validation losses: 0.6119300408965134\n",
      "Epoch 1965, reconstruction losses: 0.04674426814818311, regression losses: 0.1697196509980045, validation losses: 0.76332675112618\n",
      "Epoch 1966, reconstruction losses: 0.047858818723711394, regression losses: 0.14048677102404225, validation losses: 0.522483809907229\n",
      "Epoch 1967, reconstruction losses: 0.04726456711525598, regression losses: 0.1566284473044373, validation losses: 0.5413193121544791\n",
      "Epoch 1968, reconstruction losses: 0.046655137226846874, regression losses: 0.15411281614579603, validation losses: 0.564623150020824\n",
      "Epoch 1969, reconstruction losses: 0.047691274477713874, regression losses: 0.13862084687324594, validation losses: 0.6177134378894331\n",
      "Epoch 1970, reconstruction losses: 0.04649363031516512, regression losses: 0.13678845441835927, validation losses: 0.43450714381237865\n",
      "Epoch 1971, reconstruction losses: 0.04614284060049613, regression losses: 0.18748100248479166, validation losses: 0.5112062326191208\n",
      "Epoch 1972, reconstruction losses: 0.046679324816101875, regression losses: 0.12538657302354075, validation losses: 0.5130086077298859\n",
      "Epoch 1973, reconstruction losses: 0.04748740336356881, regression losses: 0.11944037846138819, validation losses: 0.6815067154427008\n",
      "Epoch 1974, reconstruction losses: 0.05225682707360904, regression losses: 0.19703472338787456, validation losses: 0.4681011298378056\n",
      "Epoch 1975, reconstruction losses: 0.047123033083657735, regression losses: 0.15509886070581017, validation losses: 0.48251545187315353\n",
      "Epoch 1976, reconstruction losses: 0.04622340250045018, regression losses: 0.17039089474223285, validation losses: 0.6134305540788446\n",
      "Epoch 1977, reconstruction losses: 0.04570030510291127, regression losses: 0.1286053556576198, validation losses: 0.5716508199231438\n",
      "Epoch 1978, reconstruction losses: 0.05181373942407709, regression losses: 0.14882019940344987, validation losses: 0.5171000321159078\n",
      "Epoch 1979, reconstruction losses: 0.048015538079276186, regression losses: 0.12436156887215553, validation losses: 0.5865804947923935\n",
      "Epoch 1980, reconstruction losses: 0.04832820389497213, regression losses: 0.13980634890125787, validation losses: 0.4826593803322843\n",
      "Epoch 1981, reconstruction losses: 0.04585238744948117, regression losses: 0.16447995310940494, validation losses: 0.4480826023584732\n",
      "Epoch 1982, reconstruction losses: 0.0517820255614733, regression losses: 0.1958121632938024, validation losses: 0.5820228256302298\n",
      "Epoch 1983, reconstruction losses: 0.05063238197957329, regression losses: 0.1073784159012188, validation losses: 0.6103914907143968\n",
      "Epoch 1984, reconstruction losses: 0.046411464463289524, regression losses: 0.13244243917411624, validation losses: 0.5376492781082632\n",
      "Epoch 1985, reconstruction losses: 0.05725193715508377, regression losses: 0.12059680566464828, validation losses: 0.5382736160640113\n",
      "Epoch 1986, reconstruction losses: 0.0479703061547314, regression losses: 0.11434406077654882, validation losses: 0.4868835563957049\n",
      "Epoch 1987, reconstruction losses: 0.05310425762426434, regression losses: 0.1514431681513983, validation losses: 0.4368322510698818\n",
      "Epoch 1988, reconstruction losses: 0.04557584427509337, regression losses: 0.1741325285552598, validation losses: 0.5106178894749558\n",
      "Epoch 1989, reconstruction losses: 0.049658672418514245, regression losses: 0.5456224017430694, validation losses: 0.4675929998432871\n",
      "Epoch 1990, reconstruction losses: 0.045586829901427366, regression losses: 0.16986529731184552, validation losses: 1.2584482963709775\n",
      "Epoch 1991, reconstruction losses: 0.04861866399830269, regression losses: 0.21851430506440014, validation losses: 0.6859606840065402\n",
      "Epoch 1992, reconstruction losses: 0.048918406771284714, regression losses: 0.1360320848483048, validation losses: 0.6321980253913105\n",
      "Epoch 1993, reconstruction losses: 0.049234093185657676, regression losses: 0.15667402234470323, validation losses: 0.48521049780674885\n",
      "Epoch 1994, reconstruction losses: 0.0515096519959845, regression losses: 0.15914095004470868, validation losses: 0.5491872728922924\n",
      "Epoch 1995, reconstruction losses: 0.05818206737289913, regression losses: 0.10477650482090431, validation losses: 0.5738306222927443\n",
      "Epoch 1996, reconstruction losses: 0.04652125185322704, regression losses: 0.12013195798380724, validation losses: 0.5660085563159615\n",
      "Epoch 1997, reconstruction losses: 0.04578951884505863, regression losses: 0.1319863463761977, validation losses: 0.46043952423801315\n",
      "Epoch 1998, reconstruction losses: 0.04549182225429972, regression losses: 0.150833295831188, validation losses: 0.45731920062538656\n",
      "Epoch 1999, reconstruction losses: 0.0511857240727643, regression losses: 0.16673129132977793, validation losses: 0.45284293761360683\n",
      "Epoch 2000, reconstruction losses: 0.05665242612891075, regression losses: 0.13231644808448997, validation losses: 0.5150223421091922\n",
      "Epoch 2001, reconstruction losses: 0.047241250161516576, regression losses: 0.13161981265081085, validation losses: 0.7425374941594863\n",
      "Epoch 2002, reconstruction losses: 0.0505163893989945, regression losses: 0.14486266314603663, validation losses: 0.5387759404211849\n",
      "Epoch 2003, reconstruction losses: 0.046607263663026505, regression losses: 0.17194800006870564, validation losses: 0.48067829796255557\n",
      "Epoch 2004, reconstruction losses: 0.04575614690293394, regression losses: 0.18324015829444737, validation losses: 0.8865128025364164\n",
      "Epoch 2005, reconstruction losses: 0.050103477957118746, regression losses: 0.2802960221964755, validation losses: 0.878652182879888\n",
      "Epoch 2006, reconstruction losses: 0.04857667923325291, regression losses: 0.18464331875029127, validation losses: 0.5478817471713633\n",
      "Epoch 2007, reconstruction losses: 0.04937888205041531, regression losses: 0.12248457821353917, validation losses: 0.7222793010852921\n",
      "Epoch 2008, reconstruction losses: 0.046925395257758004, regression losses: 0.1487026193809752, validation losses: 0.5568919429801135\n",
      "Epoch 2009, reconstruction losses: 0.050724902076402435, regression losses: 0.14168770651479037, validation losses: 0.46870256018985823\n",
      "Epoch 2010, reconstruction losses: 0.055854897877599605, regression losses: 0.1143249156968331, validation losses: 0.5679311953078532\n",
      "Epoch 2011, reconstruction losses: 0.04925321332639824, regression losses: 0.11450380896975958, validation losses: 0.5474932692934784\n",
      "Epoch 2012, reconstruction losses: 0.045801651501075485, regression losses: 0.12980491826763524, validation losses: 0.4577881387035758\n",
      "Epoch 2013, reconstruction losses: 0.04700844810933739, regression losses: 0.09941409994035123, validation losses: 0.45645289429849767\n",
      "Epoch 2014, reconstruction losses: 0.053590487843474977, regression losses: 0.1080841133122334, validation losses: 0.46557874627231477\n",
      "Epoch 2015, reconstruction losses: 0.05173186217288439, regression losses: 0.13752351561334794, validation losses: 0.45426609049698136\n",
      "Epoch 2016, reconstruction losses: 0.046661412596822105, regression losses: 0.13680851107312159, validation losses: 0.593841768364695\n",
      "Epoch 2017, reconstruction losses: 0.04498308271066824, regression losses: 0.20760804858248272, validation losses: 0.682935862142868\n",
      "Epoch 2018, reconstruction losses: 0.04920384458024046, regression losses: 0.1467780814195815, validation losses: 0.606519075760574\n",
      "Epoch 2019, reconstruction losses: 0.053039486361991184, regression losses: 0.15136876146405953, validation losses: 0.45077553516898955\n",
      "Epoch 2020, reconstruction losses: 0.04909211819150501, regression losses: 0.16805127316912696, validation losses: 0.5161922430663255\n",
      "Epoch 2021, reconstruction losses: 0.04561027502368211, regression losses: 0.16864809444523524, validation losses: 0.6192696732423782\n",
      "Epoch 2022, reconstruction losses: 0.0509235373716799, regression losses: 0.15143646325094948, validation losses: 0.5681811525572014\n",
      "Epoch 2023, reconstruction losses: 0.04843684686261524, regression losses: 0.1174773141185864, validation losses: 0.465690751589577\n",
      "Epoch 2024, reconstruction losses: 0.046852504689918605, regression losses: 0.10279806704312651, validation losses: 0.5192025123000766\n",
      "Epoch 2025, reconstruction losses: 0.04804057631022481, regression losses: 0.17262074799114624, validation losses: 0.49935053132483775\n",
      "Epoch 2026, reconstruction losses: 0.04551193443669972, regression losses: 0.1300453041157106, validation losses: 0.5235931205489504\n",
      "Epoch 2027, reconstruction losses: 0.051482602622390496, regression losses: 0.1708797627230803, validation losses: 0.4981059458801522\n",
      "Epoch 2028, reconstruction losses: 0.04706480568876059, regression losses: 0.16037598362384747, validation losses: 0.695748153732855\n",
      "Epoch 2029, reconstruction losses: 0.04900423629232646, regression losses: 0.10424864536656499, validation losses: 0.7150282947195102\n",
      "Epoch 2030, reconstruction losses: 0.047677310953870886, regression losses: 0.1361314279425261, validation losses: 0.6078205577387086\n",
      "Epoch 2031, reconstruction losses: 0.04524373328024894, regression losses: 0.10139637303443703, validation losses: 0.47547188284907366\n",
      "Epoch 2032, reconstruction losses: 0.04771567443641815, regression losses: 0.1404631362586333, validation losses: 0.47929089027603716\n",
      "Epoch 2033, reconstruction losses: 0.04861604443806011, regression losses: 0.16524421056541672, validation losses: 0.6699838731981078\n",
      "Epoch 2034, reconstruction losses: 0.04930671566128421, regression losses: 0.18628100081412172, validation losses: 0.5155923568861079\n",
      "Epoch 2035, reconstruction losses: 0.045195181032029026, regression losses: 0.18039766867583062, validation losses: 0.4957691202567639\n",
      "Epoch 2036, reconstruction losses: 0.04536980672582211, regression losses: 0.11739173561765004, validation losses: 0.8133598013850736\n",
      "Epoch 2037, reconstruction losses: 0.04809529268278202, regression losses: 0.137168515593014, validation losses: 0.5660281456200513\n",
      "Epoch 2038, reconstruction losses: 0.04948321128205511, regression losses: 0.1622748198712881, validation losses: 0.44889540776998055\n",
      "Epoch 2039, reconstruction losses: 0.04773080675301063, regression losses: 0.14301715064911535, validation losses: 0.48405175757773516\n",
      "Epoch 2040, reconstruction losses: 0.044487493682360275, regression losses: 0.11010081799447462, validation losses: 0.6482292987141361\n",
      "Epoch 2041, reconstruction losses: 0.047555658774997234, regression losses: 0.16411418379169077, validation losses: 0.45887444712633796\n",
      "Epoch 2042, reconstruction losses: 0.050222859985563806, regression losses: 0.11965359209495761, validation losses: 0.5173513964352495\n",
      "Epoch 2043, reconstruction losses: 0.047057032757116396, regression losses: 0.24941792036159027, validation losses: 0.4702912250009155\n",
      "Epoch 2044, reconstruction losses: 0.05131071470629176, regression losses: 0.14493811799570497, validation losses: 0.90260092053885\n",
      "Epoch 2045, reconstruction losses: 0.04603577248541408, regression losses: 0.1698030435887336, validation losses: 0.6265770394096599\n",
      "Epoch 2046, reconstruction losses: 0.047770970237545965, regression losses: 0.12610987265872464, validation losses: 0.5479039541857101\n",
      "Epoch 2047, reconstruction losses: 0.04860020418975238, regression losses: 0.14597295155033768, validation losses: 0.5267532722694406\n",
      "Epoch 2048, reconstruction losses: 0.04669087661672535, regression losses: 0.1731992788058035, validation losses: 0.622469926274111\n",
      "Epoch 2049, reconstruction losses: 0.050060559914105955, regression losses: 0.13822063281629407, validation losses: 0.5285959762651726\n",
      "Epoch 2050, reconstruction losses: 0.05045832205346301, regression losses: 0.15675702554479928, validation losses: 0.4752725933908494\n",
      "Epoch 2051, reconstruction losses: 0.051875461442074534, regression losses: 0.12123456797396598, validation losses: 0.7284961575803073\n",
      "Epoch 2052, reconstruction losses: 0.048144205787104793, regression losses: 0.12071189221958258, validation losses: 0.6013215972427403\n",
      "Epoch 2053, reconstruction losses: 0.05318424714544051, regression losses: 0.12190167976361191, validation losses: 0.4426726858117679\n",
      "Epoch 2054, reconstruction losses: 0.04755358972082416, regression losses: 0.11807919122723698, validation losses: 0.4494154663427365\n",
      "Epoch 2055, reconstruction losses: 0.05056088336076012, regression losses: 0.09956582841806574, validation losses: 0.5012309780056282\n",
      "Epoch 2056, reconstruction losses: 0.04906715166277363, regression losses: 0.158282709112392, validation losses: 0.4964450668490462\n",
      "Epoch 2057, reconstruction losses: 0.04691630773231855, regression losses: 0.1499251461745905, validation losses: 0.4652541111633476\n",
      "Epoch 2058, reconstruction losses: 0.05069903202874064, regression losses: 0.16085891596764493, validation losses: 0.5207295350662875\n",
      "Epoch 2059, reconstruction losses: 0.0457756609335522, regression losses: 0.20256270107596455, validation losses: 0.5986668859903219\n",
      "Epoch 2060, reconstruction losses: 0.04995641930140298, regression losses: 0.15449618634263332, validation losses: 0.6380175377159124\n",
      "Epoch 2061, reconstruction losses: 0.0487551502403523, regression losses: 0.1433568520971735, validation losses: 0.6072761027072683\n",
      "Epoch 2062, reconstruction losses: 0.046524416131785255, regression losses: 0.14317839765595894, validation losses: 0.5744306724904246\n",
      "Epoch 2063, reconstruction losses: 0.04613203065019038, regression losses: 0.1544700638705149, validation losses: 0.6198726153241074\n",
      "Epoch 2064, reconstruction losses: 0.045336181498664314, regression losses: 0.1615814181936507, validation losses: 0.6394089551175174\n",
      "Epoch 2065, reconstruction losses: 0.0506762186318739, regression losses: 0.16023899546137402, validation losses: 0.5922354515041781\n",
      "Epoch 2066, reconstruction losses: 0.050316470107470646, regression losses: 0.14884682843249086, validation losses: 0.4924124723909723\n",
      "Epoch 2067, reconstruction losses: 0.04388760711538364, regression losses: 0.12981553217845423, validation losses: 0.48495666970276585\n",
      "Epoch 2068, reconstruction losses: 0.04499634699855333, regression losses: 0.2075990905220488, validation losses: 0.5301460775024747\n",
      "Epoch 2069, reconstruction losses: 0.04470405345099858, regression losses: 0.1458655964869438, validation losses: 0.5166173627585178\n",
      "Epoch 2070, reconstruction losses: 0.04482747361340616, regression losses: 0.2149133684874781, validation losses: 0.628123746543969\n",
      "Epoch 2071, reconstruction losses: 0.04816948904005061, regression losses: 0.11934673736977214, validation losses: 0.5193680897600051\n",
      "Epoch 2072, reconstruction losses: 0.04696489603448788, regression losses: 0.13834443978962813, validation losses: 0.5659468846468769\n",
      "Epoch 2073, reconstruction losses: 0.05231928198683543, regression losses: 0.13493235524119457, validation losses: 0.4669049774175754\n",
      "Epoch 2074, reconstruction losses: 0.04552151155894046, regression losses: 0.12074774825412996, validation losses: 0.46009499777114216\n",
      "Epoch 2075, reconstruction losses: 0.04731954294751739, regression losses: 0.14100719636024284, validation losses: 0.5448511541466537\n",
      "Epoch 2076, reconstruction losses: 0.04917384323020254, regression losses: 0.16975565981538687, validation losses: 0.5428888503960657\n",
      "Epoch 2077, reconstruction losses: 0.045534484529810286, regression losses: 0.165538125786385, validation losses: 0.4919306332656295\n",
      "Epoch 2078, reconstruction losses: 0.05666087584156214, regression losses: 0.13778875618131697, validation losses: 0.45557209555324085\n",
      "Epoch 2079, reconstruction losses: 0.048756692863903967, regression losses: 0.16296789101165265, validation losses: 0.5228422124277201\n",
      "Epoch 2080, reconstruction losses: 0.04698190125837278, regression losses: 0.12159695051761894, validation losses: 0.7784314850539844\n",
      "Epoch 2081, reconstruction losses: 0.049885107847491596, regression losses: 0.13133024789952144, validation losses: 0.5033074643121401\n",
      "Epoch 2082, reconstruction losses: 0.04738752134244737, regression losses: 0.13827949945377793, validation losses: 0.4439288464586952\n",
      "Epoch 2083, reconstruction losses: 0.04641927260458201, regression losses: 0.09999331436189406, validation losses: 0.49860793001695386\n",
      "Epoch 2084, reconstruction losses: 0.04598757951901506, regression losses: 0.13426874104022757, validation losses: 0.4740719471395006\n",
      "Epoch 2085, reconstruction losses: 0.0457275075239207, regression losses: 0.13974333627473184, validation losses: 0.41963165407516195\n",
      "Epoch 2086, reconstruction losses: 0.04669245176988493, regression losses: 0.14478320949809173, validation losses: 0.44312240115036233\n",
      "Epoch 2087, reconstruction losses: 0.044996193068191526, regression losses: 0.12953906416938363, validation losses: 0.5455552654587763\n",
      "Epoch 2088, reconstruction losses: 0.04573417044402784, regression losses: 0.1348370542260545, validation losses: 0.5716623899296481\n",
      "Epoch 2089, reconstruction losses: 0.04599096821227939, regression losses: 0.16672776314654786, validation losses: 0.49985616786684073\n",
      "Epoch 2090, reconstruction losses: 0.04512908906084167, regression losses: 0.12231792212565522, validation losses: 0.5279984843404164\n",
      "Epoch 2091, reconstruction losses: 0.04441544366553967, regression losses: 0.12836151405877902, validation losses: 0.4660883450141155\n",
      "Epoch 2092, reconstruction losses: 0.05192714902871094, regression losses: 0.15278224385084735, validation losses: 0.4447987286027288\n",
      "Epoch 2093, reconstruction losses: 0.058647077086119055, regression losses: 0.10721814154469665, validation losses: 0.4897799367010696\n",
      "Epoch 2094, reconstruction losses: 0.047364965761570836, regression losses: 0.15790502557105462, validation losses: 0.49826570734007725\n",
      "Epoch 2095, reconstruction losses: 0.04571776316610638, regression losses: 0.18258866165988302, validation losses: 0.6148474754460219\n",
      "Epoch 2096, reconstruction losses: 0.05321948629363263, regression losses: 0.13909313245829313, validation losses: 0.4800352956154975\n",
      "Epoch 2097, reconstruction losses: 0.04794758560834624, regression losses: 0.1894206621095415, validation losses: 0.45816005693666817\n",
      "Epoch 2098, reconstruction losses: 0.04733768052905408, regression losses: 0.12725108714354047, validation losses: 0.5195334764493708\n",
      "Epoch 2099, reconstruction losses: 0.044743007499157265, regression losses: 0.13663395260539468, validation losses: 0.5079524774807453\n",
      "Epoch 2100, reconstruction losses: 0.04617958085411479, regression losses: 0.1653255181192088, validation losses: 0.5334435606970388\n",
      "Epoch 2101, reconstruction losses: 0.04534215021237185, regression losses: 0.1504456301752768, validation losses: 0.5183433296748117\n",
      "Epoch 2102, reconstruction losses: 0.04940245211299794, regression losses: 0.12477865568009441, validation losses: 0.5883803045224916\n",
      "Epoch 2103, reconstruction losses: 0.0476539951465261, regression losses: 0.13550388056149332, validation losses: 0.48251066905131684\n",
      "Epoch 2104, reconstruction losses: 0.05130511633755778, regression losses: 0.145887288603038, validation losses: 0.4769698135111674\n",
      "Epoch 2105, reconstruction losses: 0.05615364048964924, regression losses: 0.11714566092154499, validation losses: 0.6243093568668163\n",
      "Epoch 2106, reconstruction losses: 0.04787934496912043, regression losses: 0.169166095747732, validation losses: 0.544401248501828\n",
      "Epoch 2107, reconstruction losses: 0.05390310801947021, regression losses: 0.11281336302109425, validation losses: 0.4311853395109335\n",
      "Epoch 2108, reconstruction losses: 0.05585510438390528, regression losses: 0.12461969103943722, validation losses: 0.45560693902905847\n",
      "Epoch 2109, reconstruction losses: 0.04892630086166845, regression losses: 0.15080602062024748, validation losses: 0.5646149223849934\n",
      "Epoch 2110, reconstruction losses: 0.04546189010874731, regression losses: 0.13602627640613116, validation losses: 0.5656108973549516\n",
      "Epoch 2111, reconstruction losses: 0.052150336393498774, regression losses: 0.13550532437515828, validation losses: 0.5272824023499049\n",
      "Epoch 2112, reconstruction losses: 0.05066867579321007, regression losses: 0.13070113124434, validation losses: 0.5139114906472203\n",
      "Epoch 2113, reconstruction losses: 0.04799182149453154, regression losses: 0.12725868551017022, validation losses: 0.5698906426994339\n",
      "Epoch 2114, reconstruction losses: 0.05039776574826312, regression losses: 0.14557371096960042, validation losses: 0.4645447886382481\n",
      "Epoch 2115, reconstruction losses: 0.05043630528900772, regression losses: 0.14756460298230623, validation losses: 0.43815423535324294\n",
      "Epoch 2116, reconstruction losses: 0.05085049754576095, regression losses: 0.15723451932532903, validation losses: 0.5495025563109133\n",
      "Epoch 2117, reconstruction losses: 0.0480734691933234, regression losses: 0.17347713646870883, validation losses: 0.4505913944412972\n",
      "Epoch 2118, reconstruction losses: 0.05025870176801455, regression losses: 0.1713630259158039, validation losses: 0.5286488194328327\n",
      "Epoch 2119, reconstruction losses: 0.04526377400973711, regression losses: 0.14689213080807706, validation losses: 0.479641700693236\n",
      "Epoch 2120, reconstruction losses: 0.0477207422132713, regression losses: 0.13825806278096003, validation losses: 0.7523932048702315\n",
      "Epoch 2121, reconstruction losses: 0.050779058851685294, regression losses: 0.15349773129642996, validation losses: 0.6836227427435022\n",
      "Epoch 2122, reconstruction losses: 0.04962003370392522, regression losses: 0.40217032520176144, validation losses: 0.5805008692801199\n",
      "Epoch 2123, reconstruction losses: 0.04740805781308835, regression losses: 0.6007056843352099, validation losses: 0.6917337683659678\n",
      "Epoch 2124, reconstruction losses: 0.046430011364159036, regression losses: 0.2205273976313589, validation losses: 1.3263980052133155\n",
      "Epoch 2125, reconstruction losses: 0.04521530101420262, regression losses: 0.37512095586208893, validation losses: 0.5480721032085827\n",
      "Epoch 2126, reconstruction losses: 0.04810490321881486, regression losses: 0.2190041267911799, validation losses: 1.5481032835938318\n",
      "Epoch 2127, reconstruction losses: 0.04804816213942044, regression losses: 0.21055805021875595, validation losses: 0.9039258897282629\n",
      "Epoch 2128, reconstruction losses: 0.04547342445340014, regression losses: 0.17123477167246598, validation losses: 0.8714657417269839\n",
      "Epoch 2129, reconstruction losses: 0.0457818480919605, regression losses: 0.15710211136511862, validation losses: 0.41348957020129784\n",
      "Epoch 2130, reconstruction losses: 0.04684093750218625, regression losses: 0.13533400762022313, validation losses: 0.4633894679067134\n",
      "Epoch 2131, reconstruction losses: 0.0444745696218, regression losses: 0.14345060291384304, validation losses: 0.5708591139368959\n",
      "Epoch 2132, reconstruction losses: 0.04448038037857221, regression losses: 0.18828160012219336, validation losses: 0.4806453531050341\n",
      "Epoch 2133, reconstruction losses: 0.04791325158533026, regression losses: 0.1590251340910636, validation losses: 0.43403226723833627\n",
      "Epoch 2134, reconstruction losses: 0.04635841660864077, regression losses: 0.1420089290893269, validation losses: 0.4730828933833035\n",
      "Epoch 2135, reconstruction losses: 0.05010446636393801, regression losses: 0.14183022349156885, validation losses: 0.5364711172847124\n",
      "Epoch 2136, reconstruction losses: 0.04517081553203959, regression losses: 0.2679804511234687, validation losses: 0.5123485489160838\n",
      "Epoch 2137, reconstruction losses: 0.05061598258676833, regression losses: 0.17150963544906112, validation losses: 0.7467337258898817\n",
      "Epoch 2138, reconstruction losses: 0.05042967059798651, regression losses: 0.13022438155818067, validation losses: 0.4401034725120024\n",
      "Epoch 2139, reconstruction losses: 0.047761444176603336, regression losses: 0.14021531888190739, validation losses: 0.4613077685448587\n",
      "Epoch 2140, reconstruction losses: 0.04803304714936828, regression losses: 0.10705786871931637, validation losses: 0.5443505173138607\n",
      "Epoch 2141, reconstruction losses: 0.04915509173634615, regression losses: 0.20048247861511626, validation losses: 0.5699176139335377\n",
      "Epoch 2142, reconstruction losses: 0.04531055913504487, regression losses: 0.12644129716753794, validation losses: 0.4942530991480595\n",
      "Epoch 2143, reconstruction losses: 0.0466076133986235, regression losses: 0.23524621576514393, validation losses: 0.48104574730569916\n",
      "Epoch 2144, reconstruction losses: 0.0464608808509616, regression losses: 0.16671528357120224, validation losses: 0.8027958273618352\n",
      "Epoch 2145, reconstruction losses: 0.04742814583191354, regression losses: 0.21128848207988543, validation losses: 0.5691483699935616\n",
      "Epoch 2146, reconstruction losses: 0.050663819376034494, regression losses: 0.1519462134767075, validation losses: 0.6440643744923703\n",
      "Epoch 2147, reconstruction losses: 0.048346181349246266, regression losses: 0.18428565356020146, validation losses: 0.540649781162683\n",
      "Epoch 2148, reconstruction losses: 0.048643237221607856, regression losses: 0.10264266079137238, validation losses: 0.5932526276104585\n",
      "Epoch 2149, reconstruction losses: 0.0507696132199005, regression losses: 0.18946186415263472, validation losses: 0.6871117623005127\n",
      "Epoch 2150, reconstruction losses: 0.05101182432511979, regression losses: 0.14149272809651622, validation losses: 0.4257566663482115\n",
      "Epoch 2151, reconstruction losses: 0.04793314661168908, regression losses: 0.15430663398643246, validation losses: 0.4557069930759218\n",
      "Epoch 2152, reconstruction losses: 0.048888538074927365, regression losses: 0.1502491938404913, validation losses: 0.6974491221743923\n",
      "Epoch 2153, reconstruction losses: 0.04510056676145643, regression losses: 0.13615552237497042, validation losses: 0.5402011730535278\n",
      "Epoch 2154, reconstruction losses: 0.044999649008005294, regression losses: 0.14730173083699213, validation losses: 0.4398599232962837\n",
      "Epoch 2155, reconstruction losses: 0.04704505386399859, regression losses: 0.14513964971933282, validation losses: 0.6627075795030312\n",
      "Epoch 2156, reconstruction losses: 0.04776399466249607, regression losses: 0.1539792580862982, validation losses: 0.7529655197145275\n",
      "Epoch 2157, reconstruction losses: 0.0481963975222411, regression losses: 0.1448462177781732, validation losses: 0.4370003216620305\n",
      "Epoch 2158, reconstruction losses: 0.044433254759528466, regression losses: 0.16853057680712002, validation losses: 0.4425708697127423\n",
      "Epoch 2159, reconstruction losses: 0.04765958860391666, regression losses: 0.25930888842718464, validation losses: 0.8430027282950854\n",
      "Epoch 2160, reconstruction losses: 0.04706434153559135, regression losses: 0.11935682268164166, validation losses: 0.8345449818823565\n",
      "Epoch 2161, reconstruction losses: 0.05159113905119751, regression losses: 0.28265471249675417, validation losses: 0.4238523310926291\n",
      "Epoch 2162, reconstruction losses: 0.04554501026709645, regression losses: 0.12949760094920448, validation losses: 0.8703527355724731\n",
      "Epoch 2163, reconstruction losses: 0.051123618551758614, regression losses: 0.20361305965058213, validation losses: 0.7080713868027566\n",
      "Epoch 2164, reconstruction losses: 0.04464724616414502, regression losses: 0.14052528912512224, validation losses: 0.42824361395194105\n",
      "Epoch 2165, reconstruction losses: 0.046735691605567314, regression losses: 0.19521688092043013, validation losses: 0.43075627619812495\n",
      "Epoch 2166, reconstruction losses: 0.04498566290267937, regression losses: 0.12132990561210562, validation losses: 0.7425814892494809\n",
      "Epoch 2167, reconstruction losses: 0.05481140455918251, regression losses: 0.13598064270371554, validation losses: 0.5437020726411494\n",
      "Epoch 2168, reconstruction losses: 0.04718146831814158, regression losses: 0.18803297364332033, validation losses: 0.5662279666509697\n",
      "Epoch 2169, reconstruction losses: 0.04736642182504993, regression losses: 0.13526571180318908, validation losses: 0.6944631632769169\n",
      "Epoch 2170, reconstruction losses: 0.04678296692966133, regression losses: 0.18143746774600314, validation losses: 0.7740038060302952\n",
      "Epoch 2171, reconstruction losses: 0.04582451526272554, regression losses: 0.15949949148179376, validation losses: 0.4727053134034091\n",
      "Epoch 2172, reconstruction losses: 0.045352263974841454, regression losses: 0.11157197214053902, validation losses: 0.7376076074159191\n",
      "Epoch 2173, reconstruction losses: 0.04730250891729374, regression losses: 0.16796742660973887, validation losses: 0.5635565538470656\n",
      "Epoch 2174, reconstruction losses: 0.048125209509038626, regression losses: 0.15273313273633699, validation losses: 0.9245676393179808\n",
      "Epoch 2175, reconstruction losses: 0.04781459160981322, regression losses: 0.16260595535025296, validation losses: 0.5534687131903758\n",
      "Epoch 2176, reconstruction losses: 0.05104284506598236, regression losses: 0.13838757815869127, validation losses: 0.5281379835335123\n",
      "Epoch 2177, reconstruction losses: 0.04541912599073993, regression losses: 0.14360245128349058, validation losses: 0.6198156772051333\n",
      "Epoch 2178, reconstruction losses: 0.05633384906930103, regression losses: 0.21134176228118856, validation losses: 0.6120280567526747\n",
      "Epoch 2179, reconstruction losses: 0.04464573464046988, regression losses: 0.14865976917725077, validation losses: 0.6690845673537579\n",
      "Epoch 2180, reconstruction losses: 0.04830231492175061, regression losses: 0.1582497792971918, validation losses: 0.46374738099265433\n",
      "Epoch 2181, reconstruction losses: 0.04562828686004733, regression losses: 0.21536878638635668, validation losses: 0.5570520445538895\n",
      "Epoch 2182, reconstruction losses: 0.046395704505069406, regression losses: 0.15447606140316988, validation losses: 0.7778556476762277\n",
      "Epoch 2183, reconstruction losses: 0.05461202097493571, regression losses: 0.15549593230579878, validation losses: 0.44234112293327854\n",
      "Epoch 2184, reconstruction losses: 0.055265161031701864, regression losses: 0.10793567575082916, validation losses: 0.5436168670686775\n",
      "Epoch 2185, reconstruction losses: 0.04571188150383371, regression losses: 0.14223471619166522, validation losses: 0.7261240460965522\n",
      "Epoch 2186, reconstruction losses: 0.04479954238185461, regression losses: 0.17065340612883728, validation losses: 0.5609825803272617\n",
      "Epoch 2187, reconstruction losses: 0.04575731241715936, regression losses: 0.13135332646851394, validation losses: 0.5745412185213904\n",
      "Epoch 2188, reconstruction losses: 0.04984729323026331, regression losses: 0.11855931737167057, validation losses: 0.4635427173593066\n",
      "Epoch 2189, reconstruction losses: 0.046303305212339815, regression losses: 0.1536871196886198, validation losses: 0.44565565568027415\n",
      "Epoch 2190, reconstruction losses: 0.04621251295140402, regression losses: 0.12064255145960216, validation losses: 0.6269672854889615\n",
      "Epoch 2191, reconstruction losses: 0.056849534086475126, regression losses: 0.13082491004225108, validation losses: 0.4516731817747492\n",
      "Epoch 2192, reconstruction losses: 0.04692871434065702, regression losses: 0.15608713520143663, validation losses: 0.44288804807477944\n",
      "Epoch 2193, reconstruction losses: 0.04703464497361021, regression losses: 0.18247240985380966, validation losses: 0.6634206350231362\n",
      "Epoch 2194, reconstruction losses: 0.050750525238471, regression losses: 0.16290066484671034, validation losses: 0.8540613934115793\n",
      "Epoch 2195, reconstruction losses: 0.04522123824701317, regression losses: 0.16561462089789653, validation losses: 0.438709444917188\n",
      "Epoch 2196, reconstruction losses: 0.05046619733977307, regression losses: 0.1451057403218347, validation losses: 0.42690000975555414\n",
      "Epoch 2197, reconstruction losses: 0.04669114532151741, regression losses: 0.30080674518828526, validation losses: 0.53331548088212\n",
      "Epoch 2198, reconstruction losses: 0.05040561452886418, regression losses: 0.18166906206387806, validation losses: 0.8548363830724706\n",
      "Epoch 2199, reconstruction losses: 0.04605671193458876, regression losses: 0.13727423204767675, validation losses: 0.4341477248503975\n",
      "Epoch 2200, reconstruction losses: 0.0504507656948196, regression losses: 0.1238180636866352, validation losses: 0.49157068948837285\n",
      "Epoch 2201, reconstruction losses: 0.04511828634704271, regression losses: 0.14855126415491943, validation losses: 0.6219270916364696\n",
      "Epoch 2202, reconstruction losses: 0.04655594066416006, regression losses: 0.15102296975841595, validation losses: 0.6847691418488868\n",
      "Epoch 2203, reconstruction losses: 0.05065546642698347, regression losses: 0.1544509808665706, validation losses: 0.47026621340145563\n",
      "Epoch 2204, reconstruction losses: 0.05168303319890717, regression losses: 0.12077910431889533, validation losses: 0.45536985355879817\n",
      "Epoch 2205, reconstruction losses: 0.04592109879453839, regression losses: 0.14933007240104446, validation losses: 0.4704540415056248\n",
      "Epoch 2206, reconstruction losses: 0.05057668259431008, regression losses: 0.17821697982711424, validation losses: 0.5883578497063547\n",
      "Epoch 2207, reconstruction losses: 0.05710079360955927, regression losses: 0.16237495739401364, validation losses: 0.4267022905378382\n",
      "Epoch 2208, reconstruction losses: 0.04462922801855568, regression losses: 0.13152628739098468, validation losses: 0.5546918467628608\n",
      "Epoch 2209, reconstruction losses: 0.04715535614965411, regression losses: 0.14211206737503793, validation losses: 0.6223459632180077\n",
      "Epoch 2210, reconstruction losses: 0.0492661505085572, regression losses: 0.20722842207319098, validation losses: 0.591995814922996\n",
      "Epoch 2211, reconstruction losses: 0.052544196718139154, regression losses: 0.11526598866161848, validation losses: 0.5825515911333399\n",
      "Epoch 2212, reconstruction losses: 0.04878924315927473, regression losses: 0.1452386808464871, validation losses: 0.46897192789714087\n",
      "Epoch 2213, reconstruction losses: 0.04668054144108466, regression losses: 0.12243427614886379, validation losses: 0.578379944247055\n",
      "Epoch 2214, reconstruction losses: 0.04621464611811614, regression losses: 0.14104215245561771, validation losses: 0.5012483326537781\n",
      "Epoch 2215, reconstruction losses: 0.050625857009441, regression losses: 0.11564826589425653, validation losses: 0.4799036587950525\n",
      "Epoch 2216, reconstruction losses: 0.050406776983142075, regression losses: 0.1944860827001828, validation losses: 0.6288648245868814\n",
      "Epoch 2217, reconstruction losses: 0.05528361900211997, regression losses: 0.13596936049076758, validation losses: 0.8195172908377318\n",
      "Epoch 2218, reconstruction losses: 0.050596159957063305, regression losses: 0.11151228047075466, validation losses: 0.46247724262208867\n",
      "Epoch 2219, reconstruction losses: 0.04551417371888999, regression losses: 0.09885109556148952, validation losses: 0.45327865727347283\n",
      "Epoch 2220, reconstruction losses: 0.046290335143191835, regression losses: 0.14783137953422862, validation losses: 0.5986763031282831\n",
      "Epoch 2221, reconstruction losses: 0.04606012830994003, regression losses: 0.12825122381331083, validation losses: 0.8063126127712948\n",
      "Epoch 2222, reconstruction losses: 0.0485529118308475, regression losses: 0.13765608554782752, validation losses: 0.631920132269892\n",
      "Epoch 2223, reconstruction losses: 0.051396275085298516, regression losses: 0.1336273045500917, validation losses: 0.4984528986224512\n",
      "Epoch 2224, reconstruction losses: 0.04574015251899653, regression losses: 0.12952700556353205, validation losses: 0.5130659166919825\n",
      "Epoch 2225, reconstruction losses: 0.04783151814954439, regression losses: 0.20888242819550373, validation losses: 0.5641582886185722\n",
      "Epoch 2226, reconstruction losses: 0.050142406229396454, regression losses: 0.143018400638041, validation losses: 0.5145275961174139\n",
      "Epoch 2227, reconstruction losses: 0.04533516134648421, regression losses: 0.19883903941348458, validation losses: 0.4685266235979216\n",
      "Epoch 2228, reconstruction losses: 0.05045800083944784, regression losses: 0.12643573840890288, validation losses: 0.7617290327532995\n",
      "Epoch 2229, reconstruction losses: 0.04685602829044007, regression losses: 0.13527417299917316, validation losses: 0.5799502287212741\n",
      "Epoch 2230, reconstruction losses: 0.045281215365264596, regression losses: 0.19344515880828148, validation losses: 0.4809535178251296\n",
      "Epoch 2231, reconstruction losses: 0.05092401878676425, regression losses: 0.1634714859247478, validation losses: 0.5156055170187689\n",
      "Epoch 2232, reconstruction losses: 0.056519391771638686, regression losses: 0.1674487279927865, validation losses: 0.6415655770522898\n",
      "Epoch 2233, reconstruction losses: 0.044541459751497134, regression losses: 0.147387923032265, validation losses: 0.4218994807176397\n",
      "Epoch 2234, reconstruction losses: 0.04462146184677865, regression losses: 0.12775907704112965, validation losses: 0.4473755914450798\n",
      "Epoch 2235, reconstruction losses: 0.0489394316760727, regression losses: 0.1642273649398126, validation losses: 0.4485493266237667\n",
      "Epoch 2236, reconstruction losses: 0.049674272588921424, regression losses: 0.1494736317420352, validation losses: 0.6175735624151839\n",
      "Epoch 2237, reconstruction losses: 0.05002633613633455, regression losses: 0.13443561111429758, validation losses: 0.529700953492928\n",
      "Epoch 2238, reconstruction losses: 0.04643003879000084, regression losses: 0.11495957072872284, validation losses: 0.4755783704069199\n",
      "Epoch 2239, reconstruction losses: 0.04538224678617602, regression losses: 0.17480194857715103, validation losses: 0.5481588901929273\n",
      "Epoch 2240, reconstruction losses: 0.04618750267793138, regression losses: 0.11156428861137711, validation losses: 0.6010124188921656\n",
      "Epoch 2241, reconstruction losses: 0.04697670693947682, regression losses: 0.16523564778738278, validation losses: 0.5147813558403672\n",
      "Epoch 2242, reconstruction losses: 0.04651567535227344, regression losses: 0.21068447554312011, validation losses: 0.5424006653105078\n",
      "Epoch 2243, reconstruction losses: 0.04580898610999732, regression losses: 0.14779458568200524, validation losses: 0.7079980021718539\n",
      "Epoch 2244, reconstruction losses: 0.05117214204243232, regression losses: 0.14580634978941237, validation losses: 0.6283821895861241\n",
      "Epoch 2245, reconstruction losses: 0.04563964087404918, regression losses: 0.15294807380869885, validation losses: 0.5846089670881568\n",
      "Epoch 2246, reconstruction losses: 0.05482312994143384, regression losses: 0.13479289650837423, validation losses: 0.42103032666808515\n",
      "Epoch 2247, reconstruction losses: 0.04632875131925893, regression losses: 0.14452874881411643, validation losses: 0.5021588823260206\n",
      "Epoch 2248, reconstruction losses: 0.04834292755590335, regression losses: 0.1415325747936881, validation losses: 0.8354357995668913\n",
      "Epoch 2249, reconstruction losses: 0.055962059303764675, regression losses: 0.13672749718586838, validation losses: 0.5633845827102953\n",
      "Epoch 2250, reconstruction losses: 0.04633004509336124, regression losses: 0.14314583339002745, validation losses: 0.43401725390034196\n",
      "Epoch 2251, reconstruction losses: 0.050420081043566205, regression losses: 0.192592582720986, validation losses: 0.5686267792392495\n",
      "Epoch 2252, reconstruction losses: 0.04593527457515122, regression losses: 0.1633608671348068, validation losses: 0.8283020693188986\n",
      "Epoch 2253, reconstruction losses: 0.04755840745804681, regression losses: 0.1450770638246026, validation losses: 0.5289028991411372\n",
      "Epoch 2254, reconstruction losses: 0.05018977093392406, regression losses: 0.15584744433968833, validation losses: 0.4666730403929724\n",
      "Epoch 2255, reconstruction losses: 0.045946978647209966, regression losses: 0.127879141022842, validation losses: 0.554643072138124\n",
      "Epoch 2256, reconstruction losses: 0.049334947820528684, regression losses: 0.14426233321444965, validation losses: 0.5159688867086603\n",
      "Epoch 2257, reconstruction losses: 0.04624253017804319, regression losses: 0.15517180294368316, validation losses: 0.48245201981926833\n",
      "Epoch 2258, reconstruction losses: 0.04513375301048377, regression losses: 0.12886717440592932, validation losses: 0.5500840085907238\n",
      "Epoch 2259, reconstruction losses: 0.04967190517335598, regression losses: 0.1384169643995664, validation losses: 0.5019658701624239\n",
      "Epoch 2260, reconstruction losses: 0.04409646486517646, regression losses: 0.15200327057445714, validation losses: 0.5165744201431132\n",
      "Epoch 2261, reconstruction losses: 0.046096843642362564, regression losses: 0.1886287282189471, validation losses: 0.5267451904410586\n",
      "Epoch 2262, reconstruction losses: 0.0464000614619453, regression losses: 0.32209618809224916, validation losses: 0.5358155307836489\n",
      "Epoch 2263, reconstruction losses: 0.05535576443060502, regression losses: 0.14228521001933783, validation losses: 0.4475273488316993\n",
      "Epoch 2264, reconstruction losses: 0.049745980175207385, regression losses: 0.15349573968392727, validation losses: 0.48571145114276476\n",
      "Epoch 2265, reconstruction losses: 0.04577777233785559, regression losses: 0.12613340932497313, validation losses: 0.8268522139886142\n",
      "Epoch 2266, reconstruction losses: 0.05398508256710737, regression losses: 0.1330232024796158, validation losses: 0.6148472480534318\n",
      "Epoch 2267, reconstruction losses: 0.044420553585182876, regression losses: 0.30029049272938213, validation losses: 0.5094041076562209\n",
      "Epoch 2268, reconstruction losses: 0.045923374869189564, regression losses: 0.19568182293569325, validation losses: 0.7808316847106596\n",
      "Epoch 2269, reconstruction losses: 0.04521682700266576, regression losses: 0.1505093344350221, validation losses: 0.6457114763127245\n",
      "Epoch 2270, reconstruction losses: 0.0446022635739029, regression losses: 0.17762232228701896, validation losses: 0.5799579713650134\n",
      "Epoch 2271, reconstruction losses: 0.04789164979757191, regression losses: 0.27666660696564516, validation losses: 0.5677619471027354\n",
      "Epoch 2272, reconstruction losses: 0.04609868840786747, regression losses: 0.10006768190354913, validation losses: 0.7292376355595884\n",
      "Epoch 2273, reconstruction losses: 0.04542294447778708, regression losses: 0.14605070213396257, validation losses: 0.6279150697846092\n",
      "Epoch 2274, reconstruction losses: 0.04340092606071409, regression losses: 0.12169772900061779, validation losses: 0.5687458767998018\n",
      "Epoch 2275, reconstruction losses: 0.047280541840305446, regression losses: 0.13568428019878942, validation losses: 0.6034007272497256\n",
      "Epoch 2276, reconstruction losses: 0.04527150143696777, regression losses: 0.12450162263999658, validation losses: 0.47978480169540355\n",
      "Epoch 2277, reconstruction losses: 0.05106293277566981, regression losses: 0.13008172196979345, validation losses: 0.46081453258802463\n",
      "Epoch 2278, reconstruction losses: 0.0478813277467056, regression losses: 0.09995175727938695, validation losses: 0.4437373998435801\n",
      "Epoch 2279, reconstruction losses: 0.046200312116300504, regression losses: 0.12902757925398453, validation losses: 0.46535169398156073\n",
      "Epoch 2280, reconstruction losses: 0.04829958775330487, regression losses: 0.14191404178561018, validation losses: 0.528517599530056\n",
      "Epoch 2281, reconstruction losses: 0.04483017462617194, regression losses: 0.14825670531040447, validation losses: 0.5906701985994701\n",
      "Epoch 2282, reconstruction losses: 0.04324675380552661, regression losses: 0.1223135141997905, validation losses: 0.7013587365804597\n",
      "Epoch 2283, reconstruction losses: 0.045558732671183974, regression losses: 0.16165278154703372, validation losses: 0.49227885856455633\n",
      "Epoch 2284, reconstruction losses: 0.04650133181108345, regression losses: 0.18452942022053087, validation losses: 0.4950140228643699\n",
      "Epoch 2285, reconstruction losses: 0.04625247264736957, regression losses: 0.2746549313391458, validation losses: 0.8629777322903286\n",
      "Epoch 2286, reconstruction losses: 0.04859108864808635, regression losses: 0.1773911347292776, validation losses: 0.7777773798728178\n",
      "Epoch 2287, reconstruction losses: 0.04574620116886572, regression losses: 0.1565845496160089, validation losses: 0.46268132226967684\n",
      "Epoch 2288, reconstruction losses: 0.04533679157961443, regression losses: 0.214537189307267, validation losses: 0.6121894129692805\n",
      "Epoch 2289, reconstruction losses: 0.04356679646695246, regression losses: 0.11473162178672704, validation losses: 0.651964606098288\n",
      "Epoch 2290, reconstruction losses: 0.04470641865873315, regression losses: 0.16281531193713833, validation losses: 0.5404688082366026\n",
      "Epoch 2291, reconstruction losses: 0.044156948602562585, regression losses: 0.1134759858792154, validation losses: 0.509424740159699\n",
      "Epoch 2292, reconstruction losses: 0.05606782079545873, regression losses: 0.14345357859288102, validation losses: 0.5240935054077624\n",
      "Epoch 2293, reconstruction losses: 0.04323419732591176, regression losses: 0.12214778961174269, validation losses: 0.5608414089594692\n",
      "Epoch 2294, reconstruction losses: 0.04480807537174451, regression losses: 0.13003370278394485, validation losses: 0.4408674052460932\n",
      "Epoch 2295, reconstruction losses: 0.04901081038716737, regression losses: 0.1049404081536253, validation losses: 0.43298627228117703\n",
      "Epoch 2296, reconstruction losses: 0.056630240516933786, regression losses: 0.11718565502030429, validation losses: 0.46876699428723945\n",
      "Epoch 2297, reconstruction losses: 0.04496350769031337, regression losses: 0.15246918294850517, validation losses: 0.5099537479048455\n",
      "Epoch 2298, reconstruction losses: 0.046200353398795815, regression losses: 0.11802361940776762, validation losses: 0.5083707680302177\n",
      "Epoch 2299, reconstruction losses: 0.04522158449938578, regression losses: 0.12586995075154409, validation losses: 0.525300181706414\n",
      "Epoch 2300, reconstruction losses: 0.04972858518616332, regression losses: 0.12984584843628094, validation losses: 0.5441339229546224\n",
      "Epoch 2301, reconstruction losses: 0.04598496203506082, regression losses: 0.11403481235490392, validation losses: 0.46785055022768074\n",
      "Epoch 2302, reconstruction losses: 0.04647628675605304, regression losses: 0.13439196822362362, validation losses: 0.4416197282392338\n",
      "Epoch 2303, reconstruction losses: 0.050560653048992564, regression losses: 0.11330303413128769, validation losses: 0.5862132741411945\n",
      "Epoch 2304, reconstruction losses: 0.0510372147828848, regression losses: 0.33220791876478406, validation losses: 0.5045005324764709\n",
      "Epoch 2305, reconstruction losses: 0.04911465815656639, regression losses: 0.20310556037348512, validation losses: 0.7268777830087588\n",
      "Epoch 2306, reconstruction losses: 0.046141732344325885, regression losses: 0.1420595573244235, validation losses: 0.6387998083157453\n",
      "Epoch 2307, reconstruction losses: 0.044002243007590806, regression losses: 0.14829668364690538, validation losses: 0.6718802665361493\n",
      "Epoch 2308, reconstruction losses: 0.04656150531668248, regression losses: 0.11608817295821723, validation losses: 0.48449433505398243\n",
      "Epoch 2309, reconstruction losses: 0.04462263927625584, regression losses: 0.1578909868682387, validation losses: 0.5421747734929906\n",
      "Epoch 2310, reconstruction losses: 0.046798637212293416, regression losses: 0.15637660516163632, validation losses: 0.6369788821362636\n",
      "Epoch 2311, reconstruction losses: 0.04689630146402398, regression losses: 0.14725691957123815, validation losses: 0.5447534682879532\n",
      "Epoch 2312, reconstruction losses: 0.04512278834322107, regression losses: 0.18082064638258152, validation losses: 0.5218978732763223\n",
      "Epoch 2313, reconstruction losses: 0.043456063102774396, regression losses: 0.12446825751237511, validation losses: 0.7408123404683387\n",
      "Epoch 2314, reconstruction losses: 0.04538537914253274, regression losses: 0.16023801407762264, validation losses: 0.5884110389825318\n",
      "Epoch 2315, reconstruction losses: 0.05017217342955913, regression losses: 0.15796360161595852, validation losses: 0.46015905832031445\n",
      "Epoch 2316, reconstruction losses: 0.04632552016713213, regression losses: 0.13639295067365398, validation losses: 0.5210960188935878\n",
      "Epoch 2317, reconstruction losses: 0.04776262275531607, regression losses: 0.123028123061046, validation losses: 0.5403573279248818\n",
      "Epoch 2318, reconstruction losses: 0.05024331713017697, regression losses: 0.1337066078950448, validation losses: 0.4582776534054801\n",
      "Epoch 2319, reconstruction losses: 0.04365178358767331, regression losses: 0.1235191765513269, validation losses: 0.48834388327247374\n",
      "Epoch 2320, reconstruction losses: 0.053991607695876825, regression losses: 0.08868828871586507, validation losses: 0.45370696653394144\n",
      "Epoch 2321, reconstruction losses: 0.04457393768537535, regression losses: 0.1527429427856632, validation losses: 0.4886966944724963\n",
      "Epoch 2322, reconstruction losses: 0.048019317859720155, regression losses: 0.16651432509700193, validation losses: 0.60428794867105\n",
      "Epoch 2323, reconstruction losses: 0.043700389880374946, regression losses: 0.12966969924045457, validation losses: 0.6204832818763221\n",
      "Epoch 2324, reconstruction losses: 0.04577468326805341, regression losses: 0.12606897384309865, validation losses: 0.4603629194306504\n",
      "Epoch 2325, reconstruction losses: 0.04623263472081287, regression losses: 0.12840698137622106, validation losses: 0.4313491342222735\n",
      "Epoch 2326, reconstruction losses: 0.05342345426234347, regression losses: 0.11551744088825573, validation losses: 0.4372568692395798\n",
      "Epoch 2327, reconstruction losses: 0.04618837571132832, regression losses: 0.11666431551156468, validation losses: 0.4563205088660409\n",
      "Epoch 2328, reconstruction losses: 0.04593663981117737, regression losses: 0.11161459679427634, validation losses: 0.4240340337921724\n",
      "Epoch 2329, reconstruction losses: 0.05027638555056446, regression losses: 0.13309955375585758, validation losses: 0.47502167813936447\n",
      "Epoch 2330, reconstruction losses: 0.049749280987797975, regression losses: 0.11121100452193768, validation losses: 0.5946675509603356\n",
      "Epoch 2331, reconstruction losses: 0.05008535574298186, regression losses: 0.18406598398685847, validation losses: 0.7072694386702526\n",
      "Epoch 2332, reconstruction losses: 0.054376444645970204, regression losses: 0.18899604046011112, validation losses: 0.630990129427584\n",
      "Epoch 2333, reconstruction losses: 0.04646005631549189, regression losses: 0.22109298183836976, validation losses: 0.5156842605396778\n",
      "Epoch 2334, reconstruction losses: 0.04825450504420199, regression losses: 0.15791511598924876, validation losses: 0.9163959727931125\n",
      "Epoch 2335, reconstruction losses: 0.04375497831581676, regression losses: 0.15868426598206345, validation losses: 0.49773519927773757\n",
      "Epoch 2336, reconstruction losses: 0.04877298054681628, regression losses: 0.12068848769862729, validation losses: 0.6943380936650821\n",
      "Epoch 2337, reconstruction losses: 0.046985163216246156, regression losses: 0.1353908047533175, validation losses: 0.5300487658527409\n",
      "Epoch 2338, reconstruction losses: 0.04659313593732296, regression losses: 0.12869269354774612, validation losses: 0.43599581960118783\n",
      "Epoch 2339, reconstruction losses: 0.04769550608670574, regression losses: 0.13547448318137326, validation losses: 0.4868057889038314\n",
      "Epoch 2340, reconstruction losses: 0.045082987769502134, regression losses: 0.12456929008973752, validation losses: 0.47719396182736706\n",
      "Epoch 2341, reconstruction losses: 0.051392883384044075, regression losses: 0.23717606743129516, validation losses: 0.5279583991792366\n",
      "Epoch 2342, reconstruction losses: 0.04500467039517518, regression losses: 0.19837208279845908, validation losses: 0.9107321056252458\n",
      "Epoch 2343, reconstruction losses: 0.04487455454114466, regression losses: 0.19612696154036185, validation losses: 0.5532747134083549\n",
      "Epoch 2344, reconstruction losses: 0.045464115309910846, regression losses: 0.18105925528341185, validation losses: 0.5093430372299865\n",
      "Epoch 2345, reconstruction losses: 0.04638451175018722, regression losses: 0.14121332536572087, validation losses: 0.5352097155483106\n",
      "Epoch 2346, reconstruction losses: 0.04335333386048968, regression losses: 0.17587585981335974, validation losses: 0.7279733327457044\n",
      "Epoch 2347, reconstruction losses: 0.04926242745453319, regression losses: 0.17363385621135152, validation losses: 0.45883284961022397\n",
      "Epoch 2348, reconstruction losses: 0.055744241304714934, regression losses: 0.12914132825475355, validation losses: 0.5599441656430736\n",
      "Epoch 2349, reconstruction losses: 0.055011517448358735, regression losses: 0.12421680893110111, validation losses: 0.5347122854817823\n",
      "Epoch 2350, reconstruction losses: 0.053484792656737834, regression losses: 0.21071326864327533, validation losses: 0.46780917998708293\n",
      "Epoch 2351, reconstruction losses: 0.04714904600472485, regression losses: 0.20804080103620828, validation losses: 0.5838117598210434\n",
      "Epoch 2352, reconstruction losses: 0.04687567875978929, regression losses: 0.18324064173437174, validation losses: 0.4530357578113416\n",
      "Epoch 2353, reconstruction losses: 0.05362249587905282, regression losses: 0.11974922787160559, validation losses: 0.5076792016735079\n",
      "Epoch 2354, reconstruction losses: 0.04499741882726555, regression losses: 0.16897997661428843, validation losses: 0.5283109004571871\n",
      "Epoch 2355, reconstruction losses: 0.04940422025411734, regression losses: 0.1275239994750342, validation losses: 0.4856186247546433\n",
      "Epoch 2356, reconstruction losses: 0.04420802664612673, regression losses: 0.10705340151310912, validation losses: 0.5488646469678298\n",
      "Epoch 2357, reconstruction losses: 0.04806729256213883, regression losses: 0.11014346413642855, validation losses: 0.5823484176823596\n",
      "Epoch 2358, reconstruction losses: 0.04452240424960334, regression losses: 0.12835083703273642, validation losses: 0.46204050315072265\n",
      "Epoch 2359, reconstruction losses: 0.04713674957038701, regression losses: 0.14540063424917601, validation losses: 0.45200557914358597\n",
      "Epoch 2360, reconstruction losses: 0.05071750085764278, regression losses: 0.14334311274295747, validation losses: 0.5459045851721459\n",
      "Epoch 2361, reconstruction losses: 0.04922769517890749, regression losses: 0.14849329585899299, validation losses: 0.5809514054131606\n",
      "Epoch 2362, reconstruction losses: 0.04328754333416551, regression losses: 0.1491353689104491, validation losses: 0.5492009149914704\n",
      "Epoch 2363, reconstruction losses: 0.04857151969994916, regression losses: 0.1336560953257691, validation losses: 0.44846462470955434\n",
      "Epoch 2364, reconstruction losses: 0.049287568729216254, regression losses: 0.14444825981941625, validation losses: 0.5094501730881069\n",
      "Epoch 2365, reconstruction losses: 0.04326281316633391, regression losses: 0.1317597493736736, validation losses: 0.644368545472941\n",
      "Epoch 2366, reconstruction losses: 0.04362304362994863, regression losses: 0.15325826287185387, validation losses: 0.515477699028425\n",
      "Epoch 2367, reconstruction losses: 0.05266028384514409, regression losses: 0.1452658528320397, validation losses: 0.6365433173289569\n",
      "Epoch 2368, reconstruction losses: 0.05574993574385617, regression losses: 0.12222930773211323, validation losses: 0.5746565222134516\n",
      "Epoch 2369, reconstruction losses: 0.05045356723865149, regression losses: 0.13824842603389004, validation losses: 0.532247912015492\n",
      "Epoch 2370, reconstruction losses: 0.04560533305764575, regression losses: 0.15492868628880202, validation losses: 0.43717370184320986\n",
      "Epoch 2371, reconstruction losses: 0.05272596260598672, regression losses: 0.1224747118321448, validation losses: 0.6918931671806419\n",
      "Epoch 2372, reconstruction losses: 0.05048036938828694, regression losses: 0.2801416400703015, validation losses: 0.7737336157161917\n",
      "Epoch 2373, reconstruction losses: 0.04820712582281383, regression losses: 0.15692329992481738, validation losses: 0.8878764124537315\n",
      "Epoch 2374, reconstruction losses: 0.04851807579168032, regression losses: 0.12535812279363306, validation losses: 0.48226838416976126\n",
      "Epoch 2375, reconstruction losses: 0.053005833559753614, regression losses: 0.15969253729221142, validation losses: 0.4926811944114328\n",
      "Epoch 2376, reconstruction losses: 0.04710381690001417, regression losses: 0.13773599059518493, validation losses: 0.45576838738850955\n",
      "Epoch 2377, reconstruction losses: 0.047224995668740964, regression losses: 0.1664086233265875, validation losses: 0.46593912392806436\n",
      "Epoch 2378, reconstruction losses: 0.044863929764052374, regression losses: 0.1218821368535863, validation losses: 0.4453908390999876\n",
      "Epoch 2379, reconstruction losses: 0.043876345408916315, regression losses: 0.15216110435800856, validation losses: 0.5155123547418315\n",
      "Epoch 2380, reconstruction losses: 0.05422479069070772, regression losses: 0.1701658262774367, validation losses: 0.7452306551501577\n",
      "Epoch 2381, reconstruction losses: 0.04624646986303149, regression losses: 0.11979920541062777, validation losses: 0.6301157590882728\n",
      "Epoch 2382, reconstruction losses: 0.04525992072529997, regression losses: 0.11042888145779489, validation losses: 0.44101424003705797\n",
      "Epoch 2383, reconstruction losses: 0.04507307820508355, regression losses: 0.1451878366045637, validation losses: 0.4291118737015151\n",
      "Epoch 2384, reconstruction losses: 0.045593815926651134, regression losses: 0.1270174031922493, validation losses: 0.5464300546685235\n",
      "Epoch 2385, reconstruction losses: 0.04535402801560465, regression losses: 0.12868602828019038, validation losses: 0.6014172384121966\n",
      "Epoch 2386, reconstruction losses: 0.04364787338741469, regression losses: 0.11260174706647061, validation losses: 0.4708007248990334\n",
      "Epoch 2387, reconstruction losses: 0.045629430655120616, regression losses: 0.13754263310797676, validation losses: 0.5312957582978288\n",
      "Epoch 2388, reconstruction losses: 0.04401146946413137, regression losses: 0.1501718744914752, validation losses: 0.5927944378819754\n",
      "Epoch 2389, reconstruction losses: 0.0452870552693235, regression losses: 0.12692890237732657, validation losses: 0.5315367283491079\n",
      "Epoch 2390, reconstruction losses: 0.04300918415064742, regression losses: 0.15447385272666636, validation losses: 0.4596587838478552\n",
      "Epoch 2391, reconstruction losses: 0.048146467844868486, regression losses: 0.4361677657673876, validation losses: 0.7110701821041647\n",
      "Epoch 2392, reconstruction losses: 0.04755012549399741, regression losses: 0.24043269735795925, validation losses: 0.9933029774763291\n",
      "Epoch 2393, reconstruction losses: 0.04918433083312089, regression losses: 0.1594334058276206, validation losses: 0.4807799436382004\n",
      "Epoch 2394, reconstruction losses: 0.04576578594456579, regression losses: 0.14764735885692612, validation losses: 0.5481605905655197\n",
      "Epoch 2395, reconstruction losses: 0.04404498402878911, regression losses: 0.1303172186479601, validation losses: 0.5587147644918385\n",
      "Epoch 2396, reconstruction losses: 0.04444021312152298, regression losses: 0.20072487664745192, validation losses: 0.5995193037089022\n",
      "Epoch 2397, reconstruction losses: 0.04503817484757233, regression losses: 0.14296069844542325, validation losses: 0.7428131451681902\n",
      "Epoch 2398, reconstruction losses: 0.04532785344863552, regression losses: 0.15060762080498338, validation losses: 0.5963664373707249\n",
      "Epoch 2399, reconstruction losses: 0.04580902431931744, regression losses: 0.15146095333784637, validation losses: 0.6334266691278889\n",
      "Epoch 2400, reconstruction losses: 0.045490839113343305, regression losses: 0.13730783164507504, validation losses: 0.4524228701028434\n",
      "Epoch 2401, reconstruction losses: 0.05042893914984848, regression losses: 0.13221481728854081, validation losses: 0.6924694026922761\n",
      "Epoch 2402, reconstruction losses: 0.046773523826681575, regression losses: 0.15406185605468828, validation losses: 0.6184435642856863\n",
      "Epoch 2403, reconstruction losses: 0.04638535903430654, regression losses: 0.11569684484712686, validation losses: 0.4246236487646228\n",
      "Epoch 2404, reconstruction losses: 0.04472379365886008, regression losses: 0.15265561830540939, validation losses: 0.4308626403664855\n",
      "Epoch 2405, reconstruction losses: 0.044143150916979484, regression losses: 0.1068126039171287, validation losses: 0.5502660507197437\n",
      "Epoch 2406, reconstruction losses: 0.04982673591038895, regression losses: 0.1243570669222038, validation losses: 0.48160609962149337\n",
      "Epoch 2407, reconstruction losses: 0.04590653468234269, regression losses: 0.12940169882336802, validation losses: 0.45917900600917017\n",
      "Epoch 2408, reconstruction losses: 0.04596904321736007, regression losses: 0.1385433049874121, validation losses: 0.44420463471205107\n",
      "Epoch 2409, reconstruction losses: 0.04912827166366952, regression losses: 0.1509866358336245, validation losses: 0.45859192121499687\n",
      "Epoch 2410, reconstruction losses: 0.04637063258017467, regression losses: 0.12309924696387835, validation losses: 0.5255602546968725\n",
      "Epoch 2411, reconstruction losses: 0.04457466277381368, regression losses: 0.1522306327264208, validation losses: 0.529186654329358\n",
      "Epoch 2412, reconstruction losses: 0.0434653294447712, regression losses: 0.13534521300120134, validation losses: 0.6094014896490997\n",
      "Epoch 2413, reconstruction losses: 0.04871053378094733, regression losses: 0.16170525530998084, validation losses: 0.511624556888546\n",
      "Epoch 2414, reconstruction losses: 0.04321393527830625, regression losses: 0.14216850777259005, validation losses: 0.45926042324731636\n",
      "Epoch 2415, reconstruction losses: 0.04498975050508312, regression losses: 0.14160719766117466, validation losses: 0.457278397541839\n",
      "Epoch 2416, reconstruction losses: 0.04302245770504497, regression losses: 0.12976458791300757, validation losses: 0.5522564079546355\n",
      "Epoch 2417, reconstruction losses: 0.044108879828862003, regression losses: 0.12406836093710964, validation losses: 0.5835354900200179\n",
      "Epoch 2418, reconstruction losses: 0.04902564216742761, regression losses: 0.1505936616998639, validation losses: 0.47301473442330194\n",
      "Epoch 2419, reconstruction losses: 0.04305361265461281, regression losses: 0.12852353378025316, validation losses: 0.468533759179016\n",
      "Epoch 2420, reconstruction losses: 0.04332440209168039, regression losses: 0.13733259546961393, validation losses: 0.5677600591499061\n",
      "Epoch 2421, reconstruction losses: 0.04882868754144157, regression losses: 0.13534490678816205, validation losses: 0.5746514643204478\n",
      "Epoch 2422, reconstruction losses: 0.054191018514274214, regression losses: 0.14854691443126677, validation losses: 0.5597878773179431\n",
      "Epoch 2423, reconstruction losses: 0.04344965215668138, regression losses: 0.11657353786773357, validation losses: 0.4967986813002859\n",
      "Epoch 2424, reconstruction losses: 0.04445611916654529, regression losses: 0.11899178832903744, validation losses: 0.6051173027739881\n",
      "Epoch 2425, reconstruction losses: 0.04741756909610171, regression losses: 0.1241308762889855, validation losses: 0.5298390763564699\n",
      "Epoch 2426, reconstruction losses: 0.04563027795593379, regression losses: 0.14521554754161203, validation losses: 0.4817910413754301\n",
      "Epoch 2427, reconstruction losses: 0.04633502636047607, regression losses: 0.2888555119347364, validation losses: 0.43280982331098844\n",
      "Epoch 2428, reconstruction losses: 0.0553285542469794, regression losses: 0.16162607275350302, validation losses: 0.6953708120846371\n",
      "Epoch 2429, reconstruction losses: 0.050269663286837275, regression losses: 0.15873410222965068, validation losses: 0.44214712723524124\n",
      "Epoch 2430, reconstruction losses: 0.04641123556229022, regression losses: 0.1753221780195397, validation losses: 0.5756918031388777\n",
      "Epoch 2431, reconstruction losses: 0.046308818548872054, regression losses: 0.15346455935741565, validation losses: 0.6144391767635786\n",
      "Epoch 2432, reconstruction losses: 0.04446902697808893, regression losses: 0.2443177760243428, validation losses: 0.6434063653416191\n",
      "Epoch 2433, reconstruction losses: 0.04348751930895792, regression losses: 0.1894049686554437, validation losses: 0.6655640730500076\n",
      "Epoch 2434, reconstruction losses: 0.045610413414831394, regression losses: 0.15569775554328985, validation losses: 0.9773280939342748\n",
      "Epoch 2435, reconstruction losses: 0.047471851102514985, regression losses: 0.19786811086556855, validation losses: 0.6492254692607087\n",
      "Epoch 2436, reconstruction losses: 0.05434307450098862, regression losses: 0.14177596194611758, validation losses: 0.4671342468357051\n",
      "Epoch 2437, reconstruction losses: 0.04977020045439698, regression losses: 0.13964980649656625, validation losses: 0.5587627467173761\n",
      "Epoch 2438, reconstruction losses: 0.04774420846329334, regression losses: 0.16917636071384426, validation losses: 0.6868180213285395\n",
      "Epoch 2439, reconstruction losses: 0.04414638347700882, regression losses: 0.2854149790463826, validation losses: 0.4527552832989423\n",
      "Epoch 2440, reconstruction losses: 0.047980886415970925, regression losses: 0.11728544411230289, validation losses: 0.7812908712953246\n",
      "Epoch 2441, reconstruction losses: 0.04274427585033312, regression losses: 0.1840794438377889, validation losses: 0.7111468599640888\n",
      "Epoch 2442, reconstruction losses: 0.04394551480162889, regression losses: 0.1722191572448476, validation losses: 0.6202406125781083\n",
      "Epoch 2443, reconstruction losses: 0.05038207159352294, regression losses: 0.11400311223142309, validation losses: 0.4468767274927737\n",
      "Epoch 2444, reconstruction losses: 0.04811361733237574, regression losses: 0.12977824153855283, validation losses: 0.46525160717435693\n",
      "Epoch 2445, reconstruction losses: 0.04411666615586596, regression losses: 0.1422796335596193, validation losses: 0.6861008448808747\n",
      "Epoch 2446, reconstruction losses: 0.04872621880484778, regression losses: 0.1260691269939579, validation losses: 0.48821648190333455\n",
      "Epoch 2447, reconstruction losses: 0.04250208376066854, regression losses: 0.12273968736531099, validation losses: 0.421471385045316\n",
      "Epoch 2448, reconstruction losses: 0.044077664957155996, regression losses: 0.12488026712829269, validation losses: 0.42997250556060035\n",
      "Epoch 2449, reconstruction losses: 0.04802202630384778, regression losses: 0.13192298907631278, validation losses: 0.5270533242427701\n",
      "Epoch 2450, reconstruction losses: 0.045003704696789625, regression losses: 0.10361526386128375, validation losses: 0.6270795393467888\n",
      "Epoch 2451, reconstruction losses: 0.04601432460276701, regression losses: 0.12262466352265579, validation losses: 0.5788903878308391\n",
      "Epoch 2452, reconstruction losses: 0.0488920541349169, regression losses: 0.12952398742648555, validation losses: 0.4785542107391244\n",
      "Epoch 2453, reconstruction losses: 0.05096810333015294, regression losses: 0.1268556147203351, validation losses: 0.45263592837357347\n",
      "Epoch 2454, reconstruction losses: 0.04353619413225166, regression losses: 0.17559742163638498, validation losses: 0.47377283450797386\n",
      "Epoch 2455, reconstruction losses: 0.048833621427436386, regression losses: 0.12304974546683436, validation losses: 0.6307149343432212\n",
      "Epoch 2456, reconstruction losses: 0.042217643676828495, regression losses: 0.1299543233985009, validation losses: 0.516395049329733\n",
      "Epoch 2457, reconstruction losses: 0.04511610449149523, regression losses: 0.23732456139565608, validation losses: 0.49260447049109624\n",
      "Epoch 2458, reconstruction losses: 0.04692532232909445, regression losses: 0.11249958239075422, validation losses: 0.5906312404719692\n",
      "Epoch 2459, reconstruction losses: 0.045845757048462, regression losses: 0.22778737923111156, validation losses: 0.46053506280515927\n",
      "Epoch 2460, reconstruction losses: 0.043967182667443434, regression losses: 0.1468609133086565, validation losses: 0.4826058878222269\n",
      "Epoch 2461, reconstruction losses: 0.048015189275808, regression losses: 0.14793417656453525, validation losses: 0.5403270805061062\n",
      "Epoch 2462, reconstruction losses: 0.045829976099594744, regression losses: 0.163730925320249, validation losses: 0.559481906144563\n",
      "Epoch 2463, reconstruction losses: 0.044609653921908445, regression losses: 0.12184709586417193, validation losses: 0.5819681211622134\n",
      "Epoch 2464, reconstruction losses: 0.050324536234061884, regression losses: 0.14419244079286322, validation losses: 0.4270555385281441\n",
      "Epoch 2465, reconstruction losses: 0.044189459156244094, regression losses: 0.115677672868201, validation losses: 0.44989809463494795\n",
      "Epoch 2466, reconstruction losses: 0.0441759093915122, regression losses: 0.1785383197556668, validation losses: 0.5590245540315455\n",
      "Epoch 2467, reconstruction losses: 0.04292201371136282, regression losses: 0.15410730293053396, validation losses: 0.9568978087664923\n",
      "Epoch 2468, reconstruction losses: 0.04400847302034613, regression losses: 0.15324872558259803, validation losses: 0.4833231934858686\n",
      "Epoch 2469, reconstruction losses: 0.04747042662424356, regression losses: 0.20275580120947423, validation losses: 0.5426742985401414\n",
      "Epoch 2470, reconstruction losses: 0.05056595335573848, regression losses: 0.17115810654527358, validation losses: 0.6421184550973638\n",
      "Epoch 2471, reconstruction losses: 0.04849173450287882, regression losses: 0.19111404645381538, validation losses: 0.48683904417059964\n",
      "Epoch 2472, reconstruction losses: 0.04404447859495808, regression losses: 0.1478369793557187, validation losses: 0.9197515499998153\n",
      "Epoch 2473, reconstruction losses: 0.04639090164762004, regression losses: 0.17408468545454817, validation losses: 0.520607457218159\n",
      "Epoch 2474, reconstruction losses: 0.05238327382634277, regression losses: 0.1635056498477147, validation losses: 0.5403087160281427\n",
      "Epoch 2475, reconstruction losses: 0.04402618609733879, regression losses: 0.1347792024394411, validation losses: 0.5334867187021554\n",
      "Epoch 2476, reconstruction losses: 0.043228306398466324, regression losses: 0.21204404748696626, validation losses: 0.45067406032324375\n",
      "Epoch 2477, reconstruction losses: 0.045952551989744045, regression losses: 0.15124865085275843, validation losses: 0.5449757575608238\n",
      "Epoch 2478, reconstruction losses: 0.05470581197639705, regression losses: 0.14976773974552698, validation losses: 0.43739073891082875\n",
      "Epoch 2479, reconstruction losses: 0.04368824385241501, regression losses: 0.17691588102920702, validation losses: 0.5559198224413382\n",
      "Epoch 2480, reconstruction losses: 0.05363531467905845, regression losses: 0.11267254091731504, validation losses: 0.4762433572722603\n",
      "Epoch 2481, reconstruction losses: 0.04718746475110969, regression losses: 0.20212649072390132, validation losses: 0.5152389739963557\n",
      "Epoch 2482, reconstruction losses: 0.04561844457577729, regression losses: 0.12811973803230337, validation losses: 0.6048519905030739\n",
      "Epoch 2483, reconstruction losses: 0.05302474018774345, regression losses: 0.11754619713504456, validation losses: 0.5055741770184979\n",
      "Epoch 2484, reconstruction losses: 0.04539248055824338, regression losses: 0.12167378501476916, validation losses: 0.5232871284210833\n",
      "Epoch 2485, reconstruction losses: 0.047410363251243065, regression losses: 0.15071020258262416, validation losses: 0.49829595231835\n",
      "Epoch 2486, reconstruction losses: 0.04802302857256814, regression losses: 0.13996161941535062, validation losses: 0.5213433308177836\n",
      "Epoch 2487, reconstruction losses: 0.04715898475175924, regression losses: 0.14481389270916942, validation losses: 0.6605391263585675\n",
      "Epoch 2488, reconstruction losses: 0.04493541271638875, regression losses: 0.26515450156771525, validation losses: 0.5132669562850621\n",
      "Epoch 2489, reconstruction losses: 0.047512485588125104, regression losses: 0.14978407066459887, validation losses: 0.8501206615876913\n",
      "Epoch 2490, reconstruction losses: 0.047001290069477654, regression losses: 0.181060327624625, validation losses: 0.6113435725836714\n",
      "Epoch 2491, reconstruction losses: 0.05030799756319846, regression losses: 0.114758143972245, validation losses: 0.6515697763438142\n",
      "Epoch 2492, reconstruction losses: 0.04826563626563305, regression losses: 0.17709713133323912, validation losses: 0.47397355996730933\n",
      "Epoch 2493, reconstruction losses: 0.047461018208639676, regression losses: 0.14229864699202033, validation losses: 0.6813624577721544\n",
      "Epoch 2494, reconstruction losses: 0.04518293176953168, regression losses: 0.14929199157614884, validation losses: 0.5867802566848963\n",
      "Epoch 2495, reconstruction losses: 0.04748858774304281, regression losses: 0.12798106313204388, validation losses: 0.5593002584218408\n",
      "Epoch 2496, reconstruction losses: 0.052071338707576666, regression losses: 0.13502593503088572, validation losses: 0.45728116267993263\n",
      "Epoch 2497, reconstruction losses: 0.04262352598904351, regression losses: 0.14917737712132842, validation losses: 0.5141330155967276\n",
      "Epoch 2498, reconstruction losses: 0.04492411116249944, regression losses: 0.13082917725231355, validation losses: 0.7889776661502113\n",
      "Epoch 2499, reconstruction losses: 0.05495860301407181, regression losses: 0.16114648783969052, validation losses: 0.552454022365767\n",
      "Epoch 2500, reconstruction losses: 0.04510067795860599, regression losses: 0.12599505314240994, validation losses: 0.4748024141313872\n",
      "Epoch 2501, reconstruction losses: 0.043705466634317305, regression losses: 0.15603960044883614, validation losses: 0.43245349949848605\n",
      "Epoch 2502, reconstruction losses: 0.04403363804568839, regression losses: 0.16598054890230093, validation losses: 0.5575927296456934\n",
      "Epoch 2503, reconstruction losses: 0.04626720100140411, regression losses: 0.21245327903372035, validation losses: 0.5749626361000085\n",
      "Epoch 2504, reconstruction losses: 0.0427779907991355, regression losses: 0.2337908279899819, validation losses: 0.5683864872208603\n",
      "Epoch 2505, reconstruction losses: 0.045554993516931624, regression losses: 0.13141520216053948, validation losses: 0.611638986350435\n",
      "Epoch 2506, reconstruction losses: 0.04540335115674046, regression losses: 0.15084335602726642, validation losses: 0.6085939352911718\n",
      "Epoch 2507, reconstruction losses: 0.04326206129178921, regression losses: 0.11137978031512326, validation losses: 0.46055154432596046\n",
      "Epoch 2508, reconstruction losses: 0.04486471670462061, regression losses: 0.13207252877140574, validation losses: 0.43783109355525873\n",
      "Epoch 2509, reconstruction losses: 0.04706166286806895, regression losses: 0.12393042210957492, validation losses: 0.44684927567404664\n",
      "Epoch 2510, reconstruction losses: 0.046434802315009405, regression losses: 0.2790949989564433, validation losses: 0.554427155895874\n",
      "Epoch 2511, reconstruction losses: 0.04351553135276564, regression losses: 0.15402293176784088, validation losses: 0.6368055820124903\n",
      "Epoch 2512, reconstruction losses: 0.04632519808947622, regression losses: 0.17573779767767628, validation losses: 0.4186052867491871\n",
      "Epoch 2513, reconstruction losses: 0.05273901150574344, regression losses: 0.17205185425651992, validation losses: 0.47429544003641705\n",
      "Epoch 2514, reconstruction losses: 0.04677935522465139, regression losses: 0.10534640004483693, validation losses: 0.6707199566803006\n",
      "Epoch 2515, reconstruction losses: 0.04888892988139874, regression losses: 0.14800840995619666, validation losses: 0.44105342601585884\n",
      "Epoch 2516, reconstruction losses: 0.043524402679461116, regression losses: 0.14856962080924221, validation losses: 0.4359973136257378\n",
      "Epoch 2517, reconstruction losses: 0.048654421188021504, regression losses: 0.15604918619798686, validation losses: 0.4799747319680724\n",
      "Epoch 2518, reconstruction losses: 0.047944153716559405, regression losses: 0.10850596145301451, validation losses: 0.5945086564023319\n",
      "Epoch 2519, reconstruction losses: 0.049240218700903136, regression losses: 0.13832655052027837, validation losses: 0.4523778654341594\n",
      "Epoch 2520, reconstruction losses: 0.045028854196448684, regression losses: 0.13758808871531014, validation losses: 0.6126067878389146\n",
      "Epoch 2521, reconstruction losses: 0.04277389973796796, regression losses: 0.17787597310701944, validation losses: 0.4860603933240062\n",
      "Epoch 2522, reconstruction losses: 0.04467340884174609, regression losses: 0.14869902423258835, validation losses: 0.48859006070369904\n",
      "Epoch 2523, reconstruction losses: 0.047031802886456066, regression losses: 0.1397031382773472, validation losses: 0.5893762045534849\n",
      "Epoch 2524, reconstruction losses: 0.04544203846132157, regression losses: 0.20841235611721848, validation losses: 0.6564960232434313\n",
      "Epoch 2525, reconstruction losses: 0.04332512381644501, regression losses: 0.15093334779492082, validation losses: 0.6048523446789172\n",
      "Epoch 2526, reconstruction losses: 0.04247949411741986, regression losses: 0.12895406440470147, validation losses: 0.5001374722017327\n",
      "Epoch 2527, reconstruction losses: 0.05449612096248658, regression losses: 0.1416907807580603, validation losses: 0.4656809510542772\n",
      "Epoch 2528, reconstruction losses: 0.044148512832847035, regression losses: 0.14863303000856554, validation losses: 0.4482025929079426\n",
      "Epoch 2529, reconstruction losses: 0.0481337355099382, regression losses: 0.12018480513593584, validation losses: 0.5650186438941334\n",
      "Epoch 2530, reconstruction losses: 0.0463255783412195, regression losses: 0.1410547009487244, validation losses: 0.49281191252224343\n",
      "Epoch 2531, reconstruction losses: 0.049301544018416577, regression losses: 0.10352695269301143, validation losses: 0.43877289873298475\n",
      "Epoch 2532, reconstruction losses: 0.043104917075595967, regression losses: 0.20971409658493473, validation losses: 0.4975289723471916\n",
      "Epoch 2533, reconstruction losses: 0.054876358771799263, regression losses: 0.160155004325151, validation losses: 0.891172318257283\n",
      "Epoch 2534, reconstruction losses: 0.04456288188185861, regression losses: 0.12435382003031965, validation losses: 0.5195493912197628\n",
      "Epoch 2535, reconstruction losses: 0.04349306468754093, regression losses: 0.15336723456385631, validation losses: 0.5113932020574996\n",
      "Epoch 2536, reconstruction losses: 0.04721966913271089, regression losses: 0.3511523259115644, validation losses: 0.6153549473792895\n",
      "Epoch 2537, reconstruction losses: 0.047535633071038336, regression losses: 0.13688660076492012, validation losses: 0.6965882460524133\n",
      "Epoch 2538, reconstruction losses: 0.04409351228206414, regression losses: 0.12983261307582653, validation losses: 0.5368522779296564\n",
      "Epoch 2539, reconstruction losses: 0.04391484074576163, regression losses: 0.13422527255663622, validation losses: 0.514680371868161\n",
      "Epoch 2540, reconstruction losses: 0.046753981862659943, regression losses: 0.13779771082390216, validation losses: 0.44892678423961807\n",
      "Epoch 2541, reconstruction losses: 0.04331379921621647, regression losses: 0.15417212448131257, validation losses: 0.4932563064272334\n",
      "Epoch 2542, reconstruction losses: 0.04542295308334005, regression losses: 0.12450735309226763, validation losses: 0.605392110398369\n",
      "Epoch 2543, reconstruction losses: 0.04396863698400424, regression losses: 0.1455922477967417, validation losses: 0.5208178212164019\n",
      "Epoch 2544, reconstruction losses: 0.05364948695742941, regression losses: 0.11563978834017741, validation losses: 0.43691413024966425\n",
      "Epoch 2545, reconstruction losses: 0.043794472350033926, regression losses: 0.13301765978587748, validation losses: 0.46533563007961076\n",
      "Epoch 2546, reconstruction losses: 0.04339422849520889, regression losses: 0.16500902788825655, validation losses: 0.6246978642951334\n",
      "Epoch 2547, reconstruction losses: 0.05430202221490097, regression losses: 0.10960673374228505, validation losses: 0.5372780967997318\n",
      "Epoch 2548, reconstruction losses: 0.04875604182624728, regression losses: 0.15698356415958417, validation losses: 0.43787504575924685\n",
      "Epoch 2549, reconstruction losses: 0.04337800421949902, regression losses: 0.16931486665805145, validation losses: 0.5190715797340005\n",
      "Epoch 2550, reconstruction losses: 0.04454739550384111, regression losses: 0.13110423763187468, validation losses: 0.7185508819913273\n",
      "Epoch 2551, reconstruction losses: 0.044291605576699034, regression losses: 0.10884954029920893, validation losses: 0.4602768574626729\n",
      "Epoch 2552, reconstruction losses: 0.05404557524727317, regression losses: 0.1266975707355458, validation losses: 0.44124844441685906\n",
      "Epoch 2553, reconstruction losses: 0.046097688889961456, regression losses: 0.11653621093808667, validation losses: 0.4927729078039194\n",
      "Epoch 2554, reconstruction losses: 0.04428051469206149, regression losses: 0.14672649566841173, validation losses: 0.5984277011568093\n",
      "Epoch 2555, reconstruction losses: 0.04354079075569593, regression losses: 0.1443167037023933, validation losses: 0.45681241042738496\n",
      "Epoch 2556, reconstruction losses: 0.045000625250722064, regression losses: 0.15847229570845556, validation losses: 0.4923929198562015\n",
      "Epoch 2557, reconstruction losses: 0.04511696605296929, regression losses: 0.10599074342942788, validation losses: 0.545179429691604\n",
      "Epoch 2558, reconstruction losses: 0.052828190749606, regression losses: 0.14991410958160234, validation losses: 0.4279687191298208\n",
      "Epoch 2559, reconstruction losses: 0.04967621339081373, regression losses: 0.16547150819686063, validation losses: 0.441296262818921\n",
      "Epoch 2560, reconstruction losses: 0.049338414047320645, regression losses: 0.11849311013883651, validation losses: 0.4525044560921993\n",
      "Epoch 2561, reconstruction losses: 0.04908549196855878, regression losses: 0.11836830426815137, validation losses: 0.6673109395649099\n",
      "Epoch 2562, reconstruction losses: 0.04739787991889233, regression losses: 0.11813159057425111, validation losses: 0.6393636009195748\n",
      "Epoch 2563, reconstruction losses: 0.042586855815162576, regression losses: 0.12675670538155503, validation losses: 0.5268753336304381\n",
      "Epoch 2564, reconstruction losses: 0.04767903242180168, regression losses: 0.1279519417184194, validation losses: 0.6160575686404739\n",
      "Epoch 2565, reconstruction losses: 0.0448526525842375, regression losses: 0.11613424243077347, validation losses: 0.6658364555852176\n",
      "Epoch 2566, reconstruction losses: 0.043656855178162195, regression losses: 0.1190353549210792, validation losses: 0.6267311986504468\n",
      "Epoch 2567, reconstruction losses: 0.044494009214970875, regression losses: 0.12004994167783681, validation losses: 0.5586265469787042\n",
      "Epoch 2568, reconstruction losses: 0.04306096001687607, regression losses: 0.12749665773809132, validation losses: 0.42731470611361877\n",
      "Epoch 2569, reconstruction losses: 0.045546733848097765, regression losses: 0.16111887137137604, validation losses: 0.5165570449256087\n",
      "Epoch 2570, reconstruction losses: 0.04654518857290906, regression losses: 0.11331470277103999, validation losses: 0.6769292246366678\n",
      "Epoch 2571, reconstruction losses: 0.04549155249772826, regression losses: 0.15354537320325862, validation losses: 0.4954811534237122\n",
      "Epoch 2572, reconstruction losses: 0.04936009666841274, regression losses: 0.11072319729994325, validation losses: 0.5013255522476706\n",
      "Epoch 2573, reconstruction losses: 0.04166649047822477, regression losses: 0.13450559656437502, validation losses: 0.515595523191376\n",
      "Epoch 2574, reconstruction losses: 0.04572746678355065, regression losses: 0.1652457216988031, validation losses: 0.7031204324346287\n",
      "Epoch 2575, reconstruction losses: 0.04886204710945569, regression losses: 0.12132867222658804, validation losses: 0.4867141989236517\n",
      "Epoch 2576, reconstruction losses: 0.04701021792737884, regression losses: 0.13953357287733278, validation losses: 0.4211999440637694\n",
      "Epoch 2577, reconstruction losses: 0.04599762159979588, regression losses: 0.1267589703241676, validation losses: 0.5702345840541707\n",
      "Epoch 2578, reconstruction losses: 0.049065324203926466, regression losses: 0.1666445300270986, validation losses: 0.7432723150708105\n",
      "Epoch 2579, reconstruction losses: 0.048384961277794625, regression losses: 0.11114800430247672, validation losses: 0.5858905450878219\n",
      "Epoch 2580, reconstruction losses: 0.043305613171803474, regression losses: 0.14014154406050458, validation losses: 0.4628131364124008\n",
      "Epoch 2581, reconstruction losses: 0.04448898076878892, regression losses: 0.12543377905809155, validation losses: 0.7071259718809999\n",
      "Epoch 2582, reconstruction losses: 0.04851995230762446, regression losses: 0.14222030536704133, validation losses: 0.5736787275616725\n",
      "Epoch 2583, reconstruction losses: 0.04295103387575953, regression losses: 0.11999471070791438, validation losses: 0.4880283222620177\n",
      "Epoch 2584, reconstruction losses: 0.047436790979688837, regression losses: 0.1307705579625025, validation losses: 0.4468496492026168\n",
      "Epoch 2585, reconstruction losses: 0.0435187334831618, regression losses: 0.13136094748688976, validation losses: 0.5427740228165435\n",
      "Epoch 2586, reconstruction losses: 0.04486600156017356, regression losses: 0.14757040601903493, validation losses: 0.46415068687199845\n",
      "Epoch 2587, reconstruction losses: 0.041691624144439166, regression losses: 0.11193750320625669, validation losses: 0.5122143075497977\n",
      "Epoch 2588, reconstruction losses: 0.04291811249768924, regression losses: 0.14355699847519796, validation losses: 0.4439402320053179\n",
      "Epoch 2589, reconstruction losses: 0.047134129876455655, regression losses: 0.12787969465272425, validation losses: 0.4217417339936774\n",
      "Epoch 2590, reconstruction losses: 0.04718841292854522, regression losses: 0.14278351599309536, validation losses: 0.5957570083643248\n",
      "Epoch 2591, reconstruction losses: 0.04979183895589716, regression losses: 0.145847948455544, validation losses: 0.5944311669734514\n",
      "Epoch 2592, reconstruction losses: 0.0472863350889446, regression losses: 0.2891596059080447, validation losses: 0.6298733706135693\n",
      "Epoch 2593, reconstruction losses: 0.04544856033636615, regression losses: 0.2063042907359441, validation losses: 0.9655161202003737\n",
      "Epoch 2594, reconstruction losses: 0.04288417274579584, regression losses: 0.2617707196570371, validation losses: 0.7939497067996544\n",
      "Epoch 2595, reconstruction losses: 0.045685360523932864, regression losses: 0.13623920312483018, validation losses: 0.6957550513709949\n",
      "Epoch 2596, reconstruction losses: 0.043879048787803555, regression losses: 0.1434176765148561, validation losses: 0.45501312293095764\n",
      "Epoch 2597, reconstruction losses: 0.04355878918327073, regression losses: 0.174857177647275, validation losses: 0.5976147919899901\n",
      "Epoch 2598, reconstruction losses: 0.04691686593899741, regression losses: 0.12674786399439653, validation losses: 0.5411704128165222\n",
      "Epoch 2599, reconstruction losses: 0.04595973996165745, regression losses: 0.12125835464000935, validation losses: 0.6617843003883943\n",
      "Epoch 2600, reconstruction losses: 0.047126572244223, regression losses: 0.1378026316258097, validation losses: 0.49015321730539585\n",
      "Epoch 2601, reconstruction losses: 0.042333544386170666, regression losses: 0.13559104250534268, validation losses: 0.44858559664685205\n",
      "Epoch 2602, reconstruction losses: 0.04330733098700997, regression losses: 0.11656879847761827, validation losses: 0.5220286125183823\n",
      "Epoch 2603, reconstruction losses: 0.04322544693220433, regression losses: 0.16557542572608394, validation losses: 0.5376177365566882\n",
      "Epoch 2604, reconstruction losses: 0.04449776829762539, regression losses: 0.12122603894789502, validation losses: 0.5773530784831907\n",
      "Epoch 2605, reconstruction losses: 0.04509422586285127, regression losses: 0.12872647469337387, validation losses: 0.4767775284529311\n",
      "Epoch 2606, reconstruction losses: 0.04199099863277054, regression losses: 0.15609987744524523, validation losses: 0.4583926447483715\n",
      "Epoch 2607, reconstruction losses: 0.0436059683619195, regression losses: 0.15177082466920794, validation losses: 0.8446635599279446\n",
      "Epoch 2608, reconstruction losses: 0.05001804235809361, regression losses: 0.19197635308848957, validation losses: 0.5788486389240614\n",
      "Epoch 2609, reconstruction losses: 0.047037884971480565, regression losses: 0.1750533535355924, validation losses: 0.459977825656042\n",
      "Epoch 2610, reconstruction losses: 0.046836284186178, regression losses: 0.5044749290342044, validation losses: 0.5726333749342101\n",
      "Epoch 2611, reconstruction losses: 0.04695981025051491, regression losses: 0.20636383314688206, validation losses: 1.0035291243781357\n",
      "Epoch 2612, reconstruction losses: 0.044291212969270057, regression losses: 0.13388170902075727, validation losses: 0.4760315643076551\n",
      "Epoch 2613, reconstruction losses: 0.04350074015103655, regression losses: 0.12708721600245218, validation losses: 0.4851044824440376\n",
      "Epoch 2614, reconstruction losses: 0.04181203316882317, regression losses: 0.13552207697847246, validation losses: 0.48901671982380274\n",
      "Epoch 2615, reconstruction losses: 0.04319728214576539, regression losses: 0.13208564210726567, validation losses: 0.6910730791725143\n",
      "Epoch 2616, reconstruction losses: 0.04157898964884101, regression losses: 0.10837760237101833, validation losses: 0.5367751371244817\n",
      "Epoch 2617, reconstruction losses: 0.04203069359926003, regression losses: 0.10035764593530483, validation losses: 0.5150428400438904\n",
      "Epoch 2618, reconstruction losses: 0.042913048950506835, regression losses: 0.16264915840186275, validation losses: 0.5108085854701224\n",
      "Epoch 2619, reconstruction losses: 0.046498554262535435, regression losses: 0.1538811189673146, validation losses: 0.617033599128783\n",
      "Epoch 2620, reconstruction losses: 0.046281692139033985, regression losses: 0.1459875215059375, validation losses: 0.5930816669541751\n",
      "Epoch 2621, reconstruction losses: 0.04367185423316232, regression losses: 0.1464947567589978, validation losses: 0.48212686451655695\n",
      "Epoch 2622, reconstruction losses: 0.046287765126238764, regression losses: 0.12216279246193061, validation losses: 0.4962830005496086\n",
      "Epoch 2623, reconstruction losses: 0.04697632963918671, regression losses: 0.1601103851462661, validation losses: 0.5773534286517056\n",
      "Epoch 2624, reconstruction losses: 0.04434129643602539, regression losses: 0.12253219604316141, validation losses: 0.5184156375162087\n",
      "Epoch 2625, reconstruction losses: 0.043222503092227006, regression losses: 0.12682954201269395, validation losses: 0.489038675672169\n",
      "Epoch 2626, reconstruction losses: 0.0462631549144801, regression losses: 0.15637625274983621, validation losses: 0.5596102945199303\n",
      "Epoch 2627, reconstruction losses: 0.041869984898758504, regression losses: 0.11020716462079984, validation losses: 0.6195578779240752\n",
      "Epoch 2628, reconstruction losses: 0.04517431503068682, regression losses: 0.12040504994290564, validation losses: 0.5392972719773346\n",
      "Epoch 2629, reconstruction losses: 0.04231151532637661, regression losses: 0.149972824731601, validation losses: 0.5103823533076374\n",
      "Epoch 2630, reconstruction losses: 0.04187155339522607, regression losses: 0.13115644543020222, validation losses: 0.42539909626697187\n",
      "Epoch 2631, reconstruction losses: 0.04282224414102521, regression losses: 0.09804312100621894, validation losses: 0.5339415238814705\n",
      "Epoch 2632, reconstruction losses: 0.049500494002168355, regression losses: 0.11634381914126513, validation losses: 0.5000889227227259\n",
      "Epoch 2633, reconstruction losses: 0.042434025699673195, regression losses: 0.1260478181720081, validation losses: 0.4300476338585077\n",
      "Epoch 2634, reconstruction losses: 0.048519250105484184, regression losses: 0.1416502728696194, validation losses: 0.42125432249497974\n",
      "Epoch 2635, reconstruction losses: 0.04681602698809428, regression losses: 0.12636564652029986, validation losses: 0.5963136454065462\n",
      "Epoch 2636, reconstruction losses: 0.041463794830162715, regression losses: 0.1984004821733586, validation losses: 0.6379048741246\n",
      "Epoch 2637, reconstruction losses: 0.04122680979467224, regression losses: 0.09726498114490904, validation losses: 0.6215302125821465\n",
      "Epoch 2638, reconstruction losses: 0.04840248165128138, regression losses: 0.1195280362946225, validation losses: 0.5121356261513397\n",
      "Epoch 2639, reconstruction losses: 0.04388801634719052, regression losses: 0.14097667737618458, validation losses: 0.5783111031660232\n",
      "Epoch 2640, reconstruction losses: 0.04575165235668106, regression losses: 0.11228301208158399, validation losses: 0.4489935980110483\n",
      "Epoch 2641, reconstruction losses: 0.043513576674525586, regression losses: 0.12565641549431697, validation losses: 0.48736198842962813\n",
      "Epoch 2642, reconstruction losses: 0.045264871450276224, regression losses: 0.11226289581423357, validation losses: 0.5106889999103564\n",
      "Epoch 2643, reconstruction losses: 0.046699151542149035, regression losses: 0.11506625051725236, validation losses: 0.46043564835085043\n",
      "Epoch 2644, reconstruction losses: 0.04394141133222293, regression losses: 0.15197851410993193, validation losses: 0.43915998044555193\n",
      "Epoch 2645, reconstruction losses: 0.04294682106020353, regression losses: 0.10335723228306523, validation losses: 0.5265343424966948\n",
      "Epoch 2646, reconstruction losses: 0.04929474335216122, regression losses: 0.12497782164722114, validation losses: 0.5480539224070716\n",
      "Epoch 2647, reconstruction losses: 0.04376426882631588, regression losses: 0.1313583346304264, validation losses: 0.507824829620466\n",
      "Epoch 2648, reconstruction losses: 0.04256421119851739, regression losses: 0.15782829269361942, validation losses: 0.4845611736929022\n",
      "Epoch 2649, reconstruction losses: 0.04201676813743152, regression losses: 0.13043212952834263, validation losses: 0.5495189171868357\n",
      "Epoch 2650, reconstruction losses: 0.04895730650269166, regression losses: 0.1679919241754835, validation losses: 0.4895896242417982\n",
      "Epoch 2651, reconstruction losses: 0.04253447471434381, regression losses: 0.1315493107176228, validation losses: 0.5136116256085086\n",
      "Epoch 2652, reconstruction losses: 0.04169599561350082, regression losses: 0.13087446312000936, validation losses: 0.5504406505484042\n",
      "Epoch 2653, reconstruction losses: 0.04872389475965914, regression losses: 0.14447770456943979, validation losses: 0.5622058344558548\n",
      "Epoch 2654, reconstruction losses: 0.050221039634351275, regression losses: 0.14666668137401545, validation losses: 0.43630020441883355\n",
      "Epoch 2655, reconstruction losses: 0.04808918436827292, regression losses: 0.13738309100044346, validation losses: 0.500530462435124\n",
      "Epoch 2656, reconstruction losses: 0.04263309272182772, regression losses: 0.13976732963608068, validation losses: 0.495918765379661\n",
      "Epoch 2657, reconstruction losses: 0.04752029671261, regression losses: 0.14107093599679793, validation losses: 0.6078881171917682\n",
      "Epoch 2658, reconstruction losses: 0.04504014984717452, regression losses: 0.14044882637132788, validation losses: 0.5834061629610559\n",
      "Epoch 2659, reconstruction losses: 0.043600274264079183, regression losses: 0.10360874323769985, validation losses: 0.5372525430430337\n",
      "Epoch 2660, reconstruction losses: 0.05177788352452027, regression losses: 0.11068303114229365, validation losses: 0.4483351085006551\n",
      "Epoch 2661, reconstruction losses: 0.04404918887889845, regression losses: 0.10474992382525727, validation losses: 0.47793209476314547\n",
      "Epoch 2662, reconstruction losses: 0.0455489420076507, regression losses: 0.13337343290258147, validation losses: 0.5556080466115929\n",
      "Epoch 2663, reconstruction losses: 0.048687257599394004, regression losses: 0.12323223669625458, validation losses: 0.5615533537538435\n",
      "Epoch 2664, reconstruction losses: 0.04503089020227395, regression losses: 0.12639898112331108, validation losses: 0.43183875039889336\n",
      "Epoch 2665, reconstruction losses: 0.0440065691305251, regression losses: 0.1813200680387936, validation losses: 0.4668100294779936\n",
      "Epoch 2666, reconstruction losses: 0.045155260259949544, regression losses: 0.16386275522960866, validation losses: 0.6071097585867092\n",
      "Epoch 2667, reconstruction losses: 0.04610260115055968, regression losses: 0.224960229147256, validation losses: 0.48919340637426173\n",
      "Epoch 2668, reconstruction losses: 0.04828636460163258, regression losses: 0.11838939346381998, validation losses: 0.5481812324625146\n",
      "Epoch 2669, reconstruction losses: 0.04354991529318877, regression losses: 0.1307913340493346, validation losses: 0.45758160733530506\n",
      "Epoch 2670, reconstruction losses: 0.04294700131771595, regression losses: 0.10531176118430825, validation losses: 0.5168429187597271\n",
      "Epoch 2671, reconstruction losses: 0.04755770972191275, regression losses: 0.11551919108586388, validation losses: 0.6013772512432493\n",
      "Epoch 2672, reconstruction losses: 0.04590847975921548, regression losses: 0.48718769072267626, validation losses: 0.6030456525177036\n",
      "Epoch 2673, reconstruction losses: 0.042078214927956006, regression losses: 0.1524267302527616, validation losses: 1.1237151424737637\n",
      "Epoch 2674, reconstruction losses: 0.042114017685516085, regression losses: 0.1470237600388274, validation losses: 0.8042783707894099\n",
      "Epoch 2675, reconstruction losses: 0.0450914823456518, regression losses: 0.1816735489858995, validation losses: 0.8076878406761945\n",
      "Epoch 2676, reconstruction losses: 0.047490643985839576, regression losses: 0.12030287204582953, validation losses: 0.475874174315088\n",
      "Epoch 2677, reconstruction losses: 0.04856743679021312, regression losses: 0.2008883491609946, validation losses: 0.45746479576413623\n",
      "Epoch 2678, reconstruction losses: 0.046590379641912066, regression losses: 0.11371143332166898, validation losses: 0.7068692780297836\n",
      "Epoch 2679, reconstruction losses: 0.04370577434384342, regression losses: 0.15703188336175872, validation losses: 0.5641508186689309\n",
      "Epoch 2680, reconstruction losses: 0.05173020829911164, regression losses: 0.11047306269572965, validation losses: 0.43285908971059495\n",
      "Epoch 2681, reconstruction losses: 0.04273054947337128, regression losses: 0.11917421997284358, validation losses: 0.5145959761287621\n",
      "Epoch 2682, reconstruction losses: 0.04275992120855552, regression losses: 0.11890584535529711, validation losses: 0.6009806193406013\n",
      "Epoch 2683, reconstruction losses: 0.043565248167035046, regression losses: 0.1237963594933646, validation losses: 0.47735346359166314\n",
      "Epoch 2684, reconstruction losses: 0.04550407198035696, regression losses: 0.16458925564767402, validation losses: 0.4534389261909799\n",
      "Epoch 2685, reconstruction losses: 0.047299912493242634, regression losses: 0.1434542379562936, validation losses: 0.6014811821362969\n",
      "Epoch 2686, reconstruction losses: 0.04314064337409378, regression losses: 0.12846122124114331, validation losses: 0.6268163877621796\n",
      "Epoch 2687, reconstruction losses: 0.04321585682303036, regression losses: 0.1383954464248338, validation losses: 0.6342822950956251\n",
      "Epoch 2688, reconstruction losses: 0.04581449507948189, regression losses: 0.37620407743116646, validation losses: 0.4625681889274413\n",
      "Epoch 2689, reconstruction losses: 0.04791563882896299, regression losses: 0.1720710454950511, validation losses: 0.8001177139419424\n",
      "Epoch 2690, reconstruction losses: 0.04497246452366413, regression losses: 0.10904912260462628, validation losses: 0.53252868395221\n",
      "Epoch 2691, reconstruction losses: 0.045724911071472245, regression losses: 0.16222641423815629, validation losses: 0.5686270681936907\n",
      "Epoch 2692, reconstruction losses: 0.044323372895122136, regression losses: 0.1265067913958423, validation losses: 0.5683616789809076\n",
      "Epoch 2693, reconstruction losses: 0.042797974670908186, regression losses: 0.1414389637671439, validation losses: 0.6779329808656865\n",
      "Epoch 2694, reconstruction losses: 0.04755565331959437, regression losses: 0.1112610810322942, validation losses: 0.6725701077070199\n",
      "Epoch 2695, reconstruction losses: 0.042019737559813794, regression losses: 0.13434789640201736, validation losses: 0.4769006816869324\n",
      "Epoch 2696, reconstruction losses: 0.04489168994226053, regression losses: 0.11093020526391066, validation losses: 0.561815051961138\n",
      "Epoch 2697, reconstruction losses: 0.04713961455768394, regression losses: 0.2677072086609467, validation losses: 0.6097133927492207\n",
      "Epoch 2698, reconstruction losses: 0.0403399424024156, regression losses: 0.12103169719291744, validation losses: 0.92644883275353\n",
      "Epoch 2699, reconstruction losses: 0.05080607135938476, regression losses: 0.152854988044727, validation losses: 0.6491849679323861\n",
      "Epoch 2700, reconstruction losses: 0.04790865231016947, regression losses: 0.16883639933901406, validation losses: 0.4343202246565141\n",
      "Epoch 2701, reconstruction losses: 0.04452406199144272, regression losses: 0.1332509673113468, validation losses: 0.497905373219227\n",
      "Epoch 2702, reconstruction losses: 0.04241574448350065, regression losses: 0.1139861135004992, validation losses: 0.48733680103601973\n",
      "Epoch 2703, reconstruction losses: 0.0446675378926439, regression losses: 0.20217491716554045, validation losses: 0.4792040427235581\n",
      "Epoch 2704, reconstruction losses: 0.041821060795010315, regression losses: 0.15443827474206373, validation losses: 0.5990256579023141\n",
      "Epoch 2705, reconstruction losses: 0.045475655093239364, regression losses: 0.15766117909787222, validation losses: 0.4424827432286276\n",
      "Epoch 2706, reconstruction losses: 0.042341344892474236, regression losses: 0.19924610000929188, validation losses: 0.7662510258319135\n",
      "Epoch 2707, reconstruction losses: 0.04836122951155698, regression losses: 0.160984539916326, validation losses: 0.8391430521287667\n",
      "Epoch 2708, reconstruction losses: 0.04515947507029866, regression losses: 0.13996094846358634, validation losses: 0.5270341475071797\n",
      "Epoch 2709, reconstruction losses: 0.04497066829271392, regression losses: 0.13657538770890418, validation losses: 0.4264081516055105\n",
      "Epoch 2710, reconstruction losses: 0.040953288163314415, regression losses: 0.15826686618554534, validation losses: 0.4317313809838067\n",
      "Epoch 2711, reconstruction losses: 0.04356788170103141, regression losses: 0.12649146533565314, validation losses: 0.6908380131036361\n",
      "Epoch 2712, reconstruction losses: 0.04195671861672791, regression losses: 0.22657246936169295, validation losses: 0.6833645570593969\n",
      "Epoch 2713, reconstruction losses: 0.050184301090196094, regression losses: 0.14291940189391264, validation losses: 0.9134258421931373\n",
      "Epoch 2714, reconstruction losses: 0.04447794656029777, regression losses: 0.1553353022621588, validation losses: 0.5641693668582836\n",
      "Epoch 2715, reconstruction losses: 0.04309628710891581, regression losses: 0.18034686799637267, validation losses: 0.4147007924855128\n",
      "Epoch 2716, reconstruction losses: 0.04633903396726547, regression losses: 0.14415799549150848, validation losses: 0.8339312015811805\n",
      "Epoch 2717, reconstruction losses: 0.04695871764745219, regression losses: 0.21606127415376195, validation losses: 0.7136608953525883\n",
      "Epoch 2718, reconstruction losses: 0.04433590375779513, regression losses: 0.20663558435878351, validation losses: 0.4243939533635567\n",
      "Epoch 2719, reconstruction losses: 0.04513780434898927, regression losses: 0.16795444092307876, validation losses: 0.6531642148531691\n",
      "Epoch 2720, reconstruction losses: 0.04598349284005109, regression losses: 0.4554805218241472, validation losses: 0.4666090245182432\n",
      "Epoch 2721, reconstruction losses: 0.041229078844533494, regression losses: 0.15124163996902712, validation losses: 1.526806957377001\n",
      "Epoch 2722, reconstruction losses: 0.0427005557069209, regression losses: 0.2484610229967602, validation losses: 0.7935591997570247\n",
      "Epoch 2723, reconstruction losses: 0.04332949729088384, regression losses: 0.18332640926619262, validation losses: 0.7206532167055808\n",
      "Epoch 2724, reconstruction losses: 0.0468694687166407, regression losses: 0.19079668586149726, validation losses: 0.6456482981924859\n",
      "Epoch 2725, reconstruction losses: 0.04496407481053495, regression losses: 0.145999304290423, validation losses: 0.6845867357546855\n",
      "Epoch 2726, reconstruction losses: 0.042388042284354874, regression losses: 0.1257489130833288, validation losses: 0.7566621220874002\n",
      "Epoch 2727, reconstruction losses: 0.042387443237900134, regression losses: 0.13054001089368517, validation losses: 0.4959747339505229\n",
      "Epoch 2728, reconstruction losses: 0.042100821924174546, regression losses: 0.14319570401257478, validation losses: 0.4675073028736249\n",
      "Epoch 2729, reconstruction losses: 0.04229039134572836, regression losses: 0.1288506517319246, validation losses: 0.47858970105936033\n",
      "Epoch 2730, reconstruction losses: 0.04210533026497987, regression losses: 0.12394579041154176, validation losses: 0.5191881970350772\n",
      "Epoch 2731, reconstruction losses: 0.04156459384376215, regression losses: 0.12418677510975087, validation losses: 0.5679151031464997\n",
      "Epoch 2732, reconstruction losses: 0.0466610119476377, regression losses: 0.12021189358096775, validation losses: 0.5605468736503069\n",
      "Epoch 2733, reconstruction losses: 0.04279533489029422, regression losses: 0.1393480510928055, validation losses: 0.4470822263620936\n",
      "Epoch 2734, reconstruction losses: 0.052000884408746104, regression losses: 0.11692120845851416, validation losses: 0.4859963723738958\n",
      "Epoch 2735, reconstruction losses: 0.04404548023482293, regression losses: 0.12229507437445417, validation losses: 0.4753954993269913\n",
      "Epoch 2736, reconstruction losses: 0.04432685627475865, regression losses: 0.1312364119305607, validation losses: 0.46729080794286276\n",
      "Epoch 2737, reconstruction losses: 0.046719564862294546, regression losses: 0.13654345008000873, validation losses: 0.6734568143506755\n",
      "Epoch 2738, reconstruction losses: 0.04265860163072202, regression losses: 0.153065574527912, validation losses: 0.6444814388881965\n",
      "Epoch 2739, reconstruction losses: 0.041084894137094104, regression losses: 0.1470027425369606, validation losses: 0.4654514544274179\n",
      "Epoch 2740, reconstruction losses: 0.0519191702484039, regression losses: 0.13831399128881564, validation losses: 0.42680385464466264\n",
      "Epoch 2741, reconstruction losses: 0.04150990121829081, regression losses: 0.12009275626635628, validation losses: 0.4923586723093871\n",
      "Epoch 2742, reconstruction losses: 0.04354236354804378, regression losses: 0.1605481236331353, validation losses: 0.5805306977181952\n",
      "Epoch 2743, reconstruction losses: 0.04387858061483157, regression losses: 0.2780149030626093, validation losses: 0.665329073826781\n",
      "Epoch 2744, reconstruction losses: 0.0409531255732441, regression losses: 0.18466947770329983, validation losses: 0.49224673946129405\n",
      "Epoch 2745, reconstruction losses: 0.04256926450484617, regression losses: 0.1463466563152229, validation losses: 0.5025949211719505\n",
      "Epoch 2746, reconstruction losses: 0.04453977506282887, regression losses: 0.12268284254050553, validation losses: 0.6981528161405077\n",
      "Epoch 2747, reconstruction losses: 0.04488697319265496, regression losses: 0.15445483532393928, validation losses: 0.6604315291910401\n",
      "Epoch 2748, reconstruction losses: 0.04591026767409502, regression losses: 0.15584299387228104, validation losses: 0.5290074708103987\n",
      "Epoch 2749, reconstruction losses: 0.04271287637163005, regression losses: 0.2010810645977833, validation losses: 0.45472389953699904\n",
      "Epoch 2750, reconstruction losses: 0.05045477828147028, regression losses: 0.15861519687277686, validation losses: 0.5440161756582307\n",
      "Epoch 2751, reconstruction losses: 0.04307597609681452, regression losses: 0.1423950379540495, validation losses: 0.5438204160998912\n",
      "Epoch 2752, reconstruction losses: 0.044917253374954266, regression losses: 0.17276873319085437, validation losses: 0.8039478609209011\n",
      "Epoch 2753, reconstruction losses: 0.04739521018637441, regression losses: 0.18400668685637017, validation losses: 0.4606509292267982\n",
      "Epoch 2754, reconstruction losses: 0.04129779199864573, regression losses: 0.14456449339667865, validation losses: 0.4862666838362366\n",
      "Epoch 2755, reconstruction losses: 0.051463415298503554, regression losses: 0.11971196141047437, validation losses: 0.5266062049745686\n",
      "Epoch 2756, reconstruction losses: 0.04586918659661149, regression losses: 0.13720583017689425, validation losses: 0.487152012609789\n",
      "Epoch 2757, reconstruction losses: 0.044428271928408876, regression losses: 0.11402233708236013, validation losses: 0.5881986328332458\n",
      "Epoch 2758, reconstruction losses: 0.04916016433206013, regression losses: 0.12991083619738694, validation losses: 0.5419396535577313\n",
      "Epoch 2759, reconstruction losses: 0.043937835971060615, regression losses: 0.11472880216781978, validation losses: 0.4756307531288954\n",
      "Epoch 2760, reconstruction losses: 0.04716788566781952, regression losses: 0.2136037185598056, validation losses: 0.5316845239708611\n",
      "Epoch 2761, reconstruction losses: 0.044101119041569894, regression losses: 0.21321266380275522, validation losses: 0.8281550931658264\n",
      "Epoch 2762, reconstruction losses: 0.043400891786757746, regression losses: 0.12378900528592468, validation losses: 0.45458516910059765\n",
      "Epoch 2763, reconstruction losses: 0.046810123014653204, regression losses: 0.14381885500264827, validation losses: 0.43610935076038204\n",
      "Epoch 2764, reconstruction losses: 0.041969108775156465, regression losses: 0.1852093595898187, validation losses: 0.5378274681126376\n",
      "Epoch 2765, reconstruction losses: 0.04243374816399914, regression losses: 0.15035991903521712, validation losses: 0.8615248664644071\n",
      "Epoch 2766, reconstruction losses: 0.04166440695292924, regression losses: 0.1407890254551552, validation losses: 0.44903257468444424\n",
      "Epoch 2767, reconstruction losses: 0.04238481871594309, regression losses: 0.1541686242185838, validation losses: 0.4279898832453123\n",
      "Epoch 2768, reconstruction losses: 0.044482791949883534, regression losses: 0.15318040404876476, validation losses: 0.47234258446689054\n",
      "Epoch 2769, reconstruction losses: 0.044863203736438345, regression losses: 0.09678648091298285, validation losses: 0.543806413674523\n",
      "Epoch 2770, reconstruction losses: 0.04265005705544227, regression losses: 0.1068513475843444, validation losses: 0.5060905914009132\n",
      "Epoch 2771, reconstruction losses: 0.043394808688320685, regression losses: 0.11687961320722948, validation losses: 0.4404842700106381\n",
      "Epoch 2772, reconstruction losses: 0.041826759527261864, regression losses: 0.1310332501829193, validation losses: 0.4924071924074367\n",
      "Epoch 2773, reconstruction losses: 0.04169743664029095, regression losses: 0.1996718944725182, validation losses: 0.5868356157804291\n",
      "Epoch 2774, reconstruction losses: 0.04427406099299967, regression losses: 0.5080531221802893, validation losses: 0.44628210352270453\n",
      "Epoch 2775, reconstruction losses: 0.04096224732501421, regression losses: 0.16687561060569167, validation losses: 0.7100468339330128\n",
      "Epoch 2776, reconstruction losses: 0.04160909218106147, regression losses: 0.15086099400994352, validation losses: 0.675836691391767\n",
      "Epoch 2777, reconstruction losses: 0.04083480685209229, regression losses: 0.16830979652382375, validation losses: 0.6840740377748666\n",
      "Epoch 2778, reconstruction losses: 0.04436125051446769, regression losses: 0.19779059262160273, validation losses: 0.4992991775721435\n",
      "Epoch 2779, reconstruction losses: 0.04424274166990421, regression losses: 0.5214021753115917, validation losses: 0.5010584006518348\n",
      "Epoch 2780, reconstruction losses: 0.04561846597972361, regression losses: 0.14015635439660543, validation losses: 0.8874399861072577\n",
      "Epoch 2781, reconstruction losses: 0.04330099399451045, regression losses: 0.19152532134176545, validation losses: 0.6797628829804279\n",
      "Epoch 2782, reconstruction losses: 0.0477425022150414, regression losses: 0.1461730911396032, validation losses: 0.6551467383715034\n",
      "Epoch 2783, reconstruction losses: 0.04076879542363084, regression losses: 0.171808683126714, validation losses: 0.547720732195806\n",
      "Epoch 2784, reconstruction losses: 0.04281132944232159, regression losses: 0.1259587960146859, validation losses: 0.5236161887730294\n",
      "Epoch 2785, reconstruction losses: 0.047827404128304676, regression losses: 0.1257644033694916, validation losses: 0.5860897225766953\n",
      "Epoch 2786, reconstruction losses: 0.04034574576774346, regression losses: 0.11898581415349516, validation losses: 0.5441151507544963\n",
      "Epoch 2787, reconstruction losses: 0.04071021702826929, regression losses: 0.15821988190405312, validation losses: 0.47975093625272297\n",
      "Epoch 2788, reconstruction losses: 0.04480015719005026, regression losses: 0.10189382691802126, validation losses: 0.4425402768704201\n",
      "Epoch 2789, reconstruction losses: 0.04967434814112956, regression losses: 0.1112900186001957, validation losses: 0.47968949892414525\n",
      "Epoch 2790, reconstruction losses: 0.04563094897174105, regression losses: 0.13697398273263425, validation losses: 0.5137134108093684\n",
      "Epoch 2791, reconstruction losses: 0.04186093893153141, regression losses: 0.13160326613100792, validation losses: 0.4971900014251612\n",
      "Epoch 2792, reconstruction losses: 0.04044754462097701, regression losses: 0.1435505169931276, validation losses: 0.4553467975498328\n",
      "Epoch 2793, reconstruction losses: 0.046736537277558665, regression losses: 0.12833324245807498, validation losses: 0.4619870893056963\n",
      "Epoch 2794, reconstruction losses: 0.04088408723971017, regression losses: 0.11274548450701742, validation losses: 0.5472918259944975\n",
      "Epoch 2795, reconstruction losses: 0.042838494563328354, regression losses: 0.09947508285957939, validation losses: 0.5768923340453664\n",
      "Epoch 2796, reconstruction losses: 0.04290237704116249, regression losses: 0.13844526227929985, validation losses: 0.46988215876430567\n",
      "Epoch 2797, reconstruction losses: 0.04247754773559331, regression losses: 0.1250711381689063, validation losses: 0.504967777191901\n",
      "Epoch 2798, reconstruction losses: 0.041277782484400866, regression losses: 0.11759358102724307, validation losses: 0.44832721191654734\n",
      "Epoch 2799, reconstruction losses: 0.04062906180238896, regression losses: 0.17818326591211223, validation losses: 0.5399468416036648\n",
      "Epoch 2800, reconstruction losses: 0.04304949598719558, regression losses: 0.1486613192011072, validation losses: 0.48310688368001\n",
      "Epoch 2801, reconstruction losses: 0.05125599052449632, regression losses: 0.12526885190159834, validation losses: 0.4275253323347689\n",
      "Epoch 2802, reconstruction losses: 0.041271704732326775, regression losses: 0.1282639396990587, validation losses: 0.46368316326186537\n",
      "Epoch 2803, reconstruction losses: 0.04058497021156505, regression losses: 0.1685841337097761, validation losses: 0.6427915400989604\n",
      "Epoch 2804, reconstruction losses: 0.046142324331467865, regression losses: 0.16573270499332804, validation losses: 0.8453114140384362\n",
      "Epoch 2805, reconstruction losses: 0.04546015721928706, regression losses: 0.15335961501708395, validation losses: 0.591277876085907\n",
      "Epoch 2806, reconstruction losses: 0.04197973778089508, regression losses: 0.1408054486838381, validation losses: 0.4648341528124256\n",
      "Epoch 2807, reconstruction losses: 0.04047556850190388, regression losses: 0.11755481993215686, validation losses: 0.48631202566863185\n",
      "Epoch 2808, reconstruction losses: 0.040468369958585125, regression losses: 0.21231321509933346, validation losses: 0.4945381576180745\n",
      "Epoch 2809, reconstruction losses: 0.04545382926811568, regression losses: 0.1644622964816876, validation losses: 0.773520854266474\n",
      "Epoch 2810, reconstruction losses: 0.041144019479934804, regression losses: 0.11862050919115073, validation losses: 0.8134201267393285\n",
      "Epoch 2811, reconstruction losses: 0.04108261814308298, regression losses: 0.145798043195413, validation losses: 0.6525203962217574\n",
      "Epoch 2812, reconstruction losses: 0.04134645223173604, regression losses: 0.11630235881729922, validation losses: 0.5258350438257747\n",
      "Epoch 2813, reconstruction losses: 0.04149680422891469, regression losses: 0.15089721895456737, validation losses: 0.41793202541357355\n",
      "Epoch 2814, reconstruction losses: 0.03987014763922749, regression losses: 0.13145568679769068, validation losses: 0.4223636693600015\n",
      "Epoch 2815, reconstruction losses: 0.044468147227398135, regression losses: 0.18881394812253874, validation losses: 0.47113942853827956\n",
      "Epoch 2816, reconstruction losses: 0.041585676660231885, regression losses: 0.1016204037918868, validation losses: 0.5198126099295135\n",
      "Epoch 2817, reconstruction losses: 0.045358238373537065, regression losses: 0.13425089653604177, validation losses: 0.5876618215809224\n",
      "Epoch 2818, reconstruction losses: 0.04725961787246, regression losses: 0.1204399507108411, validation losses: 0.4450842536617194\n",
      "Epoch 2819, reconstruction losses: 0.04241289710190121, regression losses: 0.1346192426881859, validation losses: 0.5152070665502151\n",
      "Epoch 2820, reconstruction losses: 0.04629443724456116, regression losses: 0.13657312768548172, validation losses: 0.6490665512442948\n",
      "Epoch 2821, reconstruction losses: 0.04007612183023495, regression losses: 0.10219820274044883, validation losses: 0.44948730079986726\n",
      "Epoch 2822, reconstruction losses: 0.044100766424713056, regression losses: 0.12049005270927265, validation losses: 0.47735028384974254\n",
      "Epoch 2823, reconstruction losses: 0.043906166069280855, regression losses: 0.14652114251048176, validation losses: 0.6562674276195943\n",
      "Epoch 2824, reconstruction losses: 0.043473487198564344, regression losses: 0.17047575176653257, validation losses: 0.4992419767790223\n",
      "Epoch 2825, reconstruction losses: 0.04127719405483286, regression losses: 0.1570237669630661, validation losses: 0.46373212942441194\n",
      "Epoch 2826, reconstruction losses: 0.04074516791336666, regression losses: 0.13415426380698078, validation losses: 0.42941209257650986\n",
      "Epoch 2827, reconstruction losses: 0.042361031509581024, regression losses: 0.14730858212921225, validation losses: 0.5654106911743471\n",
      "Epoch 2828, reconstruction losses: 0.04107005760929839, regression losses: 0.12859384850834962, validation losses: 0.5108196244045937\n",
      "Epoch 2829, reconstruction losses: 0.038713908862900756, regression losses: 0.11239997133412191, validation losses: 0.4561768985258576\n",
      "Epoch 2830, reconstruction losses: 0.04148821085018362, regression losses: 0.15749623563008858, validation losses: 0.45941498937372505\n",
      "Epoch 2831, reconstruction losses: 0.0429784739827839, regression losses: 0.2897454776193324, validation losses: 0.5285113313682216\n",
      "Epoch 2832, reconstruction losses: 0.04412685348189918, regression losses: 0.13889873002496006, validation losses: 0.6185326573761408\n",
      "Epoch 2833, reconstruction losses: 0.042142253222811746, regression losses: 0.14192417424949966, validation losses: 0.5069692586215279\n",
      "Epoch 2834, reconstruction losses: 0.04590021168070069, regression losses: 0.2578910130694345, validation losses: 0.42080350889445933\n",
      "Epoch 2835, reconstruction losses: 0.043636722755906125, regression losses: 0.13632904896457623, validation losses: 0.6344635848077488\n",
      "Epoch 2836, reconstruction losses: 0.041924343893112295, regression losses: 0.1993380847735265, validation losses: 0.5074814385709048\n",
      "Epoch 2837, reconstruction losses: 0.04088747889877292, regression losses: 0.1346040397399303, validation losses: 0.4282204948823244\n",
      "Epoch 2838, reconstruction losses: 0.03992488777087284, regression losses: 0.16801992293204837, validation losses: 0.5430501741652668\n",
      "Epoch 2839, reconstruction losses: 0.04527478718519991, regression losses: 0.1688819080812466, validation losses: 0.6583035799126058\n",
      "Epoch 2840, reconstruction losses: 0.040361260334607116, regression losses: 0.15695202921164977, validation losses: 0.8872411966503209\n",
      "Epoch 2841, reconstruction losses: 0.0458362969678729, regression losses: 0.24991227469905478, validation losses: 0.582652686518966\n",
      "Epoch 2842, reconstruction losses: 0.04534193110124003, regression losses: 0.3361055065797638, validation losses: 0.6400270352221631\n",
      "Epoch 2843, reconstruction losses: 0.0404243222332851, regression losses: 0.18654730727085253, validation losses: 0.8826144140274903\n",
      "Epoch 2844, reconstruction losses: 0.039782118047145154, regression losses: 0.12424355718522707, validation losses: 0.5100927381257179\n",
      "Epoch 2845, reconstruction losses: 0.0448511159591994, regression losses: 0.10493913858133573, validation losses: 0.5394421642614262\n",
      "Epoch 2846, reconstruction losses: 0.04061688595771701, regression losses: 0.10185565500657533, validation losses: 0.46358303487767716\n",
      "Epoch 2847, reconstruction losses: 0.04093644725528176, regression losses: 0.1341488061607309, validation losses: 0.4731821976548291\n",
      "Epoch 2848, reconstruction losses: 0.04061965869205137, regression losses: 0.12244913034966846, validation losses: 0.5046913888639075\n",
      "Epoch 2849, reconstruction losses: 0.04351669523894358, regression losses: 0.17255477343867473, validation losses: 0.4592894681284492\n",
      "Epoch 2850, reconstruction losses: 0.04119033746087621, regression losses: 0.1587527694551353, validation losses: 0.4380541226121377\n",
      "Epoch 2851, reconstruction losses: 0.04059476438225581, regression losses: 0.15751443331505433, validation losses: 0.4901288170201335\n",
      "Epoch 2852, reconstruction losses: 0.040171860286877865, regression losses: 0.15206512276642212, validation losses: 0.5180540653026344\n",
      "Epoch 2853, reconstruction losses: 0.04488007890061425, regression losses: 0.1464015689861008, validation losses: 0.5524706428788355\n",
      "Epoch 2854, reconstruction losses: 0.04272977842641092, regression losses: 0.1462004749098495, validation losses: 0.5596148655994947\n",
      "Epoch 2855, reconstruction losses: 0.043671718614948736, regression losses: 0.1645879401310092, validation losses: 0.4285424827996854\n",
      "Epoch 2856, reconstruction losses: 0.04266036632915611, regression losses: 0.144745094629823, validation losses: 0.5262520881268812\n",
      "Epoch 2857, reconstruction losses: 0.04854700636890598, regression losses: 0.1109107914093124, validation losses: 0.5498703488391081\n",
      "Epoch 2858, reconstruction losses: 0.04011889632306042, regression losses: 0.10655692981769764, validation losses: 0.5919587075581187\n",
      "Epoch 2859, reconstruction losses: 0.044085957472152985, regression losses: 0.11628310873230271, validation losses: 0.4612553121906769\n",
      "Epoch 2860, reconstruction losses: 0.04573661918500798, regression losses: 0.1226823079790681, validation losses: 0.45266864265358503\n",
      "Epoch 2861, reconstruction losses: 0.04340652365516063, regression losses: 0.10094491967636127, validation losses: 0.5636306470264679\n",
      "Epoch 2862, reconstruction losses: 0.04514972600355255, regression losses: 0.11842945489145129, validation losses: 0.51688973237157\n",
      "Epoch 2863, reconstruction losses: 0.040287006451009834, regression losses: 0.15612890454348027, validation losses: 0.49173279755421334\n",
      "Epoch 2864, reconstruction losses: 0.042916276708771524, regression losses: 0.14610739472025722, validation losses: 0.6500857305469196\n",
      "Epoch 2865, reconstruction losses: 0.04055983249848722, regression losses: 0.2038576652903501, validation losses: 0.5626361935970232\n",
      "Epoch 2866, reconstruction losses: 0.041307705261452166, regression losses: 0.1286009104966128, validation losses: 0.5486191875224975\n",
      "Epoch 2867, reconstruction losses: 0.05142733315343183, regression losses: 0.16028689123931772, validation losses: 0.4745985212366975\n",
      "Epoch 2868, reconstruction losses: 0.044873208083693786, regression losses: 0.14501694002460006, validation losses: 0.7090145385498927\n",
      "Epoch 2869, reconstruction losses: 0.045857215558767615, regression losses: 0.22124403697002584, validation losses: 0.4348827048795394\n",
      "Epoch 2870, reconstruction losses: 0.042934430088318404, regression losses: 0.14352607417349117, validation losses: 0.7756227443212478\n",
      "Epoch 2871, reconstruction losses: 0.05100524141480241, regression losses: 0.13986725996761387, validation losses: 0.5677462730335924\n",
      "Epoch 2872, reconstruction losses: 0.04528954139588498, regression losses: 0.11445377257987349, validation losses: 0.4425835536474188\n",
      "Epoch 2873, reconstruction losses: 0.041065335699906315, regression losses: 0.15126647294257212, validation losses: 0.4352428672968231\n",
      "Epoch 2874, reconstruction losses: 0.042456054613026595, regression losses: 0.1244506720013511, validation losses: 0.572593471577147\n",
      "Epoch 2875, reconstruction losses: 0.04280222894243267, regression losses: 0.18015980814119698, validation losses: 0.6255843857406151\n",
      "Epoch 2876, reconstruction losses: 0.04127256964723573, regression losses: 0.1404317243471082, validation losses: 0.5323621160837027\n",
      "Epoch 2877, reconstruction losses: 0.04180015944139118, regression losses: 0.1542496873766342, validation losses: 0.4483286674941094\n",
      "Epoch 2878, reconstruction losses: 0.041165669518273856, regression losses: 0.18135561274635054, validation losses: 0.48486775915473895\n",
      "Epoch 2879, reconstruction losses: 0.04672696947278017, regression losses: 0.13011031884920657, validation losses: 0.6370984712392529\n",
      "Epoch 2880, reconstruction losses: 0.04443635389753425, regression losses: 0.21862258078140268, validation losses: 0.5991975585384521\n",
      "Epoch 2881, reconstruction losses: 0.04267144751330566, regression losses: 0.20473842992233632, validation losses: 0.6159887803188251\n",
      "Epoch 2882, reconstruction losses: 0.04021577688917406, regression losses: 0.15831804191359292, validation losses: 0.6253153854185572\n",
      "Epoch 2883, reconstruction losses: 0.05101947007252035, regression losses: 0.11899954560067658, validation losses: 0.4566336914107353\n",
      "Epoch 2884, reconstruction losses: 0.04195854103348464, regression losses: 0.12712123570681874, validation losses: 0.42247198545236764\n",
      "Epoch 2885, reconstruction losses: 0.040481378746296204, regression losses: 0.10809059936605482, validation losses: 0.7197116691715038\n",
      "Epoch 2886, reconstruction losses: 0.04318963812019386, regression losses: 0.135035949802939, validation losses: 0.7308303914521298\n",
      "Epoch 2887, reconstruction losses: 0.04001374902638594, regression losses: 0.14985415648194672, validation losses: 0.42498788639886453\n",
      "Epoch 2888, reconstruction losses: 0.04552394729774755, regression losses: 0.11430426253925659, validation losses: 0.43578677646103037\n",
      "Epoch 2889, reconstruction losses: 0.04373944498594495, regression losses: 0.1598877244962109, validation losses: 0.47197235674125193\n",
      "Epoch 2890, reconstruction losses: 0.03938037694128654, regression losses: 0.14293484935030612, validation losses: 0.5417304921500037\n",
      "Epoch 2891, reconstruction losses: 0.05016374625907257, regression losses: 0.17754059897620492, validation losses: 0.4752383366769689\n",
      "Epoch 2892, reconstruction losses: 0.04063210697249805, regression losses: 0.14966386849841506, validation losses: 0.4234843344245147\n",
      "Epoch 2893, reconstruction losses: 0.0406628133605409, regression losses: 0.15305153495117102, validation losses: 0.4783026801767781\n",
      "Epoch 2894, reconstruction losses: 0.03953070580199422, regression losses: 0.13745143588750777, validation losses: 0.6073093213729984\n",
      "Epoch 2895, reconstruction losses: 0.04348034391410175, regression losses: 0.1263804281182092, validation losses: 0.49467243064794963\n",
      "Epoch 2896, reconstruction losses: 0.04088365081578704, regression losses: 0.13523912099782043, validation losses: 0.433327055346375\n",
      "Epoch 2897, reconstruction losses: 0.04457559660282618, regression losses: 0.1506021441633505, validation losses: 0.5941939817194131\n",
      "Epoch 2898, reconstruction losses: 0.04446180722113173, regression losses: 0.17375778872942022, validation losses: 0.6288239194780328\n",
      "Epoch 2899, reconstruction losses: 0.03927969577825707, regression losses: 0.1352164309293854, validation losses: 0.5013475675886024\n",
      "Epoch 2900, reconstruction losses: 0.04159029356003798, regression losses: 0.106631417899629, validation losses: 0.45016929287399887\n",
      "Epoch 2901, reconstruction losses: 0.0437754056542184, regression losses: 0.18704628022132277, validation losses: 0.45016647913317276\n",
      "Epoch 2902, reconstruction losses: 0.045564778255475676, regression losses: 0.1593774684554007, validation losses: 0.4915309595855373\n",
      "Epoch 2903, reconstruction losses: 0.03936412215642293, regression losses: 0.11776161386572831, validation losses: 0.4561277317907452\n",
      "Epoch 2904, reconstruction losses: 0.040643704158682334, regression losses: 0.14207667189605963, validation losses: 0.4729066551515587\n",
      "Epoch 2905, reconstruction losses: 0.041450637456110696, regression losses: 0.11648423158988408, validation losses: 0.7355115481806682\n",
      "Epoch 2906, reconstruction losses: 0.04091903997286867, regression losses: 0.13169407531725283, validation losses: 0.5765214392647077\n",
      "Epoch 2907, reconstruction losses: 0.03864555342324174, regression losses: 0.11159447112022887, validation losses: 0.4368032093475266\n",
      "Epoch 2908, reconstruction losses: 0.04001421546469365, regression losses: 0.25375227875953016, validation losses: 0.455902937405006\n",
      "Epoch 2909, reconstruction losses: 0.041575871852070144, regression losses: 0.10965219815601296, validation losses: 0.6131456329043609\n",
      "Epoch 2910, reconstruction losses: 0.0408496985130435, regression losses: 0.14752183640199373, validation losses: 0.534804074806213\n",
      "Epoch 2911, reconstruction losses: 0.040095194818790834, regression losses: 0.11507350821578968, validation losses: 0.4730650957147887\n",
      "Epoch 2912, reconstruction losses: 0.044657474245473006, regression losses: 0.14377656548222004, validation losses: 0.5207819728667004\n",
      "Epoch 2913, reconstruction losses: 0.04651168508514411, regression losses: 0.16223174360338077, validation losses: 0.5031293048485526\n",
      "Epoch 2914, reconstruction losses: 0.046084026276600014, regression losses: 0.14508235854061968, validation losses: 0.4245533809677351\n",
      "Epoch 2915, reconstruction losses: 0.03985548300196175, regression losses: 0.19002379380509182, validation losses: 0.4886915197494935\n",
      "Epoch 2916, reconstruction losses: 0.04272649827018325, regression losses: 0.09370691775580879, validation losses: 0.5724053214869841\n",
      "Epoch 2917, reconstruction losses: 0.042644240589895924, regression losses: 0.13585967852183567, validation losses: 0.5461106945834252\n",
      "Epoch 2918, reconstruction losses: 0.03938300325815671, regression losses: 0.16326856114010324, validation losses: 0.4822617473918587\n",
      "Epoch 2919, reconstruction losses: 0.0472552690766343, regression losses: 0.13331962863540328, validation losses: 0.45574036634877035\n",
      "Epoch 2920, reconstruction losses: 0.038224482265240854, regression losses: 0.13522955259304867, validation losses: 0.4805188125092871\n",
      "Epoch 2921, reconstruction losses: 0.049095058862391815, regression losses: 0.12219758143591287, validation losses: 0.49257939267184875\n",
      "Epoch 2922, reconstruction losses: 0.0491149840689102, regression losses: 0.12521627138041544, validation losses: 0.5234233468802233\n",
      "Epoch 2923, reconstruction losses: 0.044192676809278214, regression losses: 0.10992382968711449, validation losses: 0.46832299652204645\n",
      "Epoch 2924, reconstruction losses: 0.04058785080996149, regression losses: 0.11065455390128395, validation losses: 0.45888594719318265\n",
      "Epoch 2925, reconstruction losses: 0.03959115659389482, regression losses: 0.12113781205300186, validation losses: 0.4377234044114727\n",
      "Epoch 2926, reconstruction losses: 0.04196707014539047, regression losses: 0.1951388198750761, validation losses: 0.43727526658710436\n",
      "Epoch 2927, reconstruction losses: 0.04209393339920598, regression losses: 0.1923242745481082, validation losses: 0.6192589148558834\n",
      "Epoch 2928, reconstruction losses: 0.04113965933017093, regression losses: 0.1201296587646629, validation losses: 0.5205061310388915\n",
      "Epoch 2929, reconstruction losses: 0.040786969682631014, regression losses: 0.15466710145395124, validation losses: 0.43004404537669016\n",
      "Epoch 2930, reconstruction losses: 0.04123491094001319, regression losses: 0.11575597019881376, validation losses: 0.7798197556728131\n",
      "Epoch 2931, reconstruction losses: 0.04015921483317129, regression losses: 0.2002352160121074, validation losses: 0.6533796908136962\n",
      "Epoch 2932, reconstruction losses: 0.04197616664738818, regression losses: 0.15308606786224804, validation losses: 0.5981072075242448\n",
      "Epoch 2933, reconstruction losses: 0.04356585438424866, regression losses: 0.5405957980144113, validation losses: 0.4451335245820775\n",
      "Epoch 2934, reconstruction losses: 0.03901806020918341, regression losses: 0.14923096572068248, validation losses: 0.9945854971756641\n",
      "Epoch 2935, reconstruction losses: 0.03900090245366785, regression losses: 0.21408452659866445, validation losses: 0.894161632039859\n",
      "Epoch 2936, reconstruction losses: 0.04207717890775903, regression losses: 0.15879223484143062, validation losses: 0.6123560822573909\n",
      "Epoch 2937, reconstruction losses: 0.04409924879328804, regression losses: 0.17238577953131579, validation losses: 0.5108001448561222\n",
      "Epoch 2938, reconstruction losses: 0.04549072693978385, regression losses: 0.11662309744580722, validation losses: 0.44397170860136326\n",
      "Epoch 2939, reconstruction losses: 0.04376871840588514, regression losses: 0.14679714581409894, validation losses: 0.48496445745090344\n",
      "Epoch 2940, reconstruction losses: 0.04877057822451067, regression losses: 0.11499307672075704, validation losses: 0.4778858371194844\n",
      "Epoch 2941, reconstruction losses: 0.04311160825709082, regression losses: 0.16124517754060785, validation losses: 0.473480930846956\n",
      "Epoch 2942, reconstruction losses: 0.048519828702843895, regression losses: 0.1499641823881578, validation losses: 0.6388601483552618\n",
      "Epoch 2943, reconstruction losses: 0.04264697571747511, regression losses: 0.1780623828339384, validation losses: 0.45956022455907863\n",
      "Epoch 2944, reconstruction losses: 0.04407240028493191, regression losses: 0.43878005651572954, validation losses: 0.5340602197426031\n",
      "Epoch 2945, reconstruction losses: 0.039041111873193216, regression losses: 0.09795763167465278, validation losses: 0.6974863757907656\n",
      "Epoch 2946, reconstruction losses: 0.04107086413588993, regression losses: 0.2128528041651262, validation losses: 0.5934694540585219\n",
      "Epoch 2947, reconstruction losses: 0.04004641976030955, regression losses: 0.1411512995329996, validation losses: 0.5773643662131754\n",
      "Epoch 2948, reconstruction losses: 0.04330689333515917, regression losses: 0.45019510164457077, validation losses: 0.4259052061187939\n",
      "Epoch 2949, reconstruction losses: 0.03908406916039443, regression losses: 0.16162318463738795, validation losses: 1.098602233202202\n",
      "Epoch 2950, reconstruction losses: 0.05038775295176281, regression losses: 0.17859476260315207, validation losses: 1.0546945032125756\n",
      "Epoch 2951, reconstruction losses: 0.04021201969431948, regression losses: 0.14206056547150847, validation losses: 0.5629202079256573\n",
      "Epoch 2952, reconstruction losses: 0.038860722023529325, regression losses: 0.15878037490423838, validation losses: 0.4458321087765609\n",
      "Epoch 2953, reconstruction losses: 0.041686123202421266, regression losses: 0.13144384361173173, validation losses: 0.492830157920368\n",
      "Epoch 2954, reconstruction losses: 0.04545661842177814, regression losses: 0.14644687855989003, validation losses: 0.571939879706517\n",
      "Epoch 2955, reconstruction losses: 0.04053296606900885, regression losses: 0.14693442053347114, validation losses: 0.5560593436603285\n",
      "Epoch 2956, reconstruction losses: 0.04002935965385366, regression losses: 0.14219609637722574, validation losses: 0.44857936800160514\n",
      "Epoch 2957, reconstruction losses: 0.04137141585158149, regression losses: 0.23609439393437548, validation losses: 0.4910641818728495\n",
      "Epoch 2958, reconstruction losses: 0.03890333442141996, regression losses: 0.11601716220957191, validation losses: 0.7039017932997975\n",
      "Epoch 2959, reconstruction losses: 0.04075015327140856, regression losses: 0.1439427447964587, validation losses: 0.44770872660008126\n",
      "Epoch 2960, reconstruction losses: 0.04083575443735222, regression losses: 0.12659412447026963, validation losses: 0.7342401620699812\n",
      "Epoch 2961, reconstruction losses: 0.04040221061422505, regression losses: 0.16926782840067076, validation losses: 0.5210074996714132\n",
      "Epoch 2962, reconstruction losses: 0.040609247426318135, regression losses: 0.13930999852137776, validation losses: 0.4263250727996257\n",
      "Epoch 2963, reconstruction losses: 0.03862306227382349, regression losses: 0.13264613257517507, validation losses: 0.4726672344380796\n",
      "Epoch 2964, reconstruction losses: 0.04557826099437765, regression losses: 0.13950419702016342, validation losses: 0.43529254058830413\n",
      "Epoch 2965, reconstruction losses: 0.04044552360888473, regression losses: 0.2158597534976201, validation losses: 0.4296734531744551\n",
      "Epoch 2966, reconstruction losses: 0.04292286730059352, regression losses: 0.1931107755339302, validation losses: 0.6334243577315968\n",
      "Epoch 2967, reconstruction losses: 0.042731914505034385, regression losses: 0.14020698074165383, validation losses: 0.5543235330035879\n",
      "Epoch 2968, reconstruction losses: 0.04053623022565808, regression losses: 0.15818801889202647, validation losses: 0.46139124286650884\n",
      "Epoch 2969, reconstruction losses: 0.0424928989454094, regression losses: 0.17598131655695423, validation losses: 0.6991252772937361\n",
      "Epoch 2970, reconstruction losses: 0.03998230284815877, regression losses: 0.16408343750629326, validation losses: 0.7581979839402574\n",
      "Epoch 2971, reconstruction losses: 0.03901837202730349, regression losses: 0.13022897468302908, validation losses: 0.6609088087808005\n",
      "Epoch 2972, reconstruction losses: 0.04169567746108753, regression losses: 0.14023893034097376, validation losses: 0.6537588415542833\n",
      "Epoch 2973, reconstruction losses: 0.03979846909987079, regression losses: 0.14488468013382547, validation losses: 0.5417634466966353\n",
      "Epoch 2974, reconstruction losses: 0.03827149391804574, regression losses: 0.13892259958004957, validation losses: 0.49896275293155423\n",
      "Epoch 2975, reconstruction losses: 0.043130181221997195, regression losses: 0.10127754001532194, validation losses: 0.4558018075618832\n",
      "Epoch 2976, reconstruction losses: 0.03839503525678806, regression losses: 0.19182915256504318, validation losses: 0.555459896664512\n",
      "Epoch 2977, reconstruction losses: 0.04261800509277974, regression losses: 0.147801447234896, validation losses: 0.8125113191510663\n",
      "Epoch 2978, reconstruction losses: 0.03893242190544338, regression losses: 0.14939398005431961, validation losses: 0.6481071044600842\n",
      "Epoch 2979, reconstruction losses: 0.03700505312544827, regression losses: 0.10996368806798265, validation losses: 0.5270893737263184\n",
      "Epoch 2980, reconstruction losses: 0.041047665113209356, regression losses: 0.12462788896165718, validation losses: 0.46247183233085676\n",
      "Epoch 2981, reconstruction losses: 0.0408912847595168, regression losses: 0.17336839120481254, validation losses: 0.5104670707798358\n",
      "Epoch 2982, reconstruction losses: 0.043513555722464424, regression losses: 0.17162231692557878, validation losses: 0.5868409144448783\n",
      "Epoch 2983, reconstruction losses: 0.0389612761922702, regression losses: 0.1255364744917104, validation losses: 0.6495627104166883\n",
      "Epoch 2984, reconstruction losses: 0.04104681953267006, regression losses: 0.12981606608393687, validation losses: 0.4711410732491789\n",
      "Epoch 2985, reconstruction losses: 0.04094670851630969, regression losses: 0.14595591217370057, validation losses: 0.4313665783708286\n",
      "Epoch 2986, reconstruction losses: 0.04224937927093208, regression losses: 0.5052895871219305, validation losses: 0.4349458400135919\n",
      "Epoch 2987, reconstruction losses: 0.048866488633902694, regression losses: 0.14216241310576078, validation losses: 0.8006263691548047\n",
      "Epoch 2988, reconstruction losses: 0.040605387159292336, regression losses: 0.17362964695140243, validation losses: 0.5242544354553729\n",
      "Epoch 2989, reconstruction losses: 0.048263895879369065, regression losses: 0.18676367038406444, validation losses: 0.5636167681415215\n",
      "Epoch 2990, reconstruction losses: 0.0471340805167857, regression losses: 0.1139640471785285, validation losses: 0.49861158707289027\n",
      "Epoch 2991, reconstruction losses: 0.04852743904831792, regression losses: 0.130459432978124, validation losses: 0.4699567250962194\n",
      "Epoch 2992, reconstruction losses: 0.04067167446164572, regression losses: 0.11573103524998392, validation losses: 0.7521345743502361\n",
      "Epoch 2993, reconstruction losses: 0.04189126637828854, regression losses: 0.1435388228864222, validation losses: 0.637553043100394\n",
      "Epoch 2994, reconstruction losses: 0.04162260909705858, regression losses: 0.13157273548544426, validation losses: 0.4354128909403658\n",
      "Epoch 2995, reconstruction losses: 0.039038407855119375, regression losses: 0.16153746737576155, validation losses: 0.44973164689171585\n",
      "Epoch 2996, reconstruction losses: 0.04029223086971328, regression losses: 0.13780898618568815, validation losses: 0.6431502707873668\n",
      "Epoch 2997, reconstruction losses: 0.04198957237585225, regression losses: 0.18341370299941662, validation losses: 0.49370768960619393\n",
      "Epoch 2998, reconstruction losses: 0.03904982538448903, regression losses: 0.1106797964388298, validation losses: 0.45454792898545743\n",
      "Epoch 2999, reconstruction losses: 0.03938025718717168, regression losses: 0.12087740185404082, validation losses: 0.4406037081855283\n",
      "Epoch 3000, reconstruction losses: 0.04290617213295352, regression losses: 0.11239648673435683, validation losses: 0.6287471516486474\n",
      "Epoch 3001, reconstruction losses: 0.04039547560665852, regression losses: 0.11909884953002528, validation losses: 0.8416337018979791\n",
      "Epoch 3002, reconstruction losses: 0.04938112848679378, regression losses: 0.21508763405043313, validation losses: 0.4968827889488316\n",
      "Epoch 3003, reconstruction losses: 0.04004949962355557, regression losses: 0.1231287669608771, validation losses: 0.4640632909776951\n",
      "Epoch 3004, reconstruction losses: 0.03846757667097705, regression losses: 0.1537751778100439, validation losses: 0.5100292703987542\n",
      "Epoch 3005, reconstruction losses: 0.04029585665002617, regression losses: 0.16512498041527018, validation losses: 0.5304334054174916\n",
      "Epoch 3006, reconstruction losses: 0.040666647577154595, regression losses: 0.14414995746325904, validation losses: 0.4580183750342971\n",
      "Epoch 3007, reconstruction losses: 0.03953845803339904, regression losses: 0.12444808726319995, validation losses: 0.43738700804149033\n",
      "Epoch 3008, reconstruction losses: 0.0378651018870475, regression losses: 0.09481452436047387, validation losses: 0.5250329764461649\n",
      "Epoch 3009, reconstruction losses: 0.043136108896457415, regression losses: 0.12274443835401083, validation losses: 0.5176532665857564\n",
      "Epoch 3010, reconstruction losses: 0.038837467030371386, regression losses: 0.13797447287795467, validation losses: 0.4686263428670199\n",
      "Epoch 3011, reconstruction losses: 0.04224901506732539, regression losses: 0.1727524148308455, validation losses: 0.4978745528700805\n",
      "Epoch 3012, reconstruction losses: 0.04309037665370579, regression losses: 0.15643905071689584, validation losses: 0.5840686251243263\n",
      "Epoch 3013, reconstruction losses: 0.040666997387253996, regression losses: 0.15207774504549204, validation losses: 0.5526581429442847\n",
      "Epoch 3014, reconstruction losses: 0.04478664858959338, regression losses: 0.127218263285042, validation losses: 0.40661924445083203\n",
      "Epoch 3015, reconstruction losses: 0.037585996195050105, regression losses: 0.13225529500035094, validation losses: 0.42024571908265446\n",
      "Epoch 3016, reconstruction losses: 0.03902928076960662, regression losses: 0.11064088239381788, validation losses: 0.5202799740579321\n",
      "Epoch 3017, reconstruction losses: 0.039987621098621265, regression losses: 0.13249256424421327, validation losses: 0.4543430870545499\n",
      "Epoch 3018, reconstruction losses: 0.040593137072989234, regression losses: 0.13079554133524943, validation losses: 0.4172908400401292\n",
      "Epoch 3019, reconstruction losses: 0.040722958224669537, regression losses: 0.10714606602221524, validation losses: 0.500568587825225\n",
      "Epoch 3020, reconstruction losses: 0.03954839251403842, regression losses: 0.14958357329778074, validation losses: 0.5654346927646249\n",
      "Epoch 3021, reconstruction losses: 0.0491252668230575, regression losses: 0.37641231341821724, validation losses: 0.4999343078405436\n",
      "Epoch 3022, reconstruction losses: 0.03761131275854111, regression losses: 0.16826979854456325, validation losses: 1.011588176003644\n",
      "Epoch 3023, reconstruction losses: 0.03914768476607595, regression losses: 0.18501840569325445, validation losses: 0.5256511933530953\n",
      "Epoch 3024, reconstruction losses: 0.03864617013733734, regression losses: 0.11452460132255377, validation losses: 0.6976775940012074\n",
      "Epoch 3025, reconstruction losses: 0.04386695564151602, regression losses: 0.16850927154706322, validation losses: 0.46315476255662935\n",
      "Epoch 3026, reconstruction losses: 0.04447913640041894, regression losses: 0.13136757995237308, validation losses: 0.5455523472515652\n",
      "Epoch 3027, reconstruction losses: 0.04279153566011566, regression losses: 0.11203633663922952, validation losses: 0.46447086614834965\n",
      "Epoch 3028, reconstruction losses: 0.048123305254235145, regression losses: 0.10926947602992738, validation losses: 0.4056078353395775\n",
      "Epoch 3029, reconstruction losses: 0.04016916173356515, regression losses: 0.10232433789076202, validation losses: 0.41590261777066045\n",
      "Epoch 3030, reconstruction losses: 0.0499569628740925, regression losses: 0.2656191440755052, validation losses: 0.48071423172940325\n",
      "Epoch 3031, reconstruction losses: 0.04225181802165859, regression losses: 0.1240209098995549, validation losses: 0.504080891218751\n",
      "Epoch 3032, reconstruction losses: 0.04031305408430029, regression losses: 0.1430073468904722, validation losses: 0.4302069707857487\n",
      "Epoch 3033, reconstruction losses: 0.043392437116993816, regression losses: 0.3206900692258346, validation losses: 0.6467545997487271\n",
      "Epoch 3034, reconstruction losses: 0.045694690254669025, regression losses: 0.1651348293506415, validation losses: 1.1283456495855968\n",
      "Epoch 3035, reconstruction losses: 0.04003473900730156, regression losses: 0.16442275540186596, validation losses: 0.5894178509878667\n",
      "Epoch 3036, reconstruction losses: 0.03943827253570436, regression losses: 0.1070723315912033, validation losses: 0.6010916120366825\n",
      "Epoch 3037, reconstruction losses: 0.04536326597121473, regression losses: 0.15588313459248684, validation losses: 0.45920387521224015\n",
      "Epoch 3038, reconstruction losses: 0.04186483931487395, regression losses: 0.21422421676054432, validation losses: 0.41409109795145604\n",
      "Epoch 3039, reconstruction losses: 0.03821934941691969, regression losses: 0.11412453925297947, validation losses: 0.4975587343321269\n",
      "Epoch 3040, reconstruction losses: 0.037258903114315234, regression losses: 0.16058787742831618, validation losses: 0.5729546644341422\n",
      "Epoch 3041, reconstruction losses: 0.04064637515021666, regression losses: 0.11110797267463812, validation losses: 0.5537298215439536\n",
      "Epoch 3042, reconstruction losses: 0.037486575536311684, regression losses: 0.12407617201616937, validation losses: 0.4562588735029131\n",
      "Epoch 3043, reconstruction losses: 0.04309407908211024, regression losses: 0.13968841875005078, validation losses: 0.5398280087778707\n",
      "Epoch 3044, reconstruction losses: 0.039700609263772946, regression losses: 0.14499258686416894, validation losses: 0.6350446060362813\n",
      "Epoch 3045, reconstruction losses: 0.04049208992528024, regression losses: 0.21437134746231484, validation losses: 0.46377566874753523\n",
      "Epoch 3046, reconstruction losses: 0.041163370228121686, regression losses: 0.1251747239283153, validation losses: 0.4360705331754002\n",
      "Epoch 3047, reconstruction losses: 0.03918168474416267, regression losses: 0.15496710608886233, validation losses: 0.453744654832579\n",
      "Epoch 3048, reconstruction losses: 0.03749472447943886, regression losses: 0.14241917353968492, validation losses: 0.44529225143132184\n",
      "Epoch 3049, reconstruction losses: 0.03842020484579232, regression losses: 0.1507027338208985, validation losses: 0.4317254515207367\n",
      "Epoch 3050, reconstruction losses: 0.04063540242062374, regression losses: 0.1982502158358369, validation losses: 0.5706748730262997\n",
      "Epoch 3051, reconstruction losses: 0.04130332226062774, regression losses: 0.12363732262168632, validation losses: 0.5196285889617378\n",
      "Epoch 3052, reconstruction losses: 0.03689029352532015, regression losses: 0.14413870195998343, validation losses: 0.47800854284005156\n",
      "Epoch 3053, reconstruction losses: 0.038215066520122354, regression losses: 0.12102615507513641, validation losses: 0.5563328875077488\n",
      "Epoch 3054, reconstruction losses: 0.03745134538799084, regression losses: 0.1270422194167647, validation losses: 0.6046118354194295\n",
      "Epoch 3055, reconstruction losses: 0.04628635270199345, regression losses: 0.15471879559794766, validation losses: 0.49099032949434696\n",
      "Epoch 3056, reconstruction losses: 0.03819576992944803, regression losses: 0.1489304204043467, validation losses: 0.44915060013221775\n",
      "Epoch 3057, reconstruction losses: 0.03884505736434174, regression losses: 0.12428341695464626, validation losses: 0.5971040544795746\n",
      "Epoch 3058, reconstruction losses: 0.03758340780328992, regression losses: 0.1495871349419548, validation losses: 0.5410773930360636\n",
      "Epoch 3059, reconstruction losses: 0.03993365334141794, regression losses: 0.1264091166755697, validation losses: 0.45916203488634183\n",
      "Epoch 3060, reconstruction losses: 0.0404259467505097, regression losses: 0.14123040326269182, validation losses: 0.44351813835648957\n",
      "Epoch 3061, reconstruction losses: 0.03824983583966196, regression losses: 0.13370021276926206, validation losses: 0.5352599855789208\n",
      "Epoch 3062, reconstruction losses: 0.03828000533041791, regression losses: 0.1439533187494086, validation losses: 0.5080704093516252\n",
      "Epoch 3063, reconstruction losses: 0.040668761980090576, regression losses: 0.16668796388212265, validation losses: 0.429656255158968\n",
      "Epoch 3064, reconstruction losses: 0.036944000753646615, regression losses: 0.13445871302709145, validation losses: 0.42223284154213053\n",
      "Epoch 3065, reconstruction losses: 0.04945536267107566, regression losses: 0.10018153798077496, validation losses: 0.4058027155568589\n",
      "Epoch 3066, reconstruction losses: 0.046641773014494986, regression losses: 0.1385588417419743, validation losses: 0.429519816275055\n",
      "Epoch 3067, reconstruction losses: 0.043773627054199564, regression losses: 0.11964479952223596, validation losses: 0.5085905847573773\n",
      "Epoch 3068, reconstruction losses: 0.03985993426323575, regression losses: 0.15400899314980515, validation losses: 0.545052774702469\n",
      "Epoch 3069, reconstruction losses: 0.04073882992339001, regression losses: 0.10183393904719437, validation losses: 0.6057313067498927\n",
      "Epoch 3070, reconstruction losses: 0.04501035278471226, regression losses: 0.2239862225908225, validation losses: 0.49255854969051016\n",
      "Epoch 3071, reconstruction losses: 0.04092307151719695, regression losses: 0.17794954924543888, validation losses: 0.6893622424852176\n",
      "Epoch 3072, reconstruction losses: 0.042232602390400664, regression losses: 0.2828713295427826, validation losses: 0.46429015685767533\n",
      "Epoch 3073, reconstruction losses: 0.04009652980980827, regression losses: 0.12332543693191508, validation losses: 0.6395015786950311\n",
      "Epoch 3074, reconstruction losses: 0.03857824398965933, regression losses: 0.1476535604403017, validation losses: 0.5663725281380154\n",
      "Epoch 3075, reconstruction losses: 0.038352149343443706, regression losses: 0.13946536568061857, validation losses: 0.601243186922077\n",
      "Epoch 3076, reconstruction losses: 0.03924397734628186, regression losses: 0.14968662712551706, validation losses: 0.4321526543828209\n",
      "Epoch 3077, reconstruction losses: 0.04374298444125228, regression losses: 0.12178192430888639, validation losses: 0.48454795980628357\n",
      "Epoch 3078, reconstruction losses: 0.039527265534858656, regression losses: 0.1113817219850671, validation losses: 0.5782568846872883\n",
      "Epoch 3079, reconstruction losses: 0.04083004726049242, regression losses: 0.13554170401952179, validation losses: 0.5708621311533917\n",
      "Epoch 3080, reconstruction losses: 0.03890698157262909, regression losses: 0.16356322039096316, validation losses: 0.5368767670606143\n",
      "Epoch 3081, reconstruction losses: 0.038915129861894764, regression losses: 0.14440417777614678, validation losses: 0.6095481400007469\n",
      "Epoch 3082, reconstruction losses: 0.0387559828577648, regression losses: 0.12138175633123414, validation losses: 0.5030137574998723\n",
      "Epoch 3083, reconstruction losses: 0.04824992994092285, regression losses: 0.11752359891845449, validation losses: 0.4433488433004743\n",
      "Epoch 3084, reconstruction losses: 0.041330073998170146, regression losses: 0.14728080383922848, validation losses: 0.5038658972760709\n",
      "Epoch 3085, reconstruction losses: 0.037759266859891345, regression losses: 0.16104056730892227, validation losses: 0.6615185266348046\n",
      "Epoch 3086, reconstruction losses: 0.038987839620946, regression losses: 0.15282256135805297, validation losses: 0.5850824987009174\n",
      "Epoch 3087, reconstruction losses: 0.03886679883541848, regression losses: 0.10105779132868885, validation losses: 0.4273108799725721\n",
      "Epoch 3088, reconstruction losses: 0.046285744994467665, regression losses: 0.12226021704343785, validation losses: 0.42300149325021036\n",
      "Epoch 3089, reconstruction losses: 0.041852447765680964, regression losses: 0.1468422249168304, validation losses: 0.5303860354313249\n",
      "Epoch 3090, reconstruction losses: 0.03843091248124083, regression losses: 0.13992536398255032, validation losses: 0.579585904334882\n",
      "Epoch 3091, reconstruction losses: 0.04077700184853312, regression losses: 0.14447599785205495, validation losses: 0.4277899606667158\n",
      "Epoch 3092, reconstruction losses: 0.041366093057900656, regression losses: 0.2851074760143551, validation losses: 0.4215505100528964\n",
      "Epoch 3093, reconstruction losses: 0.04094472901640546, regression losses: 0.153643450025245, validation losses: 0.785795475345535\n",
      "Epoch 3094, reconstruction losses: 0.039785653224408093, regression losses: 0.14202131199602883, validation losses: 0.5236132352187359\n",
      "Epoch 3095, reconstruction losses: 0.03862546451012575, regression losses: 0.2697896753476817, validation losses: 0.7040729995276593\n",
      "Epoch 3096, reconstruction losses: 0.03878630561410896, regression losses: 0.24229785548976931, validation losses: 1.0310261690279057\n",
      "Epoch 3097, reconstruction losses: 0.03709440478682479, regression losses: 0.1287181742351764, validation losses: 0.5095219655221664\n",
      "Epoch 3098, reconstruction losses: 0.03809179689284847, regression losses: 0.11242093661287247, validation losses: 0.49288614560932487\n",
      "Epoch 3099, reconstruction losses: 0.037819718004562304, regression losses: 0.14685621301125304, validation losses: 0.5332140976538494\n",
      "Epoch 3100, reconstruction losses: 0.03830500445056223, regression losses: 0.12557401446621208, validation losses: 0.6143513873313273\n",
      "Epoch 3101, reconstruction losses: 0.03774545574197838, regression losses: 0.13406185929578393, validation losses: 0.6715523494946447\n",
      "Epoch 3102, reconstruction losses: 0.03750021010507748, regression losses: 0.13422471007614153, validation losses: 0.4341388393420317\n",
      "Epoch 3103, reconstruction losses: 0.04142993530189117, regression losses: 0.4042489679710398, validation losses: 0.48785283285472647\n",
      "Epoch 3104, reconstruction losses: 0.03831534835966927, regression losses: 0.2059228038203549, validation losses: 0.7846351029674273\n",
      "Epoch 3105, reconstruction losses: 0.039038056060738416, regression losses: 0.1467179391916291, validation losses: 0.4507498408410038\n",
      "Epoch 3106, reconstruction losses: 0.043260157624602356, regression losses: 0.15720350250289433, validation losses: 0.5178495534716745\n",
      "Epoch 3107, reconstruction losses: 0.037325439623968996, regression losses: 0.13507594761397648, validation losses: 0.43536570843482203\n",
      "Epoch 3108, reconstruction losses: 0.046400304783196636, regression losses: 0.15267520575916094, validation losses: 0.4192846835079992\n",
      "Epoch 3109, reconstruction losses: 0.04566487778779575, regression losses: 0.1278993307753206, validation losses: 0.47451045036578743\n",
      "Epoch 3110, reconstruction losses: 0.03962035297631864, regression losses: 0.0970320956053772, validation losses: 0.4430242873265635\n",
      "Epoch 3111, reconstruction losses: 0.041731380041375964, regression losses: 0.12440287450242542, validation losses: 0.4638497107764933\n",
      "Epoch 3112, reconstruction losses: 0.038319637243126266, regression losses: 0.10500607877735575, validation losses: 0.5845881363949552\n",
      "Epoch 3113, reconstruction losses: 0.04003825939982372, regression losses: 0.1333148668562942, validation losses: 0.48983896689638384\n",
      "Epoch 3114, reconstruction losses: 0.0378104630619349, regression losses: 0.21568886516531405, validation losses: 0.43255351126257247\n",
      "Epoch 3115, reconstruction losses: 0.04290178421723579, regression losses: 0.138052063079884, validation losses: 0.4861662554454228\n",
      "Epoch 3116, reconstruction losses: 0.03658782813054944, regression losses: 0.13251152896360677, validation losses: 0.4557965238874601\n",
      "Epoch 3117, reconstruction losses: 0.03931419769233256, regression losses: 0.15493166295977967, validation losses: 0.5623986114762574\n",
      "Epoch 3118, reconstruction losses: 0.04234246166323323, regression losses: 0.16428658480590658, validation losses: 0.5557360487980237\n",
      "Epoch 3119, reconstruction losses: 0.04631401640126087, regression losses: 0.15317536764772208, validation losses: 0.40482728348324976\n",
      "Epoch 3120, reconstruction losses: 0.03931192862514843, regression losses: 0.12532632231581828, validation losses: 0.40084898186579976\n",
      "Epoch 3121, reconstruction losses: 0.040225687257998737, regression losses: 0.1141306865137559, validation losses: 0.43498475551726573\n",
      "Epoch 3122, reconstruction losses: 0.04035291506128569, regression losses: 0.11714687891042937, validation losses: 0.48029071503477944\n",
      "Epoch 3123, reconstruction losses: 0.03778355205418297, regression losses: 0.13785489613162225, validation losses: 0.5544636654635604\n",
      "Epoch 3124, reconstruction losses: 0.03918161100830708, regression losses: 0.13453379463080642, validation losses: 0.5008982633482352\n",
      "Epoch 3125, reconstruction losses: 0.047518559995030886, regression losses: 0.10710255351483261, validation losses: 0.48344911064380575\n",
      "Epoch 3126, reconstruction losses: 0.03806587585946933, regression losses: 0.12066665126418945, validation losses: 0.45021249642501493\n",
      "Epoch 3127, reconstruction losses: 0.04009368414106426, regression losses: 0.2102994898970733, validation losses: 0.48311109984216294\n",
      "Epoch 3128, reconstruction losses: 0.037049713027705454, regression losses: 0.1412989748442745, validation losses: 0.7499769938663343\n",
      "Epoch 3129, reconstruction losses: 0.03760267896098258, regression losses: 0.23818352633700512, validation losses: 0.52124805512325\n",
      "Epoch 3130, reconstruction losses: 0.039701316567104905, regression losses: 0.15336439161897591, validation losses: 0.5021634398929943\n",
      "Epoch 3131, reconstruction losses: 0.037868728555464706, regression losses: 0.1196267254595251, validation losses: 0.48693250615132333\n",
      "Epoch 3132, reconstruction losses: 0.03731772068976164, regression losses: 0.1306574548201012, validation losses: 0.5233474612484035\n",
      "Epoch 3133, reconstruction losses: 0.03690807055622418, regression losses: 0.13952313910109534, validation losses: 0.539140577872162\n",
      "Epoch 3134, reconstruction losses: 0.03993324560069996, regression losses: 0.19032654232090246, validation losses: 0.5116226839009691\n",
      "Epoch 3135, reconstruction losses: 0.038528658148519114, regression losses: 0.19420668866807317, validation losses: 0.5644432617662789\n",
      "Epoch 3136, reconstruction losses: 0.04386180246296685, regression losses: 0.11856328274060782, validation losses: 0.46559379021118225\n",
      "Epoch 3137, reconstruction losses: 0.03797799749317633, regression losses: 0.13055819608609395, validation losses: 0.5950410593591965\n",
      "Epoch 3138, reconstruction losses: 0.039437049130163514, regression losses: 0.13582550557801543, validation losses: 0.6107321482926099\n",
      "Epoch 3139, reconstruction losses: 0.04446251087904553, regression losses: 0.12229931442781072, validation losses: 0.4960227524507379\n",
      "Epoch 3140, reconstruction losses: 0.03748095097471054, regression losses: 0.15157872315875512, validation losses: 0.44753466503627976\n",
      "Epoch 3141, reconstruction losses: 0.040700540193806714, regression losses: 0.4008062033441119, validation losses: 0.44349492516946437\n",
      "Epoch 3142, reconstruction losses: 0.039420532322355345, regression losses: 0.13294283390106307, validation losses: 0.8220882593214773\n",
      "Epoch 3143, reconstruction losses: 0.03627852580234454, regression losses: 0.15958034470003607, validation losses: 0.7122411923136335\n",
      "Epoch 3144, reconstruction losses: 0.04410208622865052, regression losses: 0.15412912856925629, validation losses: 0.5971311434977674\n",
      "Epoch 3145, reconstruction losses: 0.03910964115177957, regression losses: 0.12748707846520055, validation losses: 0.436535629884782\n",
      "Epoch 3146, reconstruction losses: 0.03941585432223358, regression losses: 0.16974575213043805, validation losses: 0.4191296359056269\n",
      "Epoch 3147, reconstruction losses: 0.040772779889911306, regression losses: 0.13274857208915064, validation losses: 0.810422875580238\n",
      "Epoch 3148, reconstruction losses: 0.04050928085887067, regression losses: 0.10552563891437476, validation losses: 0.6217268587207435\n",
      "Epoch 3149, reconstruction losses: 0.04294744318550082, regression losses: 0.13261996593394365, validation losses: 0.43308618417343686\n",
      "Epoch 3150, reconstruction losses: 0.03753179729209304, regression losses: 0.10767929564173784, validation losses: 0.40326411371637255\n",
      "Epoch 3151, reconstruction losses: 0.03837893882219378, regression losses: 0.12320083798597027, validation losses: 0.4065747000992164\n",
      "Epoch 3152, reconstruction losses: 0.038942273128172354, regression losses: 0.14725884997608535, validation losses: 0.439189394035519\n",
      "Epoch 3153, reconstruction losses: 0.040164154436902716, regression losses: 0.12617680665484732, validation losses: 0.5812640470668626\n",
      "Epoch 3154, reconstruction losses: 0.03897259483713508, regression losses: 0.11841446379042775, validation losses: 0.46617337809411774\n",
      "Epoch 3155, reconstruction losses: 0.038822335059514566, regression losses: 0.16066399508749635, validation losses: 0.42031170405338264\n",
      "Epoch 3156, reconstruction losses: 0.046320281779291095, regression losses: 0.11190818591130244, validation losses: 0.5016698777273713\n",
      "Epoch 3157, reconstruction losses: 0.037651951739186854, regression losses: 0.13228290107516386, validation losses: 0.4027699119279641\n",
      "Epoch 3158, reconstruction losses: 0.03812705806314312, regression losses: 0.19033414045127928, validation losses: 0.4347511081436029\n",
      "Epoch 3159, reconstruction losses: 0.037405486759592, regression losses: 0.13552577441361302, validation losses: 0.6821727932946964\n",
      "Epoch 3160, reconstruction losses: 0.0373543316529421, regression losses: 0.1363651584417925, validation losses: 0.773140861230642\n",
      "Epoch 3161, reconstruction losses: 0.03763648530660227, regression losses: 0.194293343699674, validation losses: 0.4931135748282603\n",
      "Epoch 3162, reconstruction losses: 0.03909793129343598, regression losses: 0.19102914792013165, validation losses: 0.5048386999970117\n",
      "Epoch 3163, reconstruction losses: 0.03860717191291451, regression losses: 0.1348350298519052, validation losses: 0.4152453272372128\n",
      "Epoch 3164, reconstruction losses: 0.03683129272447126, regression losses: 0.11717615082271345, validation losses: 0.521355870985261\n",
      "Epoch 3165, reconstruction losses: 0.039331613101533096, regression losses: 0.1485281513983705, validation losses: 0.47248091555990873\n",
      "Epoch 3166, reconstruction losses: 0.03984919457028797, regression losses: 0.4735676280269943, validation losses: 0.4288917413065783\n",
      "Epoch 3167, reconstruction losses: 0.04479197272813511, regression losses: 0.10933371991366624, validation losses: 0.5266039680993208\n",
      "Epoch 3168, reconstruction losses: 0.03941607494187085, regression losses: 0.19283264045293552, validation losses: 0.5072770630185306\n",
      "Epoch 3169, reconstruction losses: 0.03796817038630388, regression losses: 0.11428268335325582, validation losses: 0.6438882499728502\n",
      "Epoch 3170, reconstruction losses: 0.04807009556743013, regression losses: 0.1758345146532559, validation losses: 0.5016794364208736\n",
      "Epoch 3171, reconstruction losses: 0.04317696541226179, regression losses: 0.15596487800040168, validation losses: 0.4855083947123894\n",
      "Epoch 3172, reconstruction losses: 0.03861766890106701, regression losses: 0.14113186311185782, validation losses: 0.6068710842032342\n",
      "Epoch 3173, reconstruction losses: 0.047128486005878205, regression losses: 0.13941626273907667, validation losses: 0.5662551356595348\n",
      "Epoch 3174, reconstruction losses: 0.03781661084010064, regression losses: 0.10696058896945614, validation losses: 0.4370265856775943\n",
      "Epoch 3175, reconstruction losses: 0.03843616434004665, regression losses: 0.14547026829543805, validation losses: 0.43219266454214406\n",
      "Epoch 3176, reconstruction losses: 0.035366932174116884, regression losses: 0.13160503695270387, validation losses: 0.436072083070631\n",
      "Epoch 3177, reconstruction losses: 0.04294731177159483, regression losses: 0.1219474108418599, validation losses: 0.430769834155279\n",
      "Epoch 3178, reconstruction losses: 0.03597785451675906, regression losses: 0.11202931600385585, validation losses: 0.4789934771425155\n",
      "Epoch 3179, reconstruction losses: 0.03834556596298461, regression losses: 0.12824245665758038, validation losses: 0.5795375144522281\n",
      "Epoch 3180, reconstruction losses: 0.040229173505154696, regression losses: 0.12126632194625483, validation losses: 0.4358492840423648\n",
      "Epoch 3181, reconstruction losses: 0.038514258084169986, regression losses: 0.11414197287755698, validation losses: 0.46116066479898654\n",
      "Epoch 3182, reconstruction losses: 0.04533903027838428, regression losses: 0.13886622242326932, validation losses: 0.4759019627802419\n",
      "Epoch 3183, reconstruction losses: 0.042528264410697084, regression losses: 0.1519225187132802, validation losses: 0.4508860780215872\n",
      "Epoch 3184, reconstruction losses: 0.03928759007668706, regression losses: 0.12546126784243714, validation losses: 0.42242166626820543\n",
      "Epoch 3185, reconstruction losses: 0.03687592820174003, regression losses: 0.13488091721243173, validation losses: 0.487481165651951\n",
      "Epoch 3186, reconstruction losses: 0.037379939267992025, regression losses: 0.12768960509989363, validation losses: 0.6250626475520322\n",
      "Epoch 3187, reconstruction losses: 0.037705606487284785, regression losses: 0.1347078678030232, validation losses: 0.46640897591514996\n",
      "Epoch 3188, reconstruction losses: 0.03771770165466305, regression losses: 0.11278000148009135, validation losses: 0.4142603116963138\n",
      "Epoch 3189, reconstruction losses: 0.04278500239405903, regression losses: 0.13408025634984852, validation losses: 0.47515092392238173\n",
      "Epoch 3190, reconstruction losses: 0.036218014663416835, regression losses: 0.10337272188114732, validation losses: 0.49908740725666784\n",
      "Epoch 3191, reconstruction losses: 0.037731670187894195, regression losses: 0.12084008216483914, validation losses: 0.43539576155615284\n",
      "Epoch 3192, reconstruction losses: 0.040678083177907935, regression losses: 0.42251329495987244, validation losses: 0.5193786494084538\n",
      "Epoch 3193, reconstruction losses: 0.042193092902182386, regression losses: 0.139806492803221, validation losses: 0.7195009949695286\n",
      "Epoch 3194, reconstruction losses: 0.03508726849529888, regression losses: 0.11486340709475036, validation losses: 0.5690205107641233\n",
      "Epoch 3195, reconstruction losses: 0.03718476627848102, regression losses: 0.12558136527051325, validation losses: 0.5105673137641781\n",
      "Epoch 3196, reconstruction losses: 0.03842586051792836, regression losses: 0.13098149454521552, validation losses: 0.5042452026429262\n",
      "Epoch 3197, reconstruction losses: 0.04723092238602671, regression losses: 0.11983332269506759, validation losses: 0.47543985999511107\n",
      "Epoch 3198, reconstruction losses: 0.04115945604574446, regression losses: 0.136534634501299, validation losses: 0.46193845092130015\n",
      "Epoch 3199, reconstruction losses: 0.0368780083674065, regression losses: 0.13213485457393348, validation losses: 0.4987606061552386\n",
      "Epoch 3200, reconstruction losses: 0.03850245625616508, regression losses: 0.12736151692615552, validation losses: 0.4648952668666526\n",
      "Epoch 3201, reconstruction losses: 0.04116056637400767, regression losses: 0.1581221958322464, validation losses: 0.4614426793410767\n",
      "Epoch 3202, reconstruction losses: 0.0380417074994477, regression losses: 0.1338508226939983, validation losses: 0.5887683201041608\n",
      "Epoch 3203, reconstruction losses: 0.03685546262821684, regression losses: 0.11724451463402903, validation losses: 0.5430532802856004\n",
      "Epoch 3204, reconstruction losses: 0.03990456023307904, regression losses: 0.13926897855656317, validation losses: 0.46885743331804697\n",
      "Epoch 3205, reconstruction losses: 0.03544537027520395, regression losses: 0.1238946986124774, validation losses: 0.4489671679537088\n",
      "Epoch 3206, reconstruction losses: 0.044382520559720536, regression losses: 0.11802007642944305, validation losses: 0.45555052185855416\n",
      "Epoch 3207, reconstruction losses: 0.03761080637831084, regression losses: 0.17006818609883245, validation losses: 0.46538045844747805\n",
      "Epoch 3208, reconstruction losses: 0.03754554332172358, regression losses: 0.15134419967366963, validation losses: 0.6547944644645656\n",
      "Epoch 3209, reconstruction losses: 0.03755034603092443, regression losses: 0.16110884770054407, validation losses: 0.8126381842473429\n",
      "Epoch 3210, reconstruction losses: 0.043523505015038495, regression losses: 0.18243473466001747, validation losses: 0.57224546454838\n",
      "Epoch 3211, reconstruction losses: 0.03765718518512733, regression losses: 0.1184464582418565, validation losses: 0.5609249995536165\n",
      "Epoch 3212, reconstruction losses: 0.03724597638673975, regression losses: 0.16438807427049676, validation losses: 0.4296375507779153\n",
      "Epoch 3213, reconstruction losses: 0.03777601886797792, regression losses: 0.19194378706628692, validation losses: 0.6417067138017305\n",
      "Epoch 3214, reconstruction losses: 0.03840877394367512, regression losses: 0.1851406624791098, validation losses: 0.6910895867539271\n",
      "Epoch 3215, reconstruction losses: 0.03762888920544844, regression losses: 0.14309450620819714, validation losses: 0.520287932814823\n",
      "Epoch 3216, reconstruction losses: 0.039327453438626585, regression losses: 0.11985777071328188, validation losses: 0.5987626085815991\n",
      "Epoch 3217, reconstruction losses: 0.03609612224455606, regression losses: 0.13217372611006728, validation losses: 0.5230841055925706\n",
      "Epoch 3218, reconstruction losses: 0.03750507516429581, regression losses: 0.12636408832055188, validation losses: 0.4442944216103027\n",
      "Epoch 3219, reconstruction losses: 0.03652746107667716, regression losses: 0.13260734520319298, validation losses: 0.5291500810314222\n",
      "Epoch 3220, reconstruction losses: 0.039791066972744246, regression losses: 0.10902970742666628, validation losses: 0.4490072511967162\n",
      "Epoch 3221, reconstruction losses: 0.040097719721610046, regression losses: 0.11510620723343062, validation losses: 0.42895467894320766\n",
      "Epoch 3222, reconstruction losses: 0.039702189139247515, regression losses: 0.12432759885584192, validation losses: 0.44311042556381397\n",
      "Epoch 3223, reconstruction losses: 0.036683820007546164, regression losses: 0.1189179267122338, validation losses: 0.45477591146906826\n",
      "Epoch 3224, reconstruction losses: 0.03583917218222576, regression losses: 0.12806379960247333, validation losses: 0.4430196313941336\n",
      "Epoch 3225, reconstruction losses: 0.03937443380327128, regression losses: 0.20954317435222186, validation losses: 0.4290768432571276\n",
      "Epoch 3226, reconstruction losses: 0.047473291809483, regression losses: 0.13012906877644895, validation losses: 0.5132760794444754\n",
      "Epoch 3227, reconstruction losses: 0.036831881814239055, regression losses: 0.15973935202601514, validation losses: 0.41191412111961073\n",
      "Epoch 3228, reconstruction losses: 0.03775475522301849, regression losses: 0.11561032268802213, validation losses: 0.49216473344881545\n",
      "Epoch 3229, reconstruction losses: 0.0371628437908056, regression losses: 0.12294426216884387, validation losses: 0.5962250322144467\n",
      "Epoch 3230, reconstruction losses: 0.04104112078275957, regression losses: 0.3804265662200623, validation losses: 0.5360966578461687\n",
      "Epoch 3231, reconstruction losses: 0.03656503380595187, regression losses: 0.11255158783440687, validation losses: 0.5849157210479483\n",
      "Epoch 3232, reconstruction losses: 0.046762061877760955, regression losses: 0.13948148828602508, validation losses: 0.4847789602839705\n",
      "Epoch 3233, reconstruction losses: 0.03777140546895589, regression losses: 0.13187733629067722, validation losses: 0.472671460817177\n",
      "Epoch 3234, reconstruction losses: 0.03698465430814352, regression losses: 0.17613663709056443, validation losses: 0.4930020986882875\n",
      "Epoch 3235, reconstruction losses: 0.03933551005731964, regression losses: 0.44244143168583083, validation losses: 0.5028972132263139\n",
      "Epoch 3236, reconstruction losses: 0.03705377496220813, regression losses: 0.1201982754735279, validation losses: 0.6431584499603369\n",
      "Epoch 3237, reconstruction losses: 0.03729321930301415, regression losses: 0.16718570304091934, validation losses: 0.6422544939179942\n",
      "Epoch 3238, reconstruction losses: 0.0373475669336209, regression losses: 0.12086041578250689, validation losses: 0.5903907318062187\n",
      "Epoch 3239, reconstruction losses: 0.03894849915644851, regression losses: 0.2118793691743196, validation losses: 0.4975122648394309\n",
      "Epoch 3240, reconstruction losses: 0.03709683227224264, regression losses: 0.1632781286897824, validation losses: 0.6113221816516297\n",
      "Epoch 3241, reconstruction losses: 0.040876190731839686, regression losses: 0.14859198315823524, validation losses: 0.39654318958294543\n",
      "Epoch 3242, reconstruction losses: 0.04621989421879797, regression losses: 0.16160254728880205, validation losses: 0.46226481848426476\n",
      "Epoch 3243, reconstruction losses: 0.04192371284434543, regression losses: 0.21020555220871892, validation losses: 0.49995910799272214\n",
      "Epoch 3244, reconstruction losses: 0.038928772188552424, regression losses: 0.16544100542197945, validation losses: 0.5596193755807146\n",
      "Epoch 3245, reconstruction losses: 0.039675298068733204, regression losses: 0.2021332182633572, validation losses: 0.5321921014057602\n",
      "Epoch 3246, reconstruction losses: 0.039949514021620613, regression losses: 0.14049518917829337, validation losses: 0.7271846354709961\n",
      "Epoch 3247, reconstruction losses: 0.03742332854343373, regression losses: 0.16009643829698167, validation losses: 0.4068186670489766\n",
      "Epoch 3248, reconstruction losses: 0.03948421483072384, regression losses: 0.11137053593396161, validation losses: 0.4559110662924609\n",
      "Epoch 3249, reconstruction losses: 0.03655229090005929, regression losses: 0.14544126579156, validation losses: 0.5048687141711906\n",
      "Epoch 3250, reconstruction losses: 0.03750186928261221, regression losses: 0.15221398631032912, validation losses: 0.4557611314164625\n",
      "Epoch 3251, reconstruction losses: 0.040576200956565785, regression losses: 0.20990750379235756, validation losses: 0.4303274122549082\n",
      "Epoch 3252, reconstruction losses: 0.03586305227637594, regression losses: 0.1345790601418594, validation losses: 0.47187380712234095\n",
      "Epoch 3253, reconstruction losses: 0.03888011867639996, regression losses: 0.11736531173083446, validation losses: 0.4294395813345992\n",
      "Epoch 3254, reconstruction losses: 0.035547421357909004, regression losses: 0.0955941275832881, validation losses: 0.49303827452485294\n",
      "Epoch 3255, reconstruction losses: 0.0417810639938516, regression losses: 0.13084887554532648, validation losses: 0.48993714565394064\n",
      "Epoch 3256, reconstruction losses: 0.0369199180101156, regression losses: 0.09839930113004518, validation losses: 0.44639333801185543\n",
      "Epoch 3257, reconstruction losses: 0.04002900932084559, regression losses: 0.14641569306026425, validation losses: 0.42610591698253236\n",
      "Epoch 3258, reconstruction losses: 0.03658815205145321, regression losses: 0.14320753019677132, validation losses: 0.6565061232013941\n",
      "Epoch 3259, reconstruction losses: 0.036728225284253825, regression losses: 0.10897856272080195, validation losses: 0.44798122406649865\n",
      "Epoch 3260, reconstruction losses: 0.04705221101897747, regression losses: 0.10999980818908077, validation losses: 0.4127662898923814\n",
      "Epoch 3261, reconstruction losses: 0.037617729337835644, regression losses: 0.119769766803024, validation losses: 0.4694555069267146\n",
      "Epoch 3262, reconstruction losses: 0.038538125278977035, regression losses: 0.10192267889273583, validation losses: 0.41287004855256326\n",
      "Epoch 3263, reconstruction losses: 0.0369930260455692, regression losses: 0.10725854308334173, validation losses: 0.530945617715634\n",
      "Epoch 3264, reconstruction losses: 0.036295131949937845, regression losses: 0.135134204326088, validation losses: 0.47752195458353036\n",
      "Epoch 3265, reconstruction losses: 0.033873460730822466, regression losses: 0.11044636486638447, validation losses: 0.4198752250955731\n",
      "Epoch 3266, reconstruction losses: 0.039940186436225905, regression losses: 0.10904226369043755, validation losses: 0.4287126955045222\n",
      "Epoch 3267, reconstruction losses: 0.04009710739873062, regression losses: 0.14952344437002868, validation losses: 0.48964386085679046\n",
      "Epoch 3268, reconstruction losses: 0.03591281772232896, regression losses: 0.12660883285679278, validation losses: 0.5580558616753766\n",
      "Epoch 3269, reconstruction losses: 0.03686233029170954, regression losses: 0.19112523621798444, validation losses: 0.5586806052192985\n",
      "Epoch 3270, reconstruction losses: 0.04407947667088209, regression losses: 0.147283477327327, validation losses: 0.46234325980585544\n",
      "Epoch 3271, reconstruction losses: 0.037856955665891034, regression losses: 0.13117589132116003, validation losses: 0.455900478995803\n",
      "Epoch 3272, reconstruction losses: 0.03671291419946826, regression losses: 0.13810842265467752, validation losses: 0.480725957444872\n",
      "Epoch 3273, reconstruction losses: 0.035960088280504524, regression losses: 0.1022243662483226, validation losses: 0.44446248753089246\n",
      "Epoch 3274, reconstruction losses: 0.03634212164741964, regression losses: 0.09664455597815905, validation losses: 0.4460206406056254\n",
      "Epoch 3275, reconstruction losses: 0.036563633891303245, regression losses: 0.10451399712675559, validation losses: 0.45062553912954406\n",
      "Epoch 3276, reconstruction losses: 0.03585990182164394, regression losses: 0.13283095607761694, validation losses: 0.48679896261120975\n",
      "Epoch 3277, reconstruction losses: 0.039726210745936165, regression losses: 0.22877331922770056, validation losses: 0.45248991652718323\n",
      "Epoch 3278, reconstruction losses: 0.04367996576285269, regression losses: 0.14572184128240168, validation losses: 0.4663420343128014\n",
      "Epoch 3279, reconstruction losses: 0.03632225283281502, regression losses: 0.10594652395170998, validation losses: 0.4934210230954616\n",
      "Epoch 3280, reconstruction losses: 0.039119512205907175, regression losses: 0.12553484045417895, validation losses: 0.5713456190904658\n",
      "Epoch 3281, reconstruction losses: 0.03996684060595389, regression losses: 0.15226462917894984, validation losses: 0.5183022526856423\n",
      "Epoch 3282, reconstruction losses: 0.04116090994892228, regression losses: 0.1027809316802733, validation losses: 0.5387034312329483\n",
      "Epoch 3283, reconstruction losses: 0.036602964701161526, regression losses: 0.25261698765548507, validation losses: 0.4350307425375114\n",
      "Epoch 3284, reconstruction losses: 0.038261008362189694, regression losses: 0.15702465783414432, validation losses: 0.6389975493980249\n",
      "Epoch 3285, reconstruction losses: 0.03490769161879181, regression losses: 0.16472920715406303, validation losses: 0.46926017543256504\n",
      "Epoch 3286, reconstruction losses: 0.039751347382719175, regression losses: 0.1635590959313925, validation losses: 0.4755763081834793\n",
      "Epoch 3287, reconstruction losses: 0.03668610951658437, regression losses: 0.14792532942804723, validation losses: 0.5426372460725781\n",
      "Epoch 3288, reconstruction losses: 0.03745217068943435, regression losses: 0.16624676224342058, validation losses: 0.4535648714053932\n",
      "Epoch 3289, reconstruction losses: 0.04167285915035523, regression losses: 0.11867421610688221, validation losses: 0.41483332301702\n",
      "Epoch 3290, reconstruction losses: 0.03564590921624697, regression losses: 0.11798615860202526, validation losses: 0.39870661848965877\n",
      "Epoch 3291, reconstruction losses: 0.037984290478130775, regression losses: 0.11737165707883582, validation losses: 0.4721721191653854\n",
      "Epoch 3292, reconstruction losses: 0.03603224087874497, regression losses: 0.10080239723441009, validation losses: 0.49332766196395766\n",
      "Epoch 3293, reconstruction losses: 0.03546159909955509, regression losses: 0.10121082143145861, validation losses: 0.5188930766323661\n",
      "Epoch 3294, reconstruction losses: 0.034169526120112224, regression losses: 0.09043324341469912, validation losses: 0.4728035040617638\n",
      "Epoch 3295, reconstruction losses: 0.039993350906611616, regression losses: 0.1684157568008366, validation losses: 0.4181604340614337\n",
      "Epoch 3296, reconstruction losses: 0.03607246360111644, regression losses: 0.12552341794263047, validation losses: 0.4158420782345993\n",
      "Epoch 3297, reconstruction losses: 0.03469164732439626, regression losses: 0.12483093921130116, validation losses: 0.4070416474765172\n",
      "Epoch 3298, reconstruction losses: 0.040321948161196774, regression losses: 0.13576540058298084, validation losses: 0.4677480235960051\n",
      "Epoch 3299, reconstruction losses: 0.03725846129507411, regression losses: 0.13304852848845458, validation losses: 0.631611951995798\n",
      "Epoch 3300, reconstruction losses: 0.03732625255200002, regression losses: 0.10568187187247373, validation losses: 0.5605223145810895\n",
      "Epoch 3301, reconstruction losses: 0.039431903461624354, regression losses: 0.11098991267069222, validation losses: 0.49610042040071667\n",
      "Epoch 3302, reconstruction losses: 0.04603407043707417, regression losses: 0.13095250801019848, validation losses: 0.49632157278346994\n",
      "Epoch 3303, reconstruction losses: 0.03717361552446993, regression losses: 0.17049940596163377, validation losses: 0.41832827626597324\n",
      "Epoch 3304, reconstruction losses: 0.03464763054617531, regression losses: 0.133356189856849, validation losses: 0.4908058122667408\n",
      "Epoch 3305, reconstruction losses: 0.03668101447450841, regression losses: 0.13112377107732592, validation losses: 0.6030636763774087\n",
      "Epoch 3306, reconstruction losses: 0.040519256189440384, regression losses: 0.1408888894205903, validation losses: 0.4987386444357239\n",
      "Epoch 3307, reconstruction losses: 0.035280903409936434, regression losses: 0.1366494380187678, validation losses: 0.43015456712444416\n",
      "Epoch 3308, reconstruction losses: 0.03495356011339788, regression losses: 0.10299524410688343, validation losses: 0.49262790867049755\n",
      "Epoch 3309, reconstruction losses: 0.04437253800734982, regression losses: 0.1126362363796228, validation losses: 0.4262636670181547\n",
      "Epoch 3310, reconstruction losses: 0.03654389117952916, regression losses: 0.13281736493551377, validation losses: 0.42371369053426683\n",
      "Epoch 3311, reconstruction losses: 0.041936158965240625, regression losses: 0.15040478218726866, validation losses: 0.4613315245938391\n",
      "Epoch 3312, reconstruction losses: 0.035632664325169476, regression losses: 0.10996255695411612, validation losses: 0.4374459839523182\n",
      "Epoch 3313, reconstruction losses: 0.041614177531745324, regression losses: 0.11289275693256502, validation losses: 0.45090887653702605\n",
      "Epoch 3314, reconstruction losses: 0.03754918433248605, regression losses: 0.13935882460342228, validation losses: 0.48975782426905184\n",
      "Epoch 3315, reconstruction losses: 0.038648464119628294, regression losses: 0.12996511189916793, validation losses: 0.44190348183242234\n",
      "Epoch 3316, reconstruction losses: 0.038185055310217896, regression losses: 0.13081830196697602, validation losses: 0.48635297200168626\n",
      "Epoch 3317, reconstruction losses: 0.044172733570510055, regression losses: 0.14356089581086534, validation losses: 0.4687421955657596\n",
      "Epoch 3318, reconstruction losses: 0.039753391259718815, regression losses: 0.18600997181115536, validation losses: 0.4756603757101376\n",
      "Epoch 3319, reconstruction losses: 0.03707325770188155, regression losses: 0.13339444719736193, validation losses: 0.5044459689853508\n",
      "Epoch 3320, reconstruction losses: 0.037250277659332885, regression losses: 0.10431141836603944, validation losses: 0.47213600514010134\n",
      "Epoch 3321, reconstruction losses: 0.03881250629226363, regression losses: 0.11632519015372282, validation losses: 0.45276395948771786\n",
      "Epoch 3322, reconstruction losses: 0.03786385606649452, regression losses: 0.12065506502756378, validation losses: 0.4759078614872214\n",
      "Epoch 3323, reconstruction losses: 0.03432364019338824, regression losses: 0.11257273200524709, validation losses: 0.46867186087960283\n",
      "Epoch 3324, reconstruction losses: 0.03611627973329139, regression losses: 0.10747029824967631, validation losses: 0.4942366343531292\n",
      "Epoch 3325, reconstruction losses: 0.04290865191816992, regression losses: 0.14436028976774895, validation losses: 0.4002644618673425\n",
      "Epoch 3326, reconstruction losses: 0.04493085026816962, regression losses: 0.15180809739283513, validation losses: 0.3905811799073662\n",
      "Epoch 3327, reconstruction losses: 0.03867662006569986, regression losses: 0.12980581447519746, validation losses: 0.407537703276796\n",
      "Epoch 3328, reconstruction losses: 0.03606191193002055, regression losses: 0.14960127178743324, validation losses: 0.4687126345431225\n",
      "Epoch 3329, reconstruction losses: 0.041228010501790105, regression losses: 0.13095634727339428, validation losses: 0.43550622209328066\n",
      "Epoch 3330, reconstruction losses: 0.039498933175866266, regression losses: 0.19960567081306496, validation losses: 0.5556112947969332\n",
      "Epoch 3331, reconstruction losses: 0.04069578780951803, regression losses: 0.12917784262764978, validation losses: 0.6143719768315056\n",
      "Epoch 3332, reconstruction losses: 0.036740207332897575, regression losses: 0.1406010625729001, validation losses: 0.46205812646098615\n",
      "Epoch 3333, reconstruction losses: 0.03654310743884527, regression losses: 0.14726699486101572, validation losses: 0.525855772109944\n",
      "Epoch 3334, reconstruction losses: 0.03587666346699109, regression losses: 0.14304717192916583, validation losses: 0.4912570663038891\n",
      "Epoch 3335, reconstruction losses: 0.03613772408427987, regression losses: 0.1113397233935275, validation losses: 0.5183608917719571\n",
      "Epoch 3336, reconstruction losses: 0.03406423439602791, regression losses: 0.10374533379524532, validation losses: 0.42884227742400866\n",
      "Epoch 3337, reconstruction losses: 0.03536263400575724, regression losses: 0.11791621641295708, validation losses: 0.44730729236930356\n",
      "Epoch 3338, reconstruction losses: 0.03588208014266698, regression losses: 0.146650692825323, validation losses: 0.5361879425375407\n",
      "Epoch 3339, reconstruction losses: 0.04062522461708499, regression losses: 0.14119090313401042, validation losses: 0.47903232353815417\n",
      "Epoch 3340, reconstruction losses: 0.04681197284731992, regression losses: 0.1183402332570228, validation losses: 0.41902973723974796\n",
      "Epoch 3341, reconstruction losses: 0.034755030980189894, regression losses: 0.10373017060914093, validation losses: 0.39075537334357185\n",
      "Epoch 3342, reconstruction losses: 0.036832246722437935, regression losses: 0.28655735202926635, validation losses: 0.5010273131559023\n",
      "Epoch 3343, reconstruction losses: 0.03762117903143341, regression losses: 0.15714429629747517, validation losses: 0.8527647168508178\n",
      "Epoch 3344, reconstruction losses: 0.03595551802667526, regression losses: 0.15871454071298197, validation losses: 0.494305919969088\n",
      "Epoch 3345, reconstruction losses: 0.042133449499778625, regression losses: 0.09262413250176324, validation losses: 0.5901223826993726\n",
      "Epoch 3346, reconstruction losses: 0.03761934592869502, regression losses: 0.15329121732111511, validation losses: 0.42530570054458505\n",
      "Epoch 3347, reconstruction losses: 0.03684882022874733, regression losses: 0.13025675234447465, validation losses: 0.5579991350357651\n",
      "Epoch 3348, reconstruction losses: 0.0371189635475781, regression losses: 0.16145573763347645, validation losses: 0.5792734762040677\n",
      "Epoch 3349, reconstruction losses: 0.040137642522874654, regression losses: 0.13802608489373705, validation losses: 0.4258616806448328\n",
      "Epoch 3350, reconstruction losses: 0.04416635108453268, regression losses: 0.1544739175041756, validation losses: 0.4154956665225663\n",
      "Epoch 3351, reconstruction losses: 0.04315385894486671, regression losses: 0.17235879085387845, validation losses: 0.5456681319217165\n",
      "Epoch 3352, reconstruction losses: 0.038686395463766336, regression losses: 0.16238990521276236, validation losses: 0.7529850177952124\n",
      "Epoch 3353, reconstruction losses: 0.03900338368279125, regression losses: 0.15105337146662473, validation losses: 0.6753138486375788\n",
      "Epoch 3354, reconstruction losses: 0.03492022023635495, regression losses: 0.13388045324814796, validation losses: 0.4949696890026267\n",
      "Epoch 3355, reconstruction losses: 0.041610367923081204, regression losses: 0.11166584765763768, validation losses: 0.40055454791433354\n",
      "Epoch 3356, reconstruction losses: 0.03668850406273461, regression losses: 0.11553976548598681, validation losses: 0.4868024045797178\n",
      "Epoch 3357, reconstruction losses: 0.043146363623733086, regression losses: 0.09235872816767136, validation losses: 0.52953052872668\n",
      "Epoch 3358, reconstruction losses: 0.038451589914148765, regression losses: 0.13945017297797868, validation losses: 0.45445696004666614\n",
      "Epoch 3359, reconstruction losses: 0.037809983489638016, regression losses: 0.11299495511682223, validation losses: 0.506415975741603\n",
      "Epoch 3360, reconstruction losses: 0.03826016768398968, regression losses: 0.1996955135957738, validation losses: 0.43544353467315766\n",
      "Epoch 3361, reconstruction losses: 0.03692798589937387, regression losses: 0.12085040598219225, validation losses: 0.5181359696636945\n",
      "Epoch 3362, reconstruction losses: 0.042426842542125136, regression losses: 0.14074991054196495, validation losses: 0.44923373521394566\n",
      "Epoch 3363, reconstruction losses: 0.03898655526347117, regression losses: 0.1310779692035066, validation losses: 0.5673250924561922\n",
      "Epoch 3364, reconstruction losses: 0.03650445611815337, regression losses: 0.14387272073353116, validation losses: 0.6014039639680251\n",
      "Epoch 3365, reconstruction losses: 0.04270003603305116, regression losses: 0.08642613517939517, validation losses: 0.5606898175675951\n",
      "Epoch 3366, reconstruction losses: 0.03652103049488996, regression losses: 0.09850906416137538, validation losses: 0.48421818069785694\n",
      "Epoch 3367, reconstruction losses: 0.036152637347904325, regression losses: 0.1703446838914202, validation losses: 0.42697748075893577\n",
      "Epoch 3368, reconstruction losses: 0.041809349086187414, regression losses: 0.11068002141363416, validation losses: 0.4354030291361555\n",
      "Epoch 3369, reconstruction losses: 0.035848201522428305, regression losses: 0.14995241428095868, validation losses: 0.5328546268197382\n",
      "Epoch 3370, reconstruction losses: 0.03712993722899994, regression losses: 0.09593106871771348, validation losses: 0.6073240738368102\n",
      "Epoch 3371, reconstruction losses: 0.03937806720152352, regression losses: 0.1342736306575324, validation losses: 0.45716300218668254\n",
      "Epoch 3372, reconstruction losses: 0.03556076781173129, regression losses: 0.15197850071434968, validation losses: 0.42974614255745847\n",
      "Epoch 3373, reconstruction losses: 0.036402863545574454, regression losses: 0.11412341748046352, validation losses: 0.43986866139311614\n",
      "Epoch 3374, reconstruction losses: 0.044923216116461974, regression losses: 0.13414427974250695, validation losses: 0.4411128265085985\n",
      "Epoch 3375, reconstruction losses: 0.03769861622441022, regression losses: 0.16141070298612875, validation losses: 0.4265824727477009\n",
      "Epoch 3376, reconstruction losses: 0.035667500897257176, regression losses: 0.19061307830709098, validation losses: 0.46219963864326663\n",
      "Epoch 3377, reconstruction losses: 0.03969227020573171, regression losses: 0.1439763382799912, validation losses: 0.5695309427638717\n",
      "Epoch 3378, reconstruction losses: 0.03791176404980912, regression losses: 0.11033355560251729, validation losses: 0.44467822337649254\n",
      "Epoch 3379, reconstruction losses: 0.03907550810996195, regression losses: 0.11739982051074534, validation losses: 0.45717778586412017\n",
      "Epoch 3380, reconstruction losses: 0.03598824606982896, regression losses: 0.1682810547420263, validation losses: 0.46775560778368946\n",
      "Epoch 3381, reconstruction losses: 0.03962848703608886, regression losses: 0.12018298897694316, validation losses: 0.6524302783526157\n",
      "Epoch 3382, reconstruction losses: 0.03484153941526651, regression losses: 0.11584934802724851, validation losses: 0.46836450399588964\n",
      "Epoch 3383, reconstruction losses: 0.03420256661481374, regression losses: 0.08733199704701065, validation losses: 0.40111901471542416\n",
      "Epoch 3384, reconstruction losses: 0.038748995897739225, regression losses: 0.1355958862031405, validation losses: 0.42917708762510537\n",
      "Epoch 3385, reconstruction losses: 0.034639925522616924, regression losses: 0.11886767109147964, validation losses: 0.5496240951331629\n",
      "Epoch 3386, reconstruction losses: 0.04613511328474788, regression losses: 0.1290394992777574, validation losses: 0.4553992358928687\n",
      "Epoch 3387, reconstruction losses: 0.03708569012249583, regression losses: 0.1705017704039627, validation losses: 0.4579899945124152\n",
      "Epoch 3388, reconstruction losses: 0.03692816215773165, regression losses: 0.14860864811948643, validation losses: 0.5184796469878625\n",
      "Epoch 3389, reconstruction losses: 0.03568322644594406, regression losses: 0.2973010603279632, validation losses: 0.5629067057847144\n",
      "Epoch 3390, reconstruction losses: 0.03480173739777566, regression losses: 0.158402686732303, validation losses: 1.31634029466293\n",
      "Epoch 3391, reconstruction losses: 0.036121825911235826, regression losses: 0.1822393625105734, validation losses: 0.5808325547955957\n",
      "Epoch 3392, reconstruction losses: 0.03543640786685574, regression losses: 0.25617886688635144, validation losses: 0.5664878112127925\n",
      "Epoch 3393, reconstruction losses: 0.038135542406896275, regression losses: 0.1461470931977011, validation losses: 0.6400476966636309\n",
      "Epoch 3394, reconstruction losses: 0.03895548497791722, regression losses: 0.20584378380401386, validation losses: 0.5419402689333154\n",
      "Epoch 3395, reconstruction losses: 0.04001373007402087, regression losses: 0.13855868595595974, validation losses: 0.6308602596288443\n",
      "Epoch 3396, reconstruction losses: 0.03841642835576048, regression losses: 0.17901067353345715, validation losses: 0.42545309936990106\n",
      "Epoch 3397, reconstruction losses: 0.036972525153778295, regression losses: 0.17791895483866893, validation losses: 0.5414700567907279\n",
      "Epoch 3398, reconstruction losses: 0.037779468718224685, regression losses: 0.13882689857697228, validation losses: 0.5670658727494958\n",
      "Epoch 3399, reconstruction losses: 0.03569515187520835, regression losses: 0.15091079133147758, validation losses: 0.5068454308600203\n",
      "Epoch 3400, reconstruction losses: 0.04227518515467622, regression losses: 0.13195849242731578, validation losses: 0.512776902553714\n",
      "Epoch 3401, reconstruction losses: 0.03691549054070458, regression losses: 0.13210410032888822, validation losses: 0.42117388409771767\n",
      "Epoch 3402, reconstruction losses: 0.03915972658947654, regression losses: 0.17565558403858592, validation losses: 0.45274152536862133\n",
      "Epoch 3403, reconstruction losses: 0.0342146574576133, regression losses: 0.09606883167404073, validation losses: 0.6252798157297724\n",
      "Epoch 3404, reconstruction losses: 0.03836936605808601, regression losses: 0.15182050591810528, validation losses: 0.43456155972417004\n",
      "Epoch 3405, reconstruction losses: 0.03801285803398396, regression losses: 0.18594347651153453, validation losses: 0.4150507852248578\n",
      "Epoch 3406, reconstruction losses: 0.03654310876126612, regression losses: 0.10752868407088856, validation losses: 0.4824494965270797\n",
      "Epoch 3407, reconstruction losses: 0.036316276089470675, regression losses: 0.1250073966228046, validation losses: 0.5840675591222738\n",
      "Epoch 3408, reconstruction losses: 0.038967692901231914, regression losses: 0.4633000489844332, validation losses: 0.5090938947963782\n",
      "Epoch 3409, reconstruction losses: 0.03804484893461733, regression losses: 0.3319823140838958, validation losses: 0.8481777138511941\n",
      "Epoch 3410, reconstruction losses: 0.04091182525071643, regression losses: 0.2555834505605553, validation losses: 1.0311604154621388\n",
      "Epoch 3411, reconstruction losses: 0.037514899360712374, regression losses: 0.15662236675334887, validation losses: 1.0892099612422543\n",
      "Epoch 3412, reconstruction losses: 0.0381506228428329, regression losses: 0.16882666743602798, validation losses: 0.6782998255847543\n",
      "Epoch 3413, reconstruction losses: 0.04503964730972346, regression losses: 0.15373688376001923, validation losses: 0.49509335809635924\n",
      "Epoch 3414, reconstruction losses: 0.03561825227011262, regression losses: 0.15254725686234782, validation losses: 0.5000838118144831\n",
      "Epoch 3415, reconstruction losses: 0.038713622627833726, regression losses: 0.11144507286803253, validation losses: 0.7540877875750133\n",
      "Epoch 3416, reconstruction losses: 0.03894279840594235, regression losses: 0.1629888285480609, validation losses: 0.5232603244243628\n",
      "Epoch 3417, reconstruction losses: 0.035982389574244086, regression losses: 0.15402472647936682, validation losses: 0.4604497492828978\n",
      "Epoch 3418, reconstruction losses: 0.03907216713531606, regression losses: 0.19139426979878635, validation losses: 0.4374553316758718\n",
      "Epoch 3419, reconstruction losses: 0.035861290126416895, regression losses: 0.13396980680491424, validation losses: 0.5303657677950664\n",
      "Epoch 3420, reconstruction losses: 0.03439296883254557, regression losses: 0.12653884700559942, validation losses: 0.45056182684307905\n",
      "Epoch 3421, reconstruction losses: 0.03443810181800819, regression losses: 0.10715988401737818, validation losses: 0.4074871339144348\n",
      "Epoch 3422, reconstruction losses: 0.042520723878482214, regression losses: 0.08965589888065593, validation losses: 0.4155579130286534\n",
      "Epoch 3423, reconstruction losses: 0.0354140535889897, regression losses: 0.11844916833595154, validation losses: 0.48262674784754334\n",
      "Epoch 3424, reconstruction losses: 0.038135958472091405, regression losses: 0.12752276383381556, validation losses: 0.4910586285732875\n",
      "Epoch 3425, reconstruction losses: 0.042195492332022036, regression losses: 0.14596463663571616, validation losses: 0.41891807951122756\n",
      "Epoch 3426, reconstruction losses: 0.039148939799296484, regression losses: 0.12430128245090903, validation losses: 0.4434444861645889\n",
      "Epoch 3427, reconstruction losses: 0.04310233901890069, regression losses: 0.36111188445007036, validation losses: 0.5096051572184869\n",
      "Epoch 3428, reconstruction losses: 0.037676615596621894, regression losses: 0.14039609780510637, validation losses: 1.1789356921797696\n",
      "Epoch 3429, reconstruction losses: 0.036887239690858456, regression losses: 0.19173358009575797, validation losses: 0.5854341585709947\n",
      "Epoch 3430, reconstruction losses: 0.036764180868163236, regression losses: 0.15625564046336307, validation losses: 0.4243352717359381\n",
      "Epoch 3431, reconstruction losses: 0.0374827146064645, regression losses: 0.1386693557220171, validation losses: 0.4170497992133671\n",
      "Epoch 3432, reconstruction losses: 0.036775379323365345, regression losses: 0.10015750991297794, validation losses: 0.4689839911480674\n",
      "Epoch 3433, reconstruction losses: 0.041593885610818095, regression losses: 0.10764170221527587, validation losses: 0.5657498044292228\n",
      "Epoch 3434, reconstruction losses: 0.03763123900488907, regression losses: 0.10554501514116592, validation losses: 0.453629077748015\n",
      "Epoch 3435, reconstruction losses: 0.03690166183813365, regression losses: 0.1691547012910335, validation losses: 0.5123651924184571\n",
      "Epoch 3436, reconstruction losses: 0.03621830776848781, regression losses: 0.1720294381653404, validation losses: 0.6496521853809067\n",
      "Epoch 3437, reconstruction losses: 0.03746273004366821, regression losses: 0.1323561082986023, validation losses: 0.5661885143522424\n",
      "Epoch 3438, reconstruction losses: 0.0363582382304308, regression losses: 0.17169939195009054, validation losses: 0.42317720726833774\n",
      "Epoch 3439, reconstruction losses: 0.03672253368632719, regression losses: 0.13862189709048323, validation losses: 0.4474398627771409\n",
      "Epoch 3440, reconstruction losses: 0.035687235720459655, regression losses: 0.12608001443645964, validation losses: 0.4517289688118861\n",
      "Epoch 3441, reconstruction losses: 0.03610455265253337, regression losses: 0.10334403787963183, validation losses: 0.4566299313981621\n",
      "Epoch 3442, reconstruction losses: 0.033237469910560986, regression losses: 0.10637185427376086, validation losses: 0.3919208861681494\n",
      "Epoch 3443, reconstruction losses: 0.039958347214843815, regression losses: 0.18140884555635478, validation losses: 0.4939122261394524\n",
      "Epoch 3444, reconstruction losses: 0.038046593775175774, regression losses: 0.1122566888642553, validation losses: 0.6155609503339335\n",
      "Epoch 3445, reconstruction losses: 0.03326980810620028, regression losses: 0.11606877192040065, validation losses: 0.4518397551173814\n",
      "Epoch 3446, reconstruction losses: 0.037620834989267035, regression losses: 0.14043681422970655, validation losses: 0.3955633804716951\n",
      "Epoch 3447, reconstruction losses: 0.03405976017535531, regression losses: 0.15133586529472265, validation losses: 0.4650655061197655\n",
      "Epoch 3448, reconstruction losses: 0.038801647341740755, regression losses: 0.14436674736426977, validation losses: 0.4354146743791065\n",
      "Epoch 3449, reconstruction losses: 0.036882663088206306, regression losses: 0.1557975502298954, validation losses: 0.4084464394938703\n",
      "Epoch 3450, reconstruction losses: 0.03929131064443439, regression losses: 0.13815254064920557, validation losses: 0.5312557749977478\n",
      "Epoch 3451, reconstruction losses: 0.0359124451628309, regression losses: 0.15107680142429025, validation losses: 0.43637836915816286\n",
      "Epoch 3452, reconstruction losses: 0.03568202693478019, regression losses: 0.12051371171863146, validation losses: 0.40804180297503634\n",
      "Epoch 3453, reconstruction losses: 0.03544925515601018, regression losses: 0.1118297866567326, validation losses: 0.3921813576051741\n",
      "Epoch 3454, reconstruction losses: 0.03585462742912191, regression losses: 0.11439735063955124, validation losses: 0.41822667349571296\n",
      "Epoch 3455, reconstruction losses: 0.038036841460558996, regression losses: 0.12185960001449044, validation losses: 0.5395053071366874\n",
      "Epoch 3456, reconstruction losses: 0.04414671230432719, regression losses: 0.12356721859427404, validation losses: 0.5045144652994444\n",
      "Epoch 3457, reconstruction losses: 0.0381550057965599, regression losses: 0.30838404567552136, validation losses: 0.4285053601769061\n",
      "Epoch 3458, reconstruction losses: 0.03926130231808338, regression losses: 0.15330818290136705, validation losses: 0.8184089414984383\n",
      "Epoch 3459, reconstruction losses: 0.03722145015230077, regression losses: 0.16972411170118373, validation losses: 0.4247069529039441\n",
      "Epoch 3460, reconstruction losses: 0.03802275284808341, regression losses: 0.19385628694884696, validation losses: 0.5142148306911513\n",
      "Epoch 3461, reconstruction losses: 0.038582080854997515, regression losses: 0.26894015081002354, validation losses: 0.5515877494619947\n",
      "Epoch 3462, reconstruction losses: 0.03653746775768847, regression losses: 0.18265309665459595, validation losses: 0.737297726610667\n",
      "Epoch 3463, reconstruction losses: 0.035311750143021854, regression losses: 0.21267113848693958, validation losses: 0.4354156432965701\n",
      "Epoch 3464, reconstruction losses: 0.03748981729230706, regression losses: 0.1871835456386689, validation losses: 0.8032883218505662\n",
      "Epoch 3465, reconstruction losses: 0.03765862654016996, regression losses: 0.1485294198158453, validation losses: 1.0088877445296616\n",
      "Epoch 3466, reconstruction losses: 0.034422426958272676, regression losses: 0.13383915343271335, validation losses: 0.5081467449972288\n",
      "Epoch 3467, reconstruction losses: 0.03633858140510036, regression losses: 0.25518911109046427, validation losses: 0.4663156214784058\n",
      "Epoch 3468, reconstruction losses: 0.042557103598719885, regression losses: 0.18446199948032554, validation losses: 0.879087825642443\n",
      "Epoch 3469, reconstruction losses: 0.036222235917303724, regression losses: 0.18151231593060715, validation losses: 0.558204976317506\n",
      "Epoch 3470, reconstruction losses: 0.033872044963398414, regression losses: 0.14366109309311734, validation losses: 0.7641247654851971\n",
      "Epoch 3471, reconstruction losses: 0.03868609457435506, regression losses: 0.13602545288333412, validation losses: 0.506754695269199\n",
      "Epoch 3472, reconstruction losses: 0.04017407727681224, regression losses: 0.1309299237354336, validation losses: 0.4026192275734488\n",
      "Epoch 3473, reconstruction losses: 0.036230028355760446, regression losses: 0.14453356407055976, validation losses: 0.4300321576696018\n",
      "Epoch 3474, reconstruction losses: 0.03821781011227697, regression losses: 0.12833259764963528, validation losses: 0.4549987222975617\n",
      "Epoch 3475, reconstruction losses: 0.04386176568559655, regression losses: 0.1267419144404351, validation losses: 0.41982197190268056\n",
      "Epoch 3476, reconstruction losses: 0.03492042220879261, regression losses: 0.12119219007001616, validation losses: 0.44131326218081\n",
      "Epoch 3477, reconstruction losses: 0.036319684293341196, regression losses: 0.12346477409900435, validation losses: 0.4070449473508583\n",
      "Epoch 3478, reconstruction losses: 0.03581435649369199, regression losses: 0.12617224945373207, validation losses: 0.49750938560017866\n",
      "Epoch 3479, reconstruction losses: 0.03341600051002487, regression losses: 0.10664637368680209, validation losses: 0.49034058909974243\n",
      "Epoch 3480, reconstruction losses: 0.0353460259073329, regression losses: 0.10667376083264928, validation losses: 0.45795094417446947\n",
      "Epoch 3481, reconstruction losses: 0.036580716469447036, regression losses: 0.14978410942091028, validation losses: 0.4415113713938169\n",
      "Epoch 3482, reconstruction losses: 0.03671774297541385, regression losses: 0.15018203880641484, validation losses: 0.5815756337228879\n",
      "Epoch 3483, reconstruction losses: 0.03824208862785722, regression losses: 0.13733319782369366, validation losses: 0.5206948413706802\n",
      "Epoch 3484, reconstruction losses: 0.03672192416885822, regression losses: 0.13343319829968156, validation losses: 0.44854457052406166\n",
      "Epoch 3485, reconstruction losses: 0.04129502177217918, regression losses: 0.11272822681572411, validation losses: 0.4316828818022819\n",
      "Epoch 3486, reconstruction losses: 0.03515105111359339, regression losses: 0.12788719694313114, validation losses: 0.4446764412865762\n",
      "Epoch 3487, reconstruction losses: 0.0359090889222827, regression losses: 0.11961742049228768, validation losses: 0.5628999373277024\n",
      "Epoch 3488, reconstruction losses: 0.03785736247818943, regression losses: 0.15951158849412267, validation losses: 0.5264189092341163\n",
      "Epoch 3489, reconstruction losses: 0.03616469593190116, regression losses: 0.12345665911500997, validation losses: 0.5742427519598003\n",
      "Epoch 3490, reconstruction losses: 0.0350392010306739, regression losses: 0.12383928824674624, validation losses: 0.5110572430797029\n",
      "Epoch 3491, reconstruction losses: 0.036229301783810265, regression losses: 0.11918140324439658, validation losses: 0.5117505518341346\n",
      "Epoch 3492, reconstruction losses: 0.04187409683463177, regression losses: 0.12365310245662878, validation losses: 0.5023769495531482\n",
      "Epoch 3493, reconstruction losses: 0.03398184819234548, regression losses: 0.1356454238893385, validation losses: 0.4803957189406292\n",
      "Epoch 3494, reconstruction losses: 0.035971594661037505, regression losses: 0.18790676317748095, validation losses: 0.42024071843621247\n",
      "Epoch 3495, reconstruction losses: 0.035639795873656295, regression losses: 0.15550099247648239, validation losses: 0.47019514806577895\n",
      "Epoch 3496, reconstruction losses: 0.03740782050553788, regression losses: 0.13642944972991894, validation losses: 0.4971408213493097\n",
      "Epoch 3497, reconstruction losses: 0.03847844590466508, regression losses: 0.11581045877476968, validation losses: 0.6380493458276616\n",
      "Epoch 3498, reconstruction losses: 0.03713552767490083, regression losses: 0.10101790948991536, validation losses: 0.5186867414035484\n",
      "Epoch 3499, reconstruction losses: 0.040698706800962416, regression losses: 0.13556649150309313, validation losses: 0.4290726061537422\n",
      "Epoch 3500, reconstruction losses: 0.03575374087503007, regression losses: 0.11385432966835686, validation losses: 0.43479467100238733\n",
      "Epoch 3501, reconstruction losses: 0.03616215670482223, regression losses: 0.12730586584229864, validation losses: 0.4636250568938952\n",
      "Epoch 3502, reconstruction losses: 0.03899943252881131, regression losses: 0.13317314031207445, validation losses: 0.4428938166568985\n",
      "Epoch 3503, reconstruction losses: 0.036694022915718244, regression losses: 0.12178242908757445, validation losses: 0.41496699893512756\n",
      "Epoch 3504, reconstruction losses: 0.039337476762395754, regression losses: 0.1100652173561443, validation losses: 0.41718790888171775\n",
      "Epoch 3505, reconstruction losses: 0.033983329175943114, regression losses: 0.12446430472854124, validation losses: 0.43647310628465613\n",
      "Epoch 3506, reconstruction losses: 0.043117125121019305, regression losses: 0.11604509200488035, validation losses: 0.42384538866720906\n",
      "Epoch 3507, reconstruction losses: 0.041447803894844294, regression losses: 0.12449663961018054, validation losses: 0.47041477426674566\n",
      "Epoch 3508, reconstruction losses: 0.04177287775481453, regression losses: 0.1366824944644702, validation losses: 0.4293665633427147\n",
      "Epoch 3509, reconstruction losses: 0.0357122921711451, regression losses: 0.10338402805727301, validation losses: 0.4279314434771541\n",
      "Epoch 3510, reconstruction losses: 0.034017276124634795, regression losses: 0.1227484981005119, validation losses: 0.4474901402704567\n",
      "Epoch 3511, reconstruction losses: 0.03442247824534386, regression losses: 0.12676747929719964, validation losses: 0.43935748000818403\n",
      "Epoch 3512, reconstruction losses: 0.03728317112725107, regression losses: 0.1496840474370776, validation losses: 0.4921018184920025\n",
      "Epoch 3513, reconstruction losses: 0.03386940424110036, regression losses: 0.11806561154698919, validation losses: 0.5365401216602314\n",
      "Epoch 3514, reconstruction losses: 0.04531526074300177, regression losses: 0.13136208216302883, validation losses: 0.4097522499833197\n",
      "Epoch 3515, reconstruction losses: 0.035522518941838714, regression losses: 0.15876706918543515, validation losses: 0.46135231550648265\n",
      "Epoch 3516, reconstruction losses: 0.03738321947255095, regression losses: 0.09916106186558843, validation losses: 0.47910161717209854\n",
      "Epoch 3517, reconstruction losses: 0.035837501453247794, regression losses: 0.14538886894940956, validation losses: 0.5469891930013034\n",
      "Epoch 3518, reconstruction losses: 0.03293375276505296, regression losses: 0.1248796329078037, validation losses: 0.4864377804219844\n",
      "Epoch 3519, reconstruction losses: 0.03664784460024593, regression losses: 0.11425575634093801, validation losses: 0.5038813174321682\n",
      "Epoch 3520, reconstruction losses: 0.03259527178119513, regression losses: 0.11511800304552017, validation losses: 0.48580213613260004\n",
      "Epoch 3521, reconstruction losses: 0.03744433175943249, regression losses: 0.10610673227831582, validation losses: 0.5086946611109511\n",
      "Epoch 3522, reconstruction losses: 0.035515904511926794, regression losses: 0.15583938061796798, validation losses: 0.5048337319971398\n",
      "Epoch 3523, reconstruction losses: 0.03392339756494396, regression losses: 0.10447977507120493, validation losses: 0.8167294280166022\n",
      "Epoch 3524, reconstruction losses: 0.0364378273775954, regression losses: 0.20318527223578847, validation losses: 0.6263008741909234\n",
      "Epoch 3525, reconstruction losses: 0.038019889288877354, regression losses: 0.4628666825771139, validation losses: 0.47278619602924893\n",
      "Epoch 3526, reconstruction losses: 0.03768155371203856, regression losses: 0.15430595873835126, validation losses: 0.5939690830611952\n",
      "Epoch 3527, reconstruction losses: 0.04322060741505028, regression losses: 0.1503661811278583, validation losses: 0.5851940738892659\n",
      "Epoch 3528, reconstruction losses: 0.03407377522296985, regression losses: 0.10394949421586101, validation losses: 0.4723810861874339\n",
      "Epoch 3529, reconstruction losses: 0.03822077918370617, regression losses: 0.11332030571063138, validation losses: 0.4586269421386311\n",
      "Epoch 3530, reconstruction losses: 0.03532219202609006, regression losses: 0.21885379910655517, validation losses: 0.48245314739967216\n",
      "Epoch 3531, reconstruction losses: 0.036465179333806295, regression losses: 0.10759509755565524, validation losses: 0.4833928406904987\n",
      "Epoch 3532, reconstruction losses: 0.03611093416852904, regression losses: 0.1594074665500136, validation losses: 0.43858062115245194\n",
      "Epoch 3533, reconstruction losses: 0.03874854225301866, regression losses: 0.29362280086704967, validation losses: 0.5251920827613303\n",
      "Epoch 3534, reconstruction losses: 0.0347832905438072, regression losses: 0.25289272367403803, validation losses: 0.7985585302594606\n",
      "Epoch 3535, reconstruction losses: 0.03966848714174877, regression losses: 0.1466654674730484, validation losses: 0.810122649243978\n",
      "Epoch 3536, reconstruction losses: 0.03523149826046717, regression losses: 0.16807553581799178, validation losses: 0.6279186665349338\n",
      "Epoch 3537, reconstruction losses: 0.03620098862826632, regression losses: 0.13885952497598553, validation losses: 0.48608892405366383\n",
      "Epoch 3538, reconstruction losses: 0.03605804308229788, regression losses: 0.13864800901254778, validation losses: 0.42684880446921986\n",
      "Epoch 3539, reconstruction losses: 0.04435980846762752, regression losses: 0.1224577379408261, validation losses: 0.47136836047663666\n",
      "Epoch 3540, reconstruction losses: 0.03769588743456387, regression losses: 0.16198950326895684, validation losses: 0.4872525572977844\n",
      "Epoch 3541, reconstruction losses: 0.04069676724021054, regression losses: 0.11649713371419469, validation losses: 0.4779126721014204\n",
      "Epoch 3542, reconstruction losses: 0.04318320680975543, regression losses: 0.10874701557773236, validation losses: 0.4094509566475957\n",
      "Epoch 3543, reconstruction losses: 0.037011634395257884, regression losses: 0.13991544930551933, validation losses: 0.41751565180175954\n",
      "Epoch 3544, reconstruction losses: 0.034896737063290294, regression losses: 0.14989265802546975, validation losses: 0.4427663754192539\n",
      "Epoch 3545, reconstruction losses: 0.03555342071498871, regression losses: 0.09800535883255221, validation losses: 0.38981217328178613\n",
      "Epoch 3546, reconstruction losses: 0.035280460518976944, regression losses: 0.11885639904443751, validation losses: 0.4102182566898001\n",
      "Epoch 3547, reconstruction losses: 0.037965935771053075, regression losses: 0.14540397427373225, validation losses: 0.4891264889995379\n",
      "Epoch 3548, reconstruction losses: 0.03817821380746979, regression losses: 0.15511722161005914, validation losses: 0.4137466750975374\n",
      "Epoch 3549, reconstruction losses: 0.03354541376050077, regression losses: 0.11118872009961211, validation losses: 0.46829816460703216\n",
      "Epoch 3550, reconstruction losses: 0.03505626545540019, regression losses: 0.10606802654692354, validation losses: 0.5185099485758512\n",
      "Epoch 3551, reconstruction losses: 0.036231557535044395, regression losses: 0.10115432254155102, validation losses: 0.5447166732829872\n",
      "Epoch 3552, reconstruction losses: 0.03512337089810373, regression losses: 0.08505650141215512, validation losses: 0.39973991429070665\n",
      "Epoch 3553, reconstruction losses: 0.04224187051159721, regression losses: 0.10179089180017513, validation losses: 0.41718712659591456\n",
      "Epoch 3554, reconstruction losses: 0.03767648026053792, regression losses: 0.10291055161401681, validation losses: 0.4652840432928483\n",
      "Epoch 3555, reconstruction losses: 0.03357008302911216, regression losses: 0.10913234864754635, validation losses: 0.43429024690415696\n",
      "Epoch 3556, reconstruction losses: 0.03533808632099906, regression losses: 0.10269980024436674, validation losses: 0.46604292367317723\n",
      "Epoch 3557, reconstruction losses: 0.04446597163798187, regression losses: 0.12017684761014526, validation losses: 0.4039064290909709\n",
      "Epoch 3558, reconstruction losses: 0.033006733718685385, regression losses: 0.11595919930532264, validation losses: 0.4040412927145503\n",
      "Epoch 3559, reconstruction losses: 0.035656600147090184, regression losses: 0.14687836544226457, validation losses: 0.42088801423156486\n",
      "Epoch 3560, reconstruction losses: 0.036403943365099646, regression losses: 0.12143636024506732, validation losses: 0.68879744582868\n",
      "Epoch 3561, reconstruction losses: 0.03671133496663415, regression losses: 0.300932421651315, validation losses: 0.5427407895140502\n",
      "Epoch 3562, reconstruction losses: 0.0444388656005741, regression losses: 0.14873282187263762, validation losses: 0.7041667354547387\n",
      "Epoch 3563, reconstruction losses: 0.03742719730979777, regression losses: 0.1559608499154407, validation losses: 0.42829731807340843\n",
      "Epoch 3564, reconstruction losses: 0.0368914420621893, regression losses: 0.1280714556447239, validation losses: 0.4843602655787945\n",
      "Epoch 3565, reconstruction losses: 0.03754877732603104, regression losses: 0.1611042533157821, validation losses: 0.6976730477942195\n",
      "Epoch 3566, reconstruction losses: 0.04372456519514215, regression losses: 0.13946733340723924, validation losses: 0.4954451360573947\n",
      "Epoch 3567, reconstruction losses: 0.0359762312917013, regression losses: 0.1491796019961317, validation losses: 0.42403475826742243\n",
      "Epoch 3568, reconstruction losses: 0.03584466374031369, regression losses: 0.14682095159261005, validation losses: 0.6290752412320441\n",
      "Epoch 3569, reconstruction losses: 0.03526601867474864, regression losses: 0.14316824818040144, validation losses: 0.612324315462931\n",
      "Epoch 3570, reconstruction losses: 0.036003188711076634, regression losses: 0.19110332775072925, validation losses: 0.48190952107037477\n",
      "Epoch 3571, reconstruction losses: 0.03391297410781023, regression losses: 0.1312439027208207, validation losses: 0.6171699517411879\n",
      "Epoch 3572, reconstruction losses: 0.037538827096496044, regression losses: 0.14732641087736342, validation losses: 0.5571172565354968\n",
      "Epoch 3573, reconstruction losses: 0.035182490393758606, regression losses: 0.12779664190316026, validation losses: 0.5943959924604675\n",
      "Epoch 3574, reconstruction losses: 0.03460351118369815, regression losses: 0.1513389488756185, validation losses: 0.4594060619028041\n",
      "Epoch 3575, reconstruction losses: 0.03895375642631889, regression losses: 0.20647573419329424, validation losses: 0.4851894956189167\n",
      "Epoch 3576, reconstruction losses: 0.0408023212773092, regression losses: 0.12459694142785091, validation losses: 0.43177885987297515\n",
      "Epoch 3577, reconstruction losses: 0.03662654476902219, regression losses: 0.12617131639697865, validation losses: 0.42027013582888545\n",
      "Epoch 3578, reconstruction losses: 0.03858371836080928, regression losses: 0.11066305900638701, validation losses: 0.5127510089496299\n",
      "Epoch 3579, reconstruction losses: 0.034981861916519905, regression losses: 0.11188898990796987, validation losses: 0.56537224283823\n",
      "Epoch 3580, reconstruction losses: 0.03901003158587651, regression losses: 0.2208647737673669, validation losses: 0.5514068143066304\n",
      "Epoch 3581, reconstruction losses: 0.03816579114745589, regression losses: 0.1701720763699266, validation losses: 0.5933259296691511\n",
      "Epoch 3582, reconstruction losses: 0.03621741446993261, regression losses: 0.13633339292851285, validation losses: 0.4959797746080562\n",
      "Epoch 3583, reconstruction losses: 0.03612197363291185, regression losses: 0.14237224604758017, validation losses: 0.48595193486407895\n",
      "Epoch 3584, reconstruction losses: 0.03405354274387948, regression losses: 0.11947173188013512, validation losses: 0.3813453754241824\n",
      "Epoch 3585, reconstruction losses: 0.03505120867056922, regression losses: 0.10327386984498355, validation losses: 0.48513097339009587\n",
      "Epoch 3586, reconstruction losses: 0.03369084029867736, regression losses: 0.14714143405656058, validation losses: 0.6697704566639486\n",
      "Epoch 3587, reconstruction losses: 0.03574658674795035, regression losses: 0.1379538555082117, validation losses: 0.43693522888433695\n",
      "Epoch 3588, reconstruction losses: 0.0395596357391681, regression losses: 0.14624491981597365, validation losses: 0.38114311733337825\n",
      "Epoch 3589, reconstruction losses: 0.03764704550039531, regression losses: 0.12298037976997855, validation losses: 0.40655258361887114\n",
      "Epoch 3590, reconstruction losses: 0.044801271199647226, regression losses: 0.20171427895644556, validation losses: 0.42721304616970657\n",
      "Epoch 3591, reconstruction losses: 0.03485790437978296, regression losses: 0.13950242964839277, validation losses: 0.4287294531897021\n",
      "Epoch 3592, reconstruction losses: 0.03558777243230249, regression losses: 0.13627117117296725, validation losses: 0.5573707141606814\n",
      "Epoch 3593, reconstruction losses: 0.03632470695473785, regression losses: 0.13638671403152977, validation losses: 0.8467542462905329\n",
      "Epoch 3594, reconstruction losses: 0.03944650069151691, regression losses: 0.13515073191400756, validation losses: 0.5426630337547932\n",
      "Epoch 3595, reconstruction losses: 0.033890043724011845, regression losses: 0.10792945908314386, validation losses: 0.41962714544661867\n",
      "Epoch 3596, reconstruction losses: 0.035586205015114995, regression losses: 0.14658517941082236, validation losses: 0.5251926640259087\n",
      "Epoch 3597, reconstruction losses: 0.03777680157920457, regression losses: 0.12858395911349624, validation losses: 0.6475536913199205\n",
      "Epoch 3598, reconstruction losses: 0.03502671589889491, regression losses: 0.18720339183894977, validation losses: 0.5518459796612415\n",
      "Epoch 3599, reconstruction losses: 0.03418656128510382, regression losses: 0.1292154564388991, validation losses: 0.4487846996263886\n",
      "Epoch 3600, reconstruction losses: 0.03407656072870377, regression losses: 0.12830641464669704, validation losses: 0.4489043766567061\n",
      "Epoch 3601, reconstruction losses: 0.03528191453360667, regression losses: 0.11120850023845287, validation losses: 0.4769092458225205\n",
      "Epoch 3602, reconstruction losses: 0.03530754737219728, regression losses: 0.11621088776870508, validation losses: 0.5023212571166792\n",
      "Epoch 3603, reconstruction losses: 0.03400927469162183, regression losses: 0.1507668830673422, validation losses: 0.4390917061816506\n",
      "Epoch 3604, reconstruction losses: 0.034192870273763894, regression losses: 0.1563393659411846, validation losses: 0.4165057767003881\n",
      "Epoch 3605, reconstruction losses: 0.03662976019309068, regression losses: 0.1160775547472431, validation losses: 0.45317339822348385\n",
      "Epoch 3606, reconstruction losses: 0.0347459733683928, regression losses: 0.124735833022108, validation losses: 0.4122618517442929\n",
      "Epoch 3607, reconstruction losses: 0.03841804591597321, regression losses: 0.21892783042184388, validation losses: 0.3934313770638667\n",
      "Epoch 3608, reconstruction losses: 0.041774311834334485, regression losses: 0.12728517518842514, validation losses: 0.38141731934768697\n",
      "Epoch 3609, reconstruction losses: 0.03630216385135283, regression losses: 0.14831900738306064, validation losses: 0.4008646735471324\n",
      "Epoch 3610, reconstruction losses: 0.03629151309033993, regression losses: 0.1699095417493442, validation losses: 0.45881490221121\n",
      "Epoch 3611, reconstruction losses: 0.04105841552938313, regression losses: 0.14418023945464972, validation losses: 0.5178604574575745\n",
      "Epoch 3612, reconstruction losses: 0.03921906719249134, regression losses: 0.13684857675829296, validation losses: 0.4125258234589356\n",
      "Epoch 3613, reconstruction losses: 0.034287535952787995, regression losses: 0.10884094971459526, validation losses: 0.5132151986822638\n",
      "Epoch 3614, reconstruction losses: 0.03751346605098081, regression losses: 0.10746904910934228, validation losses: 0.547585451915874\n",
      "Epoch 3615, reconstruction losses: 0.04101266747546881, regression losses: 0.11470727448405604, validation losses: 0.5491584459975937\n",
      "Epoch 3616, reconstruction losses: 0.03423728979000852, regression losses: 0.09443279085178956, validation losses: 0.4332078363670557\n",
      "Epoch 3617, reconstruction losses: 0.035148910825113115, regression losses: 0.12106781072317464, validation losses: 0.41116542601728373\n",
      "Epoch 3618, reconstruction losses: 0.03671345390199829, regression losses: 0.17232803680413084, validation losses: 0.466100345124454\n",
      "Epoch 3619, reconstruction losses: 0.03659565334450273, regression losses: 0.24051257846256358, validation losses: 0.5339596948713216\n",
      "Epoch 3620, reconstruction losses: 0.032999013073975354, regression losses: 0.11044109698390994, validation losses: 0.4921368275314082\n",
      "Epoch 3621, reconstruction losses: 0.03698530934082633, regression losses: 0.24672730493404665, validation losses: 0.479426195125359\n",
      "Epoch 3622, reconstruction losses: 0.03726445100658034, regression losses: 0.13397178982996708, validation losses: 0.5996123753057807\n",
      "Epoch 3623, reconstruction losses: 0.039646578763528624, regression losses: 0.10713753976077876, validation losses: 0.43799090664401213\n",
      "Epoch 3624, reconstruction losses: 0.04114495411176569, regression losses: 0.1603398094212211, validation losses: 0.476649415614096\n",
      "Epoch 3625, reconstruction losses: 0.03792544592148618, regression losses: 0.11146364876923387, validation losses: 0.6768206644822712\n",
      "Epoch 3626, reconstruction losses: 0.038265035430409704, regression losses: 0.16766192246602785, validation losses: 0.5437847482887136\n",
      "Epoch 3627, reconstruction losses: 0.040754266119822816, regression losses: 0.24453447879520274, validation losses: 0.45140984180751764\n",
      "Epoch 3628, reconstruction losses: 0.03406279247757787, regression losses: 0.15730316372674613, validation losses: 0.6348286733049063\n",
      "Epoch 3629, reconstruction losses: 0.03670164833809616, regression losses: 0.1670931736999898, validation losses: 0.7545897238196893\n",
      "Epoch 3630, reconstruction losses: 0.0370419473535553, regression losses: 0.13741066546197087, validation losses: 0.5386847870142577\n",
      "Epoch 3631, reconstruction losses: 0.03670838273219268, regression losses: 0.11970196191950137, validation losses: 0.3991348761742705\n",
      "Epoch 3632, reconstruction losses: 0.04302727174279634, regression losses: 0.14512914117203432, validation losses: 0.4161498765888834\n",
      "Epoch 3633, reconstruction losses: 0.03630311430900624, regression losses: 0.15856911591846634, validation losses: 0.6093634299653398\n",
      "Epoch 3634, reconstruction losses: 0.039330901802810014, regression losses: 0.30565425056332474, validation losses: 0.5765868103454124\n",
      "Epoch 3635, reconstruction losses: 0.03769702598151035, regression losses: 0.12135392920159, validation losses: 0.7221445700591451\n",
      "Epoch 3636, reconstruction losses: 0.035668066269237846, regression losses: 0.16114230762439147, validation losses: 0.729313457415447\n",
      "Epoch 3637, reconstruction losses: 0.04008344006635088, regression losses: 0.16163003706075216, validation losses: 0.44022220495216435\n",
      "Epoch 3638, reconstruction losses: 0.033316670710266595, regression losses: 0.10329979108921951, validation losses: 0.4863395708563611\n",
      "Epoch 3639, reconstruction losses: 0.03249896445682512, regression losses: 0.11664752797749266, validation losses: 0.4724368082863706\n",
      "Epoch 3640, reconstruction losses: 0.03810409430814146, regression losses: 0.12177095180034651, validation losses: 0.4748712566042192\n",
      "Epoch 3641, reconstruction losses: 0.03794371199633491, regression losses: 0.12580523971030194, validation losses: 0.6259679624966537\n",
      "Epoch 3642, reconstruction losses: 0.0346721848137061, regression losses: 0.1287479857986256, validation losses: 0.5029065391089176\n",
      "Epoch 3643, reconstruction losses: 0.040356176264731, regression losses: 0.28357601313303193, validation losses: 0.41022297509087663\n",
      "Epoch 3644, reconstruction losses: 0.03723710844917666, regression losses: 0.12338803297382378, validation losses: 0.47254340997789335\n",
      "Epoch 3645, reconstruction losses: 0.0358199191592342, regression losses: 0.13774808687265552, validation losses: 0.4804858518423698\n",
      "Epoch 3646, reconstruction losses: 0.036059829367069265, regression losses: 0.11238289724341798, validation losses: 0.5497839467430831\n",
      "Epoch 3647, reconstruction losses: 0.04283168580687162, regression losses: 0.2710241288003846, validation losses: 0.4842033080201441\n",
      "Epoch 3648, reconstruction losses: 0.03306454023028816, regression losses: 0.13188003048408473, validation losses: 0.5058286581212866\n",
      "Epoch 3649, reconstruction losses: 0.042870259693441895, regression losses: 0.1545551636706453, validation losses: 0.39403607339344643\n",
      "Epoch 3650, reconstruction losses: 0.03673744282009267, regression losses: 0.12527990317048018, validation losses: 0.6774351978003905\n",
      "Epoch 3651, reconstruction losses: 0.03470365210555044, regression losses: 0.1742805606962034, validation losses: 0.6911753299422481\n",
      "Epoch 3652, reconstruction losses: 0.035896968860014124, regression losses: 0.1353953012334509, validation losses: 0.6575200476487373\n",
      "Epoch 3653, reconstruction losses: 0.03553441578684551, regression losses: 0.1338983653197873, validation losses: 0.4310513607844637\n",
      "Epoch 3654, reconstruction losses: 0.034991614667321654, regression losses: 0.10344735749666248, validation losses: 0.48096299003602516\n",
      "Epoch 3655, reconstruction losses: 0.035529929559047047, regression losses: 0.11158871596203773, validation losses: 0.4648611034816144\n",
      "Epoch 3656, reconstruction losses: 0.0345069406554909, regression losses: 0.12494397196702606, validation losses: 0.47445599303461317\n",
      "Epoch 3657, reconstruction losses: 0.03375527483011774, regression losses: 0.1412155080037908, validation losses: 0.5350085605982907\n",
      "Epoch 3658, reconstruction losses: 0.03924466047528085, regression losses: 0.09776750049559711, validation losses: 0.5366712097395635\n",
      "Epoch 3659, reconstruction losses: 0.03563611179213721, regression losses: 0.10663174786733111, validation losses: 0.4140782125550209\n",
      "Epoch 3660, reconstruction losses: 0.034025046528932006, regression losses: 0.13352330156074865, validation losses: 0.3864331277219087\n",
      "Epoch 3661, reconstruction losses: 0.03504237981920799, regression losses: 0.11963572928508777, validation losses: 0.39278215191678084\n",
      "Epoch 3662, reconstruction losses: 0.03680923950763548, regression losses: 0.14323079820111811, validation losses: 0.41822984479341496\n",
      "Epoch 3663, reconstruction losses: 0.04230189964803819, regression losses: 0.1254041087603249, validation losses: 0.5105850728690071\n",
      "Epoch 3664, reconstruction losses: 0.037152386797919844, regression losses: 0.11317886727775517, validation losses: 0.5383931380899477\n",
      "Epoch 3665, reconstruction losses: 0.03622925386680982, regression losses: 0.1284215506377838, validation losses: 0.5301480192928057\n",
      "Epoch 3666, reconstruction losses: 0.03364510974078274, regression losses: 0.11182320198382106, validation losses: 0.47542868619400164\n",
      "Epoch 3667, reconstruction losses: 0.03904214163255971, regression losses: 0.1328787353483303, validation losses: 0.4325903072250977\n",
      "Epoch 3668, reconstruction losses: 0.03492624647491502, regression losses: 0.11117489924737675, validation losses: 0.5054467788883303\n",
      "Epoch 3669, reconstruction losses: 0.03525544271839395, regression losses: 0.10972804083790054, validation losses: 0.518856077081056\n",
      "Epoch 3670, reconstruction losses: 0.03911824731648385, regression losses: 0.10973784059573576, validation losses: 0.4617919397731446\n",
      "Epoch 3671, reconstruction losses: 0.032924454162490645, regression losses: 0.12181516412308548, validation losses: 0.4340463286028904\n",
      "Epoch 3672, reconstruction losses: 0.03628898565611212, regression losses: 0.10903923567796431, validation losses: 0.5168696645438452\n",
      "Epoch 3673, reconstruction losses: 0.03385061788516517, regression losses: 0.12359549774958505, validation losses: 0.4874582937323581\n",
      "Epoch 3674, reconstruction losses: 0.03582252650135174, regression losses: 0.13027642536289347, validation losses: 0.4740304704931841\n",
      "Epoch 3675, reconstruction losses: 0.034376693064746666, regression losses: 0.21233123686564603, validation losses: 0.49209663510309876\n",
      "Epoch 3676, reconstruction losses: 0.03447234622575884, regression losses: 0.09993661449922793, validation losses: 0.6236590419219911\n",
      "Epoch 3677, reconstruction losses: 0.035520240366760075, regression losses: 0.14968315805405336, validation losses: 0.48218170252378656\n",
      "Epoch 3678, reconstruction losses: 0.03608280516748143, regression losses: 0.1499583896853825, validation losses: 0.6451939543429893\n",
      "Epoch 3679, reconstruction losses: 0.04180569474640895, regression losses: 0.18843313516549137, validation losses: 0.7261047874289496\n",
      "Epoch 3680, reconstruction losses: 0.03551722224880396, regression losses: 0.1523384026705886, validation losses: 0.539362327911891\n",
      "Epoch 3681, reconstruction losses: 0.03534987992918988, regression losses: 0.13598055117313504, validation losses: 0.48466472552938367\n",
      "Epoch 3682, reconstruction losses: 0.04032859136662415, regression losses: 0.1365898623756878, validation losses: 0.6995170185533154\n",
      "Epoch 3683, reconstruction losses: 0.033331351777912945, regression losses: 0.13455781202022243, validation losses: 0.7102630620427095\n",
      "Epoch 3684, reconstruction losses: 0.03280552297229903, regression losses: 0.11788013832618338, validation losses: 0.47736009316005545\n",
      "Epoch 3685, reconstruction losses: 0.038223139722191136, regression losses: 0.2356937647817176, validation losses: 0.43579985186494263\n",
      "Epoch 3686, reconstruction losses: 0.03992193040907682, regression losses: 0.10975717459139545, validation losses: 0.5167254579772519\n",
      "Epoch 3687, reconstruction losses: 0.03600749607768229, regression losses: 0.16221826264069647, validation losses: 0.40270708250804227\n",
      "Epoch 3688, reconstruction losses: 0.03376567973713791, regression losses: 0.11485557148998264, validation losses: 0.5346725729173514\n",
      "Epoch 3689, reconstruction losses: 0.03759083560413616, regression losses: 0.13742641536846995, validation losses: 0.5745868805727221\n",
      "Epoch 3690, reconstruction losses: 0.043992793502768406, regression losses: 0.14604463340171725, validation losses: 0.5492801115826045\n",
      "Epoch 3691, reconstruction losses: 0.03256745596918069, regression losses: 0.1329792154350127, validation losses: 0.594510435407681\n",
      "Epoch 3692, reconstruction losses: 0.03582680950332493, regression losses: 0.10690407898321633, validation losses: 0.42065990503652195\n",
      "Epoch 3693, reconstruction losses: 0.03491883225149226, regression losses: 0.15817878305316735, validation losses: 0.5073232192895271\n",
      "Epoch 3694, reconstruction losses: 0.04074206661890636, regression losses: 0.1273445380138074, validation losses: 0.6839499684248745\n",
      "Epoch 3695, reconstruction losses: 0.034155640545547455, regression losses: 0.14162976481746595, validation losses: 0.5557375402237369\n",
      "Epoch 3696, reconstruction losses: 0.04082224999108712, regression losses: 0.1267052549048764, validation losses: 0.40830589197997685\n",
      "Epoch 3697, reconstruction losses: 0.03834140038750765, regression losses: 0.1370991117303168, validation losses: 0.4483274156002004\n",
      "Epoch 3698, reconstruction losses: 0.0356381655463577, regression losses: 0.15027360611023458, validation losses: 0.4561500658999986\n",
      "Epoch 3699, reconstruction losses: 0.036096229021006045, regression losses: 0.11353121349815709, validation losses: 0.44257037933666465\n",
      "Epoch 3700, reconstruction losses: 0.034244820380648966, regression losses: 0.11187808909089342, validation losses: 0.5017742913332697\n",
      "Epoch 3701, reconstruction losses: 0.03990288423167536, regression losses: 0.13025356704117197, validation losses: 0.5364783589301289\n",
      "Epoch 3702, reconstruction losses: 0.03499113689332851, regression losses: 0.12292828092609552, validation losses: 0.4009464652844744\n",
      "Epoch 3703, reconstruction losses: 0.04385850476929897, regression losses: 0.08582425823196155, validation losses: 0.39457920803968954\n",
      "Epoch 3704, reconstruction losses: 0.04350324900520143, regression losses: 0.13513703585621017, validation losses: 0.4134686853533074\n",
      "Epoch 3705, reconstruction losses: 0.03826576567567653, regression losses: 0.12470678584819272, validation losses: 0.3912489888968096\n",
      "Epoch 3706, reconstruction losses: 0.03639819277007434, regression losses: 0.14728142871746094, validation losses: 0.3866099671206413\n",
      "Epoch 3707, reconstruction losses: 0.03786400601545459, regression losses: 0.20294532503174995, validation losses: 0.4476420619230328\n",
      "Epoch 3708, reconstruction losses: 0.033599644603127046, regression losses: 0.12646676200479132, validation losses: 0.5343261947448386\n",
      "Epoch 3709, reconstruction losses: 0.03646863549710536, regression losses: 0.14093582511405303, validation losses: 0.4350850511468853\n",
      "Epoch 3710, reconstruction losses: 0.03764827510437915, regression losses: 0.10832583732337359, validation losses: 0.5189595182649535\n",
      "Epoch 3711, reconstruction losses: 0.0361634332388564, regression losses: 0.1506800508776841, validation losses: 0.49237827809918294\n",
      "Epoch 3712, reconstruction losses: 0.03498123751481234, regression losses: 0.14046578499157475, validation losses: 0.636371051940861\n",
      "Epoch 3713, reconstruction losses: 0.034083874386675574, regression losses: 0.13449955029807664, validation losses: 0.5640321664988043\n",
      "Epoch 3714, reconstruction losses: 0.03900793706887744, regression losses: 0.28744141284401736, validation losses: 0.4851189314152962\n",
      "Epoch 3715, reconstruction losses: 0.03930317477987968, regression losses: 0.12236304180214164, validation losses: 0.7940015831972813\n",
      "Epoch 3716, reconstruction losses: 0.034838143716237197, regression losses: 0.14862336309694515, validation losses: 0.6916831909465021\n",
      "Epoch 3717, reconstruction losses: 0.03891329435932986, regression losses: 0.14247987706835713, validation losses: 0.6609001927246603\n",
      "Epoch 3718, reconstruction losses: 0.03926267507632292, regression losses: 0.1717970636043209, validation losses: 0.4615181511489365\n",
      "Epoch 3719, reconstruction losses: 0.0357724988075956, regression losses: 0.10109586745740635, validation losses: 0.4172245464062785\n",
      "Epoch 3720, reconstruction losses: 0.03443206627251748, regression losses: 0.12573358721677325, validation losses: 0.5129475124100589\n",
      "Epoch 3721, reconstruction losses: 0.035916727903267304, regression losses: 0.14443587993538948, validation losses: 0.5496830898926418\n",
      "Epoch 3722, reconstruction losses: 0.033866706307045295, regression losses: 0.11795792321722912, validation losses: 0.4252173280307432\n",
      "Epoch 3723, reconstruction losses: 0.03994249567066301, regression losses: 0.12163950923641875, validation losses: 0.4200864703901686\n",
      "Epoch 3724, reconstruction losses: 0.042488736269382765, regression losses: 0.08827911882512104, validation losses: 0.4736475532667736\n",
      "Epoch 3725, reconstruction losses: 0.03567296465804957, regression losses: 0.13253330277475772, validation losses: 0.44242379254488734\n",
      "Epoch 3726, reconstruction losses: 0.03557212681430395, regression losses: 0.13573207869730033, validation losses: 0.5242325229655811\n",
      "Epoch 3727, reconstruction losses: 0.03424916688999891, regression losses: 0.16804506129369057, validation losses: 0.44837389871456934\n",
      "Epoch 3728, reconstruction losses: 0.03316296407246125, regression losses: 0.12043713898424319, validation losses: 0.38723433865496193\n",
      "Epoch 3729, reconstruction losses: 0.037414284458325134, regression losses: 0.08688607029230043, validation losses: 0.37878683771510807\n",
      "Epoch 3730, reconstruction losses: 0.036165318566992635, regression losses: 0.14597138023474787, validation losses: 0.4454616303383396\n",
      "Epoch 3731, reconstruction losses: 0.031974149578885246, regression losses: 0.12525958247994595, validation losses: 0.5569628309744374\n",
      "Epoch 3732, reconstruction losses: 0.039142696060235176, regression losses: 0.1268406561643697, validation losses: 0.4503849964681221\n",
      "Epoch 3733, reconstruction losses: 0.038299568050615955, regression losses: 0.11648516200478576, validation losses: 0.3918586677033973\n",
      "Epoch 3734, reconstruction losses: 0.040036744553596265, regression losses: 0.17405853778436714, validation losses: 0.3864091245128281\n",
      "Epoch 3735, reconstruction losses: 0.04153139211595333, regression losses: 0.10712146181216552, validation losses: 0.38445827893478823\n",
      "Epoch 3736, reconstruction losses: 0.035053968433481804, regression losses: 0.128468760424099, validation losses: 0.3927832600067456\n",
      "Epoch 3737, reconstruction losses: 0.035177478359292386, regression losses: 0.136667159149211, validation losses: 0.49363348613100855\n",
      "Epoch 3738, reconstruction losses: 0.035542625583956836, regression losses: 0.11529628735370456, validation losses: 0.4204998057133741\n",
      "Epoch 3739, reconstruction losses: 0.036266723219054685, regression losses: 0.12394756378564448, validation losses: 0.4587960673247185\n",
      "Epoch 3740, reconstruction losses: 0.03766865983130989, regression losses: 0.1551859883748588, validation losses: 0.5156664225793522\n",
      "Epoch 3741, reconstruction losses: 0.033939260012988824, regression losses: 0.08975196798978444, validation losses: 0.4426661608689672\n",
      "Epoch 3742, reconstruction losses: 0.03381204145932438, regression losses: 0.12621211737131444, validation losses: 0.3833772719945738\n",
      "Epoch 3743, reconstruction losses: 0.039536650181302986, regression losses: 0.14516610890150683, validation losses: 0.3829498642039795\n",
      "Epoch 3744, reconstruction losses: 0.03408173557536072, regression losses: 0.10202119308582847, validation losses: 0.4889094842586208\n",
      "Epoch 3745, reconstruction losses: 0.03656128326079053, regression losses: 0.1854435907394327, validation losses: 0.41794971981509976\n",
      "Epoch 3746, reconstruction losses: 0.03393067410860209, regression losses: 0.14700019861620311, validation losses: 0.42847637405634426\n",
      "Epoch 3747, reconstruction losses: 0.03217225987599047, regression losses: 0.10134412804186343, validation losses: 0.49545965587561325\n",
      "Epoch 3748, reconstruction losses: 0.036235174055588085, regression losses: 0.20038795299310894, validation losses: 0.4340989865945253\n",
      "Epoch 3749, reconstruction losses: 0.03209896621178455, regression losses: 0.14479435247385622, validation losses: 0.4341947494399538\n",
      "Epoch 3750, reconstruction losses: 0.033460192083535116, regression losses: 0.15019700850118153, validation losses: 0.5678476706359349\n",
      "Epoch 3751, reconstruction losses: 0.03207520150337108, regression losses: 0.11978439990847964, validation losses: 0.44255628320033086\n",
      "Epoch 3752, reconstruction losses: 0.0356961864984716, regression losses: 0.1640970146646159, validation losses: 0.39047124614977624\n",
      "Epoch 3753, reconstruction losses: 0.03554748642288483, regression losses: 0.09361068852868618, validation losses: 0.4177669973218508\n",
      "Epoch 3754, reconstruction losses: 0.033708580770128595, regression losses: 0.10876457981343103, validation losses: 0.4114389189562151\n",
      "Epoch 3755, reconstruction losses: 0.038235389549370113, regression losses: 0.1689725072454839, validation losses: 0.4311659830938829\n",
      "Epoch 3756, reconstruction losses: 0.03477027057246496, regression losses: 0.11606340856790306, validation losses: 0.643110045572727\n",
      "Epoch 3757, reconstruction losses: 0.03573778874228997, regression losses: 0.12389515966423822, validation losses: 0.5332638415382681\n",
      "Epoch 3758, reconstruction losses: 0.03553113610623437, regression losses: 0.12065416532984605, validation losses: 0.4102160611866361\n",
      "Epoch 3759, reconstruction losses: 0.03644124629779449, regression losses: 0.10458679422590912, validation losses: 0.38313560941441405\n",
      "Epoch 3760, reconstruction losses: 0.03598795535702544, regression losses: 0.1104646863907573, validation losses: 0.37139878090752654\n",
      "Epoch 3761, reconstruction losses: 0.03633878135079979, regression losses: 0.13682203356110004, validation losses: 0.42722324908390896\n",
      "Epoch 3762, reconstruction losses: 0.04227453908027874, regression losses: 0.1981991279319032, validation losses: 0.4194223983260304\n",
      "Epoch 3763, reconstruction losses: 0.03510638334202129, regression losses: 0.11262046555806424, validation losses: 0.5470663762672919\n",
      "Epoch 3764, reconstruction losses: 0.033120012017505446, regression losses: 0.12286739637177121, validation losses: 0.45619213214419485\n",
      "Epoch 3765, reconstruction losses: 0.03413681476646933, regression losses: 0.13147094846616847, validation losses: 0.5507702418374766\n",
      "Epoch 3766, reconstruction losses: 0.03582132135165915, regression losses: 0.13323108864716185, validation losses: 0.4783860891525046\n",
      "Epoch 3767, reconstruction losses: 0.03422334954670528, regression losses: 0.08772507576605679, validation losses: 0.43215864554543015\n",
      "Epoch 3768, reconstruction losses: 0.040785278519910685, regression losses: 0.115601357425724, validation losses: 0.4061217827065863\n",
      "Epoch 3769, reconstruction losses: 0.034914382162109917, regression losses: 0.13818654418514087, validation losses: 0.3930223899008952\n",
      "Epoch 3770, reconstruction losses: 0.03195379381978986, regression losses: 0.13960029498353071, validation losses: 0.4409896737282143\n",
      "Epoch 3771, reconstruction losses: 0.034966660807824526, regression losses: 0.08115245263519998, validation losses: 0.41247636906017326\n",
      "Epoch 3772, reconstruction losses: 0.04254329565214945, regression losses: 0.11134454839292679, validation losses: 0.4313720934524638\n",
      "Epoch 3773, reconstruction losses: 0.0345502257539305, regression losses: 0.09626602216069903, validation losses: 0.4502805758673465\n",
      "Epoch 3774, reconstruction losses: 0.044264707923324736, regression losses: 0.1594606645912579, validation losses: 0.43488492828333153\n",
      "Epoch 3775, reconstruction losses: 0.036981025284958446, regression losses: 0.14122578666474786, validation losses: 0.5602618902197615\n",
      "Epoch 3776, reconstruction losses: 0.035786712414548, regression losses: 0.13953946288193125, validation losses: 0.472794303470597\n",
      "Epoch 3777, reconstruction losses: 0.03461757784443321, regression losses: 0.0994149545649903, validation losses: 0.5024820587698128\n",
      "Epoch 3778, reconstruction losses: 0.035439924708677566, regression losses: 0.15807139641737755, validation losses: 0.4110784609679823\n",
      "Epoch 3779, reconstruction losses: 0.043911333291942495, regression losses: 0.16725309701553293, validation losses: 0.47265573935169897\n",
      "Epoch 3780, reconstruction losses: 0.03261974011256732, regression losses: 0.12644698200879695, validation losses: 0.5141213722919693\n",
      "Epoch 3781, reconstruction losses: 0.03558435968554384, regression losses: 0.14561102131887493, validation losses: 0.4410323661517882\n",
      "Epoch 3782, reconstruction losses: 0.03597599719826254, regression losses: 0.12224113125998257, validation losses: 0.47203016966414\n",
      "Epoch 3783, reconstruction losses: 0.0374072588590436, regression losses: 0.1048516000499864, validation losses: 0.5831630503008034\n",
      "Epoch 3784, reconstruction losses: 0.03442015933141862, regression losses: 0.1208349293931232, validation losses: 0.5072537678432874\n",
      "Epoch 3785, reconstruction losses: 0.03473776694785439, regression losses: 0.10235967892732645, validation losses: 0.4136452590289332\n",
      "Epoch 3786, reconstruction losses: 0.04122428580568752, regression losses: 0.11534982933827398, validation losses: 0.4056271847723139\n",
      "Epoch 3787, reconstruction losses: 0.03453852751350142, regression losses: 0.12057669447419965, validation losses: 0.4595243454277184\n",
      "Epoch 3788, reconstruction losses: 0.039041451399248896, regression losses: 0.11069545425825056, validation losses: 0.461699850972778\n",
      "Epoch 3789, reconstruction losses: 0.03557004274016962, regression losses: 0.13056913105648593, validation losses: 0.4248679140623009\n",
      "Epoch 3790, reconstruction losses: 0.03208460060400062, regression losses: 0.0934950719546088, validation losses: 0.4223174636731\n",
      "Epoch 3791, reconstruction losses: 0.03519802875623796, regression losses: 0.1564085080809282, validation losses: 0.39672505227240223\n",
      "Epoch 3792, reconstruction losses: 0.0325453045169558, regression losses: 0.10858888168139248, validation losses: 0.5538750013140937\n",
      "Epoch 3793, reconstruction losses: 0.03423245252261154, regression losses: 0.1278797183517451, validation losses: 0.47543640765259676\n",
      "Epoch 3794, reconstruction losses: 0.03868552311343454, regression losses: 0.11777418771929872, validation losses: 0.38733277528113147\n",
      "Epoch 3795, reconstruction losses: 0.0357950016135591, regression losses: 0.1425394624511263, validation losses: 0.5186184085406936\n",
      "Epoch 3796, reconstruction losses: 0.03540086529712559, regression losses: 0.13806903062837234, validation losses: 0.46398812396453215\n",
      "Epoch 3797, reconstruction losses: 0.037794047312962806, regression losses: 0.11723293273306315, validation losses: 0.4104117360667275\n",
      "Epoch 3798, reconstruction losses: 0.0338956683537156, regression losses: 0.11200675470604657, validation losses: 0.43192433012312836\n",
      "Epoch 3799, reconstruction losses: 0.03509502630106309, regression losses: 0.14364290049198078, validation losses: 0.47998128346854585\n",
      "Epoch 3800, reconstruction losses: 0.037419196196618106, regression losses: 0.11418087494326126, validation losses: 0.530541868488849\n",
      "Epoch 3801, reconstruction losses: 0.03766044477367488, regression losses: 0.12508343068176656, validation losses: 0.45373795310805903\n",
      "Epoch 3802, reconstruction losses: 0.03749672991922056, regression losses: 0.14839685510099399, validation losses: 0.4628513502361304\n",
      "Epoch 3803, reconstruction losses: 0.0399845661433572, regression losses: 0.11714874548791201, validation losses: 0.4364027397523374\n",
      "Epoch 3804, reconstruction losses: 0.03920797750266701, regression losses: 0.13548739347753633, validation losses: 0.5184232419372413\n",
      "Epoch 3805, reconstruction losses: 0.03517123612243829, regression losses: 0.10593255101311855, validation losses: 0.5446151165781596\n",
      "Epoch 3806, reconstruction losses: 0.033710954522132505, regression losses: 0.10222347419993053, validation losses: 0.49637737913714586\n",
      "Epoch 3807, reconstruction losses: 0.03347213614726598, regression losses: 0.18027142950359082, validation losses: 0.5132624995155455\n",
      "Epoch 3808, reconstruction losses: 0.03608756396300879, regression losses: 0.1541709450357257, validation losses: 0.6417803678308899\n",
      "Epoch 3809, reconstruction losses: 0.03469986053644121, regression losses: 0.1702975725810827, validation losses: 0.5803673153957324\n",
      "Epoch 3810, reconstruction losses: 0.038800219465222004, regression losses: 0.21980259139940247, validation losses: 0.6786999272979967\n",
      "Epoch 3811, reconstruction losses: 0.039053989200478714, regression losses: 0.12359906421380752, validation losses: 0.5686923354197502\n",
      "Epoch 3812, reconstruction losses: 0.03201631026423697, regression losses: 0.11757590885329362, validation losses: 0.5172160802040671\n",
      "Epoch 3813, reconstruction losses: 0.044319334095046715, regression losses: 0.12074788837833046, validation losses: 0.42494954282145625\n",
      "Epoch 3814, reconstruction losses: 0.03407168620760873, regression losses: 0.1400360290982759, validation losses: 0.6097139525300477\n",
      "Epoch 3815, reconstruction losses: 0.03797985404525765, regression losses: 0.16486337099761125, validation losses: 0.6803282356513953\n",
      "Epoch 3816, reconstruction losses: 0.04391652372585876, regression losses: 0.15278226965721992, validation losses: 0.40792838165868317\n",
      "Epoch 3817, reconstruction losses: 0.034573390480890955, regression losses: 0.1090861718132348, validation losses: 0.3940828617909918\n",
      "Epoch 3818, reconstruction losses: 0.03453791820612191, regression losses: 0.1255992684159698, validation losses: 0.41394194992072314\n",
      "Epoch 3819, reconstruction losses: 0.03395388252260414, regression losses: 0.13222129547566164, validation losses: 0.38661474082887354\n",
      "Epoch 3820, reconstruction losses: 0.03498828873390476, regression losses: 0.13614887663960842, validation losses: 0.47710151469559364\n",
      "Epoch 3821, reconstruction losses: 0.03810503374435072, regression losses: 0.1655627494235341, validation losses: 0.5016664231556686\n",
      "Epoch 3822, reconstruction losses: 0.038618616538284814, regression losses: 0.15106039834135243, validation losses: 0.5013221931187625\n",
      "Epoch 3823, reconstruction losses: 0.03767266145181095, regression losses: 0.11509760244898797, validation losses: 0.624478556026789\n",
      "Epoch 3824, reconstruction losses: 0.03430736027666698, regression losses: 0.1072930246498202, validation losses: 0.4721954789623761\n",
      "Epoch 3825, reconstruction losses: 0.03622538967157176, regression losses: 0.10687451480356479, validation losses: 0.4031841779286287\n",
      "Epoch 3826, reconstruction losses: 0.03796940815531748, regression losses: 0.2521253941203989, validation losses: 0.4731292475493698\n",
      "Epoch 3827, reconstruction losses: 0.03313774724317367, regression losses: 0.11278413623833362, validation losses: 0.8226252067658713\n",
      "Epoch 3828, reconstruction losses: 0.03606207937172935, regression losses: 0.15065283719660502, validation losses: 0.6133668476162086\n",
      "Epoch 3829, reconstruction losses: 0.03292845903787085, regression losses: 0.11651508819397621, validation losses: 0.43140852014646996\n",
      "Epoch 3830, reconstruction losses: 0.0336297792775316, regression losses: 0.15323332685765056, validation losses: 0.4397956716593982\n",
      "Epoch 3831, reconstruction losses: 0.03560958575997475, regression losses: 0.1399279610067407, validation losses: 0.5520573900069656\n",
      "Epoch 3832, reconstruction losses: 0.03475785133850257, regression losses: 0.1685361050888638, validation losses: 0.4781228792266704\n",
      "Epoch 3833, reconstruction losses: 0.03485087811910822, regression losses: 0.11833686368671843, validation losses: 0.4426436082213393\n",
      "Epoch 3834, reconstruction losses: 0.044436575598692074, regression losses: 0.12702302001579885, validation losses: 0.40215382618198936\n",
      "Epoch 3835, reconstruction losses: 0.034217389528447814, regression losses: 0.15738509539506995, validation losses: 0.40595943725655587\n",
      "Epoch 3836, reconstruction losses: 0.033373385325310215, regression losses: 0.11295236270965672, validation losses: 0.5735929519680487\n",
      "Epoch 3837, reconstruction losses: 0.043391797866983835, regression losses: 0.1527864126833225, validation losses: 0.5485761309352903\n",
      "Epoch 3838, reconstruction losses: 0.03914962355421729, regression losses: 0.11003727750742721, validation losses: 0.7004278916514624\n",
      "Epoch 3839, reconstruction losses: 0.035765876033673545, regression losses: 0.1359833637165211, validation losses: 0.4619158734516292\n",
      "Epoch 3840, reconstruction losses: 0.03776007729019365, regression losses: 0.16150621914682167, validation losses: 0.45620035346588417\n",
      "Epoch 3841, reconstruction losses: 0.04052557087061468, regression losses: 0.16752918281508553, validation losses: 0.4281666152834568\n",
      "Epoch 3842, reconstruction losses: 0.03491750429367828, regression losses: 0.11146147378076042, validation losses: 0.46948985537916205\n",
      "Epoch 3843, reconstruction losses: 0.03508997572544213, regression losses: 0.1556834028035396, validation losses: 0.467563942224682\n",
      "Epoch 3844, reconstruction losses: 0.032794840083971384, regression losses: 0.1655015512228788, validation losses: 0.43487062932229\n",
      "Epoch 3845, reconstruction losses: 0.03555430024178339, regression losses: 0.11047750286555047, validation losses: 0.5156754217303392\n",
      "Epoch 3846, reconstruction losses: 0.03617170719216878, regression losses: 0.17381140446170237, validation losses: 0.5817973214733173\n",
      "Epoch 3847, reconstruction losses: 0.04061893356559894, regression losses: 0.13490411217501774, validation losses: 0.6013807778578452\n",
      "Epoch 3848, reconstruction losses: 0.03464122332406719, regression losses: 0.15173815779045025, validation losses: 0.46652064119882564\n",
      "Epoch 3849, reconstruction losses: 0.03205760521150689, regression losses: 0.13472811596198958, validation losses: 0.5353007600165042\n",
      "Epoch 3850, reconstruction losses: 0.0389939238609178, regression losses: 0.08527556914892033, validation losses: 0.4251939217152598\n",
      "Epoch 3851, reconstruction losses: 0.0326103032800515, regression losses: 0.13369556165136745, validation losses: 0.44736704027529967\n",
      "Epoch 3852, reconstruction losses: 0.03265365249254658, regression losses: 0.1182595146980295, validation losses: 0.47459161356484286\n",
      "Epoch 3853, reconstruction losses: 0.032251747270771194, regression losses: 0.12143669168905612, validation losses: 0.4595235894682853\n",
      "Epoch 3854, reconstruction losses: 0.03360569048395798, regression losses: 0.1905703137343751, validation losses: 0.40568635604111286\n",
      "Epoch 3855, reconstruction losses: 0.03155247938769995, regression losses: 0.14156850983507147, validation losses: 0.45327446231946056\n",
      "Epoch 3856, reconstruction losses: 0.03397607213490319, regression losses: 0.10514029965524833, validation losses: 0.43574574541473554\n",
      "Epoch 3857, reconstruction losses: 0.034954069684073566, regression losses: 0.1981054001554714, validation losses: 0.609178622376175\n",
      "Epoch 3858, reconstruction losses: 0.03725884744433791, regression losses: 0.18876739666719106, validation losses: 0.7058922201647001\n",
      "Epoch 3859, reconstruction losses: 0.03488334442066864, regression losses: 0.13424022543560252, validation losses: 0.45144212685089835\n",
      "Epoch 3860, reconstruction losses: 0.0438371428608957, regression losses: 0.12895345171192127, validation losses: 0.5777338831624079\n",
      "Epoch 3861, reconstruction losses: 0.034476320069597874, regression losses: 0.127604515615527, validation losses: 0.4681251076906634\n",
      "Epoch 3862, reconstruction losses: 0.03266909402043183, regression losses: 0.10846616267294361, validation losses: 0.47563325020259706\n",
      "Epoch 3863, reconstruction losses: 0.03978044840734026, regression losses: 0.11478116464178387, validation losses: 0.5221731363264349\n",
      "Epoch 3864, reconstruction losses: 0.035177745093754625, regression losses: 0.14367072103978112, validation losses: 0.4183199102820998\n",
      "Epoch 3865, reconstruction losses: 0.0334753509705419, regression losses: 0.08346498726811628, validation losses: 0.43836769962606625\n",
      "Epoch 3866, reconstruction losses: 0.03527319795051899, regression losses: 0.11683042653496842, validation losses: 0.4600380658797186\n",
      "Epoch 3867, reconstruction losses: 0.03800611370990658, regression losses: 0.10680137040326608, validation losses: 0.4329297128436532\n",
      "Epoch 3868, reconstruction losses: 0.033450026444867845, regression losses: 0.1172818919208686, validation losses: 0.4617384346277932\n",
      "Epoch 3869, reconstruction losses: 0.034877248417684546, regression losses: 0.11802866067804751, validation losses: 0.497990011047774\n",
      "Epoch 3870, reconstruction losses: 0.03657097853711394, regression losses: 0.13624931876745291, validation losses: 0.5342628302948781\n",
      "Epoch 3871, reconstruction losses: 0.03207836121212648, regression losses: 0.13105989528372833, validation losses: 0.4035493439137482\n",
      "Epoch 3872, reconstruction losses: 0.03527624375208929, regression losses: 0.14035842824174366, validation losses: 0.39326006456611645\n",
      "Epoch 3873, reconstruction losses: 0.034173885584965875, regression losses: 0.13397922004457666, validation losses: 0.43089962998712217\n",
      "Epoch 3874, reconstruction losses: 0.03715797457718654, regression losses: 0.3967940236249393, validation losses: 0.5503802617615502\n",
      "Epoch 3875, reconstruction losses: 0.03406432635529945, regression losses: 0.13971945191837645, validation losses: 0.723696145054818\n",
      "Epoch 3876, reconstruction losses: 0.036808064691601604, regression losses: 0.1708843086519119, validation losses: 0.5615673262928085\n",
      "Epoch 3877, reconstruction losses: 0.033962310528868375, regression losses: 0.16778230366242455, validation losses: 0.7953313057431677\n",
      "Epoch 3878, reconstruction losses: 0.0399771679156358, regression losses: 0.14656912207490816, validation losses: 0.5092130498294306\n",
      "Epoch 3879, reconstruction losses: 0.033547758777568, regression losses: 0.1362909355994744, validation losses: 0.46553076213554956\n",
      "Epoch 3880, reconstruction losses: 0.040737916690730555, regression losses: 0.11696610619655667, validation losses: 0.5568189704505903\n",
      "Epoch 3881, reconstruction losses: 0.03236882705112901, regression losses: 0.13825013710426046, validation losses: 0.4518211061004607\n",
      "Epoch 3882, reconstruction losses: 0.0325059093430829, regression losses: 0.11653932723889751, validation losses: 0.4309643197752236\n",
      "Epoch 3883, reconstruction losses: 0.035230088981661516, regression losses: 0.13207923311126152, validation losses: 0.5310523674884792\n",
      "Epoch 3884, reconstruction losses: 0.033035955673329176, regression losses: 0.12005018266911738, validation losses: 0.5148350822910956\n",
      "Epoch 3885, reconstruction losses: 0.03439929614436205, regression losses: 0.13310645995134507, validation losses: 0.4751570849807879\n",
      "Epoch 3886, reconstruction losses: 0.03342129995236782, regression losses: 0.13914325354213802, validation losses: 0.5571969851237769\n",
      "Epoch 3887, reconstruction losses: 0.03374208750074743, regression losses: 0.11877803558414299, validation losses: 0.6531048956135393\n",
      "Epoch 3888, reconstruction losses: 0.0368036875632851, regression losses: 0.13438578444954943, validation losses: 0.49448742891457287\n",
      "Epoch 3889, reconstruction losses: 0.034326150606678985, regression losses: 0.1063057350324127, validation losses: 0.43754082309254627\n",
      "Epoch 3890, reconstruction losses: 0.03575131611874802, regression losses: 0.1383142783634045, validation losses: 0.4229520858654553\n",
      "Epoch 3891, reconstruction losses: 0.03247842502754924, regression losses: 0.10363325271472637, validation losses: 0.5371060396216274\n",
      "Epoch 3892, reconstruction losses: 0.03515910213350963, regression losses: 0.12147821181244878, validation losses: 0.5569615951987043\n",
      "Epoch 3893, reconstruction losses: 0.034518394834977935, regression losses: 0.20484283610945164, validation losses: 0.6105457518941576\n",
      "Epoch 3894, reconstruction losses: 0.037002556518685926, regression losses: 0.1680850584144143, validation losses: 0.7221637455593609\n",
      "Epoch 3895, reconstruction losses: 0.03357001445982485, regression losses: 0.12978760021080588, validation losses: 0.4826495351075255\n",
      "Epoch 3896, reconstruction losses: 0.03428271601424499, regression losses: 0.13949925973930744, validation losses: 0.46473273074211885\n",
      "Epoch 3897, reconstruction losses: 0.03435531605292967, regression losses: 0.12594426719498536, validation losses: 0.44466720906320545\n",
      "Epoch 3898, reconstruction losses: 0.033516318366701506, regression losses: 0.14898524899895205, validation losses: 0.4222749479883394\n",
      "Epoch 3899, reconstruction losses: 0.034593813539328576, regression losses: 0.13202756104353341, validation losses: 0.5257642837691795\n",
      "Epoch 3900, reconstruction losses: 0.031843757659322944, regression losses: 0.12620026233910608, validation losses: 0.5201622088366677\n",
      "Epoch 3901, reconstruction losses: 0.03235668793563982, regression losses: 0.10550968104444615, validation losses: 0.5356411790495472\n",
      "Epoch 3902, reconstruction losses: 0.0324197470650186, regression losses: 0.1389627655185261, validation losses: 0.46137655989122117\n",
      "Epoch 3903, reconstruction losses: 0.03664950292050301, regression losses: 0.15167411629883898, validation losses: 0.4421048822344854\n",
      "Epoch 3904, reconstruction losses: 0.032165054612671974, regression losses: 0.10803069730409348, validation losses: 0.4993118038633128\n",
      "Epoch 3905, reconstruction losses: 0.038374185243420435, regression losses: 0.12178136014037652, validation losses: 0.4883183800891724\n",
      "Epoch 3906, reconstruction losses: 0.034140295634348485, regression losses: 0.09634602199211828, validation losses: 0.607130142677357\n",
      "Epoch 3907, reconstruction losses: 0.03434710933417545, regression losses: 0.13610602040295475, validation losses: 0.5116978979841019\n",
      "Epoch 3908, reconstruction losses: 0.03504678525566412, regression losses: 0.13325467983363934, validation losses: 0.4167642514820664\n",
      "Epoch 3909, reconstruction losses: 0.03597361419579618, regression losses: 0.14430753950504327, validation losses: 0.5274069052098468\n",
      "Epoch 3910, reconstruction losses: 0.036154629510783486, regression losses: 0.10727270140193317, validation losses: 0.6230331568636474\n",
      "Epoch 3911, reconstruction losses: 0.03649274713162159, regression losses: 0.11693232539733203, validation losses: 0.4439163171667875\n",
      "Epoch 3912, reconstruction losses: 0.03918168938537615, regression losses: 0.11575752873320162, validation losses: 0.43205864725904464\n",
      "Epoch 3913, reconstruction losses: 0.03501690475163241, regression losses: 0.1209966159057099, validation losses: 0.4391877075410201\n",
      "Epoch 3914, reconstruction losses: 0.03774640039764014, regression losses: 0.1137659183378686, validation losses: 0.551809506495204\n",
      "Epoch 3915, reconstruction losses: 0.03314766342202556, regression losses: 0.10184548583192549, validation losses: 0.5105056060381724\n",
      "Epoch 3916, reconstruction losses: 0.0341844929786215, regression losses: 0.10781310434732823, validation losses: 0.43246794282725226\n",
      "Epoch 3917, reconstruction losses: 0.03836150688638286, regression losses: 0.09953907878574428, validation losses: 0.4530749162523105\n",
      "Epoch 3918, reconstruction losses: 0.03372292716088948, regression losses: 0.11240962973598348, validation losses: 0.4837326627956666\n",
      "Epoch 3919, reconstruction losses: 0.032906523211318095, regression losses: 0.1377087809249741, validation losses: 0.46081714122523126\n",
      "Epoch 3920, reconstruction losses: 0.039230249578043275, regression losses: 0.21815840240236176, validation losses: 0.4413923451602697\n",
      "Epoch 3921, reconstruction losses: 0.03332950614014084, regression losses: 0.12970871740958195, validation losses: 0.7470058384695782\n",
      "Epoch 3922, reconstruction losses: 0.03221461881696657, regression losses: 0.11218816757889584, validation losses: 0.6207148125349997\n",
      "Epoch 3923, reconstruction losses: 0.03721105126947095, regression losses: 0.13672276474753894, validation losses: 0.4634720669906952\n",
      "Epoch 3924, reconstruction losses: 0.03985819513457798, regression losses: 0.11171396919293276, validation losses: 0.45349975973784534\n",
      "Epoch 3925, reconstruction losses: 0.039996446127575545, regression losses: 0.11550915931242153, validation losses: 0.4011980856337143\n",
      "Epoch 3926, reconstruction losses: 0.03369181820297722, regression losses: 0.1080945124927918, validation losses: 0.4082784013071602\n",
      "Epoch 3927, reconstruction losses: 0.033767703146011165, regression losses: 0.12411337868919638, validation losses: 0.41567301674386803\n",
      "Epoch 3928, reconstruction losses: 0.04036128625482318, regression losses: 0.10211577701475394, validation losses: 0.4967741119253779\n",
      "Epoch 3929, reconstruction losses: 0.035529038354404435, regression losses: 0.09387993544229387, validation losses: 0.4622555855560604\n",
      "Epoch 3930, reconstruction losses: 0.032554509617107714, regression losses: 0.11170908380362847, validation losses: 0.4522550936548284\n",
      "Epoch 3931, reconstruction losses: 0.03337929380189961, regression losses: 0.14024110037105403, validation losses: 0.42982680833359194\n",
      "Epoch 3932, reconstruction losses: 0.03656932433361723, regression losses: 0.21751008928222687, validation losses: 0.5006540119658123\n",
      "Epoch 3933, reconstruction losses: 0.036551159573869674, regression losses: 0.10022817482271158, validation losses: 0.4834745704446791\n",
      "Epoch 3934, reconstruction losses: 0.037927637414568005, regression losses: 0.13912945168490626, validation losses: 0.4286909780136659\n",
      "Epoch 3935, reconstruction losses: 0.03421392064371202, regression losses: 0.23145595756760334, validation losses: 0.49017043024313894\n",
      "Epoch 3936, reconstruction losses: 0.03314416737030797, regression losses: 0.13500588369600686, validation losses: 0.8001348471912922\n",
      "Epoch 3937, reconstruction losses: 0.034912405140141455, regression losses: 0.25755452906725096, validation losses: 0.5319848806553793\n",
      "Epoch 3938, reconstruction losses: 0.03779523893630788, regression losses: 0.1531757073640089, validation losses: 0.6614760815583143\n",
      "Epoch 3939, reconstruction losses: 0.03495484473408378, regression losses: 0.12779448837235607, validation losses: 0.5084144680977687\n",
      "Epoch 3940, reconstruction losses: 0.03510244254594734, regression losses: 0.15788586758003414, validation losses: 0.42600366496506653\n",
      "Epoch 3941, reconstruction losses: 0.033726818799697425, regression losses: 0.11830543000801448, validation losses: 0.6625505691666345\n",
      "Epoch 3942, reconstruction losses: 0.0342519738087816, regression losses: 0.17683693234110873, validation losses: 0.4933113427513801\n",
      "Epoch 3943, reconstruction losses: 0.0347361920558436, regression losses: 0.10518656596759529, validation losses: 0.48097285321620303\n",
      "Epoch 3944, reconstruction losses: 0.03516189724238643, regression losses: 0.13245541131372582, validation losses: 0.4029198360947224\n",
      "Epoch 3945, reconstruction losses: 0.0352291672916901, regression losses: 0.14755591241366006, validation losses: 0.4706288329773671\n",
      "Epoch 3946, reconstruction losses: 0.03428263046543299, regression losses: 0.14372775755392214, validation losses: 0.5553988663133417\n",
      "Epoch 3947, reconstruction losses: 0.037454370070802295, regression losses: 0.13985804414841693, validation losses: 0.5594033145486945\n",
      "Epoch 3948, reconstruction losses: 0.03224036897831999, regression losses: 0.177056689340638, validation losses: 0.4319090410971149\n",
      "Epoch 3949, reconstruction losses: 0.03373824254252165, regression losses: 0.15626184386318157, validation losses: 0.7277340289375157\n",
      "Epoch 3950, reconstruction losses: 0.044442449841218354, regression losses: 0.18599714379193114, validation losses: 0.7041392951063739\n",
      "Epoch 3951, reconstruction losses: 0.034896157482653414, regression losses: 0.11282499889739069, validation losses: 0.5874319626013129\n",
      "Epoch 3952, reconstruction losses: 0.03373133475195764, regression losses: 0.14413159336163084, validation losses: 0.48003294598736024\n",
      "Epoch 3953, reconstruction losses: 0.039455303059487, regression losses: 0.29084877040622537, validation losses: 0.5963570258513795\n",
      "Epoch 3954, reconstruction losses: 0.03419404058202681, regression losses: 0.123658394856028, validation losses: 0.8335926430799323\n",
      "Epoch 3955, reconstruction losses: 0.03325318970632503, regression losses: 0.1490591170089358, validation losses: 0.5782174155521387\n",
      "Epoch 3956, reconstruction losses: 0.03439361084962258, regression losses: 0.124648541125172, validation losses: 0.47369789999828477\n",
      "Epoch 3957, reconstruction losses: 0.03523802632303026, regression losses: 0.1177429964676198, validation losses: 0.4773130443743308\n",
      "Epoch 3958, reconstruction losses: 0.034045536965219406, regression losses: 0.1332064338666985, validation losses: 0.41354721209031087\n",
      "Epoch 3959, reconstruction losses: 0.031819344275999105, regression losses: 0.10275944539097875, validation losses: 0.5297011672479234\n",
      "Epoch 3960, reconstruction losses: 0.040506048887165, regression losses: 0.09950077916070958, validation losses: 0.5181868403591943\n",
      "Epoch 3961, reconstruction losses: 0.037119425615764756, regression losses: 0.24037645797427895, validation losses: 0.46936709134586657\n",
      "Epoch 3962, reconstruction losses: 0.03637136001912101, regression losses: 0.1095650923453823, validation losses: 0.5643398749061951\n",
      "Epoch 3963, reconstruction losses: 0.036980650714520946, regression losses: 0.11716251085135088, validation losses: 0.461061133502075\n",
      "Epoch 3964, reconstruction losses: 0.0321294517913853, regression losses: 0.12927105174489728, validation losses: 0.45621678312373953\n",
      "Epoch 3965, reconstruction losses: 0.03477583481870569, regression losses: 0.13247913229746164, validation losses: 0.42340338450110115\n",
      "Epoch 3966, reconstruction losses: 0.033199534536472064, regression losses: 0.14821830775544423, validation losses: 0.44516637721083896\n",
      "Epoch 3967, reconstruction losses: 0.03796810517768873, regression losses: 0.16155124744010968, validation losses: 0.4021627824276723\n",
      "Epoch 3968, reconstruction losses: 0.03249163181768109, regression losses: 0.13834161598620123, validation losses: 0.43570529315142154\n",
      "Epoch 3969, reconstruction losses: 0.03345325550769416, regression losses: 0.10221287017628392, validation losses: 0.4691436496651746\n",
      "Epoch 3970, reconstruction losses: 0.03471269616106324, regression losses: 0.16164085482345159, validation losses: 0.4259610645401358\n",
      "Epoch 3971, reconstruction losses: 0.037841120737058614, regression losses: 0.24266991065985333, validation losses: 0.4830475425244404\n",
      "Epoch 3972, reconstruction losses: 0.036626867847731885, regression losses: 0.10650834549823628, validation losses: 0.7978710322363064\n",
      "Epoch 3973, reconstruction losses: 0.0337451993486011, regression losses: 0.12644034156903175, validation losses: 0.5284519229698974\n",
      "Epoch 3974, reconstruction losses: 0.03510922602123977, regression losses: 0.14004470313297762, validation losses: 0.3766569991537636\n",
      "Epoch 3975, reconstruction losses: 0.039068610725684225, regression losses: 0.1306184813166748, validation losses: 0.40242660166457433\n",
      "Epoch 3976, reconstruction losses: 0.03990080303153025, regression losses: 0.12602804961531208, validation losses: 0.4286708429121135\n",
      "Epoch 3977, reconstruction losses: 0.03574385661345752, regression losses: 0.10254819442858766, validation losses: 0.410499174373784\n",
      "Epoch 3978, reconstruction losses: 0.034518403270764594, regression losses: 0.11934627400341102, validation losses: 0.44312797655346625\n",
      "Epoch 3979, reconstruction losses: 0.03397261921890853, regression losses: 0.15010951366136388, validation losses: 0.4511170990736082\n",
      "Epoch 3980, reconstruction losses: 0.03679617699266855, regression losses: 0.14906449604149424, validation losses: 0.613770225018137\n",
      "Epoch 3981, reconstruction losses: 0.03433279369105395, regression losses: 0.14325473092971885, validation losses: 0.7077804549135488\n",
      "Epoch 3982, reconstruction losses: 0.035082606518686006, regression losses: 0.28078484588356933, validation losses: 0.5644992519835013\n",
      "Epoch 3983, reconstruction losses: 0.034217438990223524, regression losses: 0.14531978282177077, validation losses: 0.6737457252715334\n",
      "Epoch 3984, reconstruction losses: 0.034306917169196635, regression losses: 0.19793596104942204, validation losses: 0.5517758773065833\n",
      "Epoch 3985, reconstruction losses: 0.035450315208869404, regression losses: 0.14912634407273392, validation losses: 0.6708828316518114\n",
      "Epoch 3986, reconstruction losses: 0.033683022462427256, regression losses: 0.16900434118002414, validation losses: 0.6181652520833575\n",
      "Epoch 3987, reconstruction losses: 0.03432064797544732, regression losses: 0.2162645818672754, validation losses: 0.4550539261214125\n",
      "Epoch 3988, reconstruction losses: 0.03365861564858492, regression losses: 0.1274296174036053, validation losses: 0.5065814500856354\n",
      "Epoch 3989, reconstruction losses: 0.03501115286901506, regression losses: 0.12225655980128057, validation losses: 0.6157967619688964\n",
      "Epoch 3990, reconstruction losses: 0.034215883739825384, regression losses: 0.16953906621287115, validation losses: 0.5796335858793162\n",
      "Epoch 3991, reconstruction losses: 0.03832265574250977, regression losses: 0.15820887770537298, validation losses: 0.5120004543583888\n",
      "Epoch 3992, reconstruction losses: 0.03590489622727348, regression losses: 0.2546480540521481, validation losses: 0.6086510209275836\n",
      "Epoch 3993, reconstruction losses: 0.032709417763723284, regression losses: 0.17497306852567987, validation losses: 0.8785870991032342\n",
      "Epoch 3994, reconstruction losses: 0.0360916207790483, regression losses: 0.16590181061290854, validation losses: 0.4501309224169839\n",
      "Epoch 3995, reconstruction losses: 0.03227758366211386, regression losses: 0.12979497630348666, validation losses: 0.7208035549536905\n",
      "Epoch 3996, reconstruction losses: 0.03575553208522322, regression losses: 0.19077190702221966, validation losses: 0.667840054834439\n",
      "Epoch 3997, reconstruction losses: 0.036542622777946836, regression losses: 0.14863636546167286, validation losses: 0.5898896954583702\n",
      "Epoch 3998, reconstruction losses: 0.040004488791282114, regression losses: 0.16601619989435262, validation losses: 0.4617409312716599\n",
      "Epoch 3999, reconstruction losses: 0.03405285458306329, regression losses: 0.11184771382337427, validation losses: 0.45065664486139206\n",
      "Epoch 4000, reconstruction losses: 0.034514265895223405, regression losses: 0.14834235702828844, validation losses: 0.4606531835522761\n",
      "Epoch 4001, reconstruction losses: 0.039210104045210956, regression losses: 0.13675677058560717, validation losses: 0.43976828835096177\n",
      "Epoch 4002, reconstruction losses: 0.03339456584496096, regression losses: 0.1400784533370518, validation losses: 0.40963846690032213\n",
      "Epoch 4003, reconstruction losses: 0.03511055041026503, regression losses: 0.15737579793607404, validation losses: 0.41800966869416034\n",
      "Epoch 4004, reconstruction losses: 0.03526604235286424, regression losses: 0.11536862962843385, validation losses: 0.6349327976494289\n",
      "Epoch 4005, reconstruction losses: 0.04304075669237044, regression losses: 0.21727833385819043, validation losses: 0.4284117736971672\n",
      "Epoch 4006, reconstruction losses: 0.03219290089898338, regression losses: 0.19156947632925, validation losses: 0.6553908678746097\n",
      "Epoch 4007, reconstruction losses: 0.035056273794503365, regression losses: 0.14782870142087653, validation losses: 0.5124064893679953\n",
      "Epoch 4008, reconstruction losses: 0.03249309590538096, regression losses: 0.10353884505343172, validation losses: 0.6032009736048835\n",
      "Epoch 4009, reconstruction losses: 0.03454894697819621, regression losses: 0.2019332690060781, validation losses: 0.4703319255191151\n",
      "Epoch 4010, reconstruction losses: 0.03319621459651568, regression losses: 0.10637353756246944, validation losses: 0.6346981129516488\n",
      "Epoch 4011, reconstruction losses: 0.03573628144085212, regression losses: 0.23309372887266133, validation losses: 0.5288892365075941\n",
      "Epoch 4012, reconstruction losses: 0.03287124378776054, regression losses: 0.15131232926578905, validation losses: 0.5749112645577459\n",
      "Epoch 4013, reconstruction losses: 0.03333855836863483, regression losses: 0.14215901092531733, validation losses: 0.45467421947193654\n",
      "Epoch 4014, reconstruction losses: 0.034654059733903377, regression losses: 0.10674828584448307, validation losses: 0.4265783452158528\n",
      "Epoch 4015, reconstruction losses: 0.03351323464737655, regression losses: 0.10027595285276165, validation losses: 0.46987132624484335\n",
      "Epoch 4016, reconstruction losses: 0.033292170082734225, regression losses: 0.1278259632034503, validation losses: 0.44797610625438106\n",
      "Epoch 4017, reconstruction losses: 0.032124104214810364, regression losses: 0.11968211056644429, validation losses: 0.40696757098321246\n",
      "Epoch 4018, reconstruction losses: 0.04292605894101406, regression losses: 0.11900462759197734, validation losses: 0.38750704445666867\n",
      "Epoch 4019, reconstruction losses: 0.03502851240228697, regression losses: 0.1021377901635891, validation losses: 0.4113399432324016\n",
      "Epoch 4020, reconstruction losses: 0.03498349833783635, regression losses: 0.15625814137768232, validation losses: 0.41528070052507327\n",
      "Epoch 4021, reconstruction losses: 0.033761349231401755, regression losses: 0.13158056257062808, validation losses: 0.423132117114595\n",
      "Epoch 4022, reconstruction losses: 0.041918785632762974, regression losses: 0.12038577782354495, validation losses: 0.39873412936664626\n",
      "Epoch 4023, reconstruction losses: 0.03535202527189578, regression losses: 0.15243793183529153, validation losses: 0.4488176416141186\n",
      "Epoch 4024, reconstruction losses: 0.03690376482264596, regression losses: 0.15066275552059002, validation losses: 0.4580613463393909\n",
      "Epoch 4025, reconstruction losses: 0.03175795534281935, regression losses: 0.1408992424577451, validation losses: 0.5106800237205839\n",
      "Epoch 4026, reconstruction losses: 0.033625191887998715, regression losses: 0.12009449577776607, validation losses: 0.3980221827894112\n",
      "Epoch 4027, reconstruction losses: 0.0331622804369916, regression losses: 0.10621580662155744, validation losses: 0.42370534993002157\n",
      "Epoch 4028, reconstruction losses: 0.03254911650098586, regression losses: 0.1129513912715131, validation losses: 0.47610576032899415\n",
      "Epoch 4029, reconstruction losses: 0.03571981429254478, regression losses: 0.15623641516902262, validation losses: 0.4377606665119896\n",
      "Epoch 4030, reconstruction losses: 0.032711927080770496, regression losses: 0.10941765888673716, validation losses: 0.4102980485707482\n",
      "Epoch 4031, reconstruction losses: 0.03629462267979585, regression losses: 0.1393959713550349, validation losses: 0.4046977223029612\n",
      "Epoch 4032, reconstruction losses: 0.04066153450569916, regression losses: 0.09087322775503127, validation losses: 0.40634466662432733\n",
      "Epoch 4033, reconstruction losses: 0.03502840314476568, regression losses: 0.09918755126708848, validation losses: 0.4072837310383538\n",
      "Epoch 4034, reconstruction losses: 0.03419784150385251, regression losses: 0.10483380899843435, validation losses: 0.4514429635462795\n",
      "Epoch 4035, reconstruction losses: 0.03324191167955312, regression losses: 0.11863947364296185, validation losses: 0.5380481481142485\n",
      "Epoch 4036, reconstruction losses: 0.03739999442776967, regression losses: 0.1100686413681051, validation losses: 0.5450204029991836\n",
      "Epoch 4037, reconstruction losses: 0.0384350995050599, regression losses: 0.11362607265525522, validation losses: 0.4249109765127682\n",
      "Epoch 4038, reconstruction losses: 0.039296146402400305, regression losses: 0.12841945094926102, validation losses: 0.43172451117031335\n",
      "Epoch 4039, reconstruction losses: 0.03373145079318243, regression losses: 0.14060391782564377, validation losses: 0.4309998014340239\n",
      "Epoch 4040, reconstruction losses: 0.045783146546754604, regression losses: 0.3486502109328764, validation losses: 0.520560676212917\n",
      "Epoch 4041, reconstruction losses: 0.042555290273913415, regression losses: 0.13738735609805772, validation losses: 0.5888408010871644\n",
      "Epoch 4042, reconstruction losses: 0.03429532683320292, regression losses: 0.13034565711512996, validation losses: 0.5118970004512001\n",
      "Epoch 4043, reconstruction losses: 0.035248768032245706, regression losses: 0.11913756348863504, validation losses: 0.6378261603820282\n",
      "Epoch 4044, reconstruction losses: 0.04061256418559953, regression losses: 0.12326885758727396, validation losses: 0.47948186019702294\n",
      "Epoch 4045, reconstruction losses: 0.038722221780733555, regression losses: 0.12383813581462859, validation losses: 0.39283770411786556\n",
      "Epoch 4046, reconstruction losses: 0.03455919036359413, regression losses: 0.1557769966537367, validation losses: 0.43133652339553724\n",
      "Epoch 4047, reconstruction losses: 0.03535561013180857, regression losses: 0.3432984178989066, validation losses: 0.5123351857007089\n",
      "Epoch 4048, reconstruction losses: 0.03704764996259718, regression losses: 0.2708370064357818, validation losses: 0.7141268594938912\n",
      "Epoch 4049, reconstruction losses: 0.033829169503723, regression losses: 0.16787472245977964, validation losses: 0.6416036545979641\n",
      "Epoch 4050, reconstruction losses: 0.03483009565572105, regression losses: 0.16053779782480157, validation losses: 0.605934331106925\n",
      "Epoch 4051, reconstruction losses: 0.03501035021897741, regression losses: 0.12335759066167219, validation losses: 0.5032265110857097\n",
      "Epoch 4052, reconstruction losses: 0.03491227430901285, regression losses: 0.11622520032046887, validation losses: 0.42143912376646825\n",
      "Epoch 4053, reconstruction losses: 0.03262193105811504, regression losses: 0.10039800677877815, validation losses: 0.39442736375635784\n",
      "Epoch 4054, reconstruction losses: 0.04322951367170025, regression losses: 0.12113078777769666, validation losses: 0.41322845019224924\n",
      "Epoch 4055, reconstruction losses: 0.031934488056088936, regression losses: 0.09714076345748857, validation losses: 0.45016615720857217\n",
      "Epoch 4056, reconstruction losses: 0.036778519069645285, regression losses: 0.11483339508094365, validation losses: 0.41165282721872676\n",
      "Epoch 4057, reconstruction losses: 0.03223866405356325, regression losses: 0.11093102975531756, validation losses: 0.3743491285713365\n",
      "Epoch 4058, reconstruction losses: 0.03321299755412402, regression losses: 0.14462467636843385, validation losses: 0.3908441703991989\n",
      "Epoch 4059, reconstruction losses: 0.03512361323691761, regression losses: 0.16267031821682776, validation losses: 0.43213963986701537\n",
      "Epoch 4060, reconstruction losses: 0.03393300270018752, regression losses: 0.14854327191207933, validation losses: 0.601983920104309\n",
      "Epoch 4061, reconstruction losses: 0.03492821643226932, regression losses: 0.13580995125124018, validation losses: 0.5211608131324372\n",
      "Epoch 4062, reconstruction losses: 0.034048560842667594, regression losses: 0.1026557818735281, validation losses: 0.41053316648002874\n",
      "Epoch 4063, reconstruction losses: 0.032519163606843614, regression losses: 0.10654008949604787, validation losses: 0.41754713475842997\n",
      "Epoch 4064, reconstruction losses: 0.032263113626918596, regression losses: 0.11622488646173113, validation losses: 0.48459687478098334\n",
      "Epoch 4065, reconstruction losses: 0.033740057770207325, regression losses: 0.0923569995272847, validation losses: 0.4367439591561376\n",
      "Epoch 4066, reconstruction losses: 0.0338148461841746, regression losses: 0.1069111425460541, validation losses: 0.44849165882647285\n",
      "Epoch 4067, reconstruction losses: 0.03195709191837933, regression losses: 0.11545880406328278, validation losses: 0.4739510040378311\n",
      "Epoch 4068, reconstruction losses: 0.03762561075651278, regression losses: 0.15726122260300127, validation losses: 0.4193518378914582\n",
      "Epoch 4069, reconstruction losses: 0.03313550037414079, regression losses: 0.11701381756338333, validation losses: 0.4712638460707022\n",
      "Epoch 4070, reconstruction losses: 0.040347700840876834, regression losses: 0.17764546119442684, validation losses: 0.4223976715218063\n",
      "Epoch 4071, reconstruction losses: 0.03654010975899234, regression losses: 0.10852799680822524, validation losses: 0.41520757729421964\n",
      "Epoch 4072, reconstruction losses: 0.0334428026646123, regression losses: 0.12325752038705004, validation losses: 0.6181344425288642\n",
      "Epoch 4073, reconstruction losses: 0.03522674840435444, regression losses: 0.2542105145808705, validation losses: 0.6256413386926307\n",
      "Epoch 4074, reconstruction losses: 0.03899257247587666, regression losses: 0.12467194775657833, validation losses: 0.5907343524894438\n",
      "Epoch 4075, reconstruction losses: 0.03428630977638906, regression losses: 0.15174002125561464, validation losses: 0.42055135734560634\n",
      "Epoch 4076, reconstruction losses: 0.03661837823971797, regression losses: 0.15676039520261123, validation losses: 0.468371991678578\n",
      "Epoch 4077, reconstruction losses: 0.03409314369389042, regression losses: 0.11409873201568727, validation losses: 0.4272848875437697\n",
      "Epoch 4078, reconstruction losses: 0.033774847838642694, regression losses: 0.15669820890168956, validation losses: 0.5105970968813404\n",
      "Epoch 4079, reconstruction losses: 0.03521757703061012, regression losses: 0.11275050419125396, validation losses: 0.45402586722444394\n",
      "Epoch 4080, reconstruction losses: 0.03394798840366036, regression losses: 0.19152758373420892, validation losses: 0.47547829139459447\n",
      "Epoch 4081, reconstruction losses: 0.0343377940927083, regression losses: 0.13443047870315908, validation losses: 0.6621960899033795\n",
      "Epoch 4082, reconstruction losses: 0.03325035264022384, regression losses: 0.11454368864253683, validation losses: 0.5639141476488011\n",
      "Epoch 4083, reconstruction losses: 0.04128661493555882, regression losses: 0.19395744232490614, validation losses: 0.49550895709389253\n",
      "Epoch 4084, reconstruction losses: 0.0336710275302151, regression losses: 0.12927953614273355, validation losses: 0.6841647739377017\n",
      "Epoch 4085, reconstruction losses: 0.034255094056636355, regression losses: 0.1092658610327384, validation losses: 0.5860573782177025\n",
      "Epoch 4086, reconstruction losses: 0.034490886854764875, regression losses: 0.12530306420977283, validation losses: 0.5209424662428039\n",
      "Epoch 4087, reconstruction losses: 0.038605770362478545, regression losses: 0.13055627075547213, validation losses: 0.40710246178461673\n",
      "Epoch 4088, reconstruction losses: 0.033452466868015056, regression losses: 0.1182631026637751, validation losses: 0.3935911528058105\n",
      "Epoch 4089, reconstruction losses: 0.03226279618714342, regression losses: 0.09919002652307668, validation losses: 0.3998628282763683\n",
      "Epoch 4090, reconstruction losses: 0.0341814104539282, regression losses: 0.11122567085807586, validation losses: 0.4851377154348826\n",
      "Epoch 4091, reconstruction losses: 0.035691562919127943, regression losses: 0.11804725826328732, validation losses: 0.4821114262024905\n",
      "Epoch 4092, reconstruction losses: 0.03412976933376027, regression losses: 0.24421235452528425, validation losses: 0.41150577352095036\n",
      "Epoch 4093, reconstruction losses: 0.0353119535324435, regression losses: 0.12100265570660228, validation losses: 0.5173687140377526\n",
      "Epoch 4094, reconstruction losses: 0.03408865891964405, regression losses: 0.1343051995246115, validation losses: 0.5816525397094328\n",
      "Epoch 4095, reconstruction losses: 0.03546204245242697, regression losses: 0.11962924391096731, validation losses: 0.5090339998692843\n",
      "Epoch 4096, reconstruction losses: 0.039083546629236424, regression losses: 0.14643255871645716, validation losses: 0.4353741304660132\n",
      "Epoch 4097, reconstruction losses: 0.038878697030203614, regression losses: 0.2077445025573318, validation losses: 0.45081601810846067\n",
      "Epoch 4098, reconstruction losses: 0.03902965915239032, regression losses: 0.3195948245538872, validation losses: 0.9147073371996499\n",
      "Epoch 4099, reconstruction losses: 0.035847058979245644, regression losses: 0.21606632331810685, validation losses: 1.096266377732889\n",
      "Epoch 4100, reconstruction losses: 0.03380456782674156, regression losses: 0.2037678822432592, validation losses: 0.7012442894686995\n",
      "Epoch 4101, reconstruction losses: 0.0355302591400495, regression losses: 0.13472541361265455, validation losses: 1.009657588589948\n",
      "Epoch 4102, reconstruction losses: 0.035530434213314956, regression losses: 0.14805300762903273, validation losses: 0.5191208251495449\n",
      "Epoch 4103, reconstruction losses: 0.036887206434767734, regression losses: 0.18508641643683418, validation losses: 0.5448305947434752\n",
      "Epoch 4104, reconstruction losses: 0.032951555613940614, regression losses: 0.0900613524013089, validation losses: 0.5123151452443448\n",
      "Epoch 4105, reconstruction losses: 0.03408295353953, regression losses: 0.14585615688345052, validation losses: 0.518434747711131\n",
      "Epoch 4106, reconstruction losses: 0.034146740056116426, regression losses: 0.11887799345863664, validation losses: 0.4401772574551224\n",
      "Epoch 4107, reconstruction losses: 0.03930128348074074, regression losses: 0.10665122684390312, validation losses: 0.4149487782765783\n",
      "Epoch 4108, reconstruction losses: 0.035612086522246546, regression losses: 0.10765628293686899, validation losses: 0.40406494456494435\n",
      "Epoch 4109, reconstruction losses: 0.03215025765917639, regression losses: 0.14039365590584582, validation losses: 0.39281697671981575\n",
      "Epoch 4110, reconstruction losses: 0.032319359061788205, regression losses: 0.1478094335156512, validation losses: 0.4131504934257116\n",
      "Epoch 4111, reconstruction losses: 0.03331107594646864, regression losses: 0.13208795263867795, validation losses: 0.4424689070365936\n",
      "Epoch 4112, reconstruction losses: 0.03371769686601569, regression losses: 0.11549843549941384, validation losses: 0.567567524355945\n",
      "Epoch 4113, reconstruction losses: 0.0420007319756347, regression losses: 0.12189116934804865, validation losses: 0.450980136624963\n",
      "Epoch 4114, reconstruction losses: 0.032961499691029884, regression losses: 0.1089417971370335, validation losses: 0.4124474745880683\n",
      "Epoch 4115, reconstruction losses: 0.04023588320405359, regression losses: 0.1424216833430028, validation losses: 0.4279992908052578\n",
      "Epoch 4116, reconstruction losses: 0.03806988197019279, regression losses: 0.10267494939132467, validation losses: 0.4353020818044818\n",
      "Epoch 4117, reconstruction losses: 0.0385797237911577, regression losses: 0.13049830412654018, validation losses: 0.49722842180614013\n",
      "Epoch 4118, reconstruction losses: 0.03801591212205458, regression losses: 0.11884755043724937, validation losses: 0.5090525637506355\n",
      "Epoch 4119, reconstruction losses: 0.03178420829542125, regression losses: 0.11208636098345642, validation losses: 0.4535738192838506\n",
      "Epoch 4120, reconstruction losses: 0.03689672800215034, regression losses: 0.15238670632139223, validation losses: 0.4081205237568441\n",
      "Epoch 4121, reconstruction losses: 0.03628969188421332, regression losses: 0.19900188913090697, validation losses: 0.4024866570913754\n",
      "Epoch 4122, reconstruction losses: 0.03943610323103626, regression losses: 0.1389061944317717, validation losses: 0.548122648172625\n",
      "Epoch 4123, reconstruction losses: 0.032061552080630495, regression losses: 0.1308423874122165, validation losses: 0.5207149064323392\n",
      "Epoch 4124, reconstruction losses: 0.03317433990784929, regression losses: 0.12370537149994251, validation losses: 0.5657966880040616\n",
      "Epoch 4125, reconstruction losses: 0.03554317697001809, regression losses: 0.13127512134805674, validation losses: 0.4897792013071294\n",
      "Epoch 4126, reconstruction losses: 0.03297306701115057, regression losses: 0.10752631286539813, validation losses: 0.4305983997136773\n",
      "Epoch 4127, reconstruction losses: 0.03630799359119047, regression losses: 0.1529380833049782, validation losses: 0.4845848514876419\n",
      "Epoch 4128, reconstruction losses: 0.03891974179658028, regression losses: 0.11766514152972252, validation losses: 0.5940264116406171\n",
      "Epoch 4129, reconstruction losses: 0.03227292694781545, regression losses: 0.10625392956735022, validation losses: 0.5000611175256842\n",
      "Epoch 4130, reconstruction losses: 0.03132539345312202, regression losses: 0.10428115997549911, validation losses: 0.45592887724411685\n",
      "Epoch 4131, reconstruction losses: 0.03382202446336507, regression losses: 0.12063770012673808, validation losses: 0.42227466570726535\n",
      "Epoch 4132, reconstruction losses: 0.03460175625222999, regression losses: 0.11774295759814343, validation losses: 0.5095837150798035\n",
      "Epoch 4133, reconstruction losses: 0.03324504284153141, regression losses: 0.10228710781291228, validation losses: 0.5475844157663414\n",
      "Epoch 4134, reconstruction losses: 0.031022470082471807, regression losses: 0.11380028073601099, validation losses: 0.4472375599078529\n",
      "Epoch 4135, reconstruction losses: 0.03917860190612465, regression losses: 0.12768664736948596, validation losses: 0.4175469324566287\n",
      "Epoch 4136, reconstruction losses: 0.03489037023042395, regression losses: 0.15988505404798567, validation losses: 0.4187196876691673\n",
      "Epoch 4137, reconstruction losses: 0.030506914899498413, regression losses: 0.12450543132427018, validation losses: 0.4147517651075985\n",
      "Epoch 4138, reconstruction losses: 0.03601657607698542, regression losses: 0.11881576266856632, validation losses: 0.5165326686100835\n",
      "Epoch 4139, reconstruction losses: 0.032929161609494634, regression losses: 0.14172073968652749, validation losses: 0.5907992230725371\n",
      "Epoch 4140, reconstruction losses: 0.030463468271854578, regression losses: 0.10840404290625186, validation losses: 0.47503183438862273\n",
      "Epoch 4141, reconstruction losses: 0.032349671630180384, regression losses: 0.12875877201869143, validation losses: 0.4337433456970986\n",
      "Epoch 4142, reconstruction losses: 0.030245527261509135, regression losses: 0.11776164657392052, validation losses: 0.43804743007580144\n",
      "Epoch 4143, reconstruction losses: 0.0338463616286465, regression losses: 0.1221688572063283, validation losses: 0.410359655115459\n",
      "Epoch 4144, reconstruction losses: 0.03559331336327994, regression losses: 0.2076975703146107, validation losses: 0.42236775234319157\n",
      "Epoch 4145, reconstruction losses: 0.03704586013444519, regression losses: 0.13871050584630903, validation losses: 0.5582764451445644\n",
      "Epoch 4146, reconstruction losses: 0.03244945014089948, regression losses: 0.11606151136141507, validation losses: 0.5632685298203963\n",
      "Epoch 4147, reconstruction losses: 0.03269185513419269, regression losses: 0.10868872345829231, validation losses: 0.4593254803198258\n",
      "Epoch 4148, reconstruction losses: 0.03339075649310813, regression losses: 0.09836341177697719, validation losses: 0.5042557669508871\n",
      "Epoch 4149, reconstruction losses: 0.038725765513912276, regression losses: 0.12446658426785165, validation losses: 0.4982569436628319\n",
      "Epoch 4150, reconstruction losses: 0.03162555417036997, regression losses: 0.11012741383593161, validation losses: 0.4041362455752771\n",
      "Epoch 4151, reconstruction losses: 0.03611394086660651, regression losses: 0.16153452640293625, validation losses: 0.4930846555116973\n",
      "Epoch 4152, reconstruction losses: 0.04131001330766811, regression losses: 0.20964322601434182, validation losses: 0.6073035596262161\n",
      "Epoch 4153, reconstruction losses: 0.0398612362322233, regression losses: 0.24193383695876, validation losses: 0.7566978027719774\n",
      "Epoch 4154, reconstruction losses: 0.03387313047099398, regression losses: 0.21518095535025028, validation losses: 0.9939335086091438\n",
      "Epoch 4155, reconstruction losses: 0.03850200988231682, regression losses: 0.1929249342003513, validation losses: 0.5599163369721964\n",
      "Epoch 4156, reconstruction losses: 0.033489668282032314, regression losses: 0.1329485362782698, validation losses: 0.6260670337594343\n",
      "Epoch 4157, reconstruction losses: 0.03395030588804726, regression losses: 0.1336730043320299, validation losses: 0.44515872400533474\n",
      "Epoch 4158, reconstruction losses: 0.03426170024365882, regression losses: 0.10133494516728998, validation losses: 0.39788833754262076\n",
      "Epoch 4159, reconstruction losses: 0.03723454304990418, regression losses: 0.2585964688477129, validation losses: 0.403044053015186\n",
      "Epoch 4160, reconstruction losses: 0.03243503599269024, regression losses: 0.11668646972567251, validation losses: 0.6281912884083817\n",
      "Epoch 4161, reconstruction losses: 0.03332577755680962, regression losses: 0.13802853532183723, validation losses: 0.456084528692411\n",
      "Epoch 4162, reconstruction losses: 0.033462919183934806, regression losses: 0.1352212252525185, validation losses: 0.43397966572925545\n",
      "Epoch 4163, reconstruction losses: 0.03779354952125646, regression losses: 0.09169447246873538, validation losses: 0.5018424672637664\n",
      "Epoch 4164, reconstruction losses: 0.033458563326224065, regression losses: 0.1432242213044319, validation losses: 0.48598885723648483\n",
      "Epoch 4165, reconstruction losses: 0.03374249155427852, regression losses: 0.09935815699633616, validation losses: 0.4869104171116376\n",
      "Epoch 4166, reconstruction losses: 0.033889899005858544, regression losses: 0.14114011305293192, validation losses: 0.4324132442388537\n",
      "Epoch 4167, reconstruction losses: 0.03499037206038912, regression losses: 0.1067459506799147, validation losses: 0.41358481241558187\n",
      "Epoch 4168, reconstruction losses: 0.033785285848066726, regression losses: 0.14790209246450886, validation losses: 0.4965437537419545\n",
      "Epoch 4169, reconstruction losses: 0.03358361906132341, regression losses: 0.1278584098771493, validation losses: 0.48681437429829505\n",
      "Epoch 4170, reconstruction losses: 0.03864693652584108, regression losses: 0.12068185879013799, validation losses: 0.43410289938773666\n",
      "Epoch 4171, reconstruction losses: 0.036060240661082016, regression losses: 0.2080330261253902, validation losses: 0.43249761054407576\n",
      "Epoch 4172, reconstruction losses: 0.034142888288486016, regression losses: 0.14644668783719128, validation losses: 0.7500094966472497\n",
      "Epoch 4173, reconstruction losses: 0.033693071320828875, regression losses: 0.2406320888192482, validation losses: 0.6718710847630541\n",
      "Epoch 4174, reconstruction losses: 0.03279266539972015, regression losses: 0.11021823311523572, validation losses: 0.6819967224275029\n",
      "Epoch 4175, reconstruction losses: 0.032837274584547015, regression losses: 0.13524101047624815, validation losses: 0.4711221364256752\n",
      "Epoch 4176, reconstruction losses: 0.03145156086249079, regression losses: 0.1393187632999017, validation losses: 0.4429601930675231\n",
      "Epoch 4177, reconstruction losses: 0.038504188359052754, regression losses: 0.1180830840165728, validation losses: 0.45887012553199236\n",
      "Epoch 4178, reconstruction losses: 0.034292391549558196, regression losses: 0.0838488276024351, validation losses: 0.454206405376723\n",
      "Epoch 4179, reconstruction losses: 0.03453519407466298, regression losses: 0.11069938661043092, validation losses: 0.5002643803417771\n",
      "Epoch 4180, reconstruction losses: 0.04118801396216684, regression losses: 0.14027182196975904, validation losses: 0.4672452427614225\n",
      "Epoch 4181, reconstruction losses: 0.03730703631867961, regression losses: 0.35143878521259847, validation losses: 0.44114172363415355\n",
      "Epoch 4182, reconstruction losses: 0.03352742510006366, regression losses: 0.12149112006188527, validation losses: 0.7871931563577984\n",
      "Epoch 4183, reconstruction losses: 0.03990408970548552, regression losses: 0.13536762990697956, validation losses: 0.6556279521586815\n",
      "Epoch 4184, reconstruction losses: 0.03534727447392562, regression losses: 0.12729052087648768, validation losses: 0.6310368419511432\n",
      "Epoch 4185, reconstruction losses: 0.03339960255106495, regression losses: 0.11632428151818303, validation losses: 0.4591861470807239\n",
      "Epoch 4186, reconstruction losses: 0.03345784815858482, regression losses: 0.13054396207758784, validation losses: 0.45798787764294707\n",
      "Epoch 4187, reconstruction losses: 0.031155138692037964, regression losses: 0.1135425378021234, validation losses: 0.4989444697371622\n",
      "Epoch 4188, reconstruction losses: 0.033327964722190434, regression losses: 0.15626488103777852, validation losses: 0.4466700042928262\n",
      "Epoch 4189, reconstruction losses: 0.04007381379781348, regression losses: 0.11421080649321763, validation losses: 0.4313519855598721\n",
      "Epoch 4190, reconstruction losses: 0.038710209657206486, regression losses: 0.12628898996180626, validation losses: 0.4511806899466781\n",
      "Epoch 4191, reconstruction losses: 0.032239942108091287, regression losses: 0.10816964678931602, validation losses: 0.44565371366853657\n",
      "Epoch 4192, reconstruction losses: 0.03468813743867042, regression losses: 0.2203164147397863, validation losses: 0.4426410092273307\n",
      "Epoch 4193, reconstruction losses: 0.03935714126290338, regression losses: 0.11259165972514774, validation losses: 0.49218916693100345\n",
      "Epoch 4194, reconstruction losses: 0.03204156108609313, regression losses: 0.11849361598279372, validation losses: 0.42089139597497977\n",
      "Epoch 4195, reconstruction losses: 0.03253827587329289, regression losses: 0.09853647514743871, validation losses: 0.4234803450252158\n",
      "Epoch 4196, reconstruction losses: 0.03438254357785514, regression losses: 0.12637091382980747, validation losses: 0.5035276657366904\n",
      "Epoch 4197, reconstruction losses: 0.03709671109317299, regression losses: 0.20451573005057494, validation losses: 0.6168827533560229\n",
      "Epoch 4198, reconstruction losses: 0.03365777452461009, regression losses: 0.12351141096751952, validation losses: 0.6129096735402255\n",
      "Epoch 4199, reconstruction losses: 0.03780055765086739, regression losses: 0.20756316746724174, validation losses: 0.5209460416443804\n",
      "Epoch 4200, reconstruction losses: 0.03478805002962271, regression losses: 0.11846953338299708, validation losses: 0.5480827175026757\n",
      "Epoch 4201, reconstruction losses: 0.038962060770546585, regression losses: 0.14043669323926172, validation losses: 0.49763155151303284\n",
      "Epoch 4202, reconstruction losses: 0.03297861056074022, regression losses: 0.14728456766978676, validation losses: 0.44095710248464437\n",
      "Epoch 4203, reconstruction losses: 0.035942358019679925, regression losses: 0.1176339399164414, validation losses: 0.6573284020265198\n",
      "Epoch 4204, reconstruction losses: 0.03581313800518773, regression losses: 0.10450162008683588, validation losses: 0.5814469284746693\n",
      "Epoch 4205, reconstruction losses: 0.03378699233258041, regression losses: 0.0961888519006423, validation losses: 0.38604036382731005\n",
      "Epoch 4206, reconstruction losses: 0.032877715952405684, regression losses: 0.09723372164680433, validation losses: 0.3966205785967893\n",
      "Epoch 4207, reconstruction losses: 0.03538319817326819, regression losses: 0.11464904204289184, validation losses: 0.4116591556355721\n",
      "Epoch 4208, reconstruction losses: 0.03389775494889667, regression losses: 0.13111302052172533, validation losses: 0.4534148830213792\n",
      "Epoch 4209, reconstruction losses: 0.033151545493405085, regression losses: 0.11521484397272566, validation losses: 0.3961014964588404\n",
      "Epoch 4210, reconstruction losses: 0.032497426995724964, regression losses: 0.13633997089551153, validation losses: 0.3960098191921108\n",
      "Epoch 4211, reconstruction losses: 0.033218440593393704, regression losses: 0.13062977090492423, validation losses: 0.4399777823492479\n",
      "Epoch 4212, reconstruction losses: 0.032226404459647855, regression losses: 0.1569428549954205, validation losses: 0.5282707301846163\n",
      "Epoch 4213, reconstruction losses: 0.03254293611188865, regression losses: 0.12615831357618743, validation losses: 0.7202863670245352\n",
      "Epoch 4214, reconstruction losses: 0.03164532974883331, regression losses: 0.11397596990840446, validation losses: 0.4390227512540151\n",
      "Epoch 4215, reconstruction losses: 0.033066806790928, regression losses: 0.11786611052548877, validation losses: 0.4094509977337624\n",
      "Epoch 4216, reconstruction losses: 0.034318206787474693, regression losses: 0.11858534680923, validation losses: 0.38202980195517905\n",
      "Epoch 4217, reconstruction losses: 0.03901739281304181, regression losses: 0.1263472069242163, validation losses: 0.426137473289767\n",
      "Epoch 4218, reconstruction losses: 0.035395141912262076, regression losses: 0.12235329191184902, validation losses: 0.43823273510190597\n",
      "Epoch 4219, reconstruction losses: 0.03635489266654027, regression losses: 0.17730276339664588, validation losses: 0.4039858104908605\n",
      "Epoch 4220, reconstruction losses: 0.03546152424061144, regression losses: 0.14617265988678665, validation losses: 0.42925584963994873\n",
      "Epoch 4221, reconstruction losses: 0.03565801703145034, regression losses: 0.2023172570980279, validation losses: 0.4476182090963808\n",
      "Epoch 4222, reconstruction losses: 0.037157930744431376, regression losses: 0.11165786373509455, validation losses: 0.5845729471484347\n",
      "Epoch 4223, reconstruction losses: 0.040471313620174816, regression losses: 0.1513029651353369, validation losses: 0.43123596923450097\n",
      "Epoch 4224, reconstruction losses: 0.0318116527249849, regression losses: 0.1058069476422453, validation losses: 0.42376905178271385\n",
      "Epoch 4225, reconstruction losses: 0.03896336340793319, regression losses: 0.4174592304606462, validation losses: 0.4042093144229851\n",
      "Epoch 4226, reconstruction losses: 0.03380244809416835, regression losses: 0.32734697676647695, validation losses: 0.6759035816877301\n",
      "Epoch 4227, reconstruction losses: 0.03196722755312387, regression losses: 0.17769797774846466, validation losses: 0.9132096282231974\n",
      "Epoch 4228, reconstruction losses: 0.03427565556012087, regression losses: 0.13949058995151767, validation losses: 0.8129386269708406\n",
      "Epoch 4229, reconstruction losses: 0.034367402835341454, regression losses: 0.1457489382123667, validation losses: 0.5277944796565959\n",
      "Epoch 4230, reconstruction losses: 0.03912328844507669, regression losses: 0.09713426667452807, validation losses: 0.4297965206822895\n",
      "Epoch 4231, reconstruction losses: 0.04103965825830986, regression losses: 0.15304090166216863, validation losses: 0.4225558865126163\n",
      "Epoch 4232, reconstruction losses: 0.03140888496958012, regression losses: 0.12993880645259903, validation losses: 0.4126374459190951\n",
      "Epoch 4233, reconstruction losses: 0.03249531326013332, regression losses: 0.10976147220908393, validation losses: 0.6111900798588819\n",
      "Epoch 4234, reconstruction losses: 0.0347983109400617, regression losses: 0.1418815401780586, validation losses: 0.5818852030880436\n",
      "Epoch 4235, reconstruction losses: 0.04196202168166255, regression losses: 0.0944023762252659, validation losses: 0.4362139576558675\n",
      "Epoch 4236, reconstruction losses: 0.03367814793768591, regression losses: 0.1246885189730535, validation losses: 0.41056082231553226\n",
      "Epoch 4237, reconstruction losses: 0.03499928946427812, regression losses: 0.11650041582645054, validation losses: 0.4437490510076916\n",
      "Epoch 4238, reconstruction losses: 0.03243036522399781, regression losses: 0.17775567504618064, validation losses: 0.44360489967183425\n",
      "Epoch 4239, reconstruction losses: 0.03520965422507448, regression losses: 0.23767690992946727, validation losses: 0.43935524888106586\n",
      "Epoch 4240, reconstruction losses: 0.03572979354571461, regression losses: 0.10561008898846899, validation losses: 0.6679048663354168\n",
      "Epoch 4241, reconstruction losses: 0.033490772863159005, regression losses: 0.1296639191913018, validation losses: 0.6192215924694542\n",
      "Epoch 4242, reconstruction losses: 0.031240093867096565, regression losses: 0.1290558465620199, validation losses: 0.4541502544046065\n",
      "Epoch 4243, reconstruction losses: 0.03931801032521992, regression losses: 0.11901852998708555, validation losses: 0.49007618496788846\n",
      "Epoch 4244, reconstruction losses: 0.03212394675619244, regression losses: 0.12957590225553278, validation losses: 0.5137026868626415\n",
      "Epoch 4245, reconstruction losses: 0.03446021294370008, regression losses: 0.1050993358832443, validation losses: 0.5740321034638298\n",
      "Epoch 4246, reconstruction losses: 0.03752077954203511, regression losses: 0.16288660401011204, validation losses: 0.4515842354510059\n",
      "Epoch 4247, reconstruction losses: 0.032169749139025546, regression losses: 0.1162715632863349, validation losses: 0.44213818390817944\n",
      "Epoch 4248, reconstruction losses: 0.037103757138241114, regression losses: 0.1514854829295666, validation losses: 0.39516432253786077\n",
      "Epoch 4249, reconstruction losses: 0.04057251809558837, regression losses: 0.12250850413846691, validation losses: 0.4859227993898223\n",
      "Epoch 4250, reconstruction losses: 0.03450875458609019, regression losses: 0.17412860862629775, validation losses: 0.47788022165858546\n",
      "Epoch 4251, reconstruction losses: 0.03459511985155437, regression losses: 0.11049213983156363, validation losses: 0.38987884414855334\n",
      "Epoch 4252, reconstruction losses: 0.03344314653500449, regression losses: 0.10571776513778793, validation losses: 0.4062224850011115\n",
      "Epoch 4253, reconstruction losses: 0.03382328794602016, regression losses: 0.10667068604590325, validation losses: 0.3940842572871569\n",
      "Epoch 4254, reconstruction losses: 0.03657311122608835, regression losses: 0.16349166996674924, validation losses: 0.45699737478388647\n",
      "Epoch 4255, reconstruction losses: 0.04445083600925974, regression losses: 0.21042734187694218, validation losses: 0.4701160262839477\n",
      "Epoch 4256, reconstruction losses: 0.040801133728762914, regression losses: 0.10661288114015205, validation losses: 0.3935165574592705\n",
      "Epoch 4257, reconstruction losses: 0.03871357972856219, regression losses: 0.15120360010743022, validation losses: 0.4097799812311847\n",
      "Epoch 4258, reconstruction losses: 0.03444572126861615, regression losses: 0.12363375132176012, validation losses: 0.46358409358581154\n",
      "Epoch 4259, reconstruction losses: 0.034863101885096386, regression losses: 0.24962157988227612, validation losses: 0.509839150395507\n",
      "Epoch 4260, reconstruction losses: 0.03203961130433819, regression losses: 0.12452387048625391, validation losses: 0.8600718978728557\n",
      "Epoch 4261, reconstruction losses: 0.0392574916160445, regression losses: 0.1516974000497669, validation losses: 0.5618936156516915\n",
      "Epoch 4262, reconstruction losses: 0.033298689708934556, regression losses: 0.11087073260822122, validation losses: 0.45877719247141696\n",
      "Epoch 4263, reconstruction losses: 0.03391573348004548, regression losses: 0.10561435478556673, validation losses: 0.5138418575515553\n",
      "Epoch 4264, reconstruction losses: 0.03274896180673121, regression losses: 0.10454790612123147, validation losses: 0.4155840604740318\n",
      "Epoch 4265, reconstruction losses: 0.03611325588594747, regression losses: 0.1427126815502707, validation losses: 0.4336907276112447\n",
      "Epoch 4266, reconstruction losses: 0.03224824226726683, regression losses: 0.10852541182223219, validation losses: 0.4538312630431208\n",
      "Epoch 4267, reconstruction losses: 0.039288708189651154, regression losses: 0.12179993072001366, validation losses: 0.4644218855693863\n",
      "Epoch 4268, reconstruction losses: 0.03167566564460651, regression losses: 0.12952086644479663, validation losses: 0.43695525301225513\n",
      "Epoch 4269, reconstruction losses: 0.03270394948340143, regression losses: 0.13464101067703282, validation losses: 0.3994808173405183\n",
      "Epoch 4270, reconstruction losses: 0.03389925494924891, regression losses: 0.09454855520957241, validation losses: 0.4263943218602482\n",
      "Epoch 4271, reconstruction losses: 0.035063381062981555, regression losses: 0.1030937016469938, validation losses: 0.48805200649065916\n",
      "Epoch 4272, reconstruction losses: 0.03514730725943077, regression losses: 0.11198873377543994, validation losses: 0.4661249986946657\n",
      "Epoch 4273, reconstruction losses: 0.03580640232292484, regression losses: 0.10378961482595561, validation losses: 0.4346210232608132\n",
      "Epoch 4274, reconstruction losses: 0.03515235210410653, regression losses: 0.1870606899815579, validation losses: 0.39963905788141973\n",
      "Epoch 4275, reconstruction losses: 0.03376651633460543, regression losses: 0.13370600293642554, validation losses: 0.46339505408559384\n",
      "Epoch 4276, reconstruction losses: 0.0335590386802604, regression losses: 0.18894472376597637, validation losses: 0.4098061636795748\n",
      "Epoch 4277, reconstruction losses: 0.03782003124668895, regression losses: 0.30402824728278405, validation losses: 0.6446972137704081\n",
      "Epoch 4278, reconstruction losses: 0.03402855342586211, regression losses: 0.17031496099185484, validation losses: 1.0362632158440876\n",
      "Epoch 4279, reconstruction losses: 0.03488893451428626, regression losses: 0.19720304339415107, validation losses: 0.614893579843748\n",
      "Epoch 4280, reconstruction losses: 0.03158522014362236, regression losses: 0.11314382294849966, validation losses: 0.5070100981522387\n",
      "Epoch 4281, reconstruction losses: 0.03672171259586296, regression losses: 0.11615561245625104, validation losses: 0.4445140009514385\n",
      "Epoch 4282, reconstruction losses: 0.03514898046287191, regression losses: 0.12569410614000437, validation losses: 0.44097840517338815\n",
      "Epoch 4283, reconstruction losses: 0.032681097510599215, regression losses: 0.13199410969440603, validation losses: 0.5396633770855074\n",
      "Epoch 4284, reconstruction losses: 0.033946036734960265, regression losses: 0.12170955862792125, validation losses: 0.4055851623607724\n",
      "Epoch 4285, reconstruction losses: 0.03863030496525026, regression losses: 0.11160547886312269, validation losses: 0.44227570685078155\n",
      "Epoch 4286, reconstruction losses: 0.03455536294245812, regression losses: 0.1402597146911894, validation losses: 0.47354341141674305\n",
      "Epoch 4287, reconstruction losses: 0.03439539570088947, regression losses: 0.15879978977852366, validation losses: 0.4822082072887369\n",
      "Epoch 4288, reconstruction losses: 0.0373313415160632, regression losses: 0.09252819094109752, validation losses: 0.5467383466229848\n",
      "Epoch 4289, reconstruction losses: 0.03361144998566754, regression losses: 0.16258574159057113, validation losses: 0.5203761290048398\n",
      "Epoch 4290, reconstruction losses: 0.032736763222904045, regression losses: 0.1405303371511056, validation losses: 0.4845258479704675\n",
      "Epoch 4291, reconstruction losses: 0.035720051957060926, regression losses: 0.13666570230572353, validation losses: 0.4588790869865637\n",
      "Epoch 4292, reconstruction losses: 0.033538830428388455, regression losses: 0.09749154986598159, validation losses: 0.4805355930231636\n",
      "Epoch 4293, reconstruction losses: 0.031473525940070905, regression losses: 0.11055345088943018, validation losses: 0.42082438005157663\n",
      "Epoch 4294, reconstruction losses: 0.0335166087211388, regression losses: 0.12045318551590382, validation losses: 0.43461013620447786\n",
      "Epoch 4295, reconstruction losses: 0.03409924713054989, regression losses: 0.09507790293946657, validation losses: 0.470745584154231\n",
      "Epoch 4296, reconstruction losses: 0.035713661190894266, regression losses: 0.15508300038887513, validation losses: 0.4664728229579167\n",
      "Epoch 4297, reconstruction losses: 0.041576789221856515, regression losses: 0.11951506124368083, validation losses: 0.5030159961748405\n",
      "Epoch 4298, reconstruction losses: 0.0315094096597831, regression losses: 0.1283846096464133, validation losses: 0.4121793999139994\n",
      "Epoch 4299, reconstruction losses: 0.03241046823007234, regression losses: 0.10477886051245762, validation losses: 0.44304419471668655\n",
      "Epoch 4300, reconstruction losses: 0.03246280477918099, regression losses: 0.11401544219517856, validation losses: 0.5391339341269736\n",
      "Epoch 4301, reconstruction losses: 0.03645138164861651, regression losses: 0.17220513301142065, validation losses: 0.5342931646479157\n",
      "Epoch 4302, reconstruction losses: 0.032704465091446165, regression losses: 0.1340835942937471, validation losses: 0.6115574229581211\n",
      "Epoch 4303, reconstruction losses: 0.03492448596492001, regression losses: 0.16300809865133592, validation losses: 0.5725473507557987\n",
      "Epoch 4304, reconstruction losses: 0.03343100222968711, regression losses: 0.13564069876101842, validation losses: 0.4970454506921081\n",
      "Epoch 4305, reconstruction losses: 0.0324584429046325, regression losses: 0.08309015022524166, validation losses: 0.46768795904953026\n",
      "Epoch 4306, reconstruction losses: 0.03695873706016005, regression losses: 0.13423635988451157, validation losses: 0.5717844036820894\n",
      "Epoch 4307, reconstruction losses: 0.0368426348580886, regression losses: 0.11701931235726062, validation losses: 0.6885671498612881\n",
      "Epoch 4308, reconstruction losses: 0.03355317576837222, regression losses: 0.11167269078360838, validation losses: 0.5096984714259123\n",
      "Epoch 4309, reconstruction losses: 0.0350785671949862, regression losses: 0.1540809415015486, validation losses: 0.47465039364259176\n",
      "Epoch 4310, reconstruction losses: 0.036165229431244256, regression losses: 0.13118133423512413, validation losses: 0.42437064979057953\n",
      "Epoch 4311, reconstruction losses: 0.03777447152304614, regression losses: 0.09213440295838857, validation losses: 0.46816669929442045\n",
      "Epoch 4312, reconstruction losses: 0.03361147688815622, regression losses: 0.1260896845981518, validation losses: 0.46290682721256743\n",
      "Epoch 4313, reconstruction losses: 0.032119853128916936, regression losses: 0.1365529021631705, validation losses: 0.572381779932504\n",
      "Epoch 4314, reconstruction losses: 0.0353870617782673, regression losses: 0.10547813370642296, validation losses: 0.706116010547565\n",
      "Epoch 4315, reconstruction losses: 0.038092696538003915, regression losses: 0.13330055402492735, validation losses: 0.4602161466640503\n",
      "Epoch 4316, reconstruction losses: 0.03265705433151066, regression losses: 0.09317792392646257, validation losses: 0.40196705377640934\n",
      "Epoch 4317, reconstruction losses: 0.04079406637281258, regression losses: 0.1377206310879785, validation losses: 0.4094145669316317\n",
      "Epoch 4318, reconstruction losses: 0.033503181662216254, regression losses: 0.13311229121972512, validation losses: 0.46372963921374344\n",
      "Epoch 4319, reconstruction losses: 0.03420836425374664, regression losses: 0.13028099754790895, validation losses: 0.42097207304921264\n",
      "Epoch 4320, reconstruction losses: 0.036034985776964734, regression losses: 0.1315692250587405, validation losses: 0.45389358230389315\n",
      "Epoch 4321, reconstruction losses: 0.03853389990462229, regression losses: 0.129085013932426, validation losses: 0.40236688328218084\n",
      "Epoch 4322, reconstruction losses: 0.033495731817498146, regression losses: 0.10712243453497093, validation losses: 0.4245845332462833\n",
      "Epoch 4323, reconstruction losses: 0.03322066476320127, regression losses: 0.12538724518795993, validation losses: 0.5488847529468474\n",
      "Epoch 4324, reconstruction losses: 0.040890061993481525, regression losses: 0.1171841500040339, validation losses: 0.6275108259273351\n",
      "Epoch 4325, reconstruction losses: 0.03298485179807651, regression losses: 0.12151558054777394, validation losses: 0.5567877524231161\n",
      "Epoch 4326, reconstruction losses: 0.034930099513427765, regression losses: 0.14960254788643804, validation losses: 0.46174407151973407\n",
      "Epoch 4327, reconstruction losses: 0.03180903558924249, regression losses: 0.15106768592807981, validation losses: 0.43462699651960146\n",
      "Epoch 4328, reconstruction losses: 0.037674396767825635, regression losses: 0.10452125459727037, validation losses: 0.4164757909130945\n",
      "Epoch 4329, reconstruction losses: 0.032839319890475574, regression losses: 0.1585436462520159, validation losses: 0.4530307775811861\n",
      "Epoch 4330, reconstruction losses: 0.03492527280087948, regression losses: 0.11362566929781634, validation losses: 0.6394751179091461\n",
      "Epoch 4331, reconstruction losses: 0.034903928880217885, regression losses: 0.15322751945864801, validation losses: 0.5084810547239087\n",
      "Epoch 4332, reconstruction losses: 0.03313545887897999, regression losses: 0.1274398817341518, validation losses: 0.44885493065198456\n",
      "Epoch 4333, reconstruction losses: 0.03427730002985799, regression losses: 0.13201406380168235, validation losses: 0.41172398764177287\n",
      "Epoch 4334, reconstruction losses: 0.038183227629241666, regression losses: 0.1093154183663736, validation losses: 0.5310997406372668\n",
      "Epoch 4335, reconstruction losses: 0.0342592627082632, regression losses: 0.12901456807336553, validation losses: 0.535865129511311\n",
      "Epoch 4336, reconstruction losses: 0.03546590630269557, regression losses: 0.12696704789300045, validation losses: 0.48124757128650325\n",
      "Epoch 4337, reconstruction losses: 0.03345963798220385, regression losses: 0.1428297846658541, validation losses: 0.5060227013298811\n",
      "Epoch 4338, reconstruction losses: 0.04252198125844462, regression losses: 0.15880937041189871, validation losses: 0.5566127106868336\n",
      "Epoch 4339, reconstruction losses: 0.03758875355397641, regression losses: 0.12546417259004522, validation losses: 0.41577856162779253\n",
      "Epoch 4340, reconstruction losses: 0.034309999427828815, regression losses: 0.10900069269285884, validation losses: 0.42742398483060595\n",
      "Epoch 4341, reconstruction losses: 0.040944468603015226, regression losses: 0.13712721253171983, validation losses: 0.48268412822538365\n",
      "Epoch 4342, reconstruction losses: 0.030858985364463364, regression losses: 0.11037337622141993, validation losses: 0.41262146318602827\n",
      "Epoch 4343, reconstruction losses: 0.0412746968037862, regression losses: 0.1054966070341829, validation losses: 0.4509206320761741\n",
      "Epoch 4344, reconstruction losses: 0.03485523450747868, regression losses: 0.12658616543770462, validation losses: 0.4356539461053313\n",
      "Epoch 4345, reconstruction losses: 0.035858448494495494, regression losses: 0.18015744868631253, validation losses: 0.5453926148534969\n",
      "Epoch 4346, reconstruction losses: 0.036576837174717526, regression losses: 0.13377288480674004, validation losses: 0.6497498886994859\n",
      "Epoch 4347, reconstruction losses: 0.03905653227687046, regression losses: 0.15405674772886546, validation losses: 0.46901075165362294\n",
      "Epoch 4348, reconstruction losses: 0.04179913772831091, regression losses: 0.28162918427883793, validation losses: 0.5192857399579234\n",
      "Epoch 4349, reconstruction losses: 0.032490323762671885, regression losses: 0.09945329893054869, validation losses: 0.5521829142843144\n",
      "Epoch 4350, reconstruction losses: 0.035403331197618, regression losses: 0.16426025724999335, validation losses: 0.7365061951457588\n",
      "Epoch 4351, reconstruction losses: 0.035558269894962205, regression losses: 0.13974185479925932, validation losses: 0.6646000636562721\n",
      "Epoch 4352, reconstruction losses: 0.03687019829183696, regression losses: 0.1182573059493742, validation losses: 0.40777284363552696\n",
      "Epoch 4353, reconstruction losses: 0.032830584452012965, regression losses: 0.12661999095749726, validation losses: 0.416158179347192\n",
      "Epoch 4354, reconstruction losses: 0.03261063210242554, regression losses: 0.1258896605443086, validation losses: 0.505702376261287\n",
      "Epoch 4355, reconstruction losses: 0.034771735664737874, regression losses: 0.11669460580239281, validation losses: 0.5482259033636051\n",
      "Epoch 4356, reconstruction losses: 0.03322029442932739, regression losses: 0.12169359964815125, validation losses: 0.49208690461451904\n",
      "Epoch 4357, reconstruction losses: 0.03483106216734881, regression losses: 0.13754879998033173, validation losses: 0.48750517915955116\n",
      "Epoch 4358, reconstruction losses: 0.030476019701488093, regression losses: 0.0996712816281291, validation losses: 0.5365579757731441\n",
      "Epoch 4359, reconstruction losses: 0.03715034785809495, regression losses: 0.12037298704274138, validation losses: 0.5335043567541108\n",
      "Epoch 4360, reconstruction losses: 0.0337019702194771, regression losses: 0.11322359229927982, validation losses: 0.42724354458025393\n",
      "Epoch 4361, reconstruction losses: 0.0346864134992914, regression losses: 0.157458969329492, validation losses: 0.45558968004557043\n",
      "Epoch 4362, reconstruction losses: 0.03717931725104379, regression losses: 0.11314266702521807, validation losses: 0.44596298167580856\n",
      "Epoch 4363, reconstruction losses: 0.03451071055422163, regression losses: 0.12449630137130781, validation losses: 0.43279809711309686\n",
      "Epoch 4364, reconstruction losses: 0.032092577880228304, regression losses: 0.11584184246426862, validation losses: 0.45110713304089933\n",
      "Epoch 4365, reconstruction losses: 0.030741792802375566, regression losses: 0.10959394362808565, validation losses: 0.5545538951777366\n",
      "Epoch 4366, reconstruction losses: 0.03361117704821315, regression losses: 0.11516232732679745, validation losses: 0.5480188610716339\n",
      "Epoch 4367, reconstruction losses: 0.03378488429754797, regression losses: 0.10504495855105542, validation losses: 0.47594749655749397\n",
      "Epoch 4368, reconstruction losses: 0.03304131650937431, regression losses: 0.21847194445781626, validation losses: 0.4184863967855295\n",
      "Epoch 4369, reconstruction losses: 0.03402817257229934, regression losses: 0.14738831749144457, validation losses: 0.6751121141502978\n",
      "Epoch 4370, reconstruction losses: 0.03680090944250147, regression losses: 0.11118891480854516, validation losses: 0.44308924126956706\n",
      "Epoch 4371, reconstruction losses: 0.03582702258416948, regression losses: 0.12176680968146145, validation losses: 0.4679439260455884\n",
      "Epoch 4372, reconstruction losses: 0.03354087735402292, regression losses: 0.14705408258484218, validation losses: 0.6650103617904773\n",
      "Epoch 4373, reconstruction losses: 0.03542065283783366, regression losses: 0.1190242705222188, validation losses: 0.6901184298200476\n",
      "Epoch 4374, reconstruction losses: 0.032582738578853965, regression losses: 0.10098670687175, validation losses: 0.5071317279634786\n",
      "Epoch 4375, reconstruction losses: 0.0375193864459009, regression losses: 0.12041848677870025, validation losses: 0.41287211588188355\n",
      "Epoch 4376, reconstruction losses: 0.030029257876235328, regression losses: 0.13685753514982435, validation losses: 0.4020258970503169\n",
      "Epoch 4377, reconstruction losses: 0.03377571629952389, regression losses: 0.10070477775355044, validation losses: 0.41678135190173754\n",
      "Epoch 4378, reconstruction losses: 0.03394822035199963, regression losses: 0.2324146077916735, validation losses: 0.49693931027550947\n",
      "Epoch 4379, reconstruction losses: 0.04084883492907986, regression losses: 0.12895308903301822, validation losses: 0.5960841314215095\n",
      "Epoch 4380, reconstruction losses: 0.03514883938968474, regression losses: 0.10622712880446737, validation losses: 0.5336956810335111\n",
      "Epoch 4381, reconstruction losses: 0.03348517348833478, regression losses: 0.10603443040037858, validation losses: 0.42913117851889643\n",
      "Epoch 4382, reconstruction losses: 0.03319578955073821, regression losses: 0.10002142804339142, validation losses: 0.42786948818043335\n",
      "Epoch 4383, reconstruction losses: 0.031185378540479102, regression losses: 0.19690994168735423, validation losses: 0.4225693867075657\n",
      "Epoch 4384, reconstruction losses: 0.03165071644426454, regression losses: 0.1393145898479087, validation losses: 0.45588971440450243\n",
      "Epoch 4385, reconstruction losses: 0.03245408425169609, regression losses: 0.1377336578801056, validation losses: 0.40343777268964265\n",
      "Epoch 4386, reconstruction losses: 0.037593830524345534, regression losses: 0.11149421482287245, validation losses: 0.6400494257094744\n",
      "Epoch 4387, reconstruction losses: 0.03972759824167052, regression losses: 0.12385084029742201, validation losses: 0.48592454467162455\n",
      "Epoch 4388, reconstruction losses: 0.03315175041118385, regression losses: 0.13277014936579898, validation losses: 0.4017239123012728\n",
      "Epoch 4389, reconstruction losses: 0.03276328494494878, regression losses: 0.10309314221062707, validation losses: 0.43292366290158224\n",
      "Epoch 4390, reconstruction losses: 0.03689589169856562, regression losses: 0.10671637770319253, validation losses: 0.4839758345926244\n",
      "Epoch 4391, reconstruction losses: 0.033045058570947514, regression losses: 0.10242106557539343, validation losses: 0.4830313978313876\n",
      "Epoch 4392, reconstruction losses: 0.031226366358477278, regression losses: 0.1318708967032701, validation losses: 0.44989462725398927\n",
      "Epoch 4393, reconstruction losses: 0.03371831522125029, regression losses: 0.10398696542146181, validation losses: 0.4827603926921518\n",
      "Epoch 4394, reconstruction losses: 0.0321983473146535, regression losses: 0.12838685894560767, validation losses: 0.4973331881497104\n",
      "Epoch 4395, reconstruction losses: 0.034540688867230086, regression losses: 0.14393365310333991, validation losses: 0.4741108020243036\n",
      "Epoch 4396, reconstruction losses: 0.030568446660736964, regression losses: 0.0925177774806374, validation losses: 0.5385332286321339\n",
      "Epoch 4397, reconstruction losses: 0.03330576609836176, regression losses: 0.15876186012585347, validation losses: 0.4451029638938427\n",
      "Epoch 4398, reconstruction losses: 0.033815909307269236, regression losses: 0.11239591362399944, validation losses: 0.6006147799018862\n",
      "Epoch 4399, reconstruction losses: 0.03331244036045573, regression losses: 0.14672530093489675, validation losses: 0.4607392860447492\n",
      "Epoch 4400, reconstruction losses: 0.036713962081727856, regression losses: 0.18138611936822258, validation losses: 0.4732534857991583\n",
      "Epoch 4401, reconstruction losses: 0.031097454082369618, regression losses: 0.13117723239372076, validation losses: 0.6107100264113927\n",
      "Epoch 4402, reconstruction losses: 0.03152479671132971, regression losses: 0.12964589888473152, validation losses: 0.4669569916934161\n",
      "Epoch 4403, reconstruction losses: 0.03083914000535181, regression losses: 0.08705071150292013, validation losses: 0.46416997788193753\n",
      "Epoch 4404, reconstruction losses: 0.034592573697503695, regression losses: 0.22843332578106584, validation losses: 0.42852695046075917\n",
      "Epoch 4405, reconstruction losses: 0.0333809675554751, regression losses: 0.12225544950319846, validation losses: 0.6765679231989498\n",
      "Epoch 4406, reconstruction losses: 0.033955487722294696, regression losses: 0.14278815685060958, validation losses: 0.45840787520380916\n",
      "Epoch 4407, reconstruction losses: 0.03447808322161041, regression losses: 0.16556377311387552, validation losses: 0.47844402742512065\n",
      "Epoch 4408, reconstruction losses: 0.033116104004208835, regression losses: 0.14734689678896695, validation losses: 0.4249165919222879\n",
      "Epoch 4409, reconstruction losses: 0.03180326559072115, regression losses: 0.1135947500669586, validation losses: 0.5282770971522222\n",
      "Epoch 4410, reconstruction losses: 0.03290451730755583, regression losses: 0.12024797827133542, validation losses: 0.4798208834514768\n",
      "Epoch 4411, reconstruction losses: 0.034002717271112815, regression losses: 0.13576841852678936, validation losses: 0.4457510462450282\n",
      "Epoch 4412, reconstruction losses: 0.03166546280770829, regression losses: 0.11972669418263833, validation losses: 0.4193691351297899\n",
      "Epoch 4413, reconstruction losses: 0.0339184045205464, regression losses: 0.242088939860961, validation losses: 0.47776851977524537\n",
      "Epoch 4414, reconstruction losses: 0.0332733019560451, regression losses: 0.20037215889446014, validation losses: 0.4749710034785676\n",
      "Epoch 4415, reconstruction losses: 0.03370439069414781, regression losses: 0.11710165638883466, validation losses: 0.4896674814317027\n",
      "Epoch 4416, reconstruction losses: 0.03432629003452578, regression losses: 0.11506947594233619, validation losses: 0.6554757429133062\n",
      "Epoch 4417, reconstruction losses: 0.033635714455353835, regression losses: 0.12298359297408203, validation losses: 0.6050166515247906\n",
      "Epoch 4418, reconstruction losses: 0.03329320109088033, regression losses: 0.14925185715988018, validation losses: 0.4375077127696604\n",
      "Epoch 4419, reconstruction losses: 0.029980095962138468, regression losses: 0.0927550855972973, validation losses: 0.4180527247320249\n",
      "Epoch 4420, reconstruction losses: 0.04178327186292524, regression losses: 0.12229361067472697, validation losses: 0.41221150738257806\n",
      "Epoch 4421, reconstruction losses: 0.03425620113090792, regression losses: 0.28442239930896246, validation losses: 0.4620494743060057\n",
      "Epoch 4422, reconstruction losses: 0.03396678611406913, regression losses: 0.18113871573311724, validation losses: 0.8174520619438047\n",
      "Epoch 4423, reconstruction losses: 0.033188295183177306, regression losses: 0.14357963540895102, validation losses: 0.9474024122559688\n",
      "Epoch 4424, reconstruction losses: 0.033335787726650294, regression losses: 0.15328337414375737, validation losses: 0.6179704208745855\n",
      "Epoch 4425, reconstruction losses: 0.0326571925166637, regression losses: 0.11272978120445172, validation losses: 0.48621441416220135\n",
      "Epoch 4426, reconstruction losses: 0.03497678699284006, regression losses: 0.1332767660664918, validation losses: 0.4082624877138993\n",
      "Epoch 4427, reconstruction losses: 0.03179890953117139, regression losses: 0.12707299559019, validation losses: 0.5181834438354582\n",
      "Epoch 4428, reconstruction losses: 0.03527548152376271, regression losses: 0.12581862617075246, validation losses: 0.6120389330449912\n",
      "Epoch 4429, reconstruction losses: 0.03371460661977811, regression losses: 0.12018982352761351, validation losses: 0.47803610423212217\n",
      "Epoch 4430, reconstruction losses: 0.03315021615665106, regression losses: 0.14237270400722285, validation losses: 0.39533220166567845\n",
      "Epoch 4431, reconstruction losses: 0.03769059359698608, regression losses: 0.12702096034420096, validation losses: 0.4095416153543626\n",
      "Epoch 4432, reconstruction losses: 0.03188453558989318, regression losses: 0.12508805715189447, validation losses: 0.4845001632505825\n",
      "Epoch 4433, reconstruction losses: 0.03814504047071589, regression losses: 0.17108389971697674, validation losses: 0.48866639723626754\n",
      "Epoch 4434, reconstruction losses: 0.034296152586223205, regression losses: 0.1376295790950845, validation losses: 0.39976339566561975\n",
      "Epoch 4435, reconstruction losses: 0.03973967343779312, regression losses: 0.11262094844782286, validation losses: 0.3938135347100424\n",
      "Epoch 4436, reconstruction losses: 0.037865686272131535, regression losses: 0.11309302362854591, validation losses: 0.4170015642696692\n",
      "Epoch 4437, reconstruction losses: 0.03302219806825351, regression losses: 0.10040493637353312, validation losses: 0.5405484382142998\n",
      "Epoch 4438, reconstruction losses: 0.03228961841552778, regression losses: 0.11085196618232845, validation losses: 0.560963320256058\n",
      "Epoch 4439, reconstruction losses: 0.034884053701874716, regression losses: 0.10189472095464594, validation losses: 0.4471523379514706\n",
      "Epoch 4440, reconstruction losses: 0.033525962345873926, regression losses: 0.14427695060308948, validation losses: 0.40717243308131085\n",
      "Epoch 4441, reconstruction losses: 0.034545425817761106, regression losses: 0.08534875439205974, validation losses: 0.3779594226978302\n",
      "Epoch 4442, reconstruction losses: 0.03357991438015011, regression losses: 0.13408804436739502, validation losses: 0.3842915299599758\n",
      "Epoch 4443, reconstruction losses: 0.03227059099902324, regression losses: 0.13151267464807578, validation losses: 0.4298184244600932\n",
      "Epoch 4444, reconstruction losses: 0.031235149857077385, regression losses: 0.10779922681772047, validation losses: 0.4633646752558072\n",
      "Epoch 4445, reconstruction losses: 0.03482931248456453, regression losses: 0.09519594063091912, validation losses: 0.4470181304168143\n",
      "Epoch 4446, reconstruction losses: 0.030371337070982836, regression losses: 0.13613364351026805, validation losses: 0.507924572077217\n",
      "Epoch 4447, reconstruction losses: 0.035307705195931696, regression losses: 0.13559609814944076, validation losses: 0.6482481645913518\n",
      "Epoch 4448, reconstruction losses: 0.04135596361707589, regression losses: 0.13688032690634958, validation losses: 0.45504044115815956\n",
      "Epoch 4449, reconstruction losses: 0.03440320218558674, regression losses: 0.10599010267896478, validation losses: 0.38633232162313025\n",
      "Epoch 4450, reconstruction losses: 0.03602945018637581, regression losses: 0.13475522118732994, validation losses: 0.4190091517893949\n",
      "Epoch 4451, reconstruction losses: 0.03852858715542762, regression losses: 0.1225845535962495, validation losses: 0.6022360907582663\n",
      "Epoch 4452, reconstruction losses: 0.03386147868522251, regression losses: 0.13632992358731386, validation losses: 0.554633199052046\n",
      "Epoch 4453, reconstruction losses: 0.031615364691167464, regression losses: 0.13580916110858507, validation losses: 0.48148026983220077\n",
      "Epoch 4454, reconstruction losses: 0.040503441208206155, regression losses: 0.10292633211832422, validation losses: 0.4167745607344506\n",
      "Epoch 4455, reconstruction losses: 0.02985711655530422, regression losses: 0.12102394694727939, validation losses: 0.4071151668031396\n",
      "Epoch 4456, reconstruction losses: 0.03214647759570135, regression losses: 0.14247215748433673, validation losses: 0.44702888923706025\n",
      "Epoch 4457, reconstruction losses: 0.03533251353891555, regression losses: 0.15288557697881003, validation losses: 0.4821916912808964\n",
      "Epoch 4458, reconstruction losses: 0.03874544839365385, regression losses: 0.10227250215831239, validation losses: 0.4748096006445608\n",
      "Epoch 4459, reconstruction losses: 0.03467549289137388, regression losses: 0.3006680070220716, validation losses: 0.40653513410937464\n",
      "Epoch 4460, reconstruction losses: 0.03576710755747328, regression losses: 0.19898426914603762, validation losses: 0.7509867366816166\n",
      "Epoch 4461, reconstruction losses: 0.03384088801243137, regression losses: 0.139824529507593, validation losses: 0.6829375320224907\n",
      "Epoch 4462, reconstruction losses: 0.031076794982316514, regression losses: 0.0905977250197766, validation losses: 0.5806868856660563\n",
      "Epoch 4463, reconstruction losses: 0.03293892283823174, regression losses: 0.13478583793850657, validation losses: 0.4434624367591552\n",
      "Epoch 4464, reconstruction losses: 0.03885497156656009, regression losses: 0.10653633195668456, validation losses: 0.38127440396292783\n",
      "Epoch 4465, reconstruction losses: 0.03730203255469093, regression losses: 0.11575821342218617, validation losses: 0.3962411373890553\n",
      "Epoch 4466, reconstruction losses: 0.03353552790907424, regression losses: 0.13575335775429867, validation losses: 0.49370217652542064\n",
      "Epoch 4467, reconstruction losses: 0.033560234563597115, regression losses: 0.10527181462116084, validation losses: 0.4840300227970561\n",
      "Epoch 4468, reconstruction losses: 0.03340965585742507, regression losses: 0.09794641913859864, validation losses: 0.37559198729250315\n",
      "Epoch 4469, reconstruction losses: 0.04339398279055801, regression losses: 0.11244338220991669, validation losses: 0.38131068631025566\n",
      "Epoch 4470, reconstruction losses: 0.032764783904874126, regression losses: 0.16606243529698417, validation losses: 0.39523213505503046\n",
      "Epoch 4471, reconstruction losses: 0.03213452297313642, regression losses: 0.11783206074560786, validation losses: 0.6768704186937289\n",
      "Epoch 4472, reconstruction losses: 0.03414511189561262, regression losses: 0.1291336767230385, validation losses: 0.6680459147304378\n",
      "Epoch 4473, reconstruction losses: 0.03259199510986545, regression losses: 0.12483269018056184, validation losses: 0.407392278460264\n",
      "Epoch 4474, reconstruction losses: 0.03485274794611689, regression losses: 0.13951562014498292, validation losses: 0.3878197964293444\n",
      "Epoch 4475, reconstruction losses: 0.033083143562248646, regression losses: 0.14360731800783383, validation losses: 0.45426585592392793\n",
      "Epoch 4476, reconstruction losses: 0.03334906712293532, regression losses: 0.117622480455744, validation losses: 0.5234618399506817\n",
      "Epoch 4477, reconstruction losses: 0.0322929472819123, regression losses: 0.12049142281194987, validation losses: 0.416011859229538\n",
      "Epoch 4478, reconstruction losses: 0.03372996808710921, regression losses: 0.11602867067377581, validation losses: 0.47050195882829493\n",
      "Epoch 4479, reconstruction losses: 0.032628005189087, regression losses: 0.10151703445693756, validation losses: 0.39397730389121904\n",
      "Epoch 4480, reconstruction losses: 0.042741584669372945, regression losses: 0.08829284059120082, validation losses: 0.4970114330495378\n",
      "Epoch 4481, reconstruction losses: 0.03471881500693149, regression losses: 0.16167263334778376, validation losses: 0.5006228354434938\n",
      "Epoch 4482, reconstruction losses: 0.03493633235012682, regression losses: 0.11131719793795455, validation losses: 0.5300894963328278\n",
      "Epoch 4483, reconstruction losses: 0.033470772454652534, regression losses: 0.12895914054478672, validation losses: 0.43781765130236544\n",
      "Epoch 4484, reconstruction losses: 0.0355106789828772, regression losses: 0.1262030127186149, validation losses: 0.4819662957762728\n",
      "Epoch 4485, reconstruction losses: 0.03408818133788085, regression losses: 0.1260577207976952, validation losses: 0.5666229475209456\n",
      "Epoch 4486, reconstruction losses: 0.03125210899495556, regression losses: 0.10521333640735543, validation losses: 0.47200932491859815\n",
      "Epoch 4487, reconstruction losses: 0.033863240575830345, regression losses: 0.13521302565598525, validation losses: 0.4780163929021271\n",
      "Epoch 4488, reconstruction losses: 0.03505617564426698, regression losses: 0.23372875359488193, validation losses: 0.4157154770763725\n",
      "Epoch 4489, reconstruction losses: 0.03441531868938185, regression losses: 0.10863013240163993, validation losses: 0.6320639520958895\n",
      "Epoch 4490, reconstruction losses: 0.031062597357622145, regression losses: 0.15633987540790362, validation losses: 0.4955268903672396\n",
      "Epoch 4491, reconstruction losses: 0.032118452560928934, regression losses: 0.2336998353409916, validation losses: 0.4789047033911368\n",
      "Epoch 4492, reconstruction losses: 0.03302165940895929, regression losses: 0.09914603537073621, validation losses: 0.45923558162584666\n",
      "Epoch 4493, reconstruction losses: 0.03572818224993344, regression losses: 0.2135851366414253, validation losses: 0.5931163709500238\n",
      "Epoch 4494, reconstruction losses: 0.03441489685489426, regression losses: 0.1280866979835581, validation losses: 0.7526463204650088\n",
      "Epoch 4495, reconstruction losses: 0.03323631262514349, regression losses: 0.14039694032071617, validation losses: 0.5003886738530074\n",
      "Epoch 4496, reconstruction losses: 0.032963639208072645, regression losses: 0.15244398725621114, validation losses: 0.5409485135448691\n",
      "Epoch 4497, reconstruction losses: 0.03434247026581016, regression losses: 0.1263212814477679, validation losses: 0.5673953791504914\n",
      "Epoch 4498, reconstruction losses: 0.03261710406531956, regression losses: 0.157820358359825, validation losses: 0.43992400937497744\n",
      "Epoch 4499, reconstruction losses: 0.03081912838164415, regression losses: 0.11685028397292041, validation losses: 0.45876565688542853\n",
      "Epoch 4500, reconstruction losses: 0.036967197679641524, regression losses: 0.18322709884766378, validation losses: 0.4722871470040863\n",
      "Epoch 4501, reconstruction losses: 0.031388301014768416, regression losses: 0.12287546917811527, validation losses: 0.6260433497381086\n",
      "Epoch 4502, reconstruction losses: 0.034227836865167796, regression losses: 0.206922135158648, validation losses: 0.40428185965889274\n",
      "Epoch 4503, reconstruction losses: 0.034473388534314954, regression losses: 0.14677045680684864, validation losses: 0.4152911973268073\n",
      "Epoch 4504, reconstruction losses: 0.033280700093619324, regression losses: 0.10808764457876027, validation losses: 0.5546973462013354\n",
      "Epoch 4505, reconstruction losses: 0.033088149782833615, regression losses: 0.1011116722408268, validation losses: 0.6165041135378492\n",
      "Epoch 4506, reconstruction losses: 0.041156204984202124, regression losses: 0.14379899985228656, validation losses: 0.5023406161724627\n",
      "Epoch 4507, reconstruction losses: 0.03343070582895695, regression losses: 0.1454660453449856, validation losses: 0.39247241129832994\n",
      "Epoch 4508, reconstruction losses: 0.03323292024274613, regression losses: 0.15138064558503506, validation losses: 0.47548223075498797\n",
      "Epoch 4509, reconstruction losses: 0.035083483603761956, regression losses: 0.3797111920182037, validation losses: 0.403269926168185\n",
      "Epoch 4510, reconstruction losses: 0.03340766430584167, regression losses: 0.14413690166666457, validation losses: 0.6785717546915142\n",
      "Epoch 4511, reconstruction losses: 0.03295365300048597, regression losses: 0.12514115399691758, validation losses: 0.5387927072959843\n",
      "Epoch 4512, reconstruction losses: 0.0324158679846535, regression losses: 0.17253748176408426, validation losses: 0.4965472213377735\n",
      "Epoch 4513, reconstruction losses: 0.032684379695987496, regression losses: 0.10653127599707174, validation losses: 0.47892194048982273\n",
      "Epoch 4514, reconstruction losses: 0.03375639441076933, regression losses: 0.14813322752970373, validation losses: 0.4973377848475845\n",
      "Epoch 4515, reconstruction losses: 0.036736241630322936, regression losses: 0.23163485914022683, validation losses: 0.5017718923477155\n",
      "Epoch 4516, reconstruction losses: 0.04024307439809913, regression losses: 0.12531727905459847, validation losses: 0.5701377496206537\n",
      "Epoch 4517, reconstruction losses: 0.034550708056553095, regression losses: 0.20585930716874407, validation losses: 0.43210258540404095\n",
      "Epoch 4518, reconstruction losses: 0.03868538939134369, regression losses: 0.10293464123543998, validation losses: 0.5671173082798057\n",
      "Epoch 4519, reconstruction losses: 0.040501092961704475, regression losses: 0.10870660562519807, validation losses: 0.5100141026602789\n",
      "Epoch 4520, reconstruction losses: 0.03392939889922399, regression losses: 0.13199269595885593, validation losses: 0.4223752269450989\n",
      "Epoch 4521, reconstruction losses: 0.030679971296229153, regression losses: 0.09350252576698331, validation losses: 0.38573675762564663\n",
      "Epoch 4522, reconstruction losses: 0.03166574512448488, regression losses: 0.11090509885749406, validation losses: 0.4162923809395863\n",
      "Epoch 4523, reconstruction losses: 0.034691103102353, regression losses: 0.09670622993451898, validation losses: 0.5486946034147347\n",
      "Epoch 4524, reconstruction losses: 0.03276942840026949, regression losses: 0.11549909279620099, validation losses: 0.44889540768750386\n",
      "Epoch 4525, reconstruction losses: 0.03287441136223257, regression losses: 0.1244910373225892, validation losses: 0.39298771998836285\n",
      "Epoch 4526, reconstruction losses: 0.03154077472827374, regression losses: 0.12317727351964829, validation losses: 0.39403860681195785\n",
      "Epoch 4527, reconstruction losses: 0.0362890311520213, regression losses: 0.11272544668047173, validation losses: 0.37519448228913993\n",
      "Epoch 4528, reconstruction losses: 0.03439282089934026, regression losses: 0.1975013326429072, validation losses: 0.38786493365562397\n",
      "Epoch 4529, reconstruction losses: 0.03585476108331463, regression losses: 0.1373468880667951, validation losses: 0.4898018727945636\n",
      "Epoch 4530, reconstruction losses: 0.0346334996594505, regression losses: 0.140130692212974, validation losses: 0.41512434151232336\n",
      "Epoch 4531, reconstruction losses: 0.03626044485253752, regression losses: 0.1434870042882853, validation losses: 0.4121841062070325\n",
      "Epoch 4532, reconstruction losses: 0.03350142907534637, regression losses: 0.12908123517334688, validation losses: 0.3984255869812701\n",
      "Epoch 4533, reconstruction losses: 0.03697264917966089, regression losses: 0.12490510329143847, validation losses: 0.4433306750751767\n",
      "Epoch 4534, reconstruction losses: 0.032983451453115965, regression losses: 0.11264544629382199, validation losses: 0.4765531806192528\n",
      "Epoch 4535, reconstruction losses: 0.03261556290206414, regression losses: 0.14171242661797323, validation losses: 0.4890247854506819\n",
      "Epoch 4536, reconstruction losses: 0.03252906920564818, regression losses: 0.10601757277355736, validation losses: 0.4619132623229205\n",
      "Epoch 4537, reconstruction losses: 0.03625581623755201, regression losses: 0.1001381303164563, validation losses: 0.4371096118876741\n",
      "Epoch 4538, reconstruction losses: 0.03474167532793676, regression losses: 0.1502290978342152, validation losses: 0.41462679953897297\n",
      "Epoch 4539, reconstruction losses: 0.030325658036728438, regression losses: 0.12481768321327891, validation losses: 0.40419634913972474\n",
      "Epoch 4540, reconstruction losses: 0.03810809303119751, regression losses: 0.11633965513040911, validation losses: 0.47148597024607664\n",
      "Epoch 4541, reconstruction losses: 0.033478590968765924, regression losses: 0.10356586343057066, validation losses: 0.4936989529233311\n",
      "Epoch 4542, reconstruction losses: 0.030615737831967, regression losses: 0.15833896969271294, validation losses: 0.45243911857594604\n",
      "Epoch 4543, reconstruction losses: 0.03271895555120511, regression losses: 0.1482249345354565, validation losses: 0.4051692069881819\n",
      "Epoch 4544, reconstruction losses: 0.031291474950140445, regression losses: 0.09710516057689703, validation losses: 0.44030032982558465\n",
      "Epoch 4545, reconstruction losses: 0.03512832172574786, regression losses: 0.16456229716146492, validation losses: 0.46748863697094434\n",
      "Epoch 4546, reconstruction losses: 0.03344784264091226, regression losses: 0.12705602714702413, validation losses: 0.5081156041895939\n",
      "Epoch 4547, reconstruction losses: 0.035045080392874975, regression losses: 0.1137766712054748, validation losses: 0.4187077706715281\n",
      "Epoch 4548, reconstruction losses: 0.035435502865848234, regression losses: 0.11103235241180333, validation losses: 0.41228155371088654\n",
      "Epoch 4549, reconstruction losses: 0.03121329206936906, regression losses: 0.13123223426346325, validation losses: 0.4721636470966611\n",
      "Epoch 4550, reconstruction losses: 0.033978138060360534, regression losses: 0.09982665087594653, validation losses: 0.7016463176556844\n",
      "Epoch 4551, reconstruction losses: 0.03186111997378032, regression losses: 0.13460317925325174, validation losses: 0.5325884434018409\n",
      "Epoch 4552, reconstruction losses: 0.03745101361412035, regression losses: 0.1351124772481705, validation losses: 0.42421893431734325\n",
      "Epoch 4553, reconstruction losses: 0.03454581825959047, regression losses: 0.10526249447125668, validation losses: 0.42667931074523224\n",
      "Epoch 4554, reconstruction losses: 0.03736439726653587, regression losses: 0.13128637675543117, validation losses: 0.39267409160514327\n",
      "Epoch 4555, reconstruction losses: 0.035972327762312156, regression losses: 0.2102906875143773, validation losses: 0.45997824122138997\n",
      "Epoch 4556, reconstruction losses: 0.03630619794526872, regression losses: 0.12628884346347058, validation losses: 0.793371335662416\n",
      "Epoch 4557, reconstruction losses: 0.034433583025501355, regression losses: 0.12583045939916068, validation losses: 0.46768353048814265\n",
      "Epoch 4558, reconstruction losses: 0.03125526709504486, regression losses: 0.12237787512077761, validation losses: 0.4275006020899103\n",
      "Epoch 4559, reconstruction losses: 0.03595964979321557, regression losses: 0.0872672036476178, validation losses: 0.4452444352690997\n",
      "Epoch 4560, reconstruction losses: 0.03229792977119919, regression losses: 0.1004375735671534, validation losses: 0.5096134975559595\n",
      "Epoch 4561, reconstruction losses: 0.03824352112481964, regression losses: 0.14774877290158495, validation losses: 0.47402250887351105\n",
      "Epoch 4562, reconstruction losses: 0.03169130203802208, regression losses: 0.09870478131367046, validation losses: 0.4134000727372512\n",
      "Epoch 4563, reconstruction losses: 0.033752341902467155, regression losses: 0.13130512770152306, validation losses: 0.4122674870577805\n",
      "Epoch 4564, reconstruction losses: 0.042072418889585426, regression losses: 0.0943976761355901, validation losses: 0.48133181366215844\n",
      "Epoch 4565, reconstruction losses: 0.031059589218953982, regression losses: 0.11249521119332755, validation losses: 0.46288245885193674\n",
      "Epoch 4566, reconstruction losses: 0.03162716475720398, regression losses: 0.10291698178260887, validation losses: 0.4375561818169883\n",
      "Epoch 4567, reconstruction losses: 0.03152546653373108, regression losses: 0.12349487340463709, validation losses: 0.4077602159543249\n",
      "Epoch 4568, reconstruction losses: 0.03669833009621331, regression losses: 0.15807038197315945, validation losses: 0.4172072785679491\n",
      "Epoch 4569, reconstruction losses: 0.033760760885329526, regression losses: 0.11138800635975858, validation losses: 0.40714171877356387\n",
      "Epoch 4570, reconstruction losses: 0.04153169806539672, regression losses: 0.123238745933787, validation losses: 0.4583563773597502\n",
      "Epoch 4571, reconstruction losses: 0.030193354816542933, regression losses: 0.11483956588790446, validation losses: 0.4365978690842508\n",
      "Epoch 4572, reconstruction losses: 0.03293228238456001, regression losses: 0.10764050972801438, validation losses: 0.4127271730777186\n",
      "Epoch 4573, reconstruction losses: 0.03322535848824939, regression losses: 0.1141794313063167, validation losses: 0.48028670195372863\n",
      "Epoch 4574, reconstruction losses: 0.0361405945531958, regression losses: 0.10813811702953217, validation losses: 0.497670564664745\n",
      "Epoch 4575, reconstruction losses: 0.03067776838958654, regression losses: 0.13327626895779654, validation losses: 0.4788836150141373\n",
      "Epoch 4576, reconstruction losses: 0.03499813714777362, regression losses: 0.148549755688326, validation losses: 0.40676852111128237\n",
      "Epoch 4577, reconstruction losses: 0.033258414778320144, regression losses: 0.09567486913720513, validation losses: 0.44282236737777025\n",
      "Epoch 4578, reconstruction losses: 0.03432381564776094, regression losses: 0.12014549102914285, validation losses: 0.49280212778334936\n",
      "Epoch 4579, reconstruction losses: 0.03394339607575006, regression losses: 0.14152292690202303, validation losses: 0.5652365656131421\n",
      "Epoch 4580, reconstruction losses: 0.033207974763497704, regression losses: 0.1261520725375434, validation losses: 0.45947623176470703\n",
      "Epoch 4581, reconstruction losses: 0.0348496029169073, regression losses: 0.1410282047867341, validation losses: 0.47278760867777614\n",
      "Epoch 4582, reconstruction losses: 0.03052692932175812, regression losses: 0.12245179425694153, validation losses: 0.6130227276536855\n",
      "Epoch 4583, reconstruction losses: 0.0322955357689449, regression losses: 0.25297069526823157, validation losses: 0.44256500482790667\n",
      "Epoch 4584, reconstruction losses: 0.036315275892099506, regression losses: 0.11349529828198153, validation losses: 0.4506106072367675\n",
      "Epoch 4585, reconstruction losses: 0.036344575528517664, regression losses: 0.09737509914199466, validation losses: 0.4580567645681709\n",
      "Epoch 4586, reconstruction losses: 0.035887002797078196, regression losses: 0.13558934358445132, validation losses: 0.47099044216910146\n",
      "Epoch 4587, reconstruction losses: 0.03214925569712945, regression losses: 0.08109652199253319, validation losses: 0.4859625348636332\n",
      "Epoch 4588, reconstruction losses: 0.03295951231281201, regression losses: 0.10339461973669972, validation losses: 0.4572906111516427\n",
      "Epoch 4589, reconstruction losses: 0.03470783021480598, regression losses: 0.15650039264933438, validation losses: 0.4665465437043535\n",
      "Epoch 4590, reconstruction losses: 0.032105821662844716, regression losses: 0.13348671462131356, validation losses: 0.6019500049711778\n",
      "Epoch 4591, reconstruction losses: 0.03577101119259425, regression losses: 0.2182516236508863, validation losses: 0.45936343746281993\n",
      "Epoch 4592, reconstruction losses: 0.03289775823053062, regression losses: 0.15866998444068636, validation losses: 0.6847768652824506\n",
      "Epoch 4593, reconstruction losses: 0.042972948699475856, regression losses: 0.14552159092318517, validation losses: 0.5877493525667861\n",
      "Epoch 4594, reconstruction losses: 0.03246452444526019, regression losses: 0.10627666913126929, validation losses: 0.44510614055342856\n",
      "Epoch 4595, reconstruction losses: 0.04024816585344431, regression losses: 0.11505617972185349, validation losses: 0.4380422618675523\n",
      "Epoch 4596, reconstruction losses: 0.032862164824229254, regression losses: 0.12108220490961147, validation losses: 0.5378198062941129\n",
      "Epoch 4597, reconstruction losses: 0.03302003003811022, regression losses: 0.09662156056745952, validation losses: 0.5998424411730725\n",
      "Epoch 4598, reconstruction losses: 0.03259588102895937, regression losses: 0.10188025590403395, validation losses: 0.47777200120424734\n",
      "Epoch 4599, reconstruction losses: 0.030443136068778534, regression losses: 0.10442577186934922, validation losses: 0.4383294636629006\n",
      "Epoch 4600, reconstruction losses: 0.0359284802930519, regression losses: 0.08971805100862529, validation losses: 0.4384259596194109\n",
      "Epoch 4601, reconstruction losses: 0.033220261733359256, regression losses: 0.13353892407229215, validation losses: 0.45263039904607816\n",
      "Epoch 4602, reconstruction losses: 0.03821167582609442, regression losses: 0.1134186954541971, validation losses: 0.5120200968675798\n",
      "Epoch 4603, reconstruction losses: 0.039388290008447374, regression losses: 0.12925828431521372, validation losses: 0.4408725565728282\n",
      "Epoch 4604, reconstruction losses: 0.03321904315263194, regression losses: 0.11404328347666476, validation losses: 0.4472086705227536\n",
      "Epoch 4605, reconstruction losses: 0.03065142813244981, regression losses: 0.1445482536428943, validation losses: 0.4559865890517688\n",
      "Epoch 4606, reconstruction losses: 0.035128292664059486, regression losses: 0.15749013570741283, validation losses: 0.5362582376569552\n",
      "Epoch 4607, reconstruction losses: 0.030794736204863404, regression losses: 0.1579332914405758, validation losses: 0.598913133537017\n",
      "Epoch 4608, reconstruction losses: 0.031387212344733253, regression losses: 0.1749553081086676, validation losses: 0.477902607459631\n",
      "Epoch 4609, reconstruction losses: 0.031738742259618265, regression losses: 0.09325495993563843, validation losses: 0.4782581408596003\n",
      "Epoch 4610, reconstruction losses: 0.03432973341212, regression losses: 0.12345067433135262, validation losses: 0.4608995725260688\n",
      "Epoch 4611, reconstruction losses: 0.032234108601126174, regression losses: 0.11862907980302151, validation losses: 0.43876943430235826\n",
      "Epoch 4612, reconstruction losses: 0.03353530122631296, regression losses: 0.1190672707563814, validation losses: 0.4202289094377393\n",
      "Epoch 4613, reconstruction losses: 0.038147346346410066, regression losses: 0.12460952475085513, validation losses: 0.4679150094319091\n",
      "Epoch 4614, reconstruction losses: 0.030751743280088364, regression losses: 0.10702247642882971, validation losses: 0.49637645026851474\n",
      "Epoch 4615, reconstruction losses: 0.033448812280879994, regression losses: 0.1191288451611031, validation losses: 0.4722779355145392\n",
      "Epoch 4616, reconstruction losses: 0.03715261865229565, regression losses: 0.3223495703421055, validation losses: 0.44636159606783854\n",
      "Epoch 4617, reconstruction losses: 0.03517555502942884, regression losses: 0.11532601169580377, validation losses: 0.589798520507431\n",
      "Epoch 4618, reconstruction losses: 0.033104549074413625, regression losses: 0.15254305500524565, validation losses: 0.5258613354866192\n",
      "Epoch 4619, reconstruction losses: 0.029704421282494956, regression losses: 0.11129399435869874, validation losses: 0.5178333893451663\n",
      "Epoch 4620, reconstruction losses: 0.036617946580368224, regression losses: 0.16682282952682773, validation losses: 0.41768702875124514\n",
      "Epoch 4621, reconstruction losses: 0.034692139462459165, regression losses: 0.12829118273715637, validation losses: 0.4068182889149073\n",
      "Epoch 4622, reconstruction losses: 0.0331231857361687, regression losses: 0.1589814199312732, validation losses: 0.4731894972428344\n",
      "Epoch 4623, reconstruction losses: 0.03718207733883712, regression losses: 0.10534013506939577, validation losses: 0.7822655181232433\n",
      "Epoch 4624, reconstruction losses: 0.03797342874408159, regression losses: 0.11877533504133793, validation losses: 0.696970937044958\n",
      "Epoch 4625, reconstruction losses: 0.03362158607120731, regression losses: 0.1111217147891928, validation losses: 0.4460802224109736\n",
      "Epoch 4626, reconstruction losses: 0.03338914347922761, regression losses: 0.09208918474433644, validation losses: 0.42559093040333296\n",
      "Epoch 4627, reconstruction losses: 0.032781297504630144, regression losses: 0.11575198591824248, validation losses: 0.4335636452620252\n",
      "Epoch 4628, reconstruction losses: 0.030801452145350378, regression losses: 0.10411238272373947, validation losses: 0.4074924906392259\n",
      "Epoch 4629, reconstruction losses: 0.031527987189659705, regression losses: 0.10100410875687414, validation losses: 0.5063143639645709\n",
      "Epoch 4630, reconstruction losses: 0.03862501103038783, regression losses: 0.0956442943321116, validation losses: 0.5652158587945592\n",
      "Epoch 4631, reconstruction losses: 0.03214757294603672, regression losses: 0.1074869782646042, validation losses: 0.41036308800104293\n",
      "Epoch 4632, reconstruction losses: 0.03452471223643711, regression losses: 0.14258192914766815, validation losses: 0.4048197465124269\n",
      "Epoch 4633, reconstruction losses: 0.03228973283742587, regression losses: 0.13187636429362318, validation losses: 0.448788993080119\n",
      "Epoch 4634, reconstruction losses: 0.0342787870886333, regression losses: 0.19543169312256392, validation losses: 0.463812626972174\n",
      "Epoch 4635, reconstruction losses: 0.03425662373308451, regression losses: 0.1639920027019313, validation losses: 0.5031519301171004\n",
      "Epoch 4636, reconstruction losses: 0.031158984197567567, regression losses: 0.10983569596230593, validation losses: 0.4603490577603568\n",
      "Epoch 4637, reconstruction losses: 0.035588329481001414, regression losses: 0.16172941368254165, validation losses: 0.4865308885906831\n",
      "Epoch 4638, reconstruction losses: 0.03464030058517171, regression losses: 0.13241146169185253, validation losses: 0.47541508191911985\n",
      "Epoch 4639, reconstruction losses: 0.04160508580948923, regression losses: 0.14215103360644354, validation losses: 0.5723082823567924\n",
      "Epoch 4640, reconstruction losses: 0.031550891782172644, regression losses: 0.11781070655807577, validation losses: 0.4238693930952886\n",
      "Epoch 4641, reconstruction losses: 0.03335360459299077, regression losses: 0.13143349761878192, validation losses: 0.4725117443737166\n",
      "Epoch 4642, reconstruction losses: 0.035183221870049006, regression losses: 0.16088497730618803, validation losses: 0.5502713815463941\n",
      "Epoch 4643, reconstruction losses: 0.03934692780565161, regression losses: 0.23875160907919107, validation losses: 0.7111571490759935\n",
      "Epoch 4644, reconstruction losses: 0.03127295157188834, regression losses: 0.1419315482933311, validation losses: 0.5964080330557062\n",
      "Epoch 4645, reconstruction losses: 0.035750185134978706, regression losses: 0.15120742184773808, validation losses: 0.46892537221898023\n",
      "Epoch 4646, reconstruction losses: 0.03345217821225594, regression losses: 0.1428759293382255, validation losses: 0.5750895136520401\n",
      "Epoch 4647, reconstruction losses: 0.03409665147986729, regression losses: 0.13223910841942885, validation losses: 0.615569498821053\n",
      "Epoch 4648, reconstruction losses: 0.03865459385375421, regression losses: 0.12235468220237344, validation losses: 0.40992656097895447\n",
      "Epoch 4649, reconstruction losses: 0.03460234495604489, regression losses: 0.27505638817548295, validation losses: 0.45723292999543214\n",
      "Epoch 4650, reconstruction losses: 0.03284592912140931, regression losses: 0.1250658108908212, validation losses: 0.6728886080347245\n",
      "Epoch 4651, reconstruction losses: 0.03136335945934133, regression losses: 0.14793931927868906, validation losses: 0.5449061986830914\n",
      "Epoch 4652, reconstruction losses: 0.03670091979513042, regression losses: 0.1196723223015369, validation losses: 0.6292621652423589\n",
      "Epoch 4653, reconstruction losses: 0.03358778641353295, regression losses: 0.12710800382937557, validation losses: 0.5009519563815961\n",
      "Epoch 4654, reconstruction losses: 0.0321407114738823, regression losses: 0.10248404570471938, validation losses: 0.4327998751634501\n",
      "Epoch 4655, reconstruction losses: 0.03173951699593169, regression losses: 0.12061742396592573, validation losses: 0.44794218313755557\n",
      "Epoch 4656, reconstruction losses: 0.035649680235402575, regression losses: 0.1027574721467172, validation losses: 0.4955319100390207\n",
      "Epoch 4657, reconstruction losses: 0.03719274642698788, regression losses: 0.11703908247865542, validation losses: 0.4715406335781248\n",
      "Epoch 4658, reconstruction losses: 0.03256949103620048, regression losses: 0.11014972517758993, validation losses: 0.4376335426916188\n",
      "Epoch 4659, reconstruction losses: 0.03503183845098013, regression losses: 0.139122695078051, validation losses: 0.5365745978540643\n",
      "Epoch 4660, reconstruction losses: 0.037880354274779635, regression losses: 0.24487817406572218, validation losses: 0.4852314364174338\n",
      "Epoch 4661, reconstruction losses: 0.03083107743753636, regression losses: 0.1326160912893214, validation losses: 0.4695445219330435\n",
      "Epoch 4662, reconstruction losses: 0.032170963051818664, regression losses: 0.11363555776723772, validation losses: 0.39611649319194847\n",
      "Epoch 4663, reconstruction losses: 0.03208063098980888, regression losses: 0.10171830469598256, validation losses: 0.6218745936250851\n",
      "Epoch 4664, reconstruction losses: 0.034987378609456714, regression losses: 0.11673732850161807, validation losses: 0.4504849923475539\n",
      "Epoch 4665, reconstruction losses: 0.03393691919369297, regression losses: 0.12476486316800277, validation losses: 0.4055938826015884\n",
      "Epoch 4666, reconstruction losses: 0.03213591063019215, regression losses: 0.11467007146801296, validation losses: 0.44434325994840407\n",
      "Epoch 4667, reconstruction losses: 0.0331614238608397, regression losses: 0.1215845398191976, validation losses: 0.4201517017985088\n",
      "Epoch 4668, reconstruction losses: 0.03161107347759981, regression losses: 0.13104060247141974, validation losses: 0.518938409772021\n",
      "Epoch 4669, reconstruction losses: 0.03819099040368077, regression losses: 0.228976004310683, validation losses: 0.5691460181872178\n",
      "Epoch 4670, reconstruction losses: 0.03287740865510707, regression losses: 0.12068089116979953, validation losses: 0.9038125281813394\n",
      "Epoch 4671, reconstruction losses: 0.034359627213587825, regression losses: 0.15357874974469832, validation losses: 0.5674607110359279\n",
      "Epoch 4672, reconstruction losses: 0.03389479640169247, regression losses: 0.11854748449885431, validation losses: 0.4484142748497214\n",
      "Epoch 4673, reconstruction losses: 0.03300890002089277, regression losses: 0.14747847851390036, validation losses: 0.41377553915125365\n",
      "Epoch 4674, reconstruction losses: 0.03288022955696064, regression losses: 0.13675697072327528, validation losses: 0.4342578098770807\n",
      "Epoch 4675, reconstruction losses: 0.03123350134777504, regression losses: 0.11959575173610659, validation losses: 0.4377782740359341\n",
      "Epoch 4676, reconstruction losses: 0.032540634243221504, regression losses: 0.13390683224326103, validation losses: 0.5652528177772298\n",
      "Epoch 4677, reconstruction losses: 0.030465014260043884, regression losses: 0.12544934788170234, validation losses: 0.5723851777104149\n",
      "Epoch 4678, reconstruction losses: 0.030728162908486546, regression losses: 0.11492787885299631, validation losses: 0.5706986482964168\n",
      "Epoch 4679, reconstruction losses: 0.038502017691165374, regression losses: 0.16071413870739537, validation losses: 0.4822201196692156\n",
      "Epoch 4680, reconstruction losses: 0.03368508989960364, regression losses: 0.10912603058611361, validation losses: 0.44746504951025234\n",
      "Epoch 4681, reconstruction losses: 0.032512151619444055, regression losses: 0.1431938653268024, validation losses: 0.4079792038365426\n",
      "Epoch 4682, reconstruction losses: 0.03563995287219278, regression losses: 0.11020415150858695, validation losses: 0.4512358911795974\n",
      "Epoch 4683, reconstruction losses: 0.03191799350308137, regression losses: 0.08687207171167186, validation losses: 0.4869883119267783\n",
      "Epoch 4684, reconstruction losses: 0.03139057411515903, regression losses: 0.1592119757901274, validation losses: 0.4269622190569746\n",
      "Epoch 4685, reconstruction losses: 0.03491796718192615, regression losses: 0.11589188052863686, validation losses: 0.42804430063103804\n",
      "Epoch 4686, reconstruction losses: 0.032936726620568346, regression losses: 0.12268684817756471, validation losses: 0.45061408264884845\n",
      "Epoch 4687, reconstruction losses: 0.03340563649397311, regression losses: 0.1279029474669744, validation losses: 0.4143898586241701\n",
      "Epoch 4688, reconstruction losses: 0.03116445319184839, regression losses: 0.0764777035213465, validation losses: 0.4224025592557518\n",
      "Epoch 4689, reconstruction losses: 0.030714610974511395, regression losses: 0.10621237989079052, validation losses: 0.4675439478860834\n",
      "Epoch 4690, reconstruction losses: 0.03153799399700821, regression losses: 0.09888396600013225, validation losses: 0.4343486423152532\n",
      "Epoch 4691, reconstruction losses: 0.03134694991472202, regression losses: 0.10200449013208839, validation losses: 0.4403571955482611\n",
      "Epoch 4692, reconstruction losses: 0.033090087792943916, regression losses: 0.1605153133715173, validation losses: 0.4308688370030686\n",
      "Epoch 4693, reconstruction losses: 0.030701712791398744, regression losses: 0.12162075085516562, validation losses: 0.5597758551584648\n",
      "Epoch 4694, reconstruction losses: 0.034467707937322636, regression losses: 0.10323895454732535, validation losses: 0.4654871055379473\n",
      "Epoch 4695, reconstruction losses: 0.03243411342636223, regression losses: 0.13319470910654352, validation losses: 0.40468853675518557\n",
      "Epoch 4696, reconstruction losses: 0.033927159692982115, regression losses: 0.1412826366040154, validation losses: 0.4538270118665557\n",
      "Epoch 4697, reconstruction losses: 0.033191022243658046, regression losses: 0.13200769444673036, validation losses: 0.44917734477609506\n",
      "Epoch 4698, reconstruction losses: 0.031209038778658417, regression losses: 0.1078688939637359, validation losses: 0.42082810704218565\n",
      "Epoch 4699, reconstruction losses: 0.03343454238184845, regression losses: 0.15039974303572462, validation losses: 0.40176418958314386\n",
      "Epoch 4700, reconstruction losses: 0.03477244860341932, regression losses: 0.17221021513464024, validation losses: 0.3971577885695664\n",
      "Epoch 4701, reconstruction losses: 0.03366354389530198, regression losses: 0.11769530409362469, validation losses: 0.6508104973669863\n",
      "Epoch 4702, reconstruction losses: 0.0340121767451131, regression losses: 0.17075081580346704, validation losses: 0.8656977684731975\n",
      "Epoch 4703, reconstruction losses: 0.03749075087314647, regression losses: 0.20363087069318597, validation losses: 0.6732512136026254\n",
      "Epoch 4704, reconstruction losses: 0.0332134154951904, regression losses: 0.1169795360734088, validation losses: 0.621965666335553\n",
      "Epoch 4705, reconstruction losses: 0.03645950783889837, regression losses: 0.13301772202867043, validation losses: 0.4332963065589736\n",
      "Epoch 4706, reconstruction losses: 0.03736334130453339, regression losses: 0.1404079542109763, validation losses: 0.4311039176706683\n",
      "Epoch 4707, reconstruction losses: 0.0305330761091403, regression losses: 0.11991122787351213, validation losses: 0.44472439041939715\n",
      "Epoch 4708, reconstruction losses: 0.0356664551850691, regression losses: 0.12450294179832562, validation losses: 0.4890272072295947\n",
      "Epoch 4709, reconstruction losses: 0.032038265101442, regression losses: 0.09391116157432955, validation losses: 0.4557870414909988\n",
      "Epoch 4710, reconstruction losses: 0.03085296346209405, regression losses: 0.13174265828993997, validation losses: 0.43696430407361475\n",
      "Epoch 4711, reconstruction losses: 0.031201168165053257, regression losses: 0.09914979185899003, validation losses: 0.4617560930357297\n",
      "Epoch 4712, reconstruction losses: 0.03509915137916877, regression losses: 0.0996164765076766, validation losses: 0.4478200070897746\n",
      "Epoch 4713, reconstruction losses: 0.032081776545074936, regression losses: 0.10465790029717671, validation losses: 0.46118851865135113\n",
      "Epoch 4714, reconstruction losses: 0.03251507159065506, regression losses: 0.15704294278249714, validation losses: 0.5721043193195033\n",
      "Epoch 4715, reconstruction losses: 0.035519562035692696, regression losses: 0.0911215404340025, validation losses: 0.5798232460019449\n",
      "Epoch 4716, reconstruction losses: 0.03375866964065057, regression losses: 0.09498784702414945, validation losses: 0.47157656096333606\n",
      "Epoch 4717, reconstruction losses: 0.03446820498067083, regression losses: 0.2577076819232147, validation losses: 0.4166042049727612\n",
      "Epoch 4718, reconstruction losses: 0.03147758195727048, regression losses: 0.1669875962211024, validation losses: 0.7170654971788095\n",
      "Epoch 4719, reconstruction losses: 0.033717418585741274, regression losses: 0.14230725575481917, validation losses: 0.4336074644123775\n",
      "Epoch 4720, reconstruction losses: 0.03429480820081611, regression losses: 0.12953288420477635, validation losses: 0.616569121846809\n",
      "Epoch 4721, reconstruction losses: 0.030157380850287838, regression losses: 0.12402238349969237, validation losses: 0.5364056791499497\n",
      "Epoch 4722, reconstruction losses: 0.035312286424296034, regression losses: 0.13523244810948823, validation losses: 0.4083909871604316\n",
      "Epoch 4723, reconstruction losses: 0.032237267370381746, regression losses: 0.15547375215768952, validation losses: 0.413147673252223\n",
      "Epoch 4724, reconstruction losses: 0.03287564647711393, regression losses: 0.13720641738793438, validation losses: 0.5547903112212003\n",
      "Epoch 4725, reconstruction losses: 0.036463655455246165, regression losses: 0.1333225784906359, validation losses: 0.5024022867044036\n",
      "Epoch 4726, reconstruction losses: 0.03333386460530101, regression losses: 0.10802649686419527, validation losses: 0.42436344715334595\n",
      "Epoch 4727, reconstruction losses: 0.0343156705777671, regression losses: 0.12268398962545941, validation losses: 0.40075774415359017\n",
      "Epoch 4728, reconstruction losses: 0.03639241358706918, regression losses: 0.14819736693001548, validation losses: 0.5264884158305366\n",
      "Epoch 4729, reconstruction losses: 0.036476928658845074, regression losses: 0.24315411190861053, validation losses: 0.5876110238308944\n",
      "Epoch 4730, reconstruction losses: 0.036189985530503344, regression losses: 0.13646202476712982, validation losses: 0.5732425081022441\n",
      "Epoch 4731, reconstruction losses: 0.03589152926203686, regression losses: 0.15254687406573128, validation losses: 0.48954888920589623\n",
      "Epoch 4732, reconstruction losses: 0.030666971165307748, regression losses: 0.12324354909617431, validation losses: 0.5009376228372691\n",
      "Epoch 4733, reconstruction losses: 0.03872472335466261, regression losses: 0.12258923301506604, validation losses: 0.5069354599481557\n",
      "Epoch 4734, reconstruction losses: 0.03531142209729203, regression losses: 0.09922019725568271, validation losses: 0.4809393501139168\n",
      "Epoch 4735, reconstruction losses: 0.031114250754938164, regression losses: 0.1434003512387426, validation losses: 0.4779748805387895\n",
      "Epoch 4736, reconstruction losses: 0.030957848325809733, regression losses: 0.08729723757180946, validation losses: 0.43555077067264414\n",
      "Epoch 4737, reconstruction losses: 0.03220042266884389, regression losses: 0.11668562391330772, validation losses: 0.4741559309614526\n",
      "Epoch 4738, reconstruction losses: 0.03274841813721578, regression losses: 0.10392602840795317, validation losses: 0.4840236825841985\n",
      "Epoch 4739, reconstruction losses: 0.03570287599406122, regression losses: 0.1236473423021076, validation losses: 0.4628289458602775\n",
      "Epoch 4740, reconstruction losses: 0.03239990504226492, regression losses: 0.09112326164260465, validation losses: 0.41436029410434877\n",
      "Epoch 4741, reconstruction losses: 0.03237530633761747, regression losses: 0.12355394519090694, validation losses: 0.41945331736201547\n",
      "Epoch 4742, reconstruction losses: 0.03430427464110785, regression losses: 0.12119795424425442, validation losses: 0.49135247650667513\n",
      "Epoch 4743, reconstruction losses: 0.04095862135979247, regression losses: 0.3010747949982343, validation losses: 0.486192544916925\n",
      "Epoch 4744, reconstruction losses: 0.04009050014151836, regression losses: 0.1370389376546292, validation losses: 0.7069425549502756\n",
      "Epoch 4745, reconstruction losses: 0.03675330847131063, regression losses: 0.2381845234478314, validation losses: 0.6831879786662534\n",
      "Epoch 4746, reconstruction losses: 0.03139815835986829, regression losses: 0.14371203526490678, validation losses: 0.5463911114629041\n",
      "Epoch 4747, reconstruction losses: 0.032365322247505865, regression losses: 0.15354506095390225, validation losses: 0.6065964401839289\n",
      "Epoch 4748, reconstruction losses: 0.033867583130103816, regression losses: 0.1497169362367533, validation losses: 0.38764352651871664\n",
      "Epoch 4749, reconstruction losses: 0.031963665502793163, regression losses: 0.10117632510070475, validation losses: 0.4423639149228353\n",
      "Epoch 4750, reconstruction losses: 0.03013488469257383, regression losses: 0.1264918022135253, validation losses: 0.4531501342278518\n",
      "Epoch 4751, reconstruction losses: 0.03198055406436688, regression losses: 0.1236101107632241, validation losses: 0.44134711276106725\n",
      "Epoch 4752, reconstruction losses: 0.0307367017606999, regression losses: 0.11552015339246, validation losses: 0.44268585854076165\n",
      "Epoch 4753, reconstruction losses: 0.03546028220250864, regression losses: 0.12768111438252666, validation losses: 0.4200156373002901\n",
      "Epoch 4754, reconstruction losses: 0.03316098811659991, regression losses: 0.11066090031118579, validation losses: 0.4542937193191218\n",
      "Epoch 4755, reconstruction losses: 0.0355614560453466, regression losses: 0.1283052416327197, validation losses: 0.4502875985527325\n",
      "Epoch 4756, reconstruction losses: 0.030848008099748147, regression losses: 0.10277867243644054, validation losses: 0.40881210033814763\n",
      "Epoch 4757, reconstruction losses: 0.03369794957016999, regression losses: 0.13543928722642778, validation losses: 0.4650682189655706\n",
      "Epoch 4758, reconstruction losses: 0.030298098708000744, regression losses: 0.11554425325642448, validation losses: 0.5777749504656023\n",
      "Epoch 4759, reconstruction losses: 0.038799207053445126, regression losses: 0.10742282861198126, validation losses: 0.46588587429647627\n",
      "Epoch 4760, reconstruction losses: 0.03786115996516589, regression losses: 0.08017884337546369, validation losses: 0.4118027500549915\n",
      "Epoch 4761, reconstruction losses: 0.03072921827445411, regression losses: 0.13469516065514023, validation losses: 0.4211486721546212\n",
      "Epoch 4762, reconstruction losses: 0.0338768714686123, regression losses: 0.14121473965575826, validation losses: 0.42433745741802414\n",
      "Epoch 4763, reconstruction losses: 0.03160455641613936, regression losses: 0.09192584038645125, validation losses: 0.5243425066652038\n",
      "Epoch 4764, reconstruction losses: 0.030211666827697794, regression losses: 0.1100666900477687, validation losses: 0.474113496219994\n",
      "Epoch 4765, reconstruction losses: 0.0338855243079877, regression losses: 0.13291987972859376, validation losses: 0.4183010178765787\n",
      "Epoch 4766, reconstruction losses: 0.03372005479923325, regression losses: 0.14128734520381453, validation losses: 0.5441975166491693\n",
      "Epoch 4767, reconstruction losses: 0.0365807954303455, regression losses: 0.12135510378108089, validation losses: 0.45301454090823323\n",
      "Epoch 4768, reconstruction losses: 0.033138412909753015, regression losses: 0.11891527190874468, validation losses: 0.5391483523643481\n",
      "Epoch 4769, reconstruction losses: 0.036675598531134945, regression losses: 0.10622530415713205, validation losses: 0.6519599530928004\n",
      "Epoch 4770, reconstruction losses: 0.033672454899588575, regression losses: 0.13726742737740685, validation losses: 0.5012965414831521\n",
      "Epoch 4771, reconstruction losses: 0.03036154871172776, regression losses: 0.12378845909889125, validation losses: 0.5503972869294312\n",
      "Epoch 4772, reconstruction losses: 0.0337543712243554, regression losses: 0.09303592635897373, validation losses: 0.5232087223028146\n",
      "Epoch 4773, reconstruction losses: 0.0373347875343078, regression losses: 0.09214185742021219, validation losses: 0.543994420529227\n",
      "Epoch 4774, reconstruction losses: 0.04002152089241953, regression losses: 0.10061716360936908, validation losses: 0.4908475326690552\n",
      "Epoch 4775, reconstruction losses: 0.030680504397370488, regression losses: 0.15305472452864782, validation losses: 0.475919757126353\n",
      "Epoch 4776, reconstruction losses: 0.03168433423787251, regression losses: 0.10469513246198969, validation losses: 0.4681286974093145\n",
      "Epoch 4777, reconstruction losses: 0.03220155537371692, regression losses: 0.1233583295812394, validation losses: 0.5166702226231414\n",
      "Epoch 4778, reconstruction losses: 0.03441545356087605, regression losses: 0.15091557365336827, validation losses: 0.5038222985984863\n",
      "Epoch 4779, reconstruction losses: 0.03507010032970114, regression losses: 0.09299122477975441, validation losses: 0.44218454573241756\n",
      "Epoch 4780, reconstruction losses: 0.035659767902591386, regression losses: 0.13648995199158268, validation losses: 0.4177506034644958\n",
      "Epoch 4781, reconstruction losses: 0.03485619154208021, regression losses: 0.3933366145055893, validation losses: 0.47043236232599156\n",
      "Epoch 4782, reconstruction losses: 0.032583478532292244, regression losses: 0.10403029775492294, validation losses: 0.7075637412913157\n",
      "Epoch 4783, reconstruction losses: 0.03265406111973041, regression losses: 0.1314225992497429, validation losses: 0.6054311833230874\n",
      "Epoch 4784, reconstruction losses: 0.03356392216575126, regression losses: 0.0930479694461238, validation losses: 0.5540170190882873\n",
      "Epoch 4785, reconstruction losses: 0.03191958203852302, regression losses: 0.11329885985338874, validation losses: 0.5291984195286348\n",
      "Epoch 4786, reconstruction losses: 0.034597435957224934, regression losses: 0.22619320274033844, validation losses: 0.453748278811856\n",
      "Epoch 4787, reconstruction losses: 0.03215838251285888, regression losses: 0.11755547202200962, validation losses: 0.6309350601428569\n",
      "Epoch 4788, reconstruction losses: 0.03202647893567206, regression losses: 0.1259647642565887, validation losses: 0.5966767532145912\n",
      "Epoch 4789, reconstruction losses: 0.031204502803930723, regression losses: 0.12667743550362082, validation losses: 0.5350553816139516\n",
      "Epoch 4790, reconstruction losses: 0.03120979698465268, regression losses: 0.11076761114845933, validation losses: 0.5881073053796791\n",
      "Epoch 4791, reconstruction losses: 0.03175222844317868, regression losses: 0.10825365547484543, validation losses: 0.5190770024878045\n",
      "Epoch 4792, reconstruction losses: 0.030556827132296953, regression losses: 0.09523847203946031, validation losses: 0.44716182320059816\n",
      "Epoch 4793, reconstruction losses: 0.03510998091875041, regression losses: 0.12593213765089628, validation losses: 0.44526970736786964\n",
      "Epoch 4794, reconstruction losses: 0.03303165463864306, regression losses: 0.0963317019606649, validation losses: 0.56375897876304\n",
      "Epoch 4795, reconstruction losses: 0.03069590694353016, regression losses: 0.11970108281129727, validation losses: 0.5001017326720092\n",
      "Epoch 4796, reconstruction losses: 0.031023705836893806, regression losses: 0.11197963283980011, validation losses: 0.45155071298213206\n",
      "Epoch 4797, reconstruction losses: 0.03879823412387333, regression losses: 0.14605503471745304, validation losses: 0.42329475115209325\n",
      "Epoch 4798, reconstruction losses: 0.034086525109480126, regression losses: 0.29463604796904563, validation losses: 0.46210942556752876\n",
      "Epoch 4799, reconstruction losses: 0.03173977980136682, regression losses: 0.14583251888685755, validation losses: 0.9515491983984261\n",
      "Epoch 4800, reconstruction losses: 0.03712784918376211, regression losses: 0.31011147218505747, validation losses: 0.7720627559160387\n",
      "Epoch 4801, reconstruction losses: 0.03420525407490107, regression losses: 0.1705183813372151, validation losses: 0.7430380235582036\n",
      "Epoch 4802, reconstruction losses: 0.0342089249444536, regression losses: 0.32080606356257385, validation losses: 0.6533258624562286\n",
      "Epoch 4803, reconstruction losses: 0.034634370334083925, regression losses: 0.13821549888240284, validation losses: 0.49030001442212034\n",
      "Epoch 4804, reconstruction losses: 0.030350435362720973, regression losses: 0.11552627485872018, validation losses: 0.6772627870594995\n",
      "Epoch 4805, reconstruction losses: 0.02990252092219517, regression losses: 0.13816285244259768, validation losses: 0.5300301380923578\n",
      "Epoch 4806, reconstruction losses: 0.03595968362541459, regression losses: 0.5031388270479377, validation losses: 0.4225946735058486\n",
      "Epoch 4807, reconstruction losses: 0.034523888256080076, regression losses: 0.1469222972713602, validation losses: 0.5401037763952262\n",
      "Epoch 4808, reconstruction losses: 0.03376890683179549, regression losses: 0.11123313000284059, validation losses: 0.4783076564720786\n",
      "Epoch 4809, reconstruction losses: 0.029769742471894255, regression losses: 0.10772318140209902, validation losses: 0.5144694619052506\n",
      "Epoch 4810, reconstruction losses: 0.033834767708454686, regression losses: 0.08313126147275335, validation losses: 0.5248211388361478\n",
      "Epoch 4811, reconstruction losses: 0.030812576875453676, regression losses: 0.11688338193221215, validation losses: 0.46204076717780773\n",
      "Epoch 4812, reconstruction losses: 0.03186259579811715, regression losses: 0.14256024862440292, validation losses: 0.4411748833143077\n",
      "Epoch 4813, reconstruction losses: 0.032955942999429194, regression losses: 0.16818357223178432, validation losses: 0.4958806902347298\n",
      "Epoch 4814, reconstruction losses: 0.034863021955539183, regression losses: 0.1338155689266882, validation losses: 0.5249762946838125\n",
      "Epoch 4815, reconstruction losses: 0.034402041989959026, regression losses: 0.13582273235740974, validation losses: 0.46810893840292267\n",
      "Epoch 4816, reconstruction losses: 0.036426820103019265, regression losses: 0.14867416786845872, validation losses: 0.5982023521178382\n",
      "Epoch 4817, reconstruction losses: 0.03574857006883954, regression losses: 0.12030241291993292, validation losses: 0.5667846883063823\n",
      "Epoch 4818, reconstruction losses: 0.03338049862394522, regression losses: 0.1264445650486209, validation losses: 0.41372268216221936\n",
      "Epoch 4819, reconstruction losses: 0.03172629053287013, regression losses: 0.1226038208275236, validation losses: 0.4465204778368406\n",
      "Epoch 4820, reconstruction losses: 0.03593977755169329, regression losses: 0.10387311089115764, validation losses: 0.5843307694660045\n",
      "Epoch 4821, reconstruction losses: 0.03499632642420282, regression losses: 0.14893825993573276, validation losses: 0.5082056933162086\n",
      "Epoch 4822, reconstruction losses: 0.034210009322879015, regression losses: 0.1297917527088204, validation losses: 0.4464182749754914\n",
      "Epoch 4823, reconstruction losses: 0.03254970515728184, regression losses: 0.11851137798740269, validation losses: 0.4421854950426917\n",
      "Epoch 4824, reconstruction losses: 0.03062509990146553, regression losses: 0.10531901035995626, validation losses: 0.439920052968562\n",
      "Epoch 4825, reconstruction losses: 0.036338260557473176, regression losses: 0.10108295237251395, validation losses: 0.4156691894362124\n",
      "Epoch 4826, reconstruction losses: 0.03754613581376133, regression losses: 0.11537914049096555, validation losses: 0.39457123369138014\n",
      "Epoch 4827, reconstruction losses: 0.04017187661594451, regression losses: 0.10713543859762534, validation losses: 0.4259056788335607\n",
      "Epoch 4828, reconstruction losses: 0.03186168794778421, regression losses: 0.1568538675444092, validation losses: 0.387879716706046\n",
      "Epoch 4829, reconstruction losses: 0.035982572281980346, regression losses: 0.12460808879948658, validation losses: 0.42269978249306384\n",
      "Epoch 4830, reconstruction losses: 0.03309609947052136, regression losses: 0.1301259994479938, validation losses: 0.3992149260864878\n",
      "Epoch 4831, reconstruction losses: 0.030244605683594827, regression losses: 0.09862210273639982, validation losses: 0.41201376182425076\n",
      "Epoch 4832, reconstruction losses: 0.029066755469559124, regression losses: 0.10151697568460363, validation losses: 0.4674582513319833\n",
      "Epoch 4833, reconstruction losses: 0.03107660507653894, regression losses: 0.1223787727672245, validation losses: 0.4551571827552664\n",
      "Epoch 4834, reconstruction losses: 0.033371069342212414, regression losses: 0.1509659470216601, validation losses: 0.5154270775678679\n",
      "Epoch 4835, reconstruction losses: 0.041249688929248435, regression losses: 0.1028860764320898, validation losses: 0.42609089484644647\n",
      "Epoch 4836, reconstruction losses: 0.03200735628400981, regression losses: 0.13166833307149936, validation losses: 0.406263394036278\n",
      "Epoch 4837, reconstruction losses: 0.03068910234540462, regression losses: 0.11890952817799899, validation losses: 0.46893235357117613\n",
      "Epoch 4838, reconstruction losses: 0.03791191479170832, regression losses: 0.132567303056967, validation losses: 0.5110491762259531\n",
      "Epoch 4839, reconstruction losses: 0.03493021210463578, regression losses: 0.14631007146727934, validation losses: 0.4473280331250468\n",
      "Epoch 4840, reconstruction losses: 0.033093676596279625, regression losses: 0.09045991335036828, validation losses: 0.42844878178457824\n",
      "Epoch 4841, reconstruction losses: 0.02980142964598469, regression losses: 0.09846527266187803, validation losses: 0.4848783574093773\n",
      "Epoch 4842, reconstruction losses: 0.03232846821163432, regression losses: 0.11446680577275045, validation losses: 0.47589665609847187\n",
      "Epoch 4843, reconstruction losses: 0.03972293722732928, regression losses: 0.111903335898102, validation losses: 0.5112023576608232\n",
      "Epoch 4844, reconstruction losses: 0.03600530781103641, regression losses: 0.19100304757637598, validation losses: 0.5236757270009779\n",
      "Epoch 4845, reconstruction losses: 0.03410044311607218, regression losses: 0.08937599669087569, validation losses: 0.6145358959873075\n",
      "Epoch 4846, reconstruction losses: 0.03567960116976174, regression losses: 0.11502515744739364, validation losses: 0.4906758680074314\n",
      "Epoch 4847, reconstruction losses: 0.03097996398190846, regression losses: 0.10559484147597296, validation losses: 0.4674142725158069\n",
      "Epoch 4848, reconstruction losses: 0.03439376142113887, regression losses: 0.11648547782847163, validation losses: 0.4642600376065261\n",
      "Epoch 4849, reconstruction losses: 0.03737412300591121, regression losses: 0.15305301567139074, validation losses: 0.4809819225220071\n",
      "Epoch 4850, reconstruction losses: 0.03572048714256501, regression losses: 0.12825118164953356, validation losses: 0.45857513775914976\n",
      "Epoch 4851, reconstruction losses: 0.03897032880456239, regression losses: 0.10344481466027225, validation losses: 0.4679867757393721\n",
      "Epoch 4852, reconstruction losses: 0.034248331387438935, regression losses: 0.15617807290327967, validation losses: 0.5405609219436721\n",
      "Epoch 4853, reconstruction losses: 0.03188031415387209, regression losses: 0.13872174662176529, validation losses: 0.4711588665063076\n",
      "Epoch 4854, reconstruction losses: 0.032031563299247987, regression losses: 0.12388275037393999, validation losses: 0.5346997441052552\n",
      "Epoch 4855, reconstruction losses: 0.03730911503644096, regression losses: 0.10236986952620426, validation losses: 0.5321450657479548\n",
      "Epoch 4856, reconstruction losses: 0.033849115414823064, regression losses: 0.11966770913122654, validation losses: 0.4968391877430764\n",
      "Epoch 4857, reconstruction losses: 0.032911246696942516, regression losses: 0.09689485195715648, validation losses: 0.537980343378497\n",
      "Epoch 4858, reconstruction losses: 0.03485326840149484, regression losses: 0.14020993893794, validation losses: 0.5053309771163264\n",
      "Epoch 4859, reconstruction losses: 0.032675806435627515, regression losses: 0.12898383007667208, validation losses: 0.45669027645055044\n",
      "Epoch 4860, reconstruction losses: 0.032540419653976645, regression losses: 0.1403951965914259, validation losses: 0.4520771783896867\n",
      "Epoch 4861, reconstruction losses: 0.03298637505014864, regression losses: 0.12293553330425785, validation losses: 0.47040411345587424\n",
      "Epoch 4862, reconstruction losses: 0.030094720087535165, regression losses: 0.08778735230644641, validation losses: 0.5110681017861867\n",
      "Epoch 4863, reconstruction losses: 0.03293068301291045, regression losses: 0.13197708550024415, validation losses: 0.558099267351964\n",
      "Epoch 4864, reconstruction losses: 0.03396523680229178, regression losses: 0.15377288377044845, validation losses: 0.5302032481494482\n",
      "Epoch 4865, reconstruction losses: 0.034077256234429885, regression losses: 0.1760178005794388, validation losses: 0.45621946390334034\n",
      "Epoch 4866, reconstruction losses: 0.032619555922873286, regression losses: 0.16532339984832511, validation losses: 0.5304538238408879\n",
      "Epoch 4867, reconstruction losses: 0.033034296604108074, regression losses: 0.1253805584037255, validation losses: 0.4428741059673633\n",
      "Epoch 4868, reconstruction losses: 0.03909540365312521, regression losses: 0.09281190926754085, validation losses: 0.401286321168373\n",
      "Epoch 4869, reconstruction losses: 0.038495337300148785, regression losses: 0.1344248689853066, validation losses: 0.39803141306737083\n",
      "Epoch 4870, reconstruction losses: 0.03432255666507245, regression losses: 0.11771308258403772, validation losses: 0.41097042749115864\n",
      "Epoch 4871, reconstruction losses: 0.03274989941939183, regression losses: 0.12702768860506647, validation losses: 0.5031558646726583\n",
      "Epoch 4872, reconstruction losses: 0.03311976042470708, regression losses: 0.10148468090559938, validation losses: 0.5943872787634562\n",
      "Epoch 4873, reconstruction losses: 0.030765528946452826, regression losses: 0.09976030416760281, validation losses: 0.44950604575839187\n",
      "Epoch 4874, reconstruction losses: 0.03487089098713309, regression losses: 0.17229053802212288, validation losses: 0.4547053814834013\n",
      "Epoch 4875, reconstruction losses: 0.033174390807025306, regression losses: 0.1461933974074415, validation losses: 0.4566817095394351\n",
      "Epoch 4876, reconstruction losses: 0.03467856066706803, regression losses: 0.1760802628131376, validation losses: 0.44826760353994444\n",
      "Epoch 4877, reconstruction losses: 0.04170920316294291, regression losses: 0.13141691764667568, validation losses: 0.46669730899174655\n",
      "Epoch 4878, reconstruction losses: 0.03453207455205822, regression losses: 0.12258294812335262, validation losses: 0.5033248715494605\n",
      "Epoch 4879, reconstruction losses: 0.034988456256884716, regression losses: 0.12402731809491865, validation losses: 0.523231937019194\n",
      "Epoch 4880, reconstruction losses: 0.033217215191354135, regression losses: 0.10863010633884404, validation losses: 0.5742578885054318\n",
      "Epoch 4881, reconstruction losses: 0.029785328019027835, regression losses: 0.12632218617017213, validation losses: 0.4821726953182977\n",
      "Epoch 4882, reconstruction losses: 0.039984252502169845, regression losses: 0.10310890774271025, validation losses: 0.4402996168706914\n",
      "Epoch 4883, reconstruction losses: 0.03285380022008904, regression losses: 0.11909278251681446, validation losses: 0.41495145601955186\n",
      "Epoch 4884, reconstruction losses: 0.034009798889697775, regression losses: 0.23692649947848116, validation losses: 0.46959759645396826\n",
      "Epoch 4885, reconstruction losses: 0.03362811278416821, regression losses: 0.2037576656857894, validation losses: 0.5786550764232536\n",
      "Epoch 4886, reconstruction losses: 0.0339670366838833, regression losses: 0.17094141888681266, validation losses: 0.5415847613456952\n",
      "Epoch 4887, reconstruction losses: 0.03827452957048249, regression losses: 0.1351240780900672, validation losses: 0.6305760751379117\n",
      "Epoch 4888, reconstruction losses: 0.03143063179424219, regression losses: 0.1494605667533666, validation losses: 0.4452567457799379\n",
      "Epoch 4889, reconstruction losses: 0.03526904313744847, regression losses: 0.16381179345283015, validation losses: 0.5166946540165931\n",
      "Epoch 4890, reconstruction losses: 0.033583239889030544, regression losses: 0.11904405093155954, validation losses: 0.4811271648590004\n",
      "Epoch 4891, reconstruction losses: 0.03246784834386037, regression losses: 0.1406702923729365, validation losses: 0.5583207627350265\n",
      "Epoch 4892, reconstruction losses: 0.031007558461745813, regression losses: 0.12015102227201388, validation losses: 0.39906100155792257\n",
      "Epoch 4893, reconstruction losses: 0.036008309627028126, regression losses: 0.16399298045647473, validation losses: 0.5148749524663916\n",
      "Epoch 4894, reconstruction losses: 0.031738808415812926, regression losses: 0.16587216067765248, validation losses: 0.42771931320539125\n",
      "Epoch 4895, reconstruction losses: 0.034896272876106416, regression losses: 0.13663678785470101, validation losses: 0.49630154643338525\n",
      "Epoch 4896, reconstruction losses: 0.03212959783212424, regression losses: 0.15682202132173712, validation losses: 0.557086330782772\n",
      "Epoch 4897, reconstruction losses: 0.03214507344383335, regression losses: 0.12829471848982638, validation losses: 0.46414005864436847\n",
      "Epoch 4898, reconstruction losses: 0.03350376322420329, regression losses: 0.11554257786413764, validation losses: 0.47441479054283703\n",
      "Epoch 4899, reconstruction losses: 0.043496207105117785, regression losses: 0.24055426442362862, validation losses: 0.4167406853735848\n",
      "Epoch 4900, reconstruction losses: 0.036588180606010164, regression losses: 0.13870055414909382, validation losses: 0.5890553466189072\n",
      "Epoch 4901, reconstruction losses: 0.03289998814523848, regression losses: 0.17011445209043186, validation losses: 0.4768201032470382\n",
      "Epoch 4902, reconstruction losses: 0.035227369991985065, regression losses: 0.15026457300047077, validation losses: 0.538433331836061\n",
      "Epoch 4903, reconstruction losses: 0.03413709046256747, regression losses: 0.16008841948834526, validation losses: 0.566130426894405\n",
      "Epoch 4904, reconstruction losses: 0.02964842699631072, regression losses: 0.10718733624604043, validation losses: 0.45900463742195513\n",
      "Epoch 4905, reconstruction losses: 0.03168327058475199, regression losses: 0.12050771479963451, validation losses: 0.41534538749616223\n",
      "Epoch 4906, reconstruction losses: 0.03169089220991881, regression losses: 0.18953861792158477, validation losses: 0.46686693697732096\n",
      "Epoch 4907, reconstruction losses: 0.03563291905191034, regression losses: 0.13025047241805715, validation losses: 0.5792486530289511\n",
      "Epoch 4908, reconstruction losses: 0.030630337083946524, regression losses: 0.2034058269125046, validation losses: 0.47386873346388075\n",
      "Epoch 4909, reconstruction losses: 0.030275480778497173, regression losses: 0.10049935831648295, validation losses: 0.5729671737643535\n",
      "Epoch 4910, reconstruction losses: 0.031768635064686315, regression losses: 0.12347295332083078, validation losses: 0.5678030915039471\n",
      "Epoch 4911, reconstruction losses: 0.03132324501037901, regression losses: 0.12714081346906783, validation losses: 0.5125672095349353\n",
      "Epoch 4912, reconstruction losses: 0.030700781134687664, regression losses: 0.11401061939267634, validation losses: 0.49161123949730345\n",
      "Epoch 4913, reconstruction losses: 0.03772029981419586, regression losses: 0.11297001709538801, validation losses: 0.40227237366565294\n",
      "Epoch 4914, reconstruction losses: 0.03310602649671577, regression losses: 0.1532354967024582, validation losses: 0.426870815032052\n",
      "Epoch 4915, reconstruction losses: 0.03190715846453548, regression losses: 0.12343244896234468, validation losses: 0.404071183403266\n",
      "Epoch 4916, reconstruction losses: 0.032160736224270584, regression losses: 0.08945624665508109, validation losses: 0.6000171417447286\n",
      "Epoch 4917, reconstruction losses: 0.03432175405660243, regression losses: 0.1431734772928077, validation losses: 0.49146213459286214\n",
      "Epoch 4918, reconstruction losses: 0.0323324330978656, regression losses: 0.1066154522691514, validation losses: 0.43119339767781817\n",
      "Epoch 4919, reconstruction losses: 0.033498167159562664, regression losses: 0.2023420540193454, validation losses: 0.40679402365881506\n",
      "Epoch 4920, reconstruction losses: 0.034398505605706696, regression losses: 0.1440230138237558, validation losses: 0.4967189727698698\n",
      "Epoch 4921, reconstruction losses: 0.03207938535411581, regression losses: 0.11259914058361035, validation losses: 0.4670028547320696\n",
      "Epoch 4922, reconstruction losses: 0.031569676233434735, regression losses: 0.14495808049525452, validation losses: 0.44989774000489385\n",
      "Epoch 4923, reconstruction losses: 0.029749117338764213, regression losses: 0.10403867223091662, validation losses: 0.6083205307059861\n",
      "Epoch 4924, reconstruction losses: 0.03246863377956393, regression losses: 0.1673932363682373, validation losses: 0.5233598587135617\n",
      "Epoch 4925, reconstruction losses: 0.032702660158998524, regression losses: 0.19534428300054507, validation losses: 0.6477978656472496\n",
      "Epoch 4926, reconstruction losses: 0.039197105189295346, regression losses: 0.1906033339702339, validation losses: 0.7190839435539422\n",
      "Epoch 4927, reconstruction losses: 0.03569419887804987, regression losses: 0.3304422190770931, validation losses: 0.4224530047562344\n",
      "Epoch 4928, reconstruction losses: 0.031259155368777165, regression losses: 0.12680646909170956, validation losses: 0.9828182668622395\n",
      "Epoch 4929, reconstruction losses: 0.037376083816660584, regression losses: 0.18547934701921653, validation losses: 0.8453893289133833\n",
      "Epoch 4930, reconstruction losses: 0.034057584226546395, regression losses: 0.145014853296028, validation losses: 0.5242117979931168\n",
      "Epoch 4931, reconstruction losses: 0.03496328015570195, regression losses: 0.17533796687730255, validation losses: 0.49722839434796606\n",
      "Epoch 4932, reconstruction losses: 0.030148439282767128, regression losses: 0.14124783963602622, validation losses: 0.4585265231218531\n",
      "Epoch 4933, reconstruction losses: 0.04028572873305955, regression losses: 0.3448177109475899, validation losses: 0.4386947298940638\n",
      "Epoch 4934, reconstruction losses: 0.03208780288549072, regression losses: 0.12349342703377968, validation losses: 0.524630233590743\n",
      "Epoch 4935, reconstruction losses: 0.03158588609013277, regression losses: 0.1471103425290719, validation losses: 0.5133690452760591\n",
      "Epoch 4936, reconstruction losses: 0.03986456209859161, regression losses: 0.13881752683074286, validation losses: 0.5813511906222555\n",
      "Epoch 4937, reconstruction losses: 0.03273969301326805, regression losses: 0.1339892438546348, validation losses: 0.47881716029008436\n",
      "Epoch 4938, reconstruction losses: 0.02951789194898118, regression losses: 0.1075096998583518, validation losses: 0.45045285553742354\n",
      "Epoch 4939, reconstruction losses: 0.032914487975316306, regression losses: 0.14840442567058076, validation losses: 0.42790653319064964\n",
      "Epoch 4940, reconstruction losses: 0.03164636477561742, regression losses: 0.10982276188855586, validation losses: 0.49432898768866085\n",
      "Epoch 4941, reconstruction losses: 0.02882380456080403, regression losses: 0.10138544426485276, validation losses: 0.5718951140009917\n",
      "Epoch 4942, reconstruction losses: 0.03295113016417681, regression losses: 0.20516723246431987, validation losses: 0.4688232018321966\n",
      "Epoch 4943, reconstruction losses: 0.03396048957559321, regression losses: 0.1253753404985686, validation losses: 0.44214351010960706\n",
      "Epoch 4944, reconstruction losses: 0.031502264984387296, regression losses: 0.12273717684684252, validation losses: 0.4584940917761743\n",
      "Epoch 4945, reconstruction losses: 0.03414892104788378, regression losses: 0.10933093696362918, validation losses: 0.47748223731552075\n",
      "Epoch 4946, reconstruction losses: 0.0359780165215671, regression losses: 0.10520174509314549, validation losses: 0.48513674879038915\n",
      "Epoch 4947, reconstruction losses: 0.03130811726944061, regression losses: 0.1875812080446897, validation losses: 0.4972280678196352\n",
      "Epoch 4948, reconstruction losses: 0.03463295531540825, regression losses: 0.13572708772604952, validation losses: 0.4808033677912273\n",
      "Epoch 4949, reconstruction losses: 0.029732956442398515, regression losses: 0.11785428429124113, validation losses: 0.42177220500654355\n",
      "Epoch 4950, reconstruction losses: 0.029693503761891744, regression losses: 0.10384457326843685, validation losses: 0.49450639714698374\n",
      "Epoch 4951, reconstruction losses: 0.033137209260976956, regression losses: 0.13094264823651894, validation losses: 0.5448461067811698\n",
      "Epoch 4952, reconstruction losses: 0.03373435328292313, regression losses: 0.11297451933729719, validation losses: 0.5706648630585939\n",
      "Epoch 4953, reconstruction losses: 0.03207432818083585, regression losses: 0.12026684463969627, validation losses: 0.46846050200871636\n",
      "Epoch 4954, reconstruction losses: 0.03299742399929363, regression losses: 0.13874322404539052, validation losses: 0.4148158264659902\n",
      "Epoch 4955, reconstruction losses: 0.031860870513971025, regression losses: 0.11152979277965948, validation losses: 0.41300049129026745\n",
      "Epoch 4956, reconstruction losses: 0.03137965683635647, regression losses: 0.15073872297606541, validation losses: 0.446094816496053\n",
      "Epoch 4957, reconstruction losses: 0.03553131191869738, regression losses: 0.07892980000600881, validation losses: 0.5184289038871678\n",
      "Epoch 4958, reconstruction losses: 0.03145066882753222, regression losses: 0.11464068528691193, validation losses: 0.5242229222889112\n",
      "Epoch 4959, reconstruction losses: 0.03314940179788715, regression losses: 0.12760935344920796, validation losses: 0.46717133820219525\n",
      "Epoch 4960, reconstruction losses: 0.03145124427393953, regression losses: 0.13599044557656553, validation losses: 0.45365782027365015\n",
      "Epoch 4961, reconstruction losses: 0.04073735564504202, regression losses: 0.10319949904703658, validation losses: 0.4733867228173303\n",
      "Epoch 4962, reconstruction losses: 0.03744508963542156, regression losses: 0.18865200576792354, validation losses: 0.4507006959904284\n",
      "Epoch 4963, reconstruction losses: 0.0324882867789126, regression losses: 0.12481176599337819, validation losses: 0.4740252970690446\n",
      "Epoch 4964, reconstruction losses: 0.03125625254868838, regression losses: 0.11656553241744487, validation losses: 0.5039790408238748\n",
      "Epoch 4965, reconstruction losses: 0.031450090978778045, regression losses: 0.13561970056306588, validation losses: 0.503544231114725\n",
      "Epoch 4966, reconstruction losses: 0.0319829335815805, regression losses: 0.10895977461171455, validation losses: 0.4657599598688562\n",
      "Epoch 4967, reconstruction losses: 0.04137755610508604, regression losses: 0.12450385077137338, validation losses: 0.4353865742284042\n",
      "Epoch 4968, reconstruction losses: 0.032217926878218874, regression losses: 0.20100042253183747, validation losses: 0.4542673144502327\n",
      "Epoch 4969, reconstruction losses: 0.03188638986966386, regression losses: 0.0961466122971465, validation losses: 0.6504566488562941\n",
      "Epoch 4970, reconstruction losses: 0.03219011956664828, regression losses: 0.11419021378704554, validation losses: 0.5572470468239108\n",
      "Epoch 4971, reconstruction losses: 0.03299399721998056, regression losses: 0.1730507951580069, validation losses: 0.43281818873825767\n",
      "Epoch 4972, reconstruction losses: 0.03882095209369907, regression losses: 0.13594739350165988, validation losses: 0.4845767909956506\n",
      "Epoch 4973, reconstruction losses: 0.038825020206518915, regression losses: 0.08230519973669125, validation losses: 0.42601154467291114\n",
      "Epoch 4974, reconstruction losses: 0.031602387089108695, regression losses: 0.15983055936649185, validation losses: 0.4236743186828257\n",
      "Epoch 4975, reconstruction losses: 0.030873812858321564, regression losses: 0.085133951020419, validation losses: 0.43025018245866536\n",
      "Epoch 4976, reconstruction losses: 0.0356433805413639, regression losses: 0.10129157926117949, validation losses: 0.47893463868694186\n",
      "Epoch 4977, reconstruction losses: 0.036859484332926545, regression losses: 0.10267981280823048, validation losses: 0.46769846928273934\n",
      "Epoch 4978, reconstruction losses: 0.038900879208590596, regression losses: 0.10665457381390128, validation losses: 0.4424246230742973\n",
      "Epoch 4979, reconstruction losses: 0.03153883744650622, regression losses: 0.10786344554897455, validation losses: 0.4123523177625871\n",
      "Epoch 4980, reconstruction losses: 0.03375033056172759, regression losses: 0.10085262536880027, validation losses: 0.40154836636555\n",
      "Epoch 4981, reconstruction losses: 0.035091731225457945, regression losses: 0.2316373486449674, validation losses: 0.4063816856088255\n",
      "Epoch 4982, reconstruction losses: 0.03507068131695802, regression losses: 0.14500973689979135, validation losses: 0.6014486531690489\n",
      "Epoch 4983, reconstruction losses: 0.032944249947757014, regression losses: 0.18872675728887478, validation losses: 0.5595452245643331\n",
      "Epoch 4984, reconstruction losses: 0.029400649288960568, regression losses: 0.1528690512263947, validation losses: 0.8108958306158991\n",
      "Epoch 4985, reconstruction losses: 0.03347698450750983, regression losses: 0.11169138266349107, validation losses: 0.43430971094434995\n",
      "Epoch 4986, reconstruction losses: 0.02974409443587042, regression losses: 0.13822716516774977, validation losses: 0.4248539972873695\n",
      "Epoch 4987, reconstruction losses: 0.03469754335935581, regression losses: 0.11086141816282317, validation losses: 0.44363706068069175\n",
      "Epoch 4988, reconstruction losses: 0.032567012730180804, regression losses: 0.16688093022339817, validation losses: 0.46632903311451557\n",
      "Epoch 4989, reconstruction losses: 0.03225710859463923, regression losses: 0.11839212895840326, validation losses: 0.5539968542130452\n",
      "Epoch 4990, reconstruction losses: 0.02994280245229841, regression losses: 0.13434835168604978, validation losses: 0.41309858301661145\n",
      "Epoch 4991, reconstruction losses: 0.0334847246752188, regression losses: 0.13800114101926736, validation losses: 0.46239580917276235\n",
      "Epoch 4992, reconstruction losses: 0.03685436781845964, regression losses: 0.10183245190236617, validation losses: 0.4223904388365504\n",
      "Epoch 4993, reconstruction losses: 0.034803615238210135, regression losses: 0.4157234290043781, validation losses: 0.4131544180290227\n",
      "Epoch 4994, reconstruction losses: 0.03203604894195365, regression losses: 0.13188910308386645, validation losses: 0.6595650599749571\n",
      "Epoch 4995, reconstruction losses: 0.030821468517565634, regression losses: 0.1487364966972786, validation losses: 0.6521567754159576\n",
      "Epoch 4996, reconstruction losses: 0.03297672931390808, regression losses: 0.186608946483728, validation losses: 0.7031123227592474\n",
      "Epoch 4997, reconstruction losses: 0.033649365991869615, regression losses: 0.1298060452754786, validation losses: 0.4924694660773079\n",
      "Epoch 4998, reconstruction losses: 0.032698862160245534, regression losses: 0.15120311672277498, validation losses: 0.44943947878223556\n",
      "Epoch 4999, reconstruction losses: 0.03089574975151369, regression losses: 0.11886380969157129, validation losses: 0.5279122861689887\n",
      "Epoch 5000, reconstruction losses: 0.033517311701896445, regression losses: 0.11333379982610689, validation losses: 0.6605771515487072\n",
      "Epoch 5001, reconstruction losses: 0.028525179300157452, regression losses: 0.111226912357489, validation losses: 0.46175705984490656\n",
      "Epoch 5002, reconstruction losses: 0.031566750845303, regression losses: 0.1595898168139852, validation losses: 0.42219141482622463\n",
      "Epoch 5003, reconstruction losses: 0.03332451243711343, regression losses: 0.21295712066670824, validation losses: 0.4932839037096661\n",
      "Epoch 5004, reconstruction losses: 0.03399438542609385, regression losses: 0.34481011040365456, validation losses: 0.5297763263777734\n",
      "Epoch 5005, reconstruction losses: 0.033788721054447475, regression losses: 0.1344490258429942, validation losses: 0.7070112283016688\n",
      "Epoch 5006, reconstruction losses: 0.030620235189841864, regression losses: 0.14974768540363637, validation losses: 0.5662754308912039\n",
      "Epoch 5007, reconstruction losses: 0.0407602693069207, regression losses: 0.1136292347128949, validation losses: 0.5192415898772151\n",
      "Epoch 5008, reconstruction losses: 0.030089680584686883, regression losses: 0.13960313184958442, validation losses: 0.47509825424137175\n",
      "Epoch 5009, reconstruction losses: 0.03154453842926097, regression losses: 0.12404266041616438, validation losses: 0.451874313859719\n",
      "Epoch 5010, reconstruction losses: 0.03770367253375637, regression losses: 0.17273235770460355, validation losses: 0.46153250160704357\n",
      "Epoch 5011, reconstruction losses: 0.03181369022882956, regression losses: 0.13180880161832972, validation losses: 0.5439889318556458\n",
      "Epoch 5012, reconstruction losses: 0.03261304977740484, regression losses: 0.12157819356155045, validation losses: 0.5628912861997843\n",
      "Epoch 5013, reconstruction losses: 0.03242256523494927, regression losses: 0.1355349703380344, validation losses: 0.5618075635074121\n",
      "Epoch 5014, reconstruction losses: 0.031223500201769713, regression losses: 0.14260829600253838, validation losses: 0.48750418694630315\n",
      "Epoch 5015, reconstruction losses: 0.03332692196278464, regression losses: 0.10978069473507, validation losses: 0.4398139523749812\n",
      "Epoch 5016, reconstruction losses: 0.030504643669893722, regression losses: 0.12693692095972842, validation losses: 0.5165598520152578\n",
      "Epoch 5017, reconstruction losses: 0.035462916296321895, regression losses: 0.14854807045833826, validation losses: 0.5160429572775919\n",
      "Epoch 5018, reconstruction losses: 0.030080475185282077, regression losses: 0.09330657641868934, validation losses: 0.4460918419738486\n",
      "Epoch 5019, reconstruction losses: 0.03416833613943198, regression losses: 0.12517721709597388, validation losses: 0.48174393268889887\n",
      "Epoch 5020, reconstruction losses: 0.029544344433748024, regression losses: 0.11412139411205487, validation losses: 0.484819589764262\n",
      "Epoch 5021, reconstruction losses: 0.03598046554248927, regression losses: 0.3147567041660062, validation losses: 0.5340956204974684\n",
      "Epoch 5022, reconstruction losses: 0.03062849108198127, regression losses: 0.1252504285221548, validation losses: 0.7065479608441232\n",
      "Epoch 5023, reconstruction losses: 0.03592645504355747, regression losses: 0.19664181803181574, validation losses: 0.5018320909997626\n",
      "Epoch 5024, reconstruction losses: 0.031722587409447195, regression losses: 0.12629498942894432, validation losses: 0.6368052849240409\n",
      "Epoch 5025, reconstruction losses: 0.03054735178458428, regression losses: 0.13184052051192396, validation losses: 0.7070168275389956\n",
      "Epoch 5026, reconstruction losses: 0.03510769918780503, regression losses: 0.108530423133778, validation losses: 0.5174643302032004\n",
      "Epoch 5027, reconstruction losses: 0.03071841259040728, regression losses: 0.1065024799892466, validation losses: 0.5440536995548516\n",
      "Epoch 5028, reconstruction losses: 0.033043020388837455, regression losses: 0.10020733914563462, validation losses: 0.5112685756977551\n",
      "Epoch 5029, reconstruction losses: 0.04076801138721277, regression losses: 0.17920512081023593, validation losses: 0.46897694875098944\n",
      "Epoch 5030, reconstruction losses: 0.031102197729328023, regression losses: 0.14180706606840632, validation losses: 0.6040925985163964\n",
      "Epoch 5031, reconstruction losses: 0.03680015048530358, regression losses: 0.1082127113897535, validation losses: 0.5902816249148267\n",
      "Epoch 5032, reconstruction losses: 0.03412798047288508, regression losses: 0.12376613981641298, validation losses: 0.44846976455166637\n",
      "Epoch 5033, reconstruction losses: 0.03729416210234921, regression losses: 0.14892660630151047, validation losses: 0.4838317300997147\n",
      "Epoch 5034, reconstruction losses: 0.035743802068709606, regression losses: 0.11834172889788822, validation losses: 0.48866330725808704\n",
      "Epoch 5035, reconstruction losses: 0.03173028522791063, regression losses: 0.0892159290506238, validation losses: 0.4074528792422137\n",
      "Epoch 5036, reconstruction losses: 0.03164965476042499, regression losses: 0.12314569058463357, validation losses: 0.4167427749616506\n",
      "Epoch 5037, reconstruction losses: 0.03662580246671197, regression losses: 0.13608627400852058, validation losses: 0.40753474183601923\n",
      "Epoch 5038, reconstruction losses: 0.03652482466119813, regression losses: 0.3954374709737662, validation losses: 0.4206840822592384\n",
      "Epoch 5039, reconstruction losses: 0.03543229317618987, regression losses: 0.12826698362526054, validation losses: 0.5716686281005803\n",
      "Epoch 5040, reconstruction losses: 0.03165641025921481, regression losses: 0.12452694262668544, validation losses: 0.5677790569552654\n",
      "Epoch 5041, reconstruction losses: 0.03679332214204363, regression losses: 0.1107104473755314, validation losses: 0.5299520429125493\n",
      "Epoch 5042, reconstruction losses: 0.034296165682962745, regression losses: 0.14238938280016966, validation losses: 0.4496428611196208\n",
      "Epoch 5043, reconstruction losses: 0.0317077725223562, regression losses: 0.11787520609948987, validation losses: 0.44416162244756646\n",
      "Epoch 5044, reconstruction losses: 0.033125439803808665, regression losses: 0.13041364959916674, validation losses: 0.49460562911020167\n",
      "Epoch 5045, reconstruction losses: 0.03920041900281017, regression losses: 0.09781938334465548, validation losses: 0.5386072996569147\n",
      "Epoch 5046, reconstruction losses: 0.029422403142989245, regression losses: 0.12346756466661976, validation losses: 0.4383597047235644\n",
      "Epoch 5047, reconstruction losses: 0.033619120495288236, regression losses: 0.1412804186391921, validation losses: 0.4107443359124671\n",
      "Epoch 5048, reconstruction losses: 0.03463668033913313, regression losses: 0.15256929856673213, validation losses: 0.5247279522709263\n",
      "Epoch 5049, reconstruction losses: 0.03318310733014393, regression losses: 0.14086641729146218, validation losses: 0.5528720626125428\n",
      "Epoch 5050, reconstruction losses: 0.034999544867004725, regression losses: 0.2027082419689012, validation losses: 0.4462760069948561\n",
      "Epoch 5051, reconstruction losses: 0.03248086577208115, regression losses: 0.18041911469685074, validation losses: 0.4858573624252397\n",
      "Epoch 5052, reconstruction losses: 0.03232753095566609, regression losses: 0.13566743648166685, validation losses: 0.6057459680073983\n",
      "Epoch 5053, reconstruction losses: 0.030462108988165836, regression losses: 0.15369061504117126, validation losses: 0.5826931759339452\n",
      "Epoch 5054, reconstruction losses: 0.031321985833474966, regression losses: 0.15353381636652577, validation losses: 0.4610565725703691\n",
      "Epoch 5055, reconstruction losses: 0.036149216374233246, regression losses: 0.08576817975362948, validation losses: 0.4312664041570853\n",
      "Epoch 5056, reconstruction losses: 0.030220786586337953, regression losses: 0.13370399182871265, validation losses: 0.41003876370111964\n",
      "Epoch 5057, reconstruction losses: 0.030521697800254176, regression losses: 0.1208559535727052, validation losses: 0.4613723250488263\n",
      "Epoch 5058, reconstruction losses: 0.035939532947047145, regression losses: 0.10974384230845474, validation losses: 0.4617237619928522\n",
      "Epoch 5059, reconstruction losses: 0.031908899066658884, regression losses: 0.09280263276835189, validation losses: 0.43112170481810963\n",
      "Epoch 5060, reconstruction losses: 0.03119163477367866, regression losses: 0.1518552422011637, validation losses: 0.43799208574595\n",
      "Epoch 5061, reconstruction losses: 0.033647089207487824, regression losses: 0.11276704113912933, validation losses: 0.5643973786055484\n",
      "Epoch 5062, reconstruction losses: 0.032274679505487, regression losses: 0.13566109030499202, validation losses: 0.4861187483396715\n",
      "Epoch 5063, reconstruction losses: 0.03314613941798221, regression losses: 0.08722247312524932, validation losses: 0.5496246828793059\n",
      "Epoch 5064, reconstruction losses: 0.0315312487401685, regression losses: 0.09943324017358472, validation losses: 0.546909163754861\n",
      "Epoch 5065, reconstruction losses: 0.03154774566816072, regression losses: 0.1310375351739107, validation losses: 0.5083547899018359\n",
      "Epoch 5066, reconstruction losses: 0.036101707951970576, regression losses: 0.11713557858555504, validation losses: 0.4799247989556564\n",
      "Epoch 5067, reconstruction losses: 0.036833503739503684, regression losses: 0.11354730787249466, validation losses: 0.4455817971079048\n",
      "Epoch 5068, reconstruction losses: 0.031490304149546046, regression losses: 0.12438816410296546, validation losses: 0.47895863172936826\n",
      "Epoch 5069, reconstruction losses: 0.03633247363242174, regression losses: 0.1384790576908901, validation losses: 0.4756798866795217\n",
      "Epoch 5070, reconstruction losses: 0.03183868519355212, regression losses: 0.15647169946598202, validation losses: 0.4493627029314301\n",
      "Epoch 5071, reconstruction losses: 0.03467376840237825, regression losses: 0.13706541157654945, validation losses: 0.540993236920187\n",
      "Epoch 5072, reconstruction losses: 0.03253073320977036, regression losses: 0.11941321080942258, validation losses: 0.5235246803645881\n",
      "Epoch 5073, reconstruction losses: 0.032260462123337136, regression losses: 0.13532456419250988, validation losses: 0.4362507877384693\n",
      "Epoch 5074, reconstruction losses: 0.03368869523702884, regression losses: 0.15598331277326002, validation losses: 0.48400465317188696\n",
      "Epoch 5075, reconstruction losses: 0.03134293455039398, regression losses: 0.10822104690695182, validation losses: 0.6569876281285087\n",
      "Epoch 5076, reconstruction losses: 0.029777824031390517, regression losses: 0.10525293580991638, validation losses: 0.5723740711497249\n",
      "Epoch 5077, reconstruction losses: 0.02932495154189855, regression losses: 0.11674140109013388, validation losses: 0.5104836072469291\n",
      "Epoch 5078, reconstruction losses: 0.03437439019564133, regression losses: 0.379796537065791, validation losses: 0.5040176812949689\n",
      "Epoch 5079, reconstruction losses: 0.030465760146091838, regression losses: 0.12840528065729612, validation losses: 0.5311839761817545\n",
      "Epoch 5080, reconstruction losses: 0.03376396181512267, regression losses: 0.12389988724242543, validation losses: 0.5546886240042076\n",
      "Epoch 5081, reconstruction losses: 0.040195905861813194, regression losses: 0.10474238648652563, validation losses: 0.6070402605493437\n",
      "Epoch 5082, reconstruction losses: 0.03150832041509057, regression losses: 0.1649540236749661, validation losses: 0.5698127331865651\n",
      "Epoch 5083, reconstruction losses: 0.03760809670993934, regression losses: 0.12294474697889607, validation losses: 0.7072570956588982\n",
      "Epoch 5084, reconstruction losses: 0.03274475313256473, regression losses: 0.14604443563510058, validation losses: 0.5152114150979465\n",
      "Epoch 5085, reconstruction losses: 0.03701061315426039, regression losses: 0.1517544081399724, validation losses: 0.6066686200228043\n",
      "Epoch 5086, reconstruction losses: 0.034666763472053636, regression losses: 0.10887370853280362, validation losses: 0.5059798652772522\n",
      "Epoch 5087, reconstruction losses: 0.034621029163499406, regression losses: 0.18450010525168326, validation losses: 0.4815572505574259\n",
      "Epoch 5088, reconstruction losses: 0.037114211680074956, regression losses: 0.1259119467154264, validation losses: 0.701352164383002\n",
      "Epoch 5089, reconstruction losses: 0.03132995711503661, regression losses: 0.14750166428853825, validation losses: 0.5324049149257593\n",
      "Epoch 5090, reconstruction losses: 0.03203230116529908, regression losses: 0.17328179768010327, validation losses: 0.4798730870707945\n",
      "Epoch 5091, reconstruction losses: 0.03057171472464345, regression losses: 0.11045304045428965, validation losses: 0.5005887337407494\n",
      "Epoch 5092, reconstruction losses: 0.030964860426870407, regression losses: 0.15331711431415868, validation losses: 0.45247570702626827\n",
      "Epoch 5093, reconstruction losses: 0.03790469609561151, regression losses: 0.12231724900473892, validation losses: 0.6065835957960627\n",
      "Epoch 5094, reconstruction losses: 0.0349482029306169, regression losses: 0.17780897839577978, validation losses: 0.46181198508852106\n",
      "Epoch 5095, reconstruction losses: 0.03823535263832221, regression losses: 0.09636614699324325, validation losses: 0.46587600508371185\n",
      "Epoch 5096, reconstruction losses: 0.03817083475431772, regression losses: 0.1251717271341573, validation losses: 0.42746096081125545\n",
      "Epoch 5097, reconstruction losses: 0.03277940229623654, regression losses: 0.10393077582541156, validation losses: 0.452625921705613\n",
      "Epoch 5098, reconstruction losses: 0.029418724222196005, regression losses: 0.10572447023606386, validation losses: 0.4624035784891283\n",
      "Epoch 5099, reconstruction losses: 0.03013979402895992, regression losses: 0.11134848408208425, validation losses: 0.43019986589919607\n",
      "Epoch 5100, reconstruction losses: 0.03105463306320161, regression losses: 0.12500915130599946, validation losses: 0.433704570782336\n",
      "Epoch 5101, reconstruction losses: 0.03314700955824466, regression losses: 0.13416408995618473, validation losses: 0.4853432080146365\n",
      "Epoch 5102, reconstruction losses: 0.03266019961976432, regression losses: 0.11091190597190076, validation losses: 0.5375220435461054\n",
      "Epoch 5103, reconstruction losses: 0.031266886339927316, regression losses: 0.09629647268993052, validation losses: 0.5425769343263779\n",
      "Epoch 5104, reconstruction losses: 0.03103761691056053, regression losses: 0.1233417805162672, validation losses: 0.4424671901624568\n",
      "Epoch 5105, reconstruction losses: 0.03759448105090222, regression losses: 0.11023096887701947, validation losses: 0.42204675751016074\n",
      "Epoch 5106, reconstruction losses: 0.03292251610262743, regression losses: 0.0985367895324653, validation losses: 0.42318818228864374\n",
      "Epoch 5107, reconstruction losses: 0.030550892230978316, regression losses: 0.1045932439084518, validation losses: 0.471778296398382\n",
      "Epoch 5108, reconstruction losses: 0.03453977857027966, regression losses: 0.09418934838954675, validation losses: 0.4698634003918619\n",
      "Epoch 5109, reconstruction losses: 0.030998125662726566, regression losses: 0.13651094947128417, validation losses: 0.47088688241251925\n",
      "Epoch 5110, reconstruction losses: 0.032198648689938894, regression losses: 0.09189522050945172, validation losses: 0.4948578707287612\n",
      "Epoch 5111, reconstruction losses: 0.030413230536648378, regression losses: 0.08900340789259968, validation losses: 0.4688593646591236\n",
      "Epoch 5112, reconstruction losses: 0.03630986121054722, regression losses: 0.10049099366411791, validation losses: 0.42158960429286507\n",
      "Epoch 5113, reconstruction losses: 0.03137221878684675, regression losses: 0.136096184346245, validation losses: 0.43464784250838784\n",
      "Epoch 5114, reconstruction losses: 0.031222852398286465, regression losses: 0.11423670592308183, validation losses: 0.550602777351981\n",
      "Epoch 5115, reconstruction losses: 0.03234787513585608, regression losses: 0.15512277840633765, validation losses: 0.4873963263732273\n",
      "Epoch 5116, reconstruction losses: 0.03101683839742065, regression losses: 0.1556893557281258, validation losses: 0.5043649934044024\n",
      "Epoch 5117, reconstruction losses: 0.03287769044817019, regression losses: 0.17127193793334805, validation losses: 0.5408085880563165\n",
      "Epoch 5118, reconstruction losses: 0.0340711636944025, regression losses: 0.1811308059888647, validation losses: 0.5058326287148124\n",
      "Epoch 5119, reconstruction losses: 0.03317124005258586, regression losses: 0.09935827374971841, validation losses: 0.7445615308211028\n",
      "Epoch 5120, reconstruction losses: 0.032477892875832276, regression losses: 0.16573496881649097, validation losses: 0.6675045670009829\n",
      "Epoch 5121, reconstruction losses: 0.031000588554030976, regression losses: 0.12869205748205406, validation losses: 0.4884050489832369\n",
      "Epoch 5122, reconstruction losses: 0.034815544676216385, regression losses: 0.36976646571455846, validation losses: 0.4918183808950293\n",
      "Epoch 5123, reconstruction losses: 0.03446344529048201, regression losses: 0.207477494051938, validation losses: 0.7592328371408044\n",
      "Epoch 5124, reconstruction losses: 0.03330818610272068, regression losses: 0.13000584534725185, validation losses: 0.6645528360396181\n",
      "Epoch 5125, reconstruction losses: 0.0396097113731607, regression losses: 0.11635895719937427, validation losses: 0.6990476964830634\n",
      "Epoch 5126, reconstruction losses: 0.03015357556902544, regression losses: 0.12520168818257366, validation losses: 0.548091034318303\n",
      "Epoch 5127, reconstruction losses: 0.032220025064840604, regression losses: 0.13988758939876209, validation losses: 0.49918984710438197\n",
      "Epoch 5128, reconstruction losses: 0.032635871279779474, regression losses: 0.13444206384971547, validation losses: 0.4997232166349639\n",
      "Epoch 5129, reconstruction losses: 0.030562787334685405, regression losses: 0.12251945748783104, validation losses: 0.45052784307829075\n",
      "Epoch 5130, reconstruction losses: 0.03291142797857826, regression losses: 0.1633424677659042, validation losses: 0.41979410412457185\n",
      "Epoch 5131, reconstruction losses: 0.035658720931315, regression losses: 0.09997180127302051, validation losses: 0.4173401711783656\n",
      "Epoch 5132, reconstruction losses: 0.031075377351880467, regression losses: 0.11317360164429584, validation losses: 0.42214878789813337\n",
      "Epoch 5133, reconstruction losses: 0.03102359114948699, regression losses: 0.11409474596791291, validation losses: 0.44702787318671644\n",
      "Epoch 5134, reconstruction losses: 0.030452586761846583, regression losses: 0.08601449412737155, validation losses: 0.46998531639699354\n",
      "Epoch 5135, reconstruction losses: 0.03139746857089637, regression losses: 0.10814731082820063, validation losses: 0.5416761706167961\n",
      "Epoch 5136, reconstruction losses: 0.033027921812811584, regression losses: 0.10796213269534823, validation losses: 0.5315492832434867\n",
      "Epoch 5137, reconstruction losses: 0.033246802178200044, regression losses: 0.13463441925693792, validation losses: 0.45643998954381\n",
      "Epoch 5138, reconstruction losses: 0.03695181801333741, regression losses: 0.13620485113096498, validation losses: 0.4134644020933673\n",
      "Epoch 5139, reconstruction losses: 0.03269689781223483, regression losses: 0.13563636964826306, validation losses: 0.4815837469758587\n",
      "Epoch 5140, reconstruction losses: 0.03424706463551104, regression losses: 0.11959249190342576, validation losses: 0.48294253038062585\n",
      "Epoch 5141, reconstruction losses: 0.02936627578102368, regression losses: 0.17246173290945296, validation losses: 0.49914707149690196\n",
      "Epoch 5142, reconstruction losses: 0.03003896403372171, regression losses: 0.12766303109462748, validation losses: 0.4463611082958213\n",
      "Epoch 5143, reconstruction losses: 0.031043188844586178, regression losses: 0.10609092973938163, validation losses: 0.44532338242109415\n",
      "Epoch 5144, reconstruction losses: 0.03154262866231075, regression losses: 0.0947111665425896, validation losses: 0.5245862263743963\n",
      "Epoch 5145, reconstruction losses: 0.030597463035354162, regression losses: 0.11097088445115515, validation losses: 0.5277201039892933\n",
      "Epoch 5146, reconstruction losses: 0.03384956548834003, regression losses: 0.24995161626278434, validation losses: 0.44776931295962497\n",
      "Epoch 5147, reconstruction losses: 0.03350599151882905, regression losses: 0.11828125374753946, validation losses: 0.6140106490136176\n",
      "Epoch 5148, reconstruction losses: 0.037295374682815075, regression losses: 0.11501103617509534, validation losses: 0.4596571974905297\n",
      "Epoch 5149, reconstruction losses: 0.03226152377434563, regression losses: 0.11100464851607762, validation losses: 0.4677904785802932\n",
      "Epoch 5150, reconstruction losses: 0.03443636863187069, regression losses: 0.11617365360737981, validation losses: 0.4957559086399492\n",
      "Epoch 5151, reconstruction losses: 0.033749739663264375, regression losses: 0.09736899213441781, validation losses: 0.4626921887325389\n",
      "Epoch 5152, reconstruction losses: 0.031843430661034615, regression losses: 0.13625162312549666, validation losses: 0.4675838470156314\n",
      "Epoch 5153, reconstruction losses: 0.031112550264681592, regression losses: 0.12612766943974252, validation losses: 0.5420097642180122\n",
      "Epoch 5154, reconstruction losses: 0.03143397358962846, regression losses: 0.17496143791727317, validation losses: 0.461461128664895\n",
      "Epoch 5155, reconstruction losses: 0.03583553479286856, regression losses: 0.09512367227799325, validation losses: 0.4568355545936237\n",
      "Epoch 5156, reconstruction losses: 0.03187091797281313, regression losses: 0.14059554500060004, validation losses: 0.4871567693938997\n",
      "Epoch 5157, reconstruction losses: 0.03386720268407452, regression losses: 0.10930231778593232, validation losses: 0.4955434238642177\n",
      "Epoch 5158, reconstruction losses: 0.028442947626616234, regression losses: 0.11657885943744985, validation losses: 0.47879979916569404\n",
      "Epoch 5159, reconstruction losses: 0.03349741743721867, regression losses: 0.12707666636752274, validation losses: 0.45830149822659644\n",
      "Epoch 5160, reconstruction losses: 0.030672288658373473, regression losses: 0.16617859344024435, validation losses: 0.4598552999789125\n",
      "Epoch 5161, reconstruction losses: 0.034374939959395286, regression losses: 0.09772686015953916, validation losses: 0.5077980019135648\n",
      "Epoch 5162, reconstruction losses: 0.03224704312364019, regression losses: 0.1127372825594896, validation losses: 0.46319621612839956\n",
      "Epoch 5163, reconstruction losses: 0.03154540455423298, regression losses: 0.1019918425293543, validation losses: 0.4377673606984154\n",
      "Epoch 5164, reconstruction losses: 0.03331519925440362, regression losses: 0.1626076663850431, validation losses: 0.43760877434104756\n",
      "Epoch 5165, reconstruction losses: 0.03291858482233451, regression losses: 0.12156103606021926, validation losses: 0.4956672161417322\n",
      "Epoch 5166, reconstruction losses: 0.029279373733143398, regression losses: 0.13803528982072874, validation losses: 0.4664605683831216\n",
      "Epoch 5167, reconstruction losses: 0.032102063605630664, regression losses: 0.23818349351293, validation losses: 0.4645301477558594\n",
      "Epoch 5168, reconstruction losses: 0.03656997703074698, regression losses: 0.11801736906239317, validation losses: 0.5427697639016402\n",
      "Epoch 5169, reconstruction losses: 0.030725263724643077, regression losses: 0.17561667911575696, validation losses: 0.510157866023315\n",
      "Epoch 5170, reconstruction losses: 0.03164039073674671, regression losses: 0.15117113774502466, validation losses: 0.5148049966855355\n",
      "Epoch 5171, reconstruction losses: 0.029606483735263287, regression losses: 0.12346273762965833, validation losses: 0.4601709296210443\n",
      "Epoch 5172, reconstruction losses: 0.03495368909054116, regression losses: 0.1274678930640899, validation losses: 0.5633367015771094\n",
      "Epoch 5173, reconstruction losses: 0.03409372987846495, regression losses: 0.26418875709675416, validation losses: 0.5266118007049738\n",
      "Epoch 5174, reconstruction losses: 0.03429990123005256, regression losses: 0.13453983389085217, validation losses: 0.7998427606062264\n",
      "Epoch 5175, reconstruction losses: 0.032912136885109584, regression losses: 0.14870427658042415, validation losses: 0.6760133716692441\n",
      "Epoch 5176, reconstruction losses: 0.03011095653454298, regression losses: 0.11469452501902389, validation losses: 0.5011546677095797\n",
      "Epoch 5177, reconstruction losses: 0.02977232123737556, regression losses: 0.11718740393727797, validation losses: 0.5616963294834996\n",
      "Epoch 5178, reconstruction losses: 0.04117020463415079, regression losses: 0.15495102737497485, validation losses: 0.6039373975798414\n",
      "Epoch 5179, reconstruction losses: 0.03178339314916059, regression losses: 0.09504694522404981, validation losses: 0.6067698684326064\n",
      "Epoch 5180, reconstruction losses: 0.030293426970817845, regression losses: 0.1369255405268282, validation losses: 0.522137214192225\n",
      "Epoch 5181, reconstruction losses: 0.03651212247735611, regression losses: 0.12763149501526236, validation losses: 0.4954474108587527\n",
      "Epoch 5182, reconstruction losses: 0.030527602275123817, regression losses: 0.13480261733537677, validation losses: 0.44795529605548756\n",
      "Epoch 5183, reconstruction losses: 0.03099835855788628, regression losses: 0.1272074092793693, validation losses: 0.5360562341638988\n",
      "Epoch 5184, reconstruction losses: 0.038394273214807456, regression losses: 0.11108713497684766, validation losses: 0.6200555202762168\n",
      "Epoch 5185, reconstruction losses: 0.03287716193197641, regression losses: 0.13525728282525382, validation losses: 0.5128233930674931\n",
      "Epoch 5186, reconstruction losses: 0.03237048549663729, regression losses: 0.08591409009215513, validation losses: 0.5000938258365086\n",
      "Epoch 5187, reconstruction losses: 0.0347615330603443, regression losses: 0.09202539824163315, validation losses: 0.47905747792904385\n",
      "Epoch 5188, reconstruction losses: 0.03189117039732039, regression losses: 0.11070025359167805, validation losses: 0.4599452568065805\n",
      "Epoch 5189, reconstruction losses: 0.03197771836773537, regression losses: 0.08570082074494718, validation losses: 0.42649092564928\n",
      "Epoch 5190, reconstruction losses: 0.030205873670073623, regression losses: 0.12227191448831806, validation losses: 0.415101455676417\n",
      "Epoch 5191, reconstruction losses: 0.02882896451721297, regression losses: 0.14772391905005805, validation losses: 0.4653570605371003\n",
      "Epoch 5192, reconstruction losses: 0.0355425453372724, regression losses: 0.11656512410738065, validation losses: 0.5068130075712385\n",
      "Epoch 5193, reconstruction losses: 0.02970118450927272, regression losses: 0.1123965819095518, validation losses: 0.48496149665740484\n",
      "Epoch 5194, reconstruction losses: 0.03338340309860967, regression losses: 0.10480094464764185, validation losses: 0.47506729058099173\n",
      "Epoch 5195, reconstruction losses: 0.031376598200382265, regression losses: 0.11926814563858662, validation losses: 0.45313688989226647\n",
      "Epoch 5196, reconstruction losses: 0.030966306369275085, regression losses: 0.10771859657941783, validation losses: 0.4507646800147452\n",
      "Epoch 5197, reconstruction losses: 0.03172670552904869, regression losses: 0.13391118549921036, validation losses: 0.426400517263396\n",
      "Epoch 5198, reconstruction losses: 0.0302697356101984, regression losses: 0.0961224709133151, validation losses: 0.43320617806550504\n",
      "Epoch 5199, reconstruction losses: 0.030232648723205878, regression losses: 0.1604265877956146, validation losses: 0.45500669253367937\n",
      "Epoch 5200, reconstruction losses: 0.029741560259308894, regression losses: 0.1402693769819825, validation losses: 0.47593155521836417\n",
      "Epoch 5201, reconstruction losses: 0.02972568099540555, regression losses: 0.12196450711894714, validation losses: 0.5149618723641164\n",
      "Epoch 5202, reconstruction losses: 0.0347684250085991, regression losses: 0.34054173302620017, validation losses: 0.49711769152032637\n",
      "Epoch 5203, reconstruction losses: 0.02909348328047962, regression losses: 0.0973282107480899, validation losses: 0.8092038244478822\n",
      "Epoch 5204, reconstruction losses: 0.030459962254651057, regression losses: 0.12605558850077453, validation losses: 0.6603649367051458\n",
      "Epoch 5205, reconstruction losses: 0.033284047321960865, regression losses: 0.14279181042863137, validation losses: 0.6595789575223434\n",
      "Epoch 5206, reconstruction losses: 0.029120047624003928, regression losses: 0.10231038961723514, validation losses: 0.5376377102330554\n",
      "Epoch 5207, reconstruction losses: 0.03146502105958335, regression losses: 0.1012971071484024, validation losses: 0.4255842780967514\n",
      "Epoch 5208, reconstruction losses: 0.034130169761138085, regression losses: 0.23150978252523519, validation losses: 0.43931768522799625\n",
      "Epoch 5209, reconstruction losses: 0.029815833545938652, regression losses: 0.12320984935390254, validation losses: 0.477929980786938\n",
      "Epoch 5210, reconstruction losses: 0.030516142247628216, regression losses: 0.11474202720379903, validation losses: 0.5118797619384456\n",
      "Epoch 5211, reconstruction losses: 0.031082409004141515, regression losses: 0.11028648219649136, validation losses: 0.5045498499390128\n",
      "Epoch 5212, reconstruction losses: 0.029452512200852897, regression losses: 0.12382690811971267, validation losses: 0.5309396452298284\n",
      "Epoch 5213, reconstruction losses: 0.03135446781244533, regression losses: 0.1044179101623631, validation losses: 0.5604288018310205\n",
      "Epoch 5214, reconstruction losses: 0.03616007226777587, regression losses: 0.303426713008524, validation losses: 0.5167137070447285\n",
      "Epoch 5215, reconstruction losses: 0.03408482296848235, regression losses: 0.1772596741980116, validation losses: 0.7029152691944922\n",
      "Epoch 5216, reconstruction losses: 0.028866226610859788, regression losses: 0.1611525462926705, validation losses: 0.5322080785653996\n",
      "Epoch 5217, reconstruction losses: 0.030471431212735954, regression losses: 0.14404621511810045, validation losses: 0.5326984602065038\n",
      "Epoch 5218, reconstruction losses: 0.03193166033342345, regression losses: 0.15521378430580662, validation losses: 0.6111687193946196\n",
      "Epoch 5219, reconstruction losses: 0.02943066632738578, regression losses: 0.14464463279316953, validation losses: 0.4653543659359254\n",
      "Epoch 5220, reconstruction losses: 0.03208685286064722, regression losses: 0.12498317053821151, validation losses: 0.5032899491229488\n",
      "Epoch 5221, reconstruction losses: 0.03587847877855335, regression losses: 0.12567229572364264, validation losses: 0.47681405149189\n",
      "Epoch 5222, reconstruction losses: 0.030001815873871872, regression losses: 0.12216025301982719, validation losses: 0.5293555677009377\n",
      "Epoch 5223, reconstruction losses: 0.029954502369429453, regression losses: 0.1320424055259103, validation losses: 0.5187111182164049\n",
      "Epoch 5224, reconstruction losses: 0.03304058766617184, regression losses: 0.16704680079541165, validation losses: 0.4438067148767393\n",
      "Epoch 5225, reconstruction losses: 0.03826551374795285, regression losses: 0.10535231893770708, validation losses: 0.42877322912506505\n",
      "Epoch 5226, reconstruction losses: 0.03285836072870029, regression losses: 0.10971028839975475, validation losses: 0.432459555471445\n",
      "Epoch 5227, reconstruction losses: 0.033325766089326726, regression losses: 0.0893338844662934, validation losses: 0.4502431804479923\n",
      "Epoch 5228, reconstruction losses: 0.032031630203222264, regression losses: 0.08773912235718048, validation losses: 0.4687620589663171\n",
      "Epoch 5229, reconstruction losses: 0.032592280888736266, regression losses: 0.1337019118267507, validation losses: 0.4603354942131974\n",
      "Epoch 5230, reconstruction losses: 0.029840775512609673, regression losses: 0.11684783499243742, validation losses: 0.41372626868425244\n",
      "Epoch 5231, reconstruction losses: 0.028944027592043575, regression losses: 0.134286930329001, validation losses: 0.4074340933762117\n",
      "Epoch 5232, reconstruction losses: 0.032715780782693896, regression losses: 0.13662456705414353, validation losses: 0.4850870421320796\n",
      "Epoch 5233, reconstruction losses: 0.03339190441665824, regression losses: 0.11553307878744214, validation losses: 0.4878386107461835\n",
      "Epoch 5234, reconstruction losses: 0.028497026437764857, regression losses: 0.10104689941510049, validation losses: 0.46801191057788677\n",
      "Epoch 5235, reconstruction losses: 0.030896677745341057, regression losses: 0.13481671853708738, validation losses: 0.4807678402972688\n",
      "Epoch 5236, reconstruction losses: 0.031394199493119966, regression losses: 0.11326395746863488, validation losses: 0.4376649649525506\n",
      "Epoch 5237, reconstruction losses: 0.03076147860674499, regression losses: 0.09502180891514621, validation losses: 0.43686836082174235\n",
      "Epoch 5238, reconstruction losses: 0.030830909802978538, regression losses: 0.14250882584954003, validation losses: 0.43727459724607237\n",
      "Epoch 5239, reconstruction losses: 0.03937308112866043, regression losses: 0.1412247104844555, validation losses: 0.4139299591916106\n",
      "Epoch 5240, reconstruction losses: 0.03140393390767936, regression losses: 0.11762455153749064, validation losses: 0.43740192325775307\n",
      "Epoch 5241, reconstruction losses: 0.03230782930036695, regression losses: 0.09255725835146063, validation losses: 0.5247990688592069\n",
      "Epoch 5242, reconstruction losses: 0.028668138574253366, regression losses: 0.10745527450258818, validation losses: 0.5050606646745581\n",
      "Epoch 5243, reconstruction losses: 0.028605550250578572, regression losses: 0.10590530700163343, validation losses: 0.4381228486251684\n",
      "Epoch 5244, reconstruction losses: 0.03418261208868794, regression losses: 0.12389194204044608, validation losses: 0.4431836897963076\n",
      "Epoch 5245, reconstruction losses: 0.030219846592245463, regression losses: 0.12139267935816318, validation losses: 0.460343520718003\n",
      "Epoch 5246, reconstruction losses: 0.029996388422390375, regression losses: 0.20098746373245713, validation losses: 0.4479302443287079\n",
      "Epoch 5247, reconstruction losses: 0.03263073443627836, regression losses: 0.12250437305431157, validation losses: 0.7394234340304149\n",
      "Epoch 5248, reconstruction losses: 0.03131526781316448, regression losses: 0.16861786623221509, validation losses: 0.5793580516515086\n",
      "Epoch 5249, reconstruction losses: 0.03387947280064411, regression losses: 0.11189337578472527, validation losses: 0.5615646767792887\n",
      "Epoch 5250, reconstruction losses: 0.029588825556038128, regression losses: 0.10878789649739969, validation losses: 0.5440879066504811\n",
      "Epoch 5251, reconstruction losses: 0.03383187051685782, regression losses: 0.24375248381841708, validation losses: 0.4304173254925287\n",
      "Epoch 5252, reconstruction losses: 0.031280977170370095, regression losses: 0.09767859204739017, validation losses: 0.523123000462812\n",
      "Epoch 5253, reconstruction losses: 0.0307439235386053, regression losses: 0.29300557011335976, validation losses: 0.5276069316927151\n",
      "Epoch 5254, reconstruction losses: 0.029059248042691832, regression losses: 0.11487735352189285, validation losses: 0.4800113229167961\n",
      "Epoch 5255, reconstruction losses: 0.03632730168017501, regression losses: 0.12596298543074289, validation losses: 0.48399692224623286\n",
      "Epoch 5256, reconstruction losses: 0.029203373159201344, regression losses: 0.10501212129696895, validation losses: 0.5324876509971413\n",
      "Epoch 5257, reconstruction losses: 0.03210622743718992, regression losses: 0.14852466929089483, validation losses: 0.45308733797048034\n",
      "Epoch 5258, reconstruction losses: 0.02953105432180941, regression losses: 0.11590084512764237, validation losses: 0.4196761052292445\n",
      "Epoch 5259, reconstruction losses: 0.033314581842889816, regression losses: 0.09686632217620977, validation losses: 0.4208629518966208\n",
      "Epoch 5260, reconstruction losses: 0.029450713696740818, regression losses: 0.09530128872048521, validation losses: 0.45211401977044985\n",
      "Epoch 5261, reconstruction losses: 0.034923054641746415, regression losses: 0.11716928623192022, validation losses: 0.45609549268168836\n",
      "Epoch 5262, reconstruction losses: 0.033972229086726057, regression losses: 0.3762307019427874, validation losses: 0.44239706140889284\n",
      "Epoch 5263, reconstruction losses: 0.03247891340011251, regression losses: 0.1822287507518044, validation losses: 0.6361498011700891\n",
      "Epoch 5264, reconstruction losses: 0.03154475657484659, regression losses: 0.13358170277794965, validation losses: 0.5237823944029102\n",
      "Epoch 5265, reconstruction losses: 0.03010120280102407, regression losses: 0.09870284795194965, validation losses: 0.4806993749298039\n",
      "Epoch 5266, reconstruction losses: 0.02763385787868017, regression losses: 0.14165876351966342, validation losses: 0.445705801751141\n",
      "Epoch 5267, reconstruction losses: 0.034137027546188387, regression losses: 0.3677252171017571, validation losses: 0.4745470837011686\n",
      "Epoch 5268, reconstruction losses: 0.03331714709274738, regression losses: 0.09641770526685933, validation losses: 0.7449420467590145\n",
      "Epoch 5269, reconstruction losses: 0.032702163739666064, regression losses: 0.13148880211073652, validation losses: 0.6334084660829374\n",
      "Epoch 5270, reconstruction losses: 0.028716822302513312, regression losses: 0.1200406039043102, validation losses: 0.5612435441048267\n",
      "Epoch 5271, reconstruction losses: 0.03216847759465452, regression losses: 0.11414571201741046, validation losses: 0.47752289401119935\n",
      "Epoch 5272, reconstruction losses: 0.03448151162343481, regression losses: 0.11260828218899341, validation losses: 0.45779851155390366\n",
      "Epoch 5273, reconstruction losses: 0.037074006999286035, regression losses: 0.1335758440684334, validation losses: 0.44558330257197737\n",
      "Epoch 5274, reconstruction losses: 0.032557666949010064, regression losses: 0.24264712556795728, validation losses: 0.4939648762128808\n",
      "Epoch 5275, reconstruction losses: 0.03309691240145091, regression losses: 0.09908317029649506, validation losses: 0.8588849413278228\n",
      "Epoch 5276, reconstruction losses: 0.03052651038771283, regression losses: 0.17156725629515895, validation losses: 0.5760599366460113\n",
      "Epoch 5277, reconstruction losses: 0.032126578872113565, regression losses: 0.1726927026133921, validation losses: 0.4928544063370617\n",
      "Epoch 5278, reconstruction losses: 0.029352328936893952, regression losses: 0.09851659309838952, validation losses: 0.43396456273413436\n",
      "Epoch 5279, reconstruction losses: 0.03163817459263949, regression losses: 0.09322548850790108, validation losses: 0.4986878366474378\n",
      "Epoch 5280, reconstruction losses: 0.030681293612824827, regression losses: 0.1305541354277013, validation losses: 0.4437160752851679\n",
      "Epoch 5281, reconstruction losses: 0.034497801163646924, regression losses: 0.11251853225745687, validation losses: 0.4451566227297433\n",
      "Epoch 5282, reconstruction losses: 0.032218926987575475, regression losses: 0.17331932157619773, validation losses: 0.466509073262192\n",
      "Epoch 5283, reconstruction losses: 0.029536394355451412, regression losses: 0.12197343466487359, validation losses: 0.676747487301544\n",
      "Epoch 5284, reconstruction losses: 0.030658425599533957, regression losses: 0.15238030712307227, validation losses: 0.5475628705948518\n",
      "Epoch 5285, reconstruction losses: 0.031469536865097396, regression losses: 0.13308896813652688, validation losses: 0.5558756537720809\n",
      "Epoch 5286, reconstruction losses: 0.030848486262718643, regression losses: 0.13916316454281683, validation losses: 0.5895635091103061\n",
      "Epoch 5287, reconstruction losses: 0.03156174150816363, regression losses: 0.11828576282531367, validation losses: 0.46504902781408514\n",
      "Epoch 5288, reconstruction losses: 0.03394863033749822, regression losses: 0.15825764985624016, validation losses: 0.44045217789166435\n",
      "Epoch 5289, reconstruction losses: 0.032168875282979244, regression losses: 0.1173369036472233, validation losses: 0.5061112991358894\n",
      "Epoch 5290, reconstruction losses: 0.03280953839738445, regression losses: 0.11077785423633889, validation losses: 0.5351223679363026\n",
      "Epoch 5291, reconstruction losses: 0.030981983490714328, regression losses: 0.12286695900308883, validation losses: 0.4994162892209829\n",
      "Epoch 5292, reconstruction losses: 0.03152857550189931, regression losses: 0.09760702651297294, validation losses: 0.5341267991926036\n",
      "Epoch 5293, reconstruction losses: 0.0343514089824825, regression losses: 0.10898172708140808, validation losses: 0.5508694267057982\n",
      "Epoch 5294, reconstruction losses: 0.03248274455226599, regression losses: 0.1581835099171733, validation losses: 0.5158961321143991\n",
      "Epoch 5295, reconstruction losses: 0.0302149819191717, regression losses: 0.10633380341828413, validation losses: 0.5516888704992149\n",
      "Epoch 5296, reconstruction losses: 0.029803051120455844, regression losses: 0.1263066134426422, validation losses: 0.49014752554667157\n",
      "Epoch 5297, reconstruction losses: 0.03357826615125255, regression losses: 0.13008608768775592, validation losses: 0.4398068494668358\n",
      "Epoch 5298, reconstruction losses: 0.035731436614905354, regression losses: 0.13980707529806766, validation losses: 0.46414506644356246\n",
      "Epoch 5299, reconstruction losses: 0.02914732083838469, regression losses: 0.12711086168206667, validation losses: 0.4335553684899301\n",
      "Epoch 5300, reconstruction losses: 0.03176811645045789, regression losses: 0.23720476914615168, validation losses: 0.5304921020628963\n",
      "Epoch 5301, reconstruction losses: 0.031320028404372036, regression losses: 0.14719745110541746, validation losses: 0.6517794496674013\n",
      "Epoch 5302, reconstruction losses: 0.03915039268931869, regression losses: 0.13030666545663624, validation losses: 0.5363965555101087\n",
      "Epoch 5303, reconstruction losses: 0.030961739337918025, regression losses: 0.11403127631480851, validation losses: 0.4324866554796549\n",
      "Epoch 5304, reconstruction losses: 0.03408672412770089, regression losses: 0.11276813636539812, validation losses: 0.4208309768542807\n",
      "Epoch 5305, reconstruction losses: 0.02947920864879925, regression losses: 0.10187324290344289, validation losses: 0.5625565719980736\n",
      "Epoch 5306, reconstruction losses: 0.033085311004599896, regression losses: 0.179144444675051, validation losses: 0.5242640057796907\n",
      "Epoch 5307, reconstruction losses: 0.028241223382810193, regression losses: 0.10977692571157444, validation losses: 0.4392456861917802\n",
      "Epoch 5308, reconstruction losses: 0.03227722397887159, regression losses: 0.1261067113419887, validation losses: 0.41424717322002225\n",
      "Epoch 5309, reconstruction losses: 0.02744451969412814, regression losses: 0.09130757531542685, validation losses: 0.4446644784568704\n",
      "Epoch 5310, reconstruction losses: 0.03108351972401968, regression losses: 0.11638245993893415, validation losses: 0.4358191954822716\n",
      "Epoch 5311, reconstruction losses: 0.030157907799991664, regression losses: 0.1005591650178778, validation losses: 0.4197762534898423\n",
      "Epoch 5312, reconstruction losses: 0.032010704085977636, regression losses: 0.09243555120928998, validation losses: 0.4392832478091399\n",
      "Epoch 5313, reconstruction losses: 0.028418184768037806, regression losses: 0.10065406951220053, validation losses: 0.4280612437656344\n",
      "Epoch 5314, reconstruction losses: 0.03065331222361577, regression losses: 0.13224393765991094, validation losses: 0.45801774657435107\n",
      "Epoch 5315, reconstruction losses: 0.03273083367543081, regression losses: 0.10062502161932445, validation losses: 0.5606937332674823\n",
      "Epoch 5316, reconstruction losses: 0.03168890731198457, regression losses: 0.12452014191635005, validation losses: 0.5268197667415243\n",
      "Epoch 5317, reconstruction losses: 0.03004721074081352, regression losses: 0.10869989692689655, validation losses: 0.4912220833322264\n",
      "Epoch 5318, reconstruction losses: 0.03494302586671606, regression losses: 0.368317212145933, validation losses: 0.5573410678924258\n",
      "Epoch 5319, reconstruction losses: 0.031784600784670415, regression losses: 0.11240827654776175, validation losses: 0.7238690358509416\n",
      "Epoch 5320, reconstruction losses: 0.03050643855955647, regression losses: 0.14005533023073974, validation losses: 0.5716799641427319\n",
      "Epoch 5321, reconstruction losses: 0.029249219404863306, regression losses: 0.12954746399511113, validation losses: 0.5189707650629533\n",
      "Epoch 5322, reconstruction losses: 0.0348935134585194, regression losses: 0.11394849024122665, validation losses: 0.5064842117990771\n",
      "Epoch 5323, reconstruction losses: 0.029106335343029175, regression losses: 0.13255716289463976, validation losses: 0.46228497684934333\n",
      "Epoch 5324, reconstruction losses: 0.027425030393914217, regression losses: 0.10658109661892363, validation losses: 0.6107139783801918\n",
      "Epoch 5325, reconstruction losses: 0.031439282568983776, regression losses: 0.10747284686746597, validation losses: 0.6984316152686065\n",
      "Epoch 5326, reconstruction losses: 0.03154122158308061, regression losses: 0.14185053901100225, validation losses: 0.5573089997783207\n",
      "Epoch 5327, reconstruction losses: 0.03409549572520476, regression losses: 0.12214221349871497, validation losses: 0.4873150934697936\n",
      "Epoch 5328, reconstruction losses: 0.03198665494840135, regression losses: 0.149164391193718, validation losses: 0.459741850165429\n",
      "Epoch 5329, reconstruction losses: 0.031453356656652894, regression losses: 0.16161683643752955, validation losses: 0.4367846402448429\n",
      "Epoch 5330, reconstruction losses: 0.032851896498003394, regression losses: 0.2133811421649456, validation losses: 0.5140940413304844\n",
      "Epoch 5331, reconstruction losses: 0.0304719374125052, regression losses: 0.12750704168918958, validation losses: 0.6519975762016973\n",
      "Epoch 5332, reconstruction losses: 0.031117834206422508, regression losses: 0.15941761758689246, validation losses: 0.47718413139491966\n",
      "Epoch 5333, reconstruction losses: 0.029509596871955875, regression losses: 0.10071348493449754, validation losses: 0.48856565789770556\n",
      "Epoch 5334, reconstruction losses: 0.030368473645268762, regression losses: 0.1116569368734816, validation losses: 0.5799966698192172\n",
      "Epoch 5335, reconstruction losses: 0.03166644121447939, regression losses: 0.14561278508594244, validation losses: 0.5227154007050288\n",
      "Epoch 5336, reconstruction losses: 0.031467278264139475, regression losses: 0.12004263077442517, validation losses: 0.5441537388128397\n",
      "Epoch 5337, reconstruction losses: 0.03249226119607425, regression losses: 0.15990401327730863, validation losses: 0.45611939762262343\n",
      "Epoch 5338, reconstruction losses: 0.031223741806622435, regression losses: 0.12517208624273377, validation losses: 0.4492107917886355\n",
      "Epoch 5339, reconstruction losses: 0.03405479694501455, regression losses: 0.1538375801718531, validation losses: 0.48111130046791345\n",
      "Epoch 5340, reconstruction losses: 0.03197796396970145, regression losses: 0.15874245226450578, validation losses: 0.5243456575736176\n",
      "Epoch 5341, reconstruction losses: 0.028541798194466075, regression losses: 0.1371630216483893, validation losses: 0.5527167309606869\n",
      "Epoch 5342, reconstruction losses: 0.031445418188799264, regression losses: 0.12689741803261131, validation losses: 0.5124853048883865\n",
      "Epoch 5343, reconstruction losses: 0.033870130005915024, regression losses: 0.3832529486309971, validation losses: 0.5378770939934248\n",
      "Epoch 5344, reconstruction losses: 0.028397222911948645, regression losses: 0.14766499652405995, validation losses: 0.6781613877912831\n",
      "Epoch 5345, reconstruction losses: 0.031160646505604263, regression losses: 0.12379096211146066, validation losses: 0.5044467726229223\n",
      "Epoch 5346, reconstruction losses: 0.03437454148876259, regression losses: 0.1519813289387114, validation losses: 0.5851441535462835\n",
      "Epoch 5347, reconstruction losses: 0.03163065787204496, regression losses: 0.16042853891083425, validation losses: 0.656167993883048\n",
      "Epoch 5348, reconstruction losses: 0.03369487717975813, regression losses: 0.09342228920556313, validation losses: 0.4746299460233318\n",
      "Epoch 5349, reconstruction losses: 0.03273533918910421, regression losses: 0.17515003059594556, validation losses: 0.5195830540762447\n",
      "Epoch 5350, reconstruction losses: 0.030610424678030317, regression losses: 0.09669249548916657, validation losses: 0.6377847623421178\n",
      "Epoch 5351, reconstruction losses: 0.032266968175393665, regression losses: 0.1253762390667831, validation losses: 0.594043399679685\n",
      "Epoch 5352, reconstruction losses: 0.030316427939933548, regression losses: 0.12369781390902161, validation losses: 0.42837878861316414\n",
      "Epoch 5353, reconstruction losses: 0.02840694989319094, regression losses: 0.09422434836309707, validation losses: 0.44625632534624315\n",
      "Epoch 5354, reconstruction losses: 0.03218198535637095, regression losses: 0.14874492400315353, validation losses: 0.501445396893659\n",
      "Epoch 5355, reconstruction losses: 0.03298284844591964, regression losses: 0.12802909548171948, validation losses: 0.4796702623805258\n",
      "Epoch 5356, reconstruction losses: 0.029977527137025194, regression losses: 0.11887459051078676, validation losses: 0.4674705938335574\n",
      "Epoch 5357, reconstruction losses: 0.029952011299712623, regression losses: 0.12267642988415609, validation losses: 0.46417220439003115\n",
      "Epoch 5358, reconstruction losses: 0.030186788979208547, regression losses: 0.10646365247101096, validation losses: 0.45388515898380954\n",
      "Epoch 5359, reconstruction losses: 0.03795375318389404, regression losses: 0.10718360116093884, validation losses: 0.44226935171325826\n",
      "Epoch 5360, reconstruction losses: 0.030545556967325513, regression losses: 0.12320180696794832, validation losses: 0.40172832152196336\n",
      "Epoch 5361, reconstruction losses: 0.03411877909113784, regression losses: 0.11283897546091093, validation losses: 0.4138764367442031\n",
      "Epoch 5362, reconstruction losses: 0.03106665136804212, regression losses: 0.15419810426775585, validation losses: 0.4483320843041825\n",
      "Epoch 5363, reconstruction losses: 0.030728098582988063, regression losses: 0.08561971087096328, validation losses: 0.5287049208274962\n",
      "Epoch 5364, reconstruction losses: 0.03264459202656561, regression losses: 0.11061579008466246, validation losses: 0.45660314039024963\n",
      "Epoch 5365, reconstruction losses: 0.03317700316624984, regression losses: 0.15201517044902305, validation losses: 0.41713711127030423\n",
      "Epoch 5366, reconstruction losses: 0.02910970416641087, regression losses: 0.0996708579637131, validation losses: 0.5541916175496454\n",
      "Epoch 5367, reconstruction losses: 0.031180130990444463, regression losses: 0.12347277562983695, validation losses: 0.5345343509010345\n",
      "Epoch 5368, reconstruction losses: 0.030483197478301825, regression losses: 0.09039438168215723, validation losses: 0.4620239810631131\n",
      "Epoch 5369, reconstruction losses: 0.03531564316083333, regression losses: 0.14816347308685918, validation losses: 0.43217128611115635\n",
      "Epoch 5370, reconstruction losses: 0.02893469334773678, regression losses: 0.11729831547040398, validation losses: 0.4675064990786266\n",
      "Epoch 5371, reconstruction losses: 0.034027426817809646, regression losses: 0.12131875167544008, validation losses: 0.5301764365250643\n",
      "Epoch 5372, reconstruction losses: 0.03206735761830949, regression losses: 0.16210469333267538, validation losses: 0.5230756697612001\n",
      "Epoch 5373, reconstruction losses: 0.029116948688919057, regression losses: 0.11463109563220125, validation losses: 0.43463270108863405\n",
      "Epoch 5374, reconstruction losses: 0.03283367915920075, regression losses: 0.13441389914086327, validation losses: 0.4424956703719118\n",
      "Epoch 5375, reconstruction losses: 0.02726482047303068, regression losses: 0.09121872718336907, validation losses: 0.5772917667334457\n",
      "Epoch 5376, reconstruction losses: 0.030312709315723725, regression losses: 0.11038924064315551, validation losses: 0.5815335686165668\n",
      "Epoch 5377, reconstruction losses: 0.03240494786359714, regression losses: 0.1276540984669422, validation losses: 0.54524609936853\n",
      "Epoch 5378, reconstruction losses: 0.030176450650174547, regression losses: 0.12181306303226956, validation losses: 0.4957992462911348\n",
      "Epoch 5379, reconstruction losses: 0.02889318501243129, regression losses: 0.15738030058185945, validation losses: 0.46735646632443295\n",
      "Epoch 5380, reconstruction losses: 0.030826155299577104, regression losses: 0.11197357009163153, validation losses: 0.6360362426245684\n",
      "Epoch 5381, reconstruction losses: 0.03591939180980009, regression losses: 0.32900595620947237, validation losses: 0.7024910279411151\n",
      "Epoch 5382, reconstruction losses: 0.03822889966871678, regression losses: 0.3639395490192054, validation losses: 0.8346893050494688\n",
      "Epoch 5383, reconstruction losses: 0.0328649231411996, regression losses: 0.21441414426146, validation losses: 0.8451312593680675\n",
      "Epoch 5384, reconstruction losses: 0.030964081161070807, regression losses: 0.15008950367125598, validation losses: 0.5499952835427453\n",
      "Epoch 5385, reconstruction losses: 0.02981230899159183, regression losses: 0.12154755042523063, validation losses: 0.5574452690079289\n",
      "Epoch 5386, reconstruction losses: 0.031504831342388434, regression losses: 0.13702105866440029, validation losses: 0.4589046187773521\n",
      "Epoch 5387, reconstruction losses: 0.030084500875902514, regression losses: 0.09881421473494013, validation losses: 0.47826572533765255\n",
      "Epoch 5388, reconstruction losses: 0.03292818297319521, regression losses: 0.13493528621700734, validation losses: 0.4217763320721489\n",
      "Epoch 5389, reconstruction losses: 0.03018495062509858, regression losses: 0.12681425115857148, validation losses: 0.43596776270591786\n",
      "Epoch 5390, reconstruction losses: 0.029104810420318258, regression losses: 0.1236824825351266, validation losses: 0.486750281011764\n",
      "Epoch 5391, reconstruction losses: 0.03028366945023014, regression losses: 0.11480623423709956, validation losses: 0.4701006098059578\n",
      "Epoch 5392, reconstruction losses: 0.029115624512362697, regression losses: 0.11914715051079867, validation losses: 0.511799049029771\n",
      "Epoch 5393, reconstruction losses: 0.030307425666609215, regression losses: 0.13262431956986004, validation losses: 0.47527947658616343\n",
      "Epoch 5394, reconstruction losses: 0.03154454355784501, regression losses: 0.1334994968801586, validation losses: 0.5814182233726131\n",
      "Epoch 5395, reconstruction losses: 0.030531807920505614, regression losses: 0.1293793886737375, validation losses: 0.46598651476955233\n",
      "Epoch 5396, reconstruction losses: 0.028792351284003755, regression losses: 0.11732594713212041, validation losses: 0.43827248823282267\n",
      "Epoch 5397, reconstruction losses: 0.028988814415927648, regression losses: 0.09249853629850657, validation losses: 0.44509533995809\n",
      "Epoch 5398, reconstruction losses: 0.0311606122581738, regression losses: 0.12777867598816295, validation losses: 0.4418737467351385\n",
      "Epoch 5399, reconstruction losses: 0.027579846961808, regression losses: 0.13113621460348435, validation losses: 0.47412195059410334\n",
      "Epoch 5400, reconstruction losses: 0.03080181591831872, regression losses: 0.09165062192370226, validation losses: 0.4604628405975072\n",
      "Epoch 5401, reconstruction losses: 0.030217032218542952, regression losses: 0.17046418821295467, validation losses: 0.48332785866889694\n",
      "Epoch 5402, reconstruction losses: 0.0361216657485719, regression losses: 0.12747463859693822, validation losses: 0.5232559314653561\n",
      "Epoch 5403, reconstruction losses: 0.03196140606361449, regression losses: 0.14571146986268319, validation losses: 0.47731489306748687\n",
      "Epoch 5404, reconstruction losses: 0.03130906330254706, regression losses: 0.10995452217904116, validation losses: 0.4491885147139301\n",
      "Epoch 5405, reconstruction losses: 0.03428484578581928, regression losses: 0.0875574761968019, validation losses: 0.4353125044653799\n",
      "Epoch 5406, reconstruction losses: 0.02948789141201434, regression losses: 0.09921843036036476, validation losses: 0.4764869415143486\n",
      "Epoch 5407, reconstruction losses: 0.031870567675425635, regression losses: 0.10810924910048733, validation losses: 0.4307559844449195\n",
      "Epoch 5408, reconstruction losses: 0.029534269169919896, regression losses: 0.12723728641668156, validation losses: 0.43266781478908356\n",
      "Epoch 5409, reconstruction losses: 0.031238247550053614, regression losses: 0.09821414712691515, validation losses: 0.4209612813980427\n",
      "Epoch 5410, reconstruction losses: 0.030391298083127946, regression losses: 0.10563722425904401, validation losses: 0.44341292621150036\n",
      "Epoch 5411, reconstruction losses: 0.03010921927321415, regression losses: 0.13248823727346876, validation losses: 0.4884622308679699\n",
      "Epoch 5412, reconstruction losses: 0.03076951794582892, regression losses: 0.110473323016817, validation losses: 0.5295446748989416\n",
      "Epoch 5413, reconstruction losses: 0.02854393063444365, regression losses: 0.1203980639077495, validation losses: 0.42638126586792646\n",
      "Epoch 5414, reconstruction losses: 0.033702753899959866, regression losses: 0.10084550256537898, validation losses: 0.43427736296166447\n",
      "Epoch 5415, reconstruction losses: 0.030055787354961675, regression losses: 0.12755494644551907, validation losses: 0.4483443440576615\n",
      "Epoch 5416, reconstruction losses: 0.030569423209432806, regression losses: 0.10999435354920797, validation losses: 0.640331221958648\n",
      "Epoch 5417, reconstruction losses: 0.03229354138243755, regression losses: 0.12259631000504585, validation losses: 0.5209758193314006\n",
      "Epoch 5418, reconstruction losses: 0.031029618383881716, regression losses: 0.18807675728751222, validation losses: 0.41865695298138494\n",
      "Epoch 5419, reconstruction losses: 0.031823572488588144, regression losses: 0.13435227840850775, validation losses: 0.594102325120706\n",
      "Epoch 5420, reconstruction losses: 0.03695379168589266, regression losses: 0.12812669345773872, validation losses: 0.5474385024318279\n",
      "Epoch 5421, reconstruction losses: 0.02741765128626109, regression losses: 0.10486004123085005, validation losses: 0.5687827398774589\n",
      "Epoch 5422, reconstruction losses: 0.02874632465543273, regression losses: 0.11129156761423409, validation losses: 0.4691426276363463\n",
      "Epoch 5423, reconstruction losses: 0.030589009160070655, regression losses: 0.10340509353978707, validation losses: 0.41707067833047057\n",
      "Epoch 5424, reconstruction losses: 0.03416871165788861, regression losses: 0.16438549132713537, validation losses: 0.47272246687970715\n",
      "Epoch 5425, reconstruction losses: 0.03450526546835353, regression losses: 0.12495462867549942, validation losses: 0.5104293324502265\n",
      "Epoch 5426, reconstruction losses: 0.03187292004330395, regression losses: 0.16083770659797733, validation losses: 0.4038378211203249\n",
      "Epoch 5427, reconstruction losses: 0.028113849775110004, regression losses: 0.08687599362167449, validation losses: 0.4741980537754553\n",
      "Epoch 5428, reconstruction losses: 0.02973159948407207, regression losses: 0.09018589479708229, validation losses: 0.532727079278169\n",
      "Epoch 5429, reconstruction losses: 0.031345449095661136, regression losses: 0.13009012837943967, validation losses: 0.5517932151408189\n",
      "Epoch 5430, reconstruction losses: 0.030277525384870316, regression losses: 0.11016940383667784, validation losses: 0.46802137306960523\n",
      "Epoch 5431, reconstruction losses: 0.03262609549734037, regression losses: 0.14120943310596454, validation losses: 0.5084302390892543\n",
      "Epoch 5432, reconstruction losses: 0.03693560962626571, regression losses: 0.19157364411991434, validation losses: 0.5809839029783441\n",
      "Epoch 5433, reconstruction losses: 0.031198536842445078, regression losses: 0.14240647647589796, validation losses: 0.6384188717762017\n",
      "Epoch 5434, reconstruction losses: 0.03865875259157206, regression losses: 0.17440069196610308, validation losses: 0.5323984535447335\n",
      "Epoch 5435, reconstruction losses: 0.03706253946316407, regression losses: 0.10571644171176106, validation losses: 0.6679983470418664\n",
      "Epoch 5436, reconstruction losses: 0.036663904370632674, regression losses: 0.11863934200261304, validation losses: 0.5287930445276314\n",
      "Epoch 5437, reconstruction losses: 0.031078832729351177, regression losses: 0.12724379817160067, validation losses: 0.47284644367093226\n",
      "Epoch 5438, reconstruction losses: 0.03236160441594768, regression losses: 0.15190437310595992, validation losses: 0.5176322077129092\n",
      "Epoch 5439, reconstruction losses: 0.03176926191440685, regression losses: 0.15918544273016672, validation losses: 0.4890291087333253\n",
      "Epoch 5440, reconstruction losses: 0.031263199682952186, regression losses: 0.13470953904499355, validation losses: 0.4532163828552541\n",
      "Epoch 5441, reconstruction losses: 0.030189136362556497, regression losses: 0.09500571194317774, validation losses: 0.47171506880673336\n",
      "Epoch 5442, reconstruction losses: 0.03272712338180218, regression losses: 0.09960577492032338, validation losses: 0.45847668131446434\n",
      "Epoch 5443, reconstruction losses: 0.031141636980827662, regression losses: 0.10758124926178492, validation losses: 0.4635690474996812\n",
      "Epoch 5444, reconstruction losses: 0.03331440261867136, regression losses: 0.44875624475855547, validation losses: 0.47501256025663224\n",
      "Epoch 5445, reconstruction losses: 0.02997790354230658, regression losses: 0.15854660385964708, validation losses: 0.6745768447188306\n",
      "Epoch 5446, reconstruction losses: 0.030985351693594888, regression losses: 0.1439204277797829, validation losses: 0.692288621372136\n",
      "Epoch 5447, reconstruction losses: 0.03823332075420137, regression losses: 0.1747656021478785, validation losses: 0.5591185197423822\n",
      "Epoch 5448, reconstruction losses: 0.029028697002288863, regression losses: 0.1221478722498756, validation losses: 0.5849551670041226\n",
      "Epoch 5449, reconstruction losses: 0.033173846175134185, regression losses: 0.3885056408609209, validation losses: 0.6484941006296046\n",
      "Epoch 5450, reconstruction losses: 0.030088432987354495, regression losses: 0.14733753080270748, validation losses: 0.5963470707310704\n",
      "Epoch 5451, reconstruction losses: 0.03311866820438953, regression losses: 0.2067290176964449, validation losses: 0.5796003168646777\n",
      "Epoch 5452, reconstruction losses: 0.03420598159681042, regression losses: 0.09977591221112499, validation losses: 0.6260825339506283\n",
      "Epoch 5453, reconstruction losses: 0.031615556243801496, regression losses: 0.1597497966012384, validation losses: 0.5462156069598569\n",
      "Epoch 5454, reconstruction losses: 0.027164207537634936, regression losses: 0.10657012634037011, validation losses: 0.5220568922021467\n",
      "Epoch 5455, reconstruction losses: 0.028942222261508967, regression losses: 0.14394184020366763, validation losses: 0.5734538060625458\n",
      "Epoch 5456, reconstruction losses: 0.03391687435912098, regression losses: 0.12781783504783947, validation losses: 0.4952449027614866\n",
      "Epoch 5457, reconstruction losses: 0.02879334300277627, regression losses: 0.11852061813725118, validation losses: 0.4676335625822049\n",
      "Epoch 5458, reconstruction losses: 0.0332792610874081, regression losses: 0.08204230748177661, validation losses: 0.48831413583963035\n",
      "Epoch 5459, reconstruction losses: 0.03134668993885058, regression losses: 0.1472308669343506, validation losses: 0.4717659105899136\n",
      "Epoch 5460, reconstruction losses: 0.029672595466974813, regression losses: 0.10052954542585822, validation losses: 0.4472027538030229\n",
      "Epoch 5461, reconstruction losses: 0.0286757972697534, regression losses: 0.121234192138271, validation losses: 0.44144611893670316\n",
      "Epoch 5462, reconstruction losses: 0.029834401913920807, regression losses: 0.18648553133321744, validation losses: 0.48409557903252287\n",
      "Epoch 5463, reconstruction losses: 0.03413935149130271, regression losses: 0.11783788630772021, validation losses: 0.5745235438484023\n",
      "Epoch 5464, reconstruction losses: 0.028697111513161507, regression losses: 0.10687291379808356, validation losses: 0.6031824894607296\n",
      "Epoch 5465, reconstruction losses: 0.032057752893776784, regression losses: 0.12274915784116679, validation losses: 0.49928350663891624\n",
      "Epoch 5466, reconstruction losses: 0.02807900653130718, regression losses: 0.10914696209191005, validation losses: 0.40659212950387746\n",
      "Epoch 5467, reconstruction losses: 0.029414446164218767, regression losses: 0.1336088189710037, validation losses: 0.4376955366471384\n",
      "Epoch 5468, reconstruction losses: 0.030974967402663117, regression losses: 0.1385092079415894, validation losses: 0.4394331232739789\n",
      "Epoch 5469, reconstruction losses: 0.028818875232598733, regression losses: 0.10168063006965272, validation losses: 0.44963608207889305\n",
      "Epoch 5470, reconstruction losses: 0.028731799869666834, regression losses: 0.11664915492070908, validation losses: 0.4250836325713064\n",
      "Epoch 5471, reconstruction losses: 0.030601040868250974, regression losses: 0.12978505326846546, validation losses: 0.44181080159536734\n",
      "Epoch 5472, reconstruction losses: 0.02799487365082598, regression losses: 0.11133266153706989, validation losses: 0.45143897949300066\n",
      "Epoch 5473, reconstruction losses: 0.03062053077971105, regression losses: 0.09472880403223588, validation losses: 0.43619003571747156\n",
      "Epoch 5474, reconstruction losses: 0.03159686770368107, regression losses: 0.1819765707256154, validation losses: 0.4813080382705267\n",
      "Epoch 5475, reconstruction losses: 0.030750520066930315, regression losses: 0.15702422446291373, validation losses: 0.5729063394891551\n",
      "Epoch 5476, reconstruction losses: 0.027561194441750154, regression losses: 0.12069819839571846, validation losses: 0.4613636471193437\n",
      "Epoch 5477, reconstruction losses: 0.03265122909183054, regression losses: 0.13531275733231282, validation losses: 0.41638807774919673\n",
      "Epoch 5478, reconstruction losses: 0.02844772122718593, regression losses: 0.11497495620981611, validation losses: 0.40260020517961864\n",
      "Epoch 5479, reconstruction losses: 0.03224529002437744, regression losses: 0.4243508381009621, validation losses: 0.4465757704877146\n",
      "Epoch 5480, reconstruction losses: 0.02921642604048511, regression losses: 0.13196605044083973, validation losses: 0.7641812016136686\n",
      "Epoch 5481, reconstruction losses: 0.03069737852804085, regression losses: 0.22104190773715432, validation losses: 0.6233824956784615\n",
      "Epoch 5482, reconstruction losses: 0.028564444559325376, regression losses: 0.11074093500436641, validation losses: 0.5138073444642908\n",
      "Epoch 5483, reconstruction losses: 0.028951159064014877, regression losses: 0.1317260539662466, validation losses: 0.4910010276411446\n",
      "Epoch 5484, reconstruction losses: 0.03295809604957746, regression losses: 0.10828639054334571, validation losses: 0.4955397832680699\n",
      "Epoch 5485, reconstruction losses: 0.02983862725515082, regression losses: 0.10317463469128145, validation losses: 0.47025868360474976\n",
      "Epoch 5486, reconstruction losses: 0.033009594372732945, regression losses: 0.3869402160553222, validation losses: 0.4546616100441946\n",
      "Epoch 5487, reconstruction losses: 0.031072310860484103, regression losses: 0.13810239859016948, validation losses: 0.5939237508828523\n",
      "Epoch 5488, reconstruction losses: 0.03072552614998223, regression losses: 0.12955325258582917, validation losses: 0.5809254883838602\n",
      "Epoch 5489, reconstruction losses: 0.029941091648681122, regression losses: 0.10547673158908279, validation losses: 0.6609171051529344\n",
      "Epoch 5490, reconstruction losses: 0.03048202363673909, regression losses: 0.16377858277301602, validation losses: 0.5433431296079957\n",
      "Epoch 5491, reconstruction losses: 0.028491837113333713, regression losses: 0.08091767510694724, validation losses: 0.44660843948879003\n",
      "Epoch 5492, reconstruction losses: 0.028709270220266533, regression losses: 0.12216845868655551, validation losses: 0.4568836065379521\n",
      "Epoch 5493, reconstruction losses: 0.03196158661152426, regression losses: 0.13201405794681978, validation losses: 0.5853752688366882\n",
      "Epoch 5494, reconstruction losses: 0.0368041639761695, regression losses: 0.13081509105685668, validation losses: 0.5414120092722783\n",
      "Epoch 5495, reconstruction losses: 0.02824404020382844, regression losses: 0.1044163865827079, validation losses: 0.43788672034636267\n",
      "Epoch 5496, reconstruction losses: 0.029280776658862563, regression losses: 0.09680879381206818, validation losses: 0.44303432233617807\n",
      "Epoch 5497, reconstruction losses: 0.03418465003427158, regression losses: 0.29692341834806923, validation losses: 0.4424385150923021\n",
      "Epoch 5498, reconstruction losses: 0.03414549255367918, regression losses: 0.15042020707805734, validation losses: 0.7809139547991745\n",
      "Epoch 5499, reconstruction losses: 0.03207812389042814, regression losses: 0.1552398524511341, validation losses: 0.6282951039000595\n",
      "Epoch 5500, reconstruction losses: 0.031141342770881625, regression losses: 0.14370686262414445, validation losses: 0.5092818031700415\n",
      "Epoch 5501, reconstruction losses: 0.02992742938304325, regression losses: 0.18986589325415087, validation losses: 0.5655791213941535\n",
      "Epoch 5502, reconstruction losses: 0.030904433686372544, regression losses: 0.17199578028264526, validation losses: 0.693659278519688\n",
      "Epoch 5503, reconstruction losses: 0.02864588998917466, regression losses: 0.13552464469452827, validation losses: 0.4691127998106045\n",
      "Epoch 5504, reconstruction losses: 0.02878964923118301, regression losses: 0.09362032785389578, validation losses: 0.4314625758022504\n",
      "Epoch 5505, reconstruction losses: 0.032634756152626544, regression losses: 0.19380640195912546, validation losses: 0.47463135952319535\n",
      "Epoch 5506, reconstruction losses: 0.03002296294380404, regression losses: 0.1230706059703163, validation losses: 0.4708552918554429\n",
      "Epoch 5507, reconstruction losses: 0.03080733905653119, regression losses: 0.10774144000929434, validation losses: 0.4128367892011256\n",
      "Epoch 5508, reconstruction losses: 0.029945227945717832, regression losses: 0.14319421212662156, validation losses: 0.4584366103853724\n",
      "Epoch 5509, reconstruction losses: 0.02921223446444398, regression losses: 0.10082751365682863, validation losses: 0.5691437433553275\n",
      "Epoch 5510, reconstruction losses: 0.030873262347309128, regression losses: 0.13239484789303763, validation losses: 0.5359942113135003\n",
      "Epoch 5511, reconstruction losses: 0.028399869388388607, regression losses: 0.11071864573471338, validation losses: 0.4439023288249099\n",
      "Epoch 5512, reconstruction losses: 0.028831376190347296, regression losses: 0.14236986066309276, validation losses: 0.43457557397748053\n",
      "Epoch 5513, reconstruction losses: 0.032408986156376385, regression losses: 0.2959080626099122, validation losses: 0.5105089910936614\n",
      "Epoch 5514, reconstruction losses: 0.038502177722197974, regression losses: 0.14936643494983928, validation losses: 0.6536354062461268\n",
      "Epoch 5515, reconstruction losses: 0.032132755897150284, regression losses: 0.28543545031658346, validation losses: 0.46780409302784537\n",
      "Epoch 5516, reconstruction losses: 0.02959471600323355, regression losses: 0.15506619208191655, validation losses: 0.8619642957740241\n",
      "Epoch 5517, reconstruction losses: 0.029261867476726083, regression losses: 0.12175441033660049, validation losses: 0.8094672775470202\n",
      "Epoch 5518, reconstruction losses: 0.02888253965880173, regression losses: 0.1219343457030913, validation losses: 0.7394858120705149\n",
      "Epoch 5519, reconstruction losses: 0.036283646721109314, regression losses: 0.15405964067817823, validation losses: 0.47695740600058695\n",
      "Epoch 5520, reconstruction losses: 0.032185934360719384, regression losses: 0.13889749356640757, validation losses: 0.49485616259384896\n",
      "Epoch 5521, reconstruction losses: 0.029102810337152073, regression losses: 0.12212292282526918, validation losses: 0.4520054173641812\n",
      "Epoch 5522, reconstruction losses: 0.028667549083968222, regression losses: 0.08540353901141681, validation losses: 0.5273898760870093\n",
      "Epoch 5523, reconstruction losses: 0.029089238085889108, regression losses: 0.10740482438142601, validation losses: 0.5954475495657227\n",
      "Epoch 5524, reconstruction losses: 0.03306905920335289, regression losses: 0.21925095236280756, validation losses: 0.5101253493763962\n",
      "Epoch 5525, reconstruction losses: 0.030112804654170707, regression losses: 0.1612298707064301, validation losses: 0.6464636247415046\n",
      "Epoch 5526, reconstruction losses: 0.032202120664169435, regression losses: 0.262684838466383, validation losses: 0.6153562620128045\n",
      "Epoch 5527, reconstruction losses: 0.029782004711861588, regression losses: 0.2944415753768853, validation losses: 0.647977690494818\n",
      "Epoch 5528, reconstruction losses: 0.029492458756674757, regression losses: 0.11932616699217274, validation losses: 0.4741973542291364\n",
      "Epoch 5529, reconstruction losses: 0.03256507161079076, regression losses: 0.12677733815428538, validation losses: 0.5271545919622525\n",
      "Epoch 5530, reconstruction losses: 0.033183335014980206, regression losses: 0.30332508574583056, validation losses: 0.5172660032878698\n",
      "Epoch 5531, reconstruction losses: 0.028024730408517076, regression losses: 0.1212093475818746, validation losses: 0.6366732899042672\n",
      "Epoch 5532, reconstruction losses: 0.0299697583023137, regression losses: 0.15264753270533604, validation losses: 0.5251806473070435\n",
      "Epoch 5533, reconstruction losses: 0.02953090553516612, regression losses: 0.12386360318758624, validation losses: 0.5415816214604608\n",
      "Epoch 5534, reconstruction losses: 0.030048588236223632, regression losses: 0.10391342623084543, validation losses: 0.5369732557699716\n",
      "Epoch 5535, reconstruction losses: 0.03046394338965543, regression losses: 0.12048922282744814, validation losses: 0.48379374474868575\n",
      "Epoch 5536, reconstruction losses: 0.02867455961904287, regression losses: 0.12058557595579027, validation losses: 0.5288346331803733\n",
      "Epoch 5537, reconstruction losses: 0.02982304219539692, regression losses: 0.12122966626519195, validation losses: 0.5096770750105011\n",
      "Epoch 5538, reconstruction losses: 0.029658831168061728, regression losses: 0.0953249011867267, validation losses: 0.44434928294252823\n",
      "Epoch 5539, reconstruction losses: 0.030955662035101514, regression losses: 0.11299428649728356, validation losses: 0.44795385608784033\n",
      "Epoch 5540, reconstruction losses: 0.028009257847113403, regression losses: 0.10154708517319479, validation losses: 0.48561429413096063\n",
      "Epoch 5541, reconstruction losses: 0.032168987084092826, regression losses: 0.15820348769843037, validation losses: 0.5496983507977911\n",
      "Epoch 5542, reconstruction losses: 0.03317774291895504, regression losses: 0.11534542314341982, validation losses: 0.5108307830909052\n",
      "Epoch 5543, reconstruction losses: 0.030964103522369422, regression losses: 0.1413292882244025, validation losses: 0.4756754357957872\n",
      "Epoch 5544, reconstruction losses: 0.029699982738368644, regression losses: 0.088547902376638, validation losses: 0.5228680569946896\n",
      "Epoch 5545, reconstruction losses: 0.030210000881246004, regression losses: 0.12340172319378032, validation losses: 0.5013008196806614\n",
      "Epoch 5546, reconstruction losses: 0.03206700005333452, regression losses: 0.2054069730414552, validation losses: 0.43021754878179874\n",
      "Epoch 5547, reconstruction losses: 0.03579365441989565, regression losses: 0.09907936308959023, validation losses: 0.48402255764820734\n",
      "Epoch 5548, reconstruction losses: 0.03765248865317765, regression losses: 0.22294183913701687, validation losses: 0.4386638713900659\n",
      "Epoch 5549, reconstruction losses: 0.0318904558125032, regression losses: 0.1665974297194603, validation losses: 0.4652526589992221\n",
      "Epoch 5550, reconstruction losses: 0.031214022035821326, regression losses: 0.1704286763959494, validation losses: 0.5202129213574246\n",
      "Epoch 5551, reconstruction losses: 0.029563755735411278, regression losses: 0.09114863264355405, validation losses: 0.8371993124581845\n",
      "Epoch 5552, reconstruction losses: 0.03133884266458731, regression losses: 0.16223694119944232, validation losses: 0.5651299908729951\n",
      "Epoch 5553, reconstruction losses: 0.02675586764234463, regression losses: 0.087049081987941, validation losses: 0.49086527277516395\n",
      "Epoch 5554, reconstruction losses: 0.03125747482976921, regression losses: 0.17649930640537104, validation losses: 0.42593669506224185\n",
      "Epoch 5555, reconstruction losses: 0.031023542648210143, regression losses: 0.2983441157541168, validation losses: 0.42034823226268975\n",
      "Epoch 5556, reconstruction losses: 0.029214045941291386, regression losses: 0.11924112300196586, validation losses: 0.5311145620761967\n",
      "Epoch 5557, reconstruction losses: 0.030307766033895824, regression losses: 0.13599862057113424, validation losses: 0.574965961386204\n",
      "Epoch 5558, reconstruction losses: 0.03441074948638558, regression losses: 0.1049370519928751, validation losses: 0.6129832223996805\n",
      "Epoch 5559, reconstruction losses: 0.02879568143189731, regression losses: 0.12250927430889626, validation losses: 0.5038793564376433\n",
      "Epoch 5560, reconstruction losses: 0.03322717961687112, regression losses: 0.11303447918462711, validation losses: 0.4526353270023072\n",
      "Epoch 5561, reconstruction losses: 0.030500760631138678, regression losses: 0.1059550938467611, validation losses: 0.4337144226392912\n",
      "Epoch 5562, reconstruction losses: 0.029261249730747202, regression losses: 0.14234644546768113, validation losses: 0.5571638286173285\n",
      "Epoch 5563, reconstruction losses: 0.030014739819925446, regression losses: 0.11498718663863704, validation losses: 0.7173475892684337\n",
      "Epoch 5564, reconstruction losses: 0.034035415756273106, regression losses: 0.2301087489715712, validation losses: 0.6022137239639708\n",
      "Epoch 5565, reconstruction losses: 0.032443089719148895, regression losses: 0.14560359327186717, validation losses: 0.6070512789823431\n",
      "Epoch 5566, reconstruction losses: 0.029215094167722486, regression losses: 0.1742987337827626, validation losses: 0.49223175479990033\n",
      "Epoch 5567, reconstruction losses: 0.029787426305077688, regression losses: 0.10959780557222115, validation losses: 0.45803155367443205\n",
      "Epoch 5568, reconstruction losses: 0.028646857832618677, regression losses: 0.12201380090108585, validation losses: 0.5237477335468315\n",
      "Epoch 5569, reconstruction losses: 0.03244093068036831, regression losses: 0.1428646659702215, validation losses: 0.49633186140811053\n",
      "Epoch 5570, reconstruction losses: 0.03478221461508133, regression losses: 0.11301820850554319, validation losses: 0.5115682178830122\n",
      "Epoch 5571, reconstruction losses: 0.03079132570773394, regression losses: 0.11568702530804423, validation losses: 0.48252875684511964\n",
      "Epoch 5572, reconstruction losses: 0.0329509095081979, regression losses: 0.12062795654734347, validation losses: 0.4693171447768861\n",
      "Epoch 5573, reconstruction losses: 0.02933916056581628, regression losses: 0.11967682907144014, validation losses: 0.5751060744831186\n",
      "Epoch 5574, reconstruction losses: 0.030463001873016857, regression losses: 0.15272064156267634, validation losses: 0.5705637935997828\n",
      "Epoch 5575, reconstruction losses: 0.029733631586099818, regression losses: 0.10136267660064177, validation losses: 0.5433650311243013\n",
      "Epoch 5576, reconstruction losses: 0.02860719003715159, regression losses: 0.11973350874534427, validation losses: 0.5182113355366001\n",
      "Epoch 5577, reconstruction losses: 0.028492208790540423, regression losses: 0.14055180632031616, validation losses: 0.5027968512362713\n",
      "Epoch 5578, reconstruction losses: 0.030187739511198734, regression losses: 0.13787706826439308, validation losses: 0.46280464412532285\n",
      "Epoch 5579, reconstruction losses: 0.029740975378018425, regression losses: 0.09991717255040632, validation losses: 0.4834733826194908\n",
      "Epoch 5580, reconstruction losses: 0.026502821481801872, regression losses: 0.13566917942568793, validation losses: 0.5264101582996903\n",
      "Epoch 5581, reconstruction losses: 0.027501563656799094, regression losses: 0.11366100288273753, validation losses: 0.4713459268254627\n",
      "Epoch 5582, reconstruction losses: 0.030966224822202227, regression losses: 0.12492546914277844, validation losses: 0.41721106128368163\n",
      "Epoch 5583, reconstruction losses: 0.02877302554299997, regression losses: 0.08954500445574542, validation losses: 0.42182178247201746\n",
      "Epoch 5584, reconstruction losses: 0.03021799147895382, regression losses: 0.12174258985867954, validation losses: 0.4018982977159891\n",
      "Epoch 5585, reconstruction losses: 0.03146880168848006, regression losses: 0.15190595588952702, validation losses: 0.49261361236962964\n",
      "Epoch 5586, reconstruction losses: 0.028301292135606344, regression losses: 0.10534387931961758, validation losses: 0.49047488070834017\n",
      "Epoch 5587, reconstruction losses: 0.02971216840029422, regression losses: 0.17010699593448803, validation losses: 0.48413099871668774\n",
      "Epoch 5588, reconstruction losses: 0.028112197030042106, regression losses: 0.13416113412333175, validation losses: 0.611726127005092\n",
      "Epoch 5589, reconstruction losses: 0.033330153897604575, regression losses: 0.12107111012561467, validation losses: 0.518583419354729\n",
      "Epoch 5590, reconstruction losses: 0.028328440118287473, regression losses: 0.0905794885213344, validation losses: 0.41883117051551777\n",
      "Epoch 5591, reconstruction losses: 0.028524464276145002, regression losses: 0.11552621130589075, validation losses: 0.4110510478457036\n",
      "Epoch 5592, reconstruction losses: 0.02895307315718825, regression losses: 0.15204931370280783, validation losses: 0.4108467575586526\n",
      "Epoch 5593, reconstruction losses: 0.029010107783940517, regression losses: 0.11206178140598043, validation losses: 0.4610297011893256\n",
      "Epoch 5594, reconstruction losses: 0.03442308246411306, regression losses: 0.15912122838101406, validation losses: 0.4910443768760536\n",
      "Epoch 5595, reconstruction losses: 0.03068317456711466, regression losses: 0.10022405261678351, validation losses: 0.44005693141786967\n",
      "Epoch 5596, reconstruction losses: 0.02911507401911089, regression losses: 0.13141779909530854, validation losses: 0.4565308851303683\n",
      "Epoch 5597, reconstruction losses: 0.03375062473995943, regression losses: 0.12004753410589253, validation losses: 0.46223716268490433\n",
      "Epoch 5598, reconstruction losses: 0.030075277463828855, regression losses: 0.1127920372437966, validation losses: 0.42736949512400196\n",
      "Epoch 5599, reconstruction losses: 0.02838040980679059, regression losses: 0.11068088088822071, validation losses: 0.4357195123278051\n",
      "Epoch 5600, reconstruction losses: 0.030919191505421488, regression losses: 0.14279209387361333, validation losses: 0.46913869119757995\n",
      "Epoch 5601, reconstruction losses: 0.03277558785521693, regression losses: 0.18902362720510746, validation losses: 0.4956373372985294\n",
      "Epoch 5602, reconstruction losses: 0.0328347183536835, regression losses: 0.08639557690977093, validation losses: 0.5857513746877494\n",
      "Epoch 5603, reconstruction losses: 0.028965994635149202, regression losses: 0.11100339934832305, validation losses: 0.5093398665469957\n",
      "Epoch 5604, reconstruction losses: 0.027948898075546586, regression losses: 0.11668927420700369, validation losses: 0.528962274171098\n",
      "Epoch 5605, reconstruction losses: 0.03007894796323412, regression losses: 0.08254788589911143, validation losses: 0.5446922379403347\n",
      "Epoch 5606, reconstruction losses: 0.027245426005993185, regression losses: 0.14748483605697837, validation losses: 0.5133014685360628\n",
      "Epoch 5607, reconstruction losses: 0.028732033378093037, regression losses: 0.1040174110805629, validation losses: 0.4652857449144815\n",
      "Epoch 5608, reconstruction losses: 0.029134324536879086, regression losses: 0.12136561350768668, validation losses: 0.4452482960484299\n",
      "Epoch 5609, reconstruction losses: 0.029490508265480442, regression losses: 0.13379831929594851, validation losses: 0.508259909512006\n",
      "Epoch 5610, reconstruction losses: 0.031100570877247425, regression losses: 0.10988027910862438, validation losses: 0.5422624747166849\n",
      "Epoch 5611, reconstruction losses: 0.028493992371179423, regression losses: 0.1198554103723003, validation losses: 0.46534839437926717\n",
      "Epoch 5612, reconstruction losses: 0.03022136919130907, regression losses: 0.10805133891748503, validation losses: 0.45592028392434686\n",
      "Epoch 5613, reconstruction losses: 0.03519014320946847, regression losses: 0.12539523007517878, validation losses: 0.4184338537671866\n",
      "Epoch 5614, reconstruction losses: 0.030364545997740015, regression losses: 0.10944873012807305, validation losses: 0.43633256269212073\n",
      "Epoch 5615, reconstruction losses: 0.029584864607448275, regression losses: 0.11658401852731519, validation losses: 0.4240685856102053\n",
      "Epoch 5616, reconstruction losses: 0.030553849964636493, regression losses: 0.10680672100746103, validation losses: 0.4830038792666279\n",
      "Epoch 5617, reconstruction losses: 0.030134224396653118, regression losses: 0.10639151147212274, validation losses: 0.4256098940034754\n",
      "Epoch 5618, reconstruction losses: 0.02965341892649027, regression losses: 0.1269889167447308, validation losses: 0.4311495546834978\n",
      "Epoch 5619, reconstruction losses: 0.033440413612546405, regression losses: 0.1541243591345426, validation losses: 0.42489764389612017\n",
      "Epoch 5620, reconstruction losses: 0.0297653174300071, regression losses: 0.11470557289131361, validation losses: 0.5494863327990084\n",
      "Epoch 5621, reconstruction losses: 0.0332783939920314, regression losses: 0.16298507206858548, validation losses: 0.5075372480616429\n",
      "Epoch 5622, reconstruction losses: 0.029135061475846893, regression losses: 0.18961165341090763, validation losses: 0.5105558142261813\n",
      "Epoch 5623, reconstruction losses: 0.03224070451677061, regression losses: 0.20139561349852553, validation losses: 0.44551269643063685\n",
      "Epoch 5624, reconstruction losses: 0.029576542166557238, regression losses: 0.09160893118287301, validation losses: 0.5166545945135484\n",
      "Epoch 5625, reconstruction losses: 0.02788062159756916, regression losses: 0.12632702621368816, validation losses: 0.6103376925492453\n",
      "Epoch 5626, reconstruction losses: 0.03047036941990568, regression losses: 0.12231000702958128, validation losses: 0.4785107860298113\n",
      "Epoch 5627, reconstruction losses: 0.025454224899571505, regression losses: 0.09298106900018627, validation losses: 0.46437525621758347\n",
      "Epoch 5628, reconstruction losses: 0.02809644775416654, regression losses: 0.10016766458098937, validation losses: 0.4473600753609423\n",
      "Epoch 5629, reconstruction losses: 0.036046673759128144, regression losses: 0.1300376075648776, validation losses: 0.4429179309481358\n",
      "Epoch 5630, reconstruction losses: 0.031562289733257774, regression losses: 0.09604524753922954, validation losses: 0.43650893671355057\n",
      "Epoch 5631, reconstruction losses: 0.031515454698975875, regression losses: 0.11200782876032181, validation losses: 0.44299490579156187\n",
      "Epoch 5632, reconstruction losses: 0.03205289973282405, regression losses: 0.14367034781463564, validation losses: 0.6105677670527941\n",
      "Epoch 5633, reconstruction losses: 0.029863889813066063, regression losses: 0.11329294918179096, validation losses: 0.5711169761474145\n",
      "Epoch 5634, reconstruction losses: 0.02799065765855166, regression losses: 0.11877152643793613, validation losses: 0.44937846743444776\n",
      "Epoch 5635, reconstruction losses: 0.028966381494391062, regression losses: 0.11459046462759373, validation losses: 0.44015959257399084\n",
      "Epoch 5636, reconstruction losses: 0.032687437152628715, regression losses: 0.1039028250399931, validation losses: 0.4840040255433466\n",
      "Epoch 5637, reconstruction losses: 0.03164534202902773, regression losses: 0.11225297869461459, validation losses: 0.4863411765441481\n",
      "Epoch 5638, reconstruction losses: 0.028415291290062747, regression losses: 0.10645462667036551, validation losses: 0.4631195616220003\n",
      "Epoch 5639, reconstruction losses: 0.02797229298730356, regression losses: 0.09236979813325184, validation losses: 0.47283027657803267\n",
      "Epoch 5640, reconstruction losses: 0.028586926556979853, regression losses: 0.11942608168733237, validation losses: 0.5023765680024364\n",
      "Epoch 5641, reconstruction losses: 0.030755738253897495, regression losses: 0.11972299240136519, validation losses: 0.5098120216828669\n",
      "Epoch 5642, reconstruction losses: 0.03233509993841781, regression losses: 0.09088812767298908, validation losses: 0.44335067261498445\n",
      "Epoch 5643, reconstruction losses: 0.02975702821922317, regression losses: 0.10599426488053076, validation losses: 0.43550183346042143\n",
      "Epoch 5644, reconstruction losses: 0.029605304848876263, regression losses: 0.11592179837126372, validation losses: 0.43608894094924266\n",
      "Epoch 5645, reconstruction losses: 0.03198305339480815, regression losses: 0.10396299295026491, validation losses: 0.5182457708918445\n",
      "Epoch 5646, reconstruction losses: 0.02911193555692196, regression losses: 0.11016381904723041, validation losses: 0.49236061014805876\n",
      "Epoch 5647, reconstruction losses: 0.02902859063879748, regression losses: 0.0940181010830913, validation losses: 0.4565627294311609\n",
      "Epoch 5648, reconstruction losses: 0.03325021995110164, regression losses: 0.12080065380662384, validation losses: 0.48038646891756076\n",
      "Epoch 5649, reconstruction losses: 0.028585787545615415, regression losses: 0.1131157997043539, validation losses: 0.46540686618403443\n",
      "Epoch 5650, reconstruction losses: 0.03128302881671256, regression losses: 0.0927182370868898, validation losses: 0.4887468094261732\n",
      "Epoch 5651, reconstruction losses: 0.03072647627431957, regression losses: 0.1431132586405761, validation losses: 0.47334130970604416\n",
      "Epoch 5652, reconstruction losses: 0.030755210696103014, regression losses: 0.12889442746613974, validation losses: 0.4696118327961477\n",
      "Epoch 5653, reconstruction losses: 0.03087414061107821, regression losses: 0.20535509738271437, validation losses: 0.4540260185129459\n",
      "Epoch 5654, reconstruction losses: 0.03272090427289123, regression losses: 0.12721482583167598, validation losses: 0.7322702262532149\n",
      "Epoch 5655, reconstruction losses: 0.027452314911365027, regression losses: 0.142730232709204, validation losses: 0.6016560236804727\n",
      "Epoch 5656, reconstruction losses: 0.029870074672525233, regression losses: 0.10641363215031105, validation losses: 0.6259970486505323\n",
      "Epoch 5657, reconstruction losses: 0.02919119743739963, regression losses: 0.12689462223890444, validation losses: 0.5344457958361184\n",
      "Epoch 5658, reconstruction losses: 0.02967314992229634, regression losses: 0.09517681475495483, validation losses: 0.4699978799593531\n",
      "Epoch 5659, reconstruction losses: 0.028310115253009166, regression losses: 0.14080678386148932, validation losses: 0.4641695178036012\n",
      "Epoch 5660, reconstruction losses: 0.029372481667404707, regression losses: 0.11492411710881836, validation losses: 0.5413465797051262\n",
      "Epoch 5661, reconstruction losses: 0.03174085784087389, regression losses: 0.14286951914311027, validation losses: 0.5749446994975944\n",
      "Epoch 5662, reconstruction losses: 0.02770106770329821, regression losses: 0.09693327561708703, validation losses: 0.6843741817401311\n",
      "Epoch 5663, reconstruction losses: 0.030866126953985027, regression losses: 0.151328099505199, validation losses: 0.5734080729580925\n",
      "Epoch 5664, reconstruction losses: 0.02948573490948282, regression losses: 0.1147414978384122, validation losses: 0.5225595540473051\n",
      "Epoch 5665, reconstruction losses: 0.0290430694285138, regression losses: 0.11106278018293594, validation losses: 0.4753153795460754\n",
      "Epoch 5666, reconstruction losses: 0.02891373802486697, regression losses: 0.09726347308081135, validation losses: 0.48229485391780613\n",
      "Epoch 5667, reconstruction losses: 0.034247841880546206, regression losses: 0.11685703501945548, validation losses: 0.4796400795072922\n",
      "Epoch 5668, reconstruction losses: 0.028020691940137843, regression losses: 0.12217503770972156, validation losses: 0.5301739566143076\n",
      "Epoch 5669, reconstruction losses: 0.03413911878009288, regression losses: 0.1333489755645641, validation losses: 0.49759723337984846\n",
      "Epoch 5670, reconstruction losses: 0.028637399769943003, regression losses: 0.13312902993281905, validation losses: 0.5037667742329793\n",
      "Epoch 5671, reconstruction losses: 0.029701603680971106, regression losses: 0.10849483527032541, validation losses: 0.47423836123112534\n",
      "Epoch 5672, reconstruction losses: 0.028095386823058885, regression losses: 0.12798082969619018, validation losses: 0.5017417531972101\n",
      "Epoch 5673, reconstruction losses: 0.03903661514702419, regression losses: 0.14444348738774793, validation losses: 0.476976160876265\n",
      "Epoch 5674, reconstruction losses: 0.028067563918696956, regression losses: 0.11093550492734036, validation losses: 0.4234133373075402\n",
      "Epoch 5675, reconstruction losses: 0.026553031215344795, regression losses: 0.10700232033534327, validation losses: 0.4225646116853617\n",
      "Epoch 5676, reconstruction losses: 0.02788539156441133, regression losses: 0.08382539172044817, validation losses: 0.42970790523917696\n",
      "Epoch 5677, reconstruction losses: 0.02982185632949657, regression losses: 0.1410406429980662, validation losses: 0.5018777521412245\n",
      "Epoch 5678, reconstruction losses: 0.029201271489444663, regression losses: 0.1355276549430762, validation losses: 0.5733764799084428\n",
      "Epoch 5679, reconstruction losses: 0.030370158439470437, regression losses: 0.09032743132363359, validation losses: 0.5331138787874455\n",
      "Epoch 5680, reconstruction losses: 0.02948521001149459, regression losses: 0.09264143468084172, validation losses: 0.4374817470637965\n",
      "Epoch 5681, reconstruction losses: 0.028569290549888895, regression losses: 0.16991544566255135, validation losses: 0.4398100521428766\n",
      "Epoch 5682, reconstruction losses: 0.029740786087603076, regression losses: 0.1836199636666187, validation losses: 0.5756744702815647\n",
      "Epoch 5683, reconstruction losses: 0.031223266959800274, regression losses: 0.12876037506830856, validation losses: 0.7767795989190465\n",
      "Epoch 5684, reconstruction losses: 0.03193013346412704, regression losses: 0.4175380389593484, validation losses: 0.48179144116742234\n",
      "Epoch 5685, reconstruction losses: 0.031306970020545444, regression losses: 0.15918182482392584, validation losses: 0.6103466900940863\n",
      "Epoch 5686, reconstruction losses: 0.030001914427564794, regression losses: 0.16141875203051495, validation losses: 0.5038335632429578\n",
      "Epoch 5687, reconstruction losses: 0.02969071580913194, regression losses: 0.14947812834263755, validation losses: 0.6391114875904909\n",
      "Epoch 5688, reconstruction losses: 0.028728677115841254, regression losses: 0.09598655105555474, validation losses: 0.6279353888631976\n",
      "Epoch 5689, reconstruction losses: 0.02895160179092391, regression losses: 0.11717570443586398, validation losses: 0.4613090115676049\n",
      "Epoch 5690, reconstruction losses: 0.02937590457227857, regression losses: 0.24326911328905368, validation losses: 0.5797143747185721\n",
      "Epoch 5691, reconstruction losses: 0.030419396921913793, regression losses: 0.1976240311417971, validation losses: 0.8359165196920368\n",
      "Epoch 5692, reconstruction losses: 0.03336491502316144, regression losses: 0.14484873811567303, validation losses: 0.6480184979541491\n",
      "Epoch 5693, reconstruction losses: 0.029118678050029875, regression losses: 0.12353389298390831, validation losses: 0.6280632097144904\n",
      "Epoch 5694, reconstruction losses: 0.0364441180131785, regression losses: 0.1402960485539163, validation losses: 0.4950154583132653\n",
      "Epoch 5695, reconstruction losses: 0.0264658268847034, regression losses: 0.1235017308931575, validation losses: 0.5095865728303073\n",
      "Epoch 5696, reconstruction losses: 0.031282054269958295, regression losses: 0.18960156539739847, validation losses: 0.4921618281438419\n",
      "Epoch 5697, reconstruction losses: 0.028693488710534572, regression losses: 0.11555424738724937, validation losses: 0.41862937156785057\n",
      "Epoch 5698, reconstruction losses: 0.02833891138215095, regression losses: 0.1102956684945396, validation losses: 0.4523489624584404\n",
      "Epoch 5699, reconstruction losses: 0.027832360353556303, regression losses: 0.10496517078733149, validation losses: 0.5023443334749806\n",
      "Epoch 5700, reconstruction losses: 0.0325680931285289, regression losses: 0.3870625647000429, validation losses: 0.5126607093450537\n",
      "Epoch 5701, reconstruction losses: 0.031036104187735294, regression losses: 0.14966774244706274, validation losses: 0.7425841336966077\n",
      "Epoch 5702, reconstruction losses: 0.03305578625790509, regression losses: 0.17025595131699103, validation losses: 0.7125116688559275\n",
      "Epoch 5703, reconstruction losses: 0.027197480737132965, regression losses: 0.1228118477867571, validation losses: 0.4855978721394437\n",
      "Epoch 5704, reconstruction losses: 0.03139534909102345, regression losses: 0.11848450985084065, validation losses: 0.5483501812274761\n",
      "Epoch 5705, reconstruction losses: 0.02686734881062345, regression losses: 0.12235947885716217, validation losses: 0.5005444223539389\n",
      "Epoch 5706, reconstruction losses: 0.03158398008630414, regression losses: 0.21104389336915508, validation losses: 0.4577955429141213\n",
      "Epoch 5707, reconstruction losses: 0.03048945892240241, regression losses: 0.1164993253785239, validation losses: 0.4479771119196268\n",
      "Epoch 5708, reconstruction losses: 0.027988620923797978, regression losses: 0.1300026355149529, validation losses: 0.43573897597606753\n",
      "Epoch 5709, reconstruction losses: 0.027166798570112876, regression losses: 0.10061656077920177, validation losses: 0.4769067407682554\n",
      "Epoch 5710, reconstruction losses: 0.029423526214316115, regression losses: 0.11892560268728261, validation losses: 0.5402127463746904\n",
      "Epoch 5711, reconstruction losses: 0.02915385394663446, regression losses: 0.1735927538528172, validation losses: 0.5181905973298717\n",
      "Epoch 5712, reconstruction losses: 0.028305513039487924, regression losses: 0.12573183857420267, validation losses: 0.5850965008037042\n",
      "Epoch 5713, reconstruction losses: 0.03214557224504138, regression losses: 0.1402736686699011, validation losses: 0.448938977794062\n",
      "Epoch 5714, reconstruction losses: 0.030136429983303452, regression losses: 0.17360196395563993, validation losses: 0.4656402499933982\n",
      "Epoch 5715, reconstruction losses: 0.030726778452352346, regression losses: 0.21509671767406663, validation losses: 0.4986180114419022\n",
      "Epoch 5716, reconstruction losses: 0.028707303949054283, regression losses: 0.15661843080419682, validation losses: 0.603695792966627\n",
      "Epoch 5717, reconstruction losses: 0.029833048744571693, regression losses: 0.15892104682427444, validation losses: 0.5719650972218726\n",
      "Epoch 5718, reconstruction losses: 0.029532787640353088, regression losses: 0.08231244116493999, validation losses: 0.5499893216936644\n",
      "Epoch 5719, reconstruction losses: 0.02802029013322914, regression losses: 0.1650891446551698, validation losses: 0.5025177436964827\n",
      "Epoch 5720, reconstruction losses: 0.028930490776605422, regression losses: 0.10845430314787677, validation losses: 0.5771355314497612\n",
      "Epoch 5721, reconstruction losses: 0.029387574653119072, regression losses: 0.13054600302892586, validation losses: 0.4852326471795939\n",
      "Epoch 5722, reconstruction losses: 0.03073452936537244, regression losses: 0.12246901264725954, validation losses: 0.4564835744787472\n",
      "Epoch 5723, reconstruction losses: 0.028812236348892177, regression losses: 0.09848407608975054, validation losses: 0.5135673550241407\n",
      "Epoch 5724, reconstruction losses: 0.028249823378882502, regression losses: 0.11801141250777376, validation losses: 0.47241052021075247\n",
      "Epoch 5725, reconstruction losses: 0.027562163486146773, regression losses: 0.10773869207880367, validation losses: 0.4884352313280506\n",
      "Epoch 5726, reconstruction losses: 0.028692644110060766, regression losses: 0.08257022455657191, validation losses: 0.46848509630043766\n",
      "Epoch 5727, reconstruction losses: 0.03080026968965507, regression losses: 0.1432491487218272, validation losses: 0.5423161741588555\n",
      "Epoch 5728, reconstruction losses: 0.027946255981339287, regression losses: 0.17352089306602206, validation losses: 0.597824702317582\n",
      "Epoch 5729, reconstruction losses: 0.027553147747966106, regression losses: 0.13184000146128205, validation losses: 0.44048312390347333\n",
      "Epoch 5730, reconstruction losses: 0.03177608280095323, regression losses: 0.09100801938075677, validation losses: 0.4120122088355902\n",
      "Epoch 5731, reconstruction losses: 0.030104688627073696, regression losses: 0.12325749062728307, validation losses: 0.4130526688725602\n",
      "Epoch 5732, reconstruction losses: 0.029387630047540945, regression losses: 0.10213115296413453, validation losses: 0.49329563430252316\n",
      "Epoch 5733, reconstruction losses: 0.030019639721189536, regression losses: 0.09146662931485046, validation losses: 0.5208032582978253\n",
      "Epoch 5734, reconstruction losses: 0.02814512163752502, regression losses: 0.08741575709089366, validation losses: 0.4773736351342541\n",
      "Epoch 5735, reconstruction losses: 0.0295760341691422, regression losses: 0.11511610451345686, validation losses: 0.44605395420392274\n",
      "Epoch 5736, reconstruction losses: 0.02944944232280425, regression losses: 0.14460754277209814, validation losses: 0.4249825440899937\n",
      "Epoch 5737, reconstruction losses: 0.02770480864654965, regression losses: 0.16757950937588545, validation losses: 0.4577928160544698\n",
      "Epoch 5738, reconstruction losses: 0.02877735271183213, regression losses: 0.13594965202939333, validation losses: 0.6447589044107995\n",
      "Epoch 5739, reconstruction losses: 0.030022886640391724, regression losses: 0.1400049529470123, validation losses: 0.4887709016281292\n",
      "Epoch 5740, reconstruction losses: 0.028618335179441852, regression losses: 0.13052857542846938, validation losses: 0.4825440953814356\n",
      "Epoch 5741, reconstruction losses: 0.031128374734360587, regression losses: 0.14687707634653796, validation losses: 0.5114203383609658\n",
      "Epoch 5742, reconstruction losses: 0.03200084725286892, regression losses: 0.09249776273686112, validation losses: 0.46000472826161143\n",
      "Epoch 5743, reconstruction losses: 0.032030925042126936, regression losses: 0.1088415794759075, validation losses: 0.4499714713896647\n",
      "Epoch 5744, reconstruction losses: 0.028225590721373102, regression losses: 0.11047883416412622, validation losses: 0.47863187649695593\n",
      "Epoch 5745, reconstruction losses: 0.028070495386020557, regression losses: 0.10232132505669865, validation losses: 0.4663316818111831\n",
      "Epoch 5746, reconstruction losses: 0.02885950904456453, regression losses: 0.12674475452821615, validation losses: 0.4593816139069336\n",
      "Epoch 5747, reconstruction losses: 0.026870649005262256, regression losses: 0.19624739767343746, validation losses: 0.42758943531676874\n",
      "Epoch 5748, reconstruction losses: 0.027038542575988974, regression losses: 0.10852470780831715, validation losses: 0.4669219282694552\n",
      "Epoch 5749, reconstruction losses: 0.030654199266903763, regression losses: 0.17256226447880338, validation losses: 0.4622117631923419\n",
      "Epoch 5750, reconstruction losses: 0.036259153971964206, regression losses: 0.13507758853594018, validation losses: 0.5008473788633517\n",
      "Epoch 5751, reconstruction losses: 0.031582595647662935, regression losses: 0.1320942599017466, validation losses: 0.43830448493270413\n",
      "Epoch 5752, reconstruction losses: 0.030396477449943664, regression losses: 0.12708237026016472, validation losses: 0.4441754621067231\n",
      "Epoch 5753, reconstruction losses: 0.029798208701551372, regression losses: 0.1320464682949481, validation losses: 0.4637230230592034\n",
      "Epoch 5754, reconstruction losses: 0.030659557490583224, regression losses: 0.09644779273258836, validation losses: 0.4745119345391873\n",
      "Epoch 5755, reconstruction losses: 0.02982672444272166, regression losses: 0.44240195129855725, validation losses: 0.4547321125541611\n",
      "Epoch 5756, reconstruction losses: 0.027292145580388893, regression losses: 0.1326939077454661, validation losses: 0.7926208918938938\n",
      "Epoch 5757, reconstruction losses: 0.03314115774389636, regression losses: 0.13854407666985769, validation losses: 0.5902989338210229\n",
      "Epoch 5758, reconstruction losses: 0.02796030303986806, regression losses: 0.09156093403445731, validation losses: 0.5565305189770554\n",
      "Epoch 5759, reconstruction losses: 0.026857991589938065, regression losses: 0.13783733285580804, validation losses: 0.5611055067749061\n",
      "Epoch 5760, reconstruction losses: 0.030017576317103306, regression losses: 0.10618611925840274, validation losses: 0.5074046692958543\n",
      "Epoch 5761, reconstruction losses: 0.027427359919879813, regression losses: 0.14680809755037177, validation losses: 0.46315986171341356\n",
      "Epoch 5762, reconstruction losses: 0.0303684993216001, regression losses: 0.12839451432484666, validation losses: 0.4564392396809059\n",
      "Epoch 5763, reconstruction losses: 0.032989188951947086, regression losses: 0.09822875810247927, validation losses: 0.4740140315365641\n",
      "Epoch 5764, reconstruction losses: 0.031231191906267188, regression losses: 0.21468586370478182, validation losses: 0.4689275785523358\n",
      "Epoch 5765, reconstruction losses: 0.03250667147134593, regression losses: 0.5447519057667836, validation losses: 0.5022577238414907\n",
      "Epoch 5766, reconstruction losses: 0.029266556999219963, regression losses: 0.17970917309930393, validation losses: 1.1697995561999515\n",
      "Epoch 5767, reconstruction losses: 0.026579977923502713, regression losses: 0.1515052958711311, validation losses: 0.8527047746810379\n",
      "Epoch 5768, reconstruction losses: 0.02973379000055329, regression losses: 0.15178165747264105, validation losses: 0.6303098422708083\n",
      "Epoch 5769, reconstruction losses: 0.02810087382452219, regression losses: 0.1709450571881746, validation losses: 0.6343862039647269\n",
      "Epoch 5770, reconstruction losses: 0.029077622436779044, regression losses: 0.14173419014971927, validation losses: 0.44405441066770096\n",
      "Epoch 5771, reconstruction losses: 0.03373170277984718, regression losses: 0.14341125192790252, validation losses: 0.44671880567238725\n",
      "Epoch 5772, reconstruction losses: 0.029900836509774473, regression losses: 0.1671438362461636, validation losses: 0.43685327702788623\n",
      "Epoch 5773, reconstruction losses: 0.028065155849141675, regression losses: 0.1276684115538886, validation losses: 0.42122575898220876\n",
      "Epoch 5774, reconstruction losses: 0.0268612191612473, regression losses: 0.14068138192801558, validation losses: 0.46269947415109397\n",
      "Epoch 5775, reconstruction losses: 0.03254395479932669, regression losses: 0.13008750439243283, validation losses: 0.5215441696678036\n",
      "Epoch 5776, reconstruction losses: 0.03372427724367922, regression losses: 0.1093453037648593, validation losses: 0.45631849373921607\n",
      "Epoch 5777, reconstruction losses: 0.026548187183119985, regression losses: 0.1256735816006333, validation losses: 0.4311283264538011\n",
      "Epoch 5778, reconstruction losses: 0.02652303491027132, regression losses: 0.09726964230451436, validation losses: 0.478985515594996\n",
      "Epoch 5779, reconstruction losses: 0.027161153532552093, regression losses: 0.10774586891002558, validation losses: 0.45264198695729996\n",
      "Epoch 5780, reconstruction losses: 0.032346534532300075, regression losses: 0.1205751677673609, validation losses: 0.42612122210057995\n",
      "Epoch 5781, reconstruction losses: 0.030650406384033914, regression losses: 0.10144321138692045, validation losses: 0.42872598662897515\n",
      "Epoch 5782, reconstruction losses: 0.02952372002437292, regression losses: 0.13747894672859154, validation losses: 0.4423628628556587\n",
      "Epoch 5783, reconstruction losses: 0.029344235901470724, regression losses: 0.10638191794419705, validation losses: 0.4093236040759802\n",
      "Epoch 5784, reconstruction losses: 0.02957218213271259, regression losses: 0.14913048242305005, validation losses: 0.4116821787469862\n",
      "Epoch 5785, reconstruction losses: 0.02783079168003922, regression losses: 0.14323220929178243, validation losses: 0.4686542990053572\n",
      "Epoch 5786, reconstruction losses: 0.028981480416512183, regression losses: 0.21450199356059096, validation losses: 0.4787016827723377\n",
      "Epoch 5787, reconstruction losses: 0.03552723658237024, regression losses: 0.29768581549725376, validation losses: 0.6316134353619983\n",
      "Epoch 5788, reconstruction losses: 0.03552387022453474, regression losses: 0.11078548136560261, validation losses: 0.4666425744946834\n",
      "Epoch 5789, reconstruction losses: 0.02821735107942922, regression losses: 0.15966105505916936, validation losses: 0.5389684299224387\n",
      "Epoch 5790, reconstruction losses: 0.02812263627284492, regression losses: 0.12622429967140497, validation losses: 0.574349227016497\n",
      "Epoch 5791, reconstruction losses: 0.03068397200092047, regression losses: 0.11675671825989982, validation losses: 0.6485708451766745\n",
      "Epoch 5792, reconstruction losses: 0.029678643943811304, regression losses: 0.10746251622346718, validation losses: 0.5722319255387817\n",
      "Epoch 5793, reconstruction losses: 0.0291548387054048, regression losses: 0.1239661670918074, validation losses: 0.45498427654031254\n",
      "Epoch 5794, reconstruction losses: 0.02968456988155532, regression losses: 0.13455552129175563, validation losses: 0.44575667033277444\n",
      "Epoch 5795, reconstruction losses: 0.03170542723309942, regression losses: 0.10599081138573228, validation losses: 0.4412408717124295\n",
      "Epoch 5796, reconstruction losses: 0.026509483497057316, regression losses: 0.08274133811690712, validation losses: 0.5065266359495856\n",
      "Epoch 5797, reconstruction losses: 0.02594880082636688, regression losses: 0.14129150715160815, validation losses: 0.515556300174756\n",
      "Epoch 5798, reconstruction losses: 0.03163727597677881, regression losses: 0.2695680294029727, validation losses: 0.48223288399623837\n",
      "Epoch 5799, reconstruction losses: 0.02846410028091359, regression losses: 0.15106689249565086, validation losses: 0.7947971971038151\n",
      "Epoch 5800, reconstruction losses: 0.02784259565879671, regression losses: 0.16410387624630174, validation losses: 0.5436586779759618\n",
      "Epoch 5801, reconstruction losses: 0.028081663453116655, regression losses: 0.14005781187912664, validation losses: 0.6286441983981313\n",
      "Epoch 5802, reconstruction losses: 0.029817345265147663, regression losses: 0.18039051670629397, validation losses: 0.624341196134697\n",
      "Epoch 5803, reconstruction losses: 0.028259884144625352, regression losses: 0.10002003347780426, validation losses: 0.5312212937349472\n",
      "Epoch 5804, reconstruction losses: 0.028554126410890283, regression losses: 0.1446536503896907, validation losses: 0.4590566631884518\n",
      "Epoch 5805, reconstruction losses: 0.029555138215587525, regression losses: 0.14152194181728067, validation losses: 0.4489338900436414\n",
      "Epoch 5806, reconstruction losses: 0.02937627984742216, regression losses: 0.09944962382368552, validation losses: 0.4536347251603752\n",
      "Epoch 5807, reconstruction losses: 0.030394437939682183, regression losses: 0.14697374103229527, validation losses: 0.48714611506789957\n",
      "Epoch 5808, reconstruction losses: 0.02859573094232966, regression losses: 0.1438704957449857, validation losses: 0.48732036745813256\n",
      "Epoch 5809, reconstruction losses: 0.02933031083975081, regression losses: 0.11327398183299872, validation losses: 0.5321082737167644\n",
      "Epoch 5810, reconstruction losses: 0.02678360270136858, regression losses: 0.08893061374255135, validation losses: 0.40995998245045956\n",
      "Epoch 5811, reconstruction losses: 0.03532655015817669, regression losses: 0.2424709779383255, validation losses: 0.4443676719052823\n",
      "Epoch 5812, reconstruction losses: 0.025678351404596476, regression losses: 0.10497011705209496, validation losses: 0.6520910818231913\n",
      "Epoch 5813, reconstruction losses: 0.028239018752828197, regression losses: 0.12524348998121337, validation losses: 0.5863544035840317\n",
      "Epoch 5814, reconstruction losses: 0.0284006204711004, regression losses: 0.12862119546929543, validation losses: 0.5294277660281198\n",
      "Epoch 5815, reconstruction losses: 0.02778058343922011, regression losses: 0.1116562645824729, validation losses: 0.5088960825971256\n",
      "Epoch 5816, reconstruction losses: 0.0271253335550958, regression losses: 0.11196410782653522, validation losses: 0.4560031472624792\n",
      "Epoch 5817, reconstruction losses: 0.02588345398807452, regression losses: 0.10585537229193133, validation losses: 0.43061246322616836\n",
      "Epoch 5818, reconstruction losses: 0.027508898026313445, regression losses: 0.08529603430996488, validation losses: 0.4547477926639906\n",
      "Epoch 5819, reconstruction losses: 0.026474197996428975, regression losses: 0.09473300304637787, validation losses: 0.4775284132093235\n",
      "Epoch 5820, reconstruction losses: 0.031054954588746773, regression losses: 0.11996137478798397, validation losses: 0.4908774488395791\n",
      "Epoch 5821, reconstruction losses: 0.027032916147434662, regression losses: 0.16447261442229194, validation losses: 0.4522602156115122\n",
      "Epoch 5822, reconstruction losses: 0.0298507038969624, regression losses: 0.10545776262923941, validation losses: 0.46774292353066077\n",
      "Epoch 5823, reconstruction losses: 0.02843966633979742, regression losses: 0.10861495947974206, validation losses: 0.47413466976772717\n",
      "Epoch 5824, reconstruction losses: 0.032408677215158506, regression losses: 0.1390737672078601, validation losses: 0.423078038291278\n",
      "Epoch 5825, reconstruction losses: 0.028442985450466522, regression losses: 0.09278963764360804, validation losses: 0.43409995794586326\n",
      "Epoch 5826, reconstruction losses: 0.031208243826092563, regression losses: 0.3864027210649724, validation losses: 0.4451315071425736\n",
      "Epoch 5827, reconstruction losses: 0.028791537259419842, regression losses: 0.13252295175254564, validation losses: 0.656240313963238\n",
      "Epoch 5828, reconstruction losses: 0.029723782219675997, regression losses: 0.13856002837135026, validation losses: 0.632183298092527\n",
      "Epoch 5829, reconstruction losses: 0.026758702493759147, regression losses: 0.10775591713299591, validation losses: 0.4936663186110615\n",
      "Epoch 5830, reconstruction losses: 0.02541973877945105, regression losses: 0.18704902517541122, validation losses: 0.5360299922079981\n",
      "Epoch 5831, reconstruction losses: 0.02917382345634688, regression losses: 0.10171678935498016, validation losses: 0.5315244548410021\n",
      "Epoch 5832, reconstruction losses: 0.025995243685839765, regression losses: 0.112883628443136, validation losses: 0.4410605271336856\n",
      "Epoch 5833, reconstruction losses: 0.029016906625947803, regression losses: 0.09279240315710378, validation losses: 0.4475529595305521\n",
      "Epoch 5834, reconstruction losses: 0.030965387029031274, regression losses: 0.14171387721242112, validation losses: 0.43755921402255904\n",
      "Epoch 5835, reconstruction losses: 0.02561372238108565, regression losses: 0.11539565747981304, validation losses: 0.444205959037144\n",
      "Epoch 5836, reconstruction losses: 0.031415507857104334, regression losses: 0.15154517898573228, validation losses: 0.42813858375708275\n",
      "Epoch 5837, reconstruction losses: 0.02581170861068763, regression losses: 0.11427958863547429, validation losses: 0.5103140662247405\n",
      "Epoch 5838, reconstruction losses: 0.0292126328279579, regression losses: 0.1337332958341414, validation losses: 0.5666110588685475\n",
      "Epoch 5839, reconstruction losses: 0.03047892329884765, regression losses: 0.0914251039390821, validation losses: 0.5464027904565287\n",
      "Epoch 5840, reconstruction losses: 0.028655628941643602, regression losses: 0.12460406736625451, validation losses: 0.49270450861169984\n",
      "Epoch 5841, reconstruction losses: 0.028282105816199665, regression losses: 0.10619250768055742, validation losses: 0.44591260451353687\n",
      "Epoch 5842, reconstruction losses: 0.02855351232828605, regression losses: 0.15090554280737964, validation losses: 0.4176443099797902\n",
      "Epoch 5843, reconstruction losses: 0.028188644303213495, regression losses: 0.13203790229900753, validation losses: 0.4020739752624503\n",
      "Epoch 5844, reconstruction losses: 0.027048901014214168, regression losses: 0.10915584239538947, validation losses: 0.41763581671564814\n",
      "Epoch 5845, reconstruction losses: 0.02668508094906894, regression losses: 0.13084718343527976, validation losses: 0.45692274254441323\n",
      "Epoch 5846, reconstruction losses: 0.026866148027846662, regression losses: 0.09461758821634882, validation losses: 0.5074798943115512\n",
      "Epoch 5847, reconstruction losses: 0.02510325626638613, regression losses: 0.09013324104438955, validation losses: 0.4598149204650672\n",
      "Epoch 5848, reconstruction losses: 0.02888704691546474, regression losses: 0.1251201892680496, validation losses: 0.4154970921647635\n",
      "Epoch 5849, reconstruction losses: 0.03130247003784419, regression losses: 0.13339307294986705, validation losses: 0.4177135733068042\n",
      "Epoch 5850, reconstruction losses: 0.025734852182403716, regression losses: 0.08002669182977647, validation losses: 0.4230589069252835\n",
      "Epoch 5851, reconstruction losses: 0.02688246108024158, regression losses: 0.1028770376340509, validation losses: 0.4670257237818336\n",
      "Epoch 5852, reconstruction losses: 0.029896665737356897, regression losses: 0.13244277127638943, validation losses: 0.46575922148330084\n",
      "Epoch 5853, reconstruction losses: 0.028528446300213325, regression losses: 0.1637918722695466, validation losses: 0.42823512182156565\n",
      "Epoch 5854, reconstruction losses: 0.030829620798232652, regression losses: 0.1665104806906566, validation losses: 0.3954399651717512\n",
      "Epoch 5855, reconstruction losses: 0.030173569606295293, regression losses: 0.13668414179956498, validation losses: 0.4234862221425868\n",
      "Epoch 5856, reconstruction losses: 0.026960331077214746, regression losses: 0.1407562008628896, validation losses: 0.4399981856030922\n",
      "Epoch 5857, reconstruction losses: 0.029297092002894983, regression losses: 0.10744332581126924, validation losses: 0.4152090628598054\n",
      "Epoch 5858, reconstruction losses: 0.03077760766807591, regression losses: 0.14727277485104306, validation losses: 0.4146531365857505\n",
      "Epoch 5859, reconstruction losses: 0.02861028666746455, regression losses: 0.13191080230724903, validation losses: 0.4809930282113536\n",
      "Epoch 5860, reconstruction losses: 0.027063036089439385, regression losses: 0.104047485367606, validation losses: 0.4117621211050898\n",
      "Epoch 5861, reconstruction losses: 0.029918620611457482, regression losses: 0.141873091811554, validation losses: 0.46492901270137993\n",
      "Epoch 5862, reconstruction losses: 0.028266075258663276, regression losses: 0.1125773003576073, validation losses: 0.5151403777504759\n",
      "Epoch 5863, reconstruction losses: 0.03127657529777585, regression losses: 0.11834057275366923, validation losses: 0.5905476196208136\n",
      "Epoch 5864, reconstruction losses: 0.029851185536390337, regression losses: 0.4037318891368067, validation losses: 0.46630643231992225\n",
      "Epoch 5865, reconstruction losses: 0.02726233060628023, regression losses: 0.16880725180110534, validation losses: 0.6338917151013241\n",
      "Epoch 5866, reconstruction losses: 0.02959473872830843, regression losses: 0.15329080130005085, validation losses: 0.50725466136488\n",
      "Epoch 5867, reconstruction losses: 0.02776698852328578, regression losses: 0.12658545888211906, validation losses: 0.5727905394756241\n",
      "Epoch 5868, reconstruction losses: 0.028681358614432273, regression losses: 0.1267303332675867, validation losses: 0.506148155600054\n",
      "Epoch 5869, reconstruction losses: 0.029903060623556535, regression losses: 0.14827114698767957, validation losses: 0.4831939941888837\n",
      "Epoch 5870, reconstruction losses: 0.0281046590654901, regression losses: 0.10606105309432015, validation losses: 0.49481185024345953\n",
      "Epoch 5871, reconstruction losses: 0.028057134319365403, regression losses: 0.10909557293848161, validation losses: 0.51288994713671\n",
      "Epoch 5872, reconstruction losses: 0.02882765039252546, regression losses: 0.10520606743111255, validation losses: 0.45559842633904823\n",
      "Epoch 5873, reconstruction losses: 0.03225181654025379, regression losses: 0.12424558300967219, validation losses: 0.42283981704191215\n",
      "Epoch 5874, reconstruction losses: 0.03130635714371459, regression losses: 0.12016599710492422, validation losses: 0.458600905071982\n",
      "Epoch 5875, reconstruction losses: 0.02631677079085431, regression losses: 0.14299687951395426, validation losses: 0.4476797672428291\n",
      "Epoch 5876, reconstruction losses: 0.02820962083882382, regression losses: 0.11166527013322348, validation losses: 0.4894876384930622\n",
      "Epoch 5877, reconstruction losses: 0.030480945455402288, regression losses: 0.1359987378353855, validation losses: 0.43461813820554435\n",
      "Epoch 5878, reconstruction losses: 0.03205872049971004, regression losses: 0.13985735128255453, validation losses: 0.4305728739713303\n",
      "Epoch 5879, reconstruction losses: 0.026564023907275927, regression losses: 0.11080955434110651, validation losses: 0.5072270428616525\n",
      "Epoch 5880, reconstruction losses: 0.029399863109948597, regression losses: 0.13721057892039862, validation losses: 0.5073302288547586\n",
      "Epoch 5881, reconstruction losses: 0.029099933159829335, regression losses: 0.13241832958496952, validation losses: 0.4726664331280551\n",
      "Epoch 5882, reconstruction losses: 0.02853883393674529, regression losses: 0.10571625599092542, validation losses: 0.4596545043820497\n",
      "Epoch 5883, reconstruction losses: 0.03184659955206081, regression losses: 0.2874245153702495, validation losses: 0.4275597799904597\n",
      "Epoch 5884, reconstruction losses: 0.024166305497612443, regression losses: 0.15167545583377545, validation losses: 0.6198462151658912\n",
      "Epoch 5885, reconstruction losses: 0.030076233053022247, regression losses: 0.1087743109350242, validation losses: 0.533766303999267\n",
      "Epoch 5886, reconstruction losses: 0.025972020691039762, regression losses: 0.170904766490807, validation losses: 0.4501605247212955\n",
      "Epoch 5887, reconstruction losses: 0.026767217666918124, regression losses: 0.10215433602648445, validation losses: 0.45672298668803857\n",
      "Epoch 5888, reconstruction losses: 0.03145406359933652, regression losses: 0.11330632987642156, validation losses: 0.4514047715806123\n",
      "Epoch 5889, reconstruction losses: 0.027429389830994372, regression losses: 0.09701330082457049, validation losses: 0.43084151910447677\n",
      "Epoch 5890, reconstruction losses: 0.02859471836813319, regression losses: 0.18280096717027144, validation losses: 0.5659555454199594\n",
      "Epoch 5891, reconstruction losses: 0.03024227334198095, regression losses: 0.11952294534085035, validation losses: 0.7949051787569474\n",
      "Epoch 5892, reconstruction losses: 0.029461297990763784, regression losses: 0.1546414739411469, validation losses: 0.4636396178539328\n",
      "Epoch 5893, reconstruction losses: 0.029795341659320795, regression losses: 0.11426315184718877, validation losses: 0.3848793522830194\n",
      "Epoch 5894, reconstruction losses: 0.027287650624734785, regression losses: 0.10773461365009444, validation losses: 0.3808815069232578\n",
      "Epoch 5895, reconstruction losses: 0.026211537011193844, regression losses: 0.14173139974101834, validation losses: 0.41912283388008853\n",
      "Epoch 5896, reconstruction losses: 0.026851105824697248, regression losses: 0.1392927129211084, validation losses: 0.44165910881760695\n",
      "Epoch 5897, reconstruction losses: 0.028305433952404403, regression losses: 0.11339872710326314, validation losses: 0.45126972609060334\n",
      "Epoch 5898, reconstruction losses: 0.02787340308414044, regression losses: 0.1534496627483751, validation losses: 0.42214097262641637\n",
      "Epoch 5899, reconstruction losses: 0.026224841771327962, regression losses: 0.1034137621017925, validation losses: 0.44479501417019257\n",
      "Epoch 5900, reconstruction losses: 0.028774552147645727, regression losses: 0.14759433305627898, validation losses: 0.45412979023018857\n",
      "Epoch 5901, reconstruction losses: 0.026644527529042852, regression losses: 0.09332871253176331, validation losses: 0.4818225069054369\n",
      "Epoch 5902, reconstruction losses: 0.027935034060667604, regression losses: 0.11381616670646909, validation losses: 0.4537559594146147\n",
      "Epoch 5903, reconstruction losses: 0.03579626394438836, regression losses: 0.2164158710909284, validation losses: 0.49040161937686944\n",
      "Epoch 5904, reconstruction losses: 0.030784926649186188, regression losses: 0.11290054139431721, validation losses: 0.6783702528608391\n",
      "Epoch 5905, reconstruction losses: 0.02688667705880012, regression losses: 0.16141877492609716, validation losses: 0.5852158481884149\n",
      "Epoch 5906, reconstruction losses: 0.030080159532141538, regression losses: 0.1783828436943941, validation losses: 0.5006473613017125\n",
      "Epoch 5907, reconstruction losses: 0.03093650180018466, regression losses: 0.1927226875154616, validation losses: 0.46823477145999476\n",
      "Epoch 5908, reconstruction losses: 0.030358434442046865, regression losses: 0.10544438877842506, validation losses: 0.43462157919793026\n",
      "Epoch 5909, reconstruction losses: 0.03390678932554659, regression losses: 0.10524633845978737, validation losses: 0.41226466548562973\n",
      "Epoch 5910, reconstruction losses: 0.029822076328653673, regression losses: 0.13407947352425326, validation losses: 0.5001550233028851\n",
      "Epoch 5911, reconstruction losses: 0.028506179779305946, regression losses: 0.09288858946937156, validation losses: 0.48468741718773783\n",
      "Epoch 5912, reconstruction losses: 0.025000727075972295, regression losses: 0.1482746554751811, validation losses: 0.4347465821829562\n",
      "Epoch 5913, reconstruction losses: 0.02713353456038826, regression losses: 0.10569010937914393, validation losses: 0.45853011994103265\n",
      "Epoch 5914, reconstruction losses: 0.024224924808313078, regression losses: 0.1194434578429584, validation losses: 0.47056651239984354\n",
      "Epoch 5915, reconstruction losses: 0.028025003741367904, regression losses: 0.1005909539496341, validation losses: 0.43724851146063365\n",
      "Epoch 5916, reconstruction losses: 0.027510168049197706, regression losses: 0.10232127413485563, validation losses: 0.41690641069301865\n",
      "Epoch 5917, reconstruction losses: 0.02687876494116821, regression losses: 0.13814103447573928, validation losses: 0.4522709178110265\n",
      "Epoch 5918, reconstruction losses: 0.02488851003677667, regression losses: 0.09111186645064943, validation losses: 0.5045488957658547\n",
      "Epoch 5919, reconstruction losses: 0.029095731254151973, regression losses: 0.12189669153028387, validation losses: 0.49449867645706064\n",
      "Epoch 5920, reconstruction losses: 0.026875750472837925, regression losses: 0.15121196240603466, validation losses: 0.4864280607350092\n",
      "Epoch 5921, reconstruction losses: 0.02677065424041538, regression losses: 0.11665731150822435, validation losses: 0.4821095961343984\n",
      "Epoch 5922, reconstruction losses: 0.03078787255086601, regression losses: 0.1242617434321191, validation losses: 0.4337915015021749\n",
      "Epoch 5923, reconstruction losses: 0.02761669152888191, regression losses: 0.11807834909043917, validation losses: 0.44650023773767833\n",
      "Epoch 5924, reconstruction losses: 0.024844278722127546, regression losses: 0.12354363938426058, validation losses: 0.45136205350853165\n",
      "Epoch 5925, reconstruction losses: 0.03404000719069493, regression losses: 0.09688920010878248, validation losses: 0.4614197118605998\n",
      "Epoch 5926, reconstruction losses: 0.03134268876806105, regression losses: 0.362144281408922, validation losses: 0.45437588626974545\n",
      "Epoch 5927, reconstruction losses: 0.025065939329934606, regression losses: 0.10863862343537993, validation losses: 0.6134282763758686\n",
      "Epoch 5928, reconstruction losses: 0.026797304962816456, regression losses: 0.1256654394930444, validation losses: 0.5841363785260962\n",
      "Epoch 5929, reconstruction losses: 0.027520248561947926, regression losses: 0.15143131522151326, validation losses: 0.5549280704591615\n",
      "Epoch 5930, reconstruction losses: 0.03264225164414683, regression losses: 0.35385243356585105, validation losses: 0.5817883770206819\n",
      "Epoch 5931, reconstruction losses: 0.027148905953742104, regression losses: 0.15568605426923082, validation losses: 0.8634195770392101\n",
      "Epoch 5932, reconstruction losses: 0.028794738499830805, regression losses: 0.2187531929987433, validation losses: 0.5726773074464131\n",
      "Epoch 5933, reconstruction losses: 0.027504082908197815, regression losses: 0.1266158995671711, validation losses: 0.6214842874583756\n",
      "Epoch 5934, reconstruction losses: 0.026825586848355554, regression losses: 0.1407517809959155, validation losses: 0.5870440943287835\n",
      "Epoch 5935, reconstruction losses: 0.029132248234335238, regression losses: 0.13755321855199049, validation losses: 0.5206015666894405\n",
      "Epoch 5936, reconstruction losses: 0.028893376897759327, regression losses: 0.13508048852313362, validation losses: 0.6056571455646824\n",
      "Epoch 5937, reconstruction losses: 0.027138441602953978, regression losses: 0.1583952275032899, validation losses: 0.5147462614734934\n",
      "Epoch 5938, reconstruction losses: 0.02749831546987538, regression losses: 0.1469430702782478, validation losses: 0.4464978232473853\n",
      "Epoch 5939, reconstruction losses: 0.0263923691794894, regression losses: 0.12905278663517442, validation losses: 0.43134654336778566\n",
      "Epoch 5940, reconstruction losses: 0.028271675350835575, regression losses: 0.11084915546526228, validation losses: 0.4786362715771856\n",
      "Epoch 5941, reconstruction losses: 0.02836938858226906, regression losses: 0.11964979897949857, validation losses: 0.5037760460291762\n",
      "Epoch 5942, reconstruction losses: 0.02907281724947382, regression losses: 0.13887997271041036, validation losses: 0.474938930303031\n",
      "Epoch 5943, reconstruction losses: 0.02759645063610926, regression losses: 0.11637469149492594, validation losses: 0.49014427225546\n",
      "Epoch 5944, reconstruction losses: 0.02618624493415297, regression losses: 0.12494462923782694, validation losses: 0.4598050250125777\n",
      "Epoch 5945, reconstruction losses: 0.026843863726761803, regression losses: 0.1129708254943668, validation losses: 0.4670022269988939\n",
      "Epoch 5946, reconstruction losses: 0.02901346706004807, regression losses: 0.116581832465858, validation losses: 0.48974601465247647\n",
      "Epoch 5947, reconstruction losses: 0.028549038961188242, regression losses: 0.09365285227800543, validation losses: 0.4509629000977285\n",
      "Epoch 5948, reconstruction losses: 0.027592353352625894, regression losses: 0.09826878014197112, validation losses: 0.4557899334987462\n",
      "Epoch 5949, reconstruction losses: 0.027042064691101445, regression losses: 0.12403020216342033, validation losses: 0.46232019304099187\n",
      "Epoch 5950, reconstruction losses: 0.025158065392389028, regression losses: 0.10869429552812618, validation losses: 0.4789757819509912\n",
      "Epoch 5951, reconstruction losses: 0.029452811640807333, regression losses: 0.20357598576509717, validation losses: 0.43281483388403025\n",
      "Epoch 5952, reconstruction losses: 0.030829064277623122, regression losses: 0.150519341174891, validation losses: 0.527518851825687\n",
      "Epoch 5953, reconstruction losses: 0.03154212669739645, regression losses: 0.15071778926190318, validation losses: 0.5701491910170863\n",
      "Epoch 5954, reconstruction losses: 0.029420684140650424, regression losses: 0.169632197918512, validation losses: 0.5638545692084307\n",
      "Epoch 5955, reconstruction losses: 0.029594407872966147, regression losses: 0.12028001793820639, validation losses: 0.5534012329933437\n",
      "Epoch 5956, reconstruction losses: 0.02662607587730333, regression losses: 0.11593547118394634, validation losses: 0.49463584592204757\n",
      "Epoch 5957, reconstruction losses: 0.027464553969436853, regression losses: 0.09817668308988615, validation losses: 0.4874368734313481\n",
      "Epoch 5958, reconstruction losses: 0.029163197671749685, regression losses: 0.12379819595618964, validation losses: 0.4407191393188598\n",
      "Epoch 5959, reconstruction losses: 0.026282987963610123, regression losses: 0.10655638891606095, validation losses: 0.46942313837241323\n",
      "Epoch 5960, reconstruction losses: 0.02586179643875911, regression losses: 0.09844587239762564, validation losses: 0.6108867192612258\n",
      "Epoch 5961, reconstruction losses: 0.026347286464623636, regression losses: 0.13274283853090016, validation losses: 0.538218660262507\n",
      "Epoch 5962, reconstruction losses: 0.028205389623338392, regression losses: 0.11711568043004307, validation losses: 0.4663165626201027\n",
      "Epoch 5963, reconstruction losses: 0.030574703880495303, regression losses: 0.11160017522244618, validation losses: 0.48021715300446527\n",
      "Epoch 5964, reconstruction losses: 0.026596613530431162, regression losses: 0.10618186831817858, validation losses: 0.4288858659003582\n",
      "Epoch 5965, reconstruction losses: 0.029790226845710154, regression losses: 0.10703903623759423, validation losses: 0.44299133892207904\n",
      "Epoch 5966, reconstruction losses: 0.028678783272435362, regression losses: 0.10748355584817387, validation losses: 0.4327700898406936\n",
      "Epoch 5967, reconstruction losses: 0.029425935388188666, regression losses: 0.1422810850681514, validation losses: 0.4531737313577831\n",
      "Epoch 5968, reconstruction losses: 0.027552701449306553, regression losses: 0.12069514717465345, validation losses: 0.48138845352386805\n",
      "Epoch 5969, reconstruction losses: 0.026577120986700325, regression losses: 0.11179440389841792, validation losses: 0.5188556505417196\n",
      "Epoch 5970, reconstruction losses: 0.02680717002422519, regression losses: 0.14002039423994767, validation losses: 0.46039273251575685\n",
      "Epoch 5971, reconstruction losses: 0.029634933203188822, regression losses: 0.18578938582788065, validation losses: 0.41765662772909845\n",
      "Epoch 5972, reconstruction losses: 0.02888661128774233, regression losses: 0.17937172288199152, validation losses: 0.509495081632482\n",
      "Epoch 5973, reconstruction losses: 0.02816264204506004, regression losses: 0.1565856320630727, validation losses: 0.599568116684281\n",
      "Epoch 5974, reconstruction losses: 0.030606191947655317, regression losses: 0.14970382613842645, validation losses: 0.7688370869075147\n",
      "Epoch 5975, reconstruction losses: 0.03041434511709515, regression losses: 0.14593392971510238, validation losses: 0.7283875918871207\n",
      "Epoch 5976, reconstruction losses: 0.030333193819023455, regression losses: 0.1861773129567192, validation losses: 0.5876531545103317\n",
      "Epoch 5977, reconstruction losses: 0.02998719687413786, regression losses: 0.1389538845762496, validation losses: 0.6998564328146054\n",
      "Epoch 5978, reconstruction losses: 0.02976762832668218, regression losses: 0.4018743419987276, validation losses: 0.5938488360168893\n",
      "Epoch 5979, reconstruction losses: 0.0255907627571085, regression losses: 0.09569615343740251, validation losses: 0.7802766160119573\n",
      "Epoch 5980, reconstruction losses: 0.02476101352654251, regression losses: 0.1548472406475996, validation losses: 0.7083624048802619\n",
      "Epoch 5981, reconstruction losses: 0.027225070972517158, regression losses: 0.134019508974387, validation losses: 0.5478752547462608\n",
      "Epoch 5982, reconstruction losses: 0.030354025818675412, regression losses: 0.12546790249499742, validation losses: 0.5314647562848305\n",
      "Epoch 5983, reconstruction losses: 0.027851344999033415, regression losses: 0.12305402528297434, validation losses: 0.6094330021829729\n",
      "Epoch 5984, reconstruction losses: 0.03434188866898129, regression losses: 0.23166321412517785, validation losses: 0.5751423245869294\n",
      "Epoch 5985, reconstruction losses: 0.027307666650898406, regression losses: 0.14085057043697166, validation losses: 0.5985244524839691\n",
      "Epoch 5986, reconstruction losses: 0.028915589667926175, regression losses: 0.11882297712253567, validation losses: 0.5588101912086022\n",
      "Epoch 5987, reconstruction losses: 0.028880824710465033, regression losses: 0.12666864547165044, validation losses: 0.5369822190448118\n",
      "Epoch 5988, reconstruction losses: 0.03173122559133126, regression losses: 0.12517041725854816, validation losses: 0.6059333798997678\n",
      "Epoch 5989, reconstruction losses: 0.028600755143592366, regression losses: 0.10850169471205685, validation losses: 0.6384734405032884\n",
      "Epoch 5990, reconstruction losses: 0.027337157664820706, regression losses: 0.1110079467447171, validation losses: 0.5937165648117824\n",
      "Epoch 5991, reconstruction losses: 0.030742893208101647, regression losses: 0.16519509054286335, validation losses: 0.5684016347925003\n",
      "Epoch 5992, reconstruction losses: 0.02891356818284148, regression losses: 0.12425547140920594, validation losses: 0.6377665057800169\n",
      "Epoch 5993, reconstruction losses: 0.02914925617352824, regression losses: 0.13444177135353935, validation losses: 0.5771410563013558\n",
      "Epoch 5994, reconstruction losses: 0.025838913728098833, regression losses: 0.1509796282004366, validation losses: 0.46453981631866037\n",
      "Epoch 5995, reconstruction losses: 0.02605043077785211, regression losses: 0.11557323878856843, validation losses: 0.41732959089674143\n",
      "Epoch 5996, reconstruction losses: 0.02671217068919941, regression losses: 0.1473691948830558, validation losses: 0.43132219378752124\n",
      "Epoch 5997, reconstruction losses: 0.028814612168830647, regression losses: 0.20475459226442486, validation losses: 0.48066267484453573\n",
      "Epoch 5998, reconstruction losses: 0.028157523032909394, regression losses: 0.1104410971215162, validation losses: 0.6799652281380171\n",
      "Epoch 5999, reconstruction losses: 0.02744493655073009, regression losses: 0.17121563595673628, validation losses: 0.5218085916314888\n",
      "Epoch 6000, reconstruction losses: 0.024721579609827033, regression losses: 0.12472032657954799, validation losses: 0.43919493298010476\n",
      "Epoch 6001, reconstruction losses: 0.02553725396393983, regression losses: 0.11818653771176406, validation losses: 0.5066136032799642\n",
      "Epoch 6002, reconstruction losses: 0.027997264859287056, regression losses: 0.13997396753691005, validation losses: 0.47698568938619845\n",
      "Epoch 6003, reconstruction losses: 0.027637311377238988, regression losses: 0.14309077013024615, validation losses: 0.5172861258625681\n",
      "Epoch 6004, reconstruction losses: 0.02508674043889058, regression losses: 0.10390428585459852, validation losses: 0.49584760595025884\n",
      "Epoch 6005, reconstruction losses: 0.028031630888694058, regression losses: 0.11708198819600676, validation losses: 0.44598294550733464\n",
      "Epoch 6006, reconstruction losses: 0.0309743296179635, regression losses: 0.1323175708582612, validation losses: 0.43678796382157975\n",
      "Epoch 6007, reconstruction losses: 0.02996412784301856, regression losses: 0.1286557512925723, validation losses: 0.4198425269144681\n",
      "Epoch 6008, reconstruction losses: 0.02592867829457709, regression losses: 0.11000614978932592, validation losses: 0.42490073506014936\n",
      "Epoch 6009, reconstruction losses: 0.028104891927747774, regression losses: 0.12146560710618118, validation losses: 0.45847753664631635\n",
      "Epoch 6010, reconstruction losses: 0.03153669148714434, regression losses: 0.22824965392739566, validation losses: 0.529925630420832\n",
      "Epoch 6011, reconstruction losses: 0.027940359161502826, regression losses: 0.24692295226230168, validation losses: 0.6182891104508665\n",
      "Epoch 6012, reconstruction losses: 0.029560854038458352, regression losses: 0.1666361248068752, validation losses: 0.5562929858453682\n",
      "Epoch 6013, reconstruction losses: 0.02987992303371437, regression losses: 0.12071950498365351, validation losses: 0.5216600242889196\n",
      "Epoch 6014, reconstruction losses: 0.02865160486739805, regression losses: 0.10265820960948477, validation losses: 0.48977505732024673\n",
      "Epoch 6015, reconstruction losses: 0.024332749466106175, regression losses: 0.1273660153202433, validation losses: 0.4893201084866214\n",
      "Epoch 6016, reconstruction losses: 0.027974075299257297, regression losses: 0.22196137094179602, validation losses: 0.47161618043616266\n",
      "Epoch 6017, reconstruction losses: 0.027834514493546774, regression losses: 0.09826195513363833, validation losses: 0.5299017243517019\n",
      "Epoch 6018, reconstruction losses: 0.0293955329988969, regression losses: 0.09096941712324556, validation losses: 0.4851711412142865\n",
      "Epoch 6019, reconstruction losses: 0.027040388454605862, regression losses: 0.1567787964396986, validation losses: 0.42962191636051994\n",
      "Epoch 6020, reconstruction losses: 0.02729843906854776, regression losses: 0.10969892126104275, validation losses: 0.4468483473383726\n",
      "Epoch 6021, reconstruction losses: 0.025970888107290018, regression losses: 0.11491869270798986, validation losses: 0.5079412147611282\n",
      "Epoch 6022, reconstruction losses: 0.028283626309630282, regression losses: 0.12513936931030467, validation losses: 0.578024896110473\n",
      "Epoch 6023, reconstruction losses: 0.027086901034633258, regression losses: 0.10888639894003804, validation losses: 0.6168756294286786\n",
      "Epoch 6024, reconstruction losses: 0.027627615893170122, regression losses: 0.1064035411978272, validation losses: 0.5203776020747907\n",
      "Epoch 6025, reconstruction losses: 0.026057618726485886, regression losses: 0.10928195841094322, validation losses: 0.4444630823520723\n",
      "Epoch 6026, reconstruction losses: 0.02762973765515483, regression losses: 0.0926146970979838, validation losses: 0.4332217571509903\n",
      "Epoch 6027, reconstruction losses: 0.026912442512626946, regression losses: 0.11771021783493837, validation losses: 0.4404820289645727\n",
      "Epoch 6028, reconstruction losses: 0.025932292044283264, regression losses: 0.12801701814390673, validation losses: 0.5352862269844804\n",
      "Epoch 6029, reconstruction losses: 0.02718519156665852, regression losses: 0.1191246344100673, validation losses: 0.5347148108199884\n",
      "Epoch 6030, reconstruction losses: 0.025257704957806958, regression losses: 0.11565486106158228, validation losses: 0.49041797734092796\n",
      "Epoch 6031, reconstruction losses: 0.028394091261260752, regression losses: 0.08806202456665338, validation losses: 0.4654813916655935\n",
      "Epoch 6032, reconstruction losses: 0.025168145110418715, regression losses: 0.13248169488459094, validation losses: 0.4402836967058072\n",
      "Epoch 6033, reconstruction losses: 0.025230393178220654, regression losses: 0.11914474627901185, validation losses: 0.48316286804244835\n",
      "Epoch 6034, reconstruction losses: 0.03121551606205733, regression losses: 0.2351500339512467, validation losses: 0.5746087838400109\n",
      "Epoch 6035, reconstruction losses: 0.026393362260233512, regression losses: 0.11775972865821797, validation losses: 0.4561288555263916\n",
      "Epoch 6036, reconstruction losses: 0.023895931892535006, regression losses: 0.12102255652407591, validation losses: 0.435568129473407\n",
      "Epoch 6037, reconstruction losses: 0.024596311220638448, regression losses: 0.11589715356964103, validation losses: 0.4319139002763932\n",
      "Epoch 6038, reconstruction losses: 0.02845222358482738, regression losses: 0.14628609927575603, validation losses: 0.5578425339054356\n",
      "Epoch 6039, reconstruction losses: 0.028345404143271274, regression losses: 0.1491693514397845, validation losses: 0.4364385825532047\n",
      "Epoch 6040, reconstruction losses: 0.027878540919828446, regression losses: 0.11197077652822754, validation losses: 0.427594393725434\n",
      "Epoch 6041, reconstruction losses: 0.02985064904395776, regression losses: 0.13543686380056177, validation losses: 0.390995253329614\n",
      "Epoch 6042, reconstruction losses: 0.0277418467463776, regression losses: 0.1299372151128208, validation losses: 0.39937424823811285\n",
      "Epoch 6043, reconstruction losses: 0.026526578773307385, regression losses: 0.11838031876151729, validation losses: 0.4768945215899625\n",
      "Epoch 6044, reconstruction losses: 0.029960651266896017, regression losses: 0.13394019641131238, validation losses: 0.4974383388557163\n",
      "Epoch 6045, reconstruction losses: 0.024895702101897482, regression losses: 0.10442223131737459, validation losses: 0.39979758208254673\n",
      "Epoch 6046, reconstruction losses: 0.026499058045278856, regression losses: 0.12111731369723494, validation losses: 0.41413314367180537\n",
      "Epoch 6047, reconstruction losses: 0.026311919126892364, regression losses: 0.1041440860705102, validation losses: 0.43478628557977367\n",
      "Epoch 6048, reconstruction losses: 0.024663052688677765, regression losses: 0.09563749649493132, validation losses: 0.489727758059737\n",
      "Epoch 6049, reconstruction losses: 0.02809524089546725, regression losses: 0.12219941524659912, validation losses: 0.4833791633739868\n",
      "Epoch 6050, reconstruction losses: 0.025995794669565538, regression losses: 0.09471042260150779, validation losses: 0.4583880532297735\n",
      "Epoch 6051, reconstruction losses: 0.02734705320378957, regression losses: 0.17713422666455186, validation losses: 0.43328203887287364\n",
      "Epoch 6052, reconstruction losses: 0.025036911280580682, regression losses: 0.17418114852532124, validation losses: 0.7315748773732474\n",
      "Epoch 6053, reconstruction losses: 0.028429544655676913, regression losses: 0.16907217430216806, validation losses: 0.8215256121027941\n",
      "Epoch 6054, reconstruction losses: 0.02687740648326981, regression losses: 0.17351949144793052, validation losses: 0.7391292910339587\n",
      "Epoch 6055, reconstruction losses: 0.024079663083846136, regression losses: 0.12146449161863934, validation losses: 0.6069774527876771\n",
      "Epoch 6056, reconstruction losses: 0.02752153649475569, regression losses: 0.15083828533485355, validation losses: 0.46023663242102775\n",
      "Epoch 6057, reconstruction losses: 0.024364915960503785, regression losses: 0.12335071590043241, validation losses: 0.434960523039805\n",
      "Epoch 6058, reconstruction losses: 0.027240863022570387, regression losses: 0.18458132632226426, validation losses: 0.4772356300563883\n",
      "Epoch 6059, reconstruction losses: 0.029995947185390184, regression losses: 0.12671266025541664, validation losses: 0.4982830136023559\n",
      "Epoch 6060, reconstruction losses: 0.02706493378347742, regression losses: 0.15479058331940895, validation losses: 0.41465149371666205\n",
      "Epoch 6061, reconstruction losses: 0.02690169229690312, regression losses: 0.16472993134319933, validation losses: 0.5503340486372473\n",
      "Epoch 6062, reconstruction losses: 0.029128822020883342, regression losses: 0.17202994753055176, validation losses: 0.5949924764441193\n",
      "Epoch 6063, reconstruction losses: 0.027021561181917727, regression losses: 0.10759866234495608, validation losses: 0.6558907212953056\n",
      "Epoch 6064, reconstruction losses: 0.025160542162251543, regression losses: 0.12254873341156176, validation losses: 0.4972875079704483\n",
      "Epoch 6065, reconstruction losses: 0.026708286125998085, regression losses: 0.13152708743344999, validation losses: 0.44120602555295346\n",
      "Epoch 6066, reconstruction losses: 0.026785970759588155, regression losses: 0.10729082916540018, validation losses: 0.47757228074683633\n",
      "Epoch 6067, reconstruction losses: 0.028907578341769227, regression losses: 0.10206804612355934, validation losses: 0.4549050984853632\n",
      "Epoch 6068, reconstruction losses: 0.02762932666101484, regression losses: 0.13092496818354218, validation losses: 0.5168319659694494\n",
      "Epoch 6069, reconstruction losses: 0.027240859121120967, regression losses: 0.13336992548349036, validation losses: 0.557490182942897\n",
      "Epoch 6070, reconstruction losses: 0.027370789275231396, regression losses: 0.14279694591537226, validation losses: 0.4402507654354786\n",
      "Epoch 6071, reconstruction losses: 0.02856675854558747, regression losses: 0.10659502744009124, validation losses: 0.38217718058208194\n",
      "Epoch 6072, reconstruction losses: 0.027884045089079455, regression losses: 0.18088773154508, validation losses: 0.38254429749544416\n",
      "Epoch 6073, reconstruction losses: 0.026112137526468022, regression losses: 0.09817964009777849, validation losses: 0.4950103313544045\n",
      "Epoch 6074, reconstruction losses: 0.026831695677652326, regression losses: 0.13336448081731614, validation losses: 0.4860395771266038\n",
      "Epoch 6075, reconstruction losses: 0.029302793088509242, regression losses: 0.19570094631468365, validation losses: 0.4876795619564143\n",
      "Epoch 6076, reconstruction losses: 0.028795865221001055, regression losses: 0.35110846166722864, validation losses: 0.5178336682552007\n",
      "Epoch 6077, reconstruction losses: 0.027821411094046452, regression losses: 0.10038998958971393, validation losses: 0.7392131673124153\n",
      "Epoch 6078, reconstruction losses: 0.029654081516243012, regression losses: 0.17907764102807058, validation losses: 0.5670096214991904\n",
      "Epoch 6079, reconstruction losses: 0.024564442034554816, regression losses: 0.10870621921679963, validation losses: 0.5324997202213669\n",
      "Epoch 6080, reconstruction losses: 0.02608401370120185, regression losses: 0.12263706544399969, validation losses: 0.46737807879217175\n",
      "Epoch 6081, reconstruction losses: 0.02926481182240264, regression losses: 0.1341737473045108, validation losses: 0.4700267648788693\n",
      "Epoch 6082, reconstruction losses: 0.02784261086050887, regression losses: 0.08144553788892077, validation losses: 0.5770636050344649\n",
      "Epoch 6083, reconstruction losses: 0.023702462440523188, regression losses: 0.14115924985281658, validation losses: 0.5054644156463695\n",
      "Epoch 6084, reconstruction losses: 0.02545328914742586, regression losses: 0.1326658744461732, validation losses: 0.4517153216907315\n",
      "Epoch 6085, reconstruction losses: 0.026525687709690257, regression losses: 0.11649105334746598, validation losses: 0.45679302712820014\n",
      "Epoch 6086, reconstruction losses: 0.02617910942439174, regression losses: 0.10660927318267542, validation losses: 0.43388847496073435\n",
      "Epoch 6087, reconstruction losses: 0.028676880934015336, regression losses: 0.18942069221155397, validation losses: 0.4341201309675719\n",
      "Epoch 6088, reconstruction losses: 0.028490649120699294, regression losses: 0.11953961325483857, validation losses: 0.5864392812010117\n",
      "Epoch 6089, reconstruction losses: 0.025745966353209027, regression losses: 0.10936009274692943, validation losses: 0.5979476915469997\n",
      "Epoch 6090, reconstruction losses: 0.02843631683651599, regression losses: 0.10168126699241878, validation losses: 0.4525550943630914\n",
      "Epoch 6091, reconstruction losses: 0.027195389393138064, regression losses: 0.16993592437156121, validation losses: 0.47923022175384894\n",
      "Epoch 6092, reconstruction losses: 0.026079458691813266, regression losses: 0.11501034178358735, validation losses: 0.4723407771667716\n",
      "Epoch 6093, reconstruction losses: 0.032191703640468444, regression losses: 0.12039795800729822, validation losses: 0.4647184083112507\n",
      "Epoch 6094, reconstruction losses: 0.028792297459586134, regression losses: 0.10335483072942922, validation losses: 0.4016127325285399\n",
      "Epoch 6095, reconstruction losses: 0.028040216227689038, regression losses: 0.11127276777123557, validation losses: 0.3923730934136168\n",
      "Epoch 6096, reconstruction losses: 0.028522158451929902, regression losses: 0.1198691504582243, validation losses: 0.47516408693756007\n",
      "Epoch 6097, reconstruction losses: 0.027365723935420083, regression losses: 0.14491912416041217, validation losses: 0.47181635322516563\n",
      "Epoch 6098, reconstruction losses: 0.0296491863100216, regression losses: 0.12841222929199358, validation losses: 0.4234222723579273\n",
      "Epoch 6099, reconstruction losses: 0.026660453846955288, regression losses: 0.12217935737238794, validation losses: 0.43022339111288016\n",
      "Epoch 6100, reconstruction losses: 0.027216826771879022, regression losses: 0.10846286935667777, validation losses: 0.45882383677212657\n",
      "Epoch 6101, reconstruction losses: 0.025433915062743607, regression losses: 0.11510732369111752, validation losses: 0.5225527843056212\n",
      "Epoch 6102, reconstruction losses: 0.02638474688578906, regression losses: 0.10135522841422706, validation losses: 0.4939841370634503\n",
      "Epoch 6103, reconstruction losses: 0.024201161123236708, regression losses: 0.10559425976459424, validation losses: 0.4615605408939319\n",
      "Epoch 6104, reconstruction losses: 0.029146650703478598, regression losses: 0.1504599915787159, validation losses: 0.4727037257880492\n",
      "Epoch 6105, reconstruction losses: 0.026056478785792828, regression losses: 0.13027440740472032, validation losses: 0.5563280032826502\n",
      "Epoch 6106, reconstruction losses: 0.0253732943095433, regression losses: 0.13033269387250115, validation losses: 0.4846389389679238\n",
      "Epoch 6107, reconstruction losses: 0.02652269821591396, regression losses: 0.18116825040211504, validation losses: 0.4275964449947778\n",
      "Epoch 6108, reconstruction losses: 0.02619591270128001, regression losses: 0.10742923196066319, validation losses: 0.44587092172294984\n",
      "Epoch 6109, reconstruction losses: 0.02682299431470964, regression losses: 0.09965921322704828, validation losses: 0.44865341746838366\n",
      "Epoch 6110, reconstruction losses: 0.028245544817518963, regression losses: 0.12586970345391568, validation losses: 0.4952558413727162\n",
      "Epoch 6111, reconstruction losses: 0.027441853790646474, regression losses: 0.10917493061725461, validation losses: 0.5543857657503981\n",
      "Epoch 6112, reconstruction losses: 0.028671644862692507, regression losses: 0.15126670403577852, validation losses: 0.4840455131473485\n",
      "Epoch 6113, reconstruction losses: 0.027184809374038173, regression losses: 0.09814629880864573, validation losses: 0.4806174668310178\n",
      "Epoch 6114, reconstruction losses: 0.02631201920478746, regression losses: 0.09129042308183466, validation losses: 0.4551410301882192\n",
      "Epoch 6115, reconstruction losses: 0.028139975143872172, regression losses: 0.08896895393164636, validation losses: 0.5038880497731164\n",
      "Epoch 6116, reconstruction losses: 0.026355671879805358, regression losses: 0.08177277720385298, validation losses: 0.4860562889372497\n",
      "Epoch 6117, reconstruction losses: 0.02842952760656338, regression losses: 0.10131289769991597, validation losses: 0.49112229124109863\n",
      "Epoch 6118, reconstruction losses: 0.028099818288484974, regression losses: 0.14852829126579223, validation losses: 0.5566755110041038\n",
      "Epoch 6119, reconstruction losses: 0.02526702567114846, regression losses: 0.10343620975222843, validation losses: 0.47478287506869143\n",
      "Epoch 6120, reconstruction losses: 0.025915655114883588, regression losses: 0.1002368812508394, validation losses: 0.46699466696959047\n",
      "Epoch 6121, reconstruction losses: 0.02886742151593038, regression losses: 0.2617046859479095, validation losses: 0.4609863817257274\n",
      "Epoch 6122, reconstruction losses: 0.02644443427023281, regression losses: 0.27070170510148706, validation losses: 0.5703636312397607\n",
      "Epoch 6123, reconstruction losses: 0.028561492960811737, regression losses: 0.1251718509303064, validation losses: 0.5636636749225842\n",
      "Epoch 6124, reconstruction losses: 0.02503482886454592, regression losses: 0.13366863522765104, validation losses: 0.620238253664794\n",
      "Epoch 6125, reconstruction losses: 0.02692316803799454, regression losses: 0.11631784217216212, validation losses: 0.5770234644444803\n",
      "Epoch 6126, reconstruction losses: 0.024979447896212703, regression losses: 0.09887539584405251, validation losses: 0.5309783062224813\n",
      "Epoch 6127, reconstruction losses: 0.030872257477702916, regression losses: 0.18337824694616528, validation losses: 0.5115599353578079\n",
      "Epoch 6128, reconstruction losses: 0.025863199031906176, regression losses: 0.22510176567781592, validation losses: 0.545006296993601\n",
      "Epoch 6129, reconstruction losses: 0.03164500055016839, regression losses: 0.1462909341560932, validation losses: 0.7432067208558485\n",
      "Epoch 6130, reconstruction losses: 0.03037396174981873, regression losses: 0.3011114055981928, validation losses: 0.7194122334998171\n",
      "Epoch 6131, reconstruction losses: 0.0265897025719829, regression losses: 0.14529859262766553, validation losses: 0.8613689225509644\n",
      "Epoch 6132, reconstruction losses: 0.029771370152357, regression losses: 0.14716724214353963, validation losses: 0.5864634333093904\n",
      "Epoch 6133, reconstruction losses: 0.028572539969222155, regression losses: 0.11580842499766043, validation losses: 0.5439652978312106\n",
      "Epoch 6134, reconstruction losses: 0.025569937725913667, regression losses: 0.11204338455842339, validation losses: 0.5870082447529424\n",
      "Epoch 6135, reconstruction losses: 0.02450099609589395, regression losses: 0.1014056912106239, validation losses: 0.5832656695921434\n",
      "Epoch 6136, reconstruction losses: 0.026900752902406053, regression losses: 0.11401564000816569, validation losses: 0.515016517038348\n",
      "Epoch 6137, reconstruction losses: 0.027891114943156735, regression losses: 0.13526328156044592, validation losses: 0.4464494255317886\n",
      "Epoch 6138, reconstruction losses: 0.026282500524194854, regression losses: 0.14544276249360108, validation losses: 0.5392777833626049\n",
      "Epoch 6139, reconstruction losses: 0.02349381962315533, regression losses: 0.10475680947787468, validation losses: 0.5248029607110976\n",
      "Epoch 6140, reconstruction losses: 0.0261039933856844, regression losses: 0.17099939099767844, validation losses: 0.5859374482006027\n",
      "Epoch 6141, reconstruction losses: 0.026541584014972135, regression losses: 0.14533582502955195, validation losses: 0.7299862698224703\n",
      "Epoch 6142, reconstruction losses: 0.02415970527336505, regression losses: 0.12085017407358176, validation losses: 0.6113484238741788\n",
      "Epoch 6143, reconstruction losses: 0.02730326881092265, regression losses: 0.10147601233670146, validation losses: 0.48027401366589256\n",
      "Epoch 6144, reconstruction losses: 0.02443678817524099, regression losses: 0.09557593628730796, validation losses: 0.46258183875867087\n",
      "Epoch 6145, reconstruction losses: 0.02330884517310209, regression losses: 0.11175866961877795, validation losses: 0.5350776434984793\n",
      "Epoch 6146, reconstruction losses: 0.025705235828885176, regression losses: 0.1205875098013254, validation losses: 0.5268852296453538\n",
      "Epoch 6147, reconstruction losses: 0.0273520515701071, regression losses: 0.11275958020210879, validation losses: 0.4564869970224403\n",
      "Epoch 6148, reconstruction losses: 0.02674158333294608, regression losses: 0.10185299406523807, validation losses: 0.4300259236583013\n",
      "Epoch 6149, reconstruction losses: 0.02644226279496889, regression losses: 0.12408038448160852, validation losses: 0.42963655827368386\n",
      "Epoch 6150, reconstruction losses: 0.027247089683040453, regression losses: 0.1179651622353158, validation losses: 0.4823521609168157\n",
      "Epoch 6151, reconstruction losses: 0.026177007861145594, regression losses: 0.14215264579154863, validation losses: 0.6051720037402084\n",
      "Epoch 6152, reconstruction losses: 0.026247648171833268, regression losses: 0.10749211292576627, validation losses: 0.6088655865325822\n",
      "Epoch 6153, reconstruction losses: 0.026046933249890436, regression losses: 0.12262825023926817, validation losses: 0.563848941379395\n",
      "Epoch 6154, reconstruction losses: 0.02400232932019914, regression losses: 0.15447168953958088, validation losses: 0.526268529497168\n",
      "Epoch 6155, reconstruction losses: 0.024943249362508968, regression losses: 0.10740767451090519, validation losses: 0.4919179241453025\n",
      "Epoch 6156, reconstruction losses: 0.026711993073896906, regression losses: 0.14002145060065938, validation losses: 0.48902775365151213\n",
      "Epoch 6157, reconstruction losses: 0.02659313785437794, regression losses: 0.11245851745675048, validation losses: 0.4195350824412676\n",
      "Epoch 6158, reconstruction losses: 0.025479778082411825, regression losses: 0.09751411585060334, validation losses: 0.41658523400106207\n",
      "Epoch 6159, reconstruction losses: 0.028404056591108662, regression losses: 0.13240950983394745, validation losses: 0.4290274105450166\n",
      "Epoch 6160, reconstruction losses: 0.02596485481117026, regression losses: 0.13654702478167707, validation losses: 0.4772799048114901\n",
      "Epoch 6161, reconstruction losses: 0.027075374431009002, regression losses: 0.12461535263243256, validation losses: 0.5277578576990941\n",
      "Epoch 6162, reconstruction losses: 0.02435776673121433, regression losses: 0.09870365935955669, validation losses: 0.5409851709399082\n",
      "Epoch 6163, reconstruction losses: 0.025685114920032604, regression losses: 0.11332473441934116, validation losses: 0.5024651221654565\n",
      "Epoch 6164, reconstruction losses: 0.02602210648559801, regression losses: 0.13642861544335788, validation losses: 0.4289835188677963\n",
      "Epoch 6165, reconstruction losses: 0.026464994163820307, regression losses: 0.1169222931130916, validation losses: 0.45862755587405196\n",
      "Epoch 6166, reconstruction losses: 0.02727240713618536, regression losses: 0.12447460087191124, validation losses: 0.4337234611192778\n",
      "Epoch 6167, reconstruction losses: 0.02660951850203275, regression losses: 0.10997229632167133, validation losses: 0.4205961657014911\n",
      "Epoch 6168, reconstruction losses: 0.03046425370062661, regression losses: 0.15988354485645892, validation losses: 0.4307712250124634\n",
      "Epoch 6169, reconstruction losses: 0.02840118555584762, regression losses: 0.13493573577305262, validation losses: 0.41974093934052903\n",
      "Epoch 6170, reconstruction losses: 0.029236113870657596, regression losses: 0.1233648676228139, validation losses: 0.43175851024423867\n",
      "Epoch 6171, reconstruction losses: 0.03123683568292552, regression losses: 0.16310375312063835, validation losses: 0.48602930804937583\n",
      "Epoch 6172, reconstruction losses: 0.026305309136789554, regression losses: 0.1439066320768893, validation losses: 0.5705481208557103\n",
      "Epoch 6173, reconstruction losses: 0.02813625434306117, regression losses: 0.17141697528467612, validation losses: 0.4327639617268336\n",
      "Epoch 6174, reconstruction losses: 0.025058760646590388, regression losses: 0.1581802541707704, validation losses: 0.5984879678731357\n",
      "Epoch 6175, reconstruction losses: 0.025371433219666346, regression losses: 0.09077483920945349, validation losses: 0.4614437231956805\n",
      "Epoch 6176, reconstruction losses: 0.025987906982556694, regression losses: 0.1481090698827625, validation losses: 0.46121818725707253\n",
      "Epoch 6177, reconstruction losses: 0.027669649464736747, regression losses: 0.10684731861908375, validation losses: 0.46463823917064695\n",
      "Epoch 6178, reconstruction losses: 0.024096904446985486, regression losses: 0.13605773227030532, validation losses: 0.4359726849760301\n",
      "Epoch 6179, reconstruction losses: 0.024799738005479542, regression losses: 0.09417537575205578, validation losses: 0.4071404382127038\n",
      "Epoch 6180, reconstruction losses: 0.02851463820467499, regression losses: 0.1584086769738043, validation losses: 0.4298751970050395\n",
      "Epoch 6181, reconstruction losses: 0.025241133953705613, regression losses: 0.10422993062540846, validation losses: 0.47770020449012923\n",
      "Epoch 6182, reconstruction losses: 0.025274810713973132, regression losses: 0.09807975834821281, validation losses: 0.4850864941644578\n",
      "Epoch 6183, reconstruction losses: 0.027442104144473727, regression losses: 0.13982848881669135, validation losses: 0.45465835904022106\n",
      "Epoch 6184, reconstruction losses: 0.028076547924748434, regression losses: 0.1604411376092117, validation losses: 0.46079755841309733\n",
      "Epoch 6185, reconstruction losses: 0.026282653683525357, regression losses: 0.11064808338247388, validation losses: 0.541053415717796\n",
      "Epoch 6186, reconstruction losses: 0.02376118908676256, regression losses: 0.11471423376191123, validation losses: 0.49038303962738555\n",
      "Epoch 6187, reconstruction losses: 0.024688944292638244, regression losses: 0.10031796561834344, validation losses: 0.44991591493209065\n",
      "Epoch 6188, reconstruction losses: 0.02812021671505636, regression losses: 0.11927369763867286, validation losses: 0.45299888198159843\n",
      "Epoch 6189, reconstruction losses: 0.024834000843196057, regression losses: 0.08231186298115557, validation losses: 0.47244855941462066\n",
      "Epoch 6190, reconstruction losses: 0.029702817975628168, regression losses: 0.13499801584112572, validation losses: 0.5632738028848143\n",
      "Epoch 6191, reconstruction losses: 0.024984753821895102, regression losses: 0.12403642518392297, validation losses: 0.5113765755507098\n",
      "Epoch 6192, reconstruction losses: 0.028296441643380646, regression losses: 0.12403709213135658, validation losses: 0.44363838071931266\n",
      "Epoch 6193, reconstruction losses: 0.02645389087665624, regression losses: 0.11317210251353688, validation losses: 0.4188660211648909\n",
      "Epoch 6194, reconstruction losses: 0.02746243833543705, regression losses: 0.15090660323671426, validation losses: 0.47354660648754837\n",
      "Epoch 6195, reconstruction losses: 0.022866027324513535, regression losses: 0.11595518440468679, validation losses: 0.5966170583809588\n",
      "Epoch 6196, reconstruction losses: 0.02675990489845682, regression losses: 0.1370512104737483, validation losses: 0.4707891354981118\n",
      "Epoch 6197, reconstruction losses: 0.027077371943697533, regression losses: 0.14583887668365203, validation losses: 0.41827006836128044\n",
      "Epoch 6198, reconstruction losses: 0.027819616537101157, regression losses: 0.1341612637334543, validation losses: 0.4529831217079075\n",
      "Epoch 6199, reconstruction losses: 0.024397884457978695, regression losses: 0.10081916295253242, validation losses: 0.43765338976815027\n",
      "Epoch 6200, reconstruction losses: 0.026522119901762783, regression losses: 0.08574052639919595, validation losses: 0.46591057807636455\n",
      "Epoch 6201, reconstruction losses: 0.024665059828935687, regression losses: 0.09866125047041098, validation losses: 0.47613834585287645\n",
      "Epoch 6202, reconstruction losses: 0.02741282651762693, regression losses: 0.13696252793177868, validation losses: 0.484173831240826\n",
      "Epoch 6203, reconstruction losses: 0.03431339404906007, regression losses: 0.15586937382885102, validation losses: 0.42590500854076907\n",
      "Epoch 6204, reconstruction losses: 0.027658676132543393, regression losses: 0.11319590400156583, validation losses: 0.4009622262102206\n",
      "Epoch 6205, reconstruction losses: 0.025422620789334535, regression losses: 0.10128902209578636, validation losses: 0.406760067426678\n",
      "Epoch 6206, reconstruction losses: 0.02548155698037873, regression losses: 0.1327847764579253, validation losses: 0.4249175797815897\n",
      "Epoch 6207, reconstruction losses: 0.022872854334878887, regression losses: 0.09198696325835475, validation losses: 0.5604281321143083\n",
      "Epoch 6208, reconstruction losses: 0.025791645982940512, regression losses: 0.09039762572227353, validation losses: 0.5670652962080126\n",
      "Epoch 6209, reconstruction losses: 0.02553459293096139, regression losses: 0.14323024433713527, validation losses: 0.4199627180041075\n",
      "Epoch 6210, reconstruction losses: 0.02464426311440867, regression losses: 0.10242527339172768, validation losses: 0.4106961035465406\n",
      "Epoch 6211, reconstruction losses: 0.025225245312294097, regression losses: 0.09752711784374196, validation losses: 0.48000380319956504\n",
      "Epoch 6212, reconstruction losses: 0.025232336921808696, regression losses: 0.10018672115000733, validation losses: 0.49137090526578\n",
      "Epoch 6213, reconstruction losses: 0.028259867678284884, regression losses: 0.10711018882038524, validation losses: 0.47366955679470235\n",
      "Epoch 6214, reconstruction losses: 0.027433847171700606, regression losses: 0.10469617534777785, validation losses: 0.43002862099018857\n",
      "Epoch 6215, reconstruction losses: 0.026095498598888888, regression losses: 0.1136769944860291, validation losses: 0.41982894745827637\n",
      "Epoch 6216, reconstruction losses: 0.027333953280422017, regression losses: 0.09305438724549112, validation losses: 0.43018092186824797\n",
      "Epoch 6217, reconstruction losses: 0.027778310259547703, regression losses: 0.11485294672487698, validation losses: 0.46067524043156505\n",
      "Epoch 6218, reconstruction losses: 0.02471736482582792, regression losses: 0.115881166118487, validation losses: 0.4756155097311918\n",
      "Epoch 6219, reconstruction losses: 0.028366835008198088, regression losses: 0.145359910327835, validation losses: 0.4958737508097495\n",
      "Epoch 6220, reconstruction losses: 0.025589841932196263, regression losses: 0.1078789037178691, validation losses: 0.4813325015393924\n",
      "Epoch 6221, reconstruction losses: 0.024879877095530772, regression losses: 0.1041368718251443, validation losses: 0.4385140534892564\n",
      "Epoch 6222, reconstruction losses: 0.028432674339704013, regression losses: 0.10223193140319693, validation losses: 0.43317308543981264\n",
      "Epoch 6223, reconstruction losses: 0.02430255911032523, regression losses: 0.10971139831299746, validation losses: 0.4282905308377455\n",
      "Epoch 6224, reconstruction losses: 0.02516965952669776, regression losses: 0.10384602565954543, validation losses: 0.46703085861349725\n",
      "Epoch 6225, reconstruction losses: 0.024682973329279642, regression losses: 0.11859726941920076, validation losses: 0.5242763976759302\n",
      "Epoch 6226, reconstruction losses: 0.025177155728675557, regression losses: 0.13010128558394254, validation losses: 0.5174438515222417\n",
      "Epoch 6227, reconstruction losses: 0.02674425739827411, regression losses: 0.11123403040154733, validation losses: 0.4724292256033697\n",
      "Epoch 6228, reconstruction losses: 0.026255423114993227, regression losses: 0.10294296733828154, validation losses: 0.4561428620999744\n",
      "Epoch 6229, reconstruction losses: 0.027336088498453495, regression losses: 0.1328675936438468, validation losses: 0.42090188661076666\n",
      "Epoch 6230, reconstruction losses: 0.028542089319284366, regression losses: 0.10378064612331124, validation losses: 0.39985770259305065\n",
      "Epoch 6231, reconstruction losses: 0.023741968373340167, regression losses: 0.1438684465884574, validation losses: 0.42139468900656407\n",
      "Epoch 6232, reconstruction losses: 0.027761836224165403, regression losses: 0.42357088664204195, validation losses: 0.5129552324023662\n",
      "Epoch 6233, reconstruction losses: 0.029317212280019378, regression losses: 0.13144661709711897, validation losses: 0.7194591148895567\n",
      "Epoch 6234, reconstruction losses: 0.026602277636896425, regression losses: 0.16730186391733784, validation losses: 0.647738545377881\n",
      "Epoch 6235, reconstruction losses: 0.027512589768086276, regression losses: 0.19982095232147654, validation losses: 0.5978241673247356\n",
      "Epoch 6236, reconstruction losses: 0.0266472857949027, regression losses: 0.1263380530969046, validation losses: 0.7127763710918376\n",
      "Epoch 6237, reconstruction losses: 0.02368190541539682, regression losses: 0.14554761659346765, validation losses: 0.7120089073961691\n",
      "Epoch 6238, reconstruction losses: 0.026516826016880372, regression losses: 0.10599894798164201, validation losses: 0.5071172497166895\n",
      "Epoch 6239, reconstruction losses: 0.026410942874363595, regression losses: 0.10558946535769703, validation losses: 0.4823417380920281\n",
      "Epoch 6240, reconstruction losses: 0.024565115520677357, regression losses: 0.12350908853397738, validation losses: 0.472883030159751\n",
      "Epoch 6241, reconstruction losses: 0.0245748100564074, regression losses: 0.11953023638164019, validation losses: 0.492611558838753\n",
      "Epoch 6242, reconstruction losses: 0.02332704076362965, regression losses: 0.09149248830713974, validation losses: 0.5175725675269776\n",
      "Epoch 6243, reconstruction losses: 0.026883603191882356, regression losses: 0.17373834701244498, validation losses: 0.5004331543529598\n",
      "Epoch 6244, reconstruction losses: 0.024806545656427877, regression losses: 0.09696989911177308, validation losses: 0.4730321238584763\n",
      "Epoch 6245, reconstruction losses: 0.027867573961976602, regression losses: 0.2178811274834546, validation losses: 0.4386155102582132\n",
      "Epoch 6246, reconstruction losses: 0.021619656136660725, regression losses: 0.10389606566046332, validation losses: 0.5495040036540295\n",
      "Epoch 6247, reconstruction losses: 0.02945489449701905, regression losses: 0.18724305348483028, validation losses: 0.45932494356891357\n",
      "Epoch 6248, reconstruction losses: 0.025432932633638994, regression losses: 0.12403816091400008, validation losses: 0.6395984097174161\n",
      "Epoch 6249, reconstruction losses: 0.026334316724957143, regression losses: 0.14735377030065078, validation losses: 0.6357001867510953\n",
      "Epoch 6250, reconstruction losses: 0.02686664347366796, regression losses: 0.2474360448945746, validation losses: 0.5121433735219918\n",
      "Epoch 6251, reconstruction losses: 0.02654180389641333, regression losses: 0.13010524893153322, validation losses: 0.6114861323602726\n",
      "Epoch 6252, reconstruction losses: 0.02692723940935133, regression losses: 0.17755029664584113, validation losses: 0.5431909673304904\n",
      "Epoch 6253, reconstruction losses: 0.023590210370565686, regression losses: 0.09615078418968138, validation losses: 0.4455341101557464\n",
      "Epoch 6254, reconstruction losses: 0.02484526155736811, regression losses: 0.13521843306806153, validation losses: 0.40363803745760357\n",
      "Epoch 6255, reconstruction losses: 0.026791336576328446, regression losses: 0.09038922777037445, validation losses: 0.3904862964254319\n",
      "Epoch 6256, reconstruction losses: 0.02841180803437658, regression losses: 0.13725744633912434, validation losses: 0.42197471595395086\n",
      "Epoch 6257, reconstruction losses: 0.025614261239837354, regression losses: 0.12476239314531234, validation losses: 0.4109034640730002\n",
      "Epoch 6258, reconstruction losses: 0.02324676193541231, regression losses: 0.10484492371581258, validation losses: 0.42435829796065133\n",
      "Epoch 6259, reconstruction losses: 0.024810238740698987, regression losses: 0.09878281638085402, validation losses: 0.4455046437001153\n",
      "Epoch 6260, reconstruction losses: 0.025892134045215624, regression losses: 0.14795066410873717, validation losses: 0.5026140288408083\n",
      "Epoch 6261, reconstruction losses: 0.027625026246600796, regression losses: 0.22295953706461016, validation losses: 0.6354789874998401\n",
      "Epoch 6262, reconstruction losses: 0.028902157989328315, regression losses: 0.1489410345219323, validation losses: 0.615600172127629\n",
      "Epoch 6263, reconstruction losses: 0.025114237217205324, regression losses: 0.13246219164988676, validation losses: 0.5191639478611244\n",
      "Epoch 6264, reconstruction losses: 0.024910840734807635, regression losses: 0.1480590680080885, validation losses: 0.46398096099277214\n",
      "Epoch 6265, reconstruction losses: 0.025778445652983286, regression losses: 0.12254481580243917, validation losses: 0.4797299142588772\n",
      "Epoch 6266, reconstruction losses: 0.02385640565848186, regression losses: 0.14962225096974655, validation losses: 0.4467385368778353\n",
      "Epoch 6267, reconstruction losses: 0.024124056769617028, regression losses: 0.14337788105099428, validation losses: 0.593566693472333\n",
      "Epoch 6268, reconstruction losses: 0.02532603182483692, regression losses: 0.13743657096177442, validation losses: 0.7034228777963709\n",
      "Epoch 6269, reconstruction losses: 0.02584082362768962, regression losses: 0.1342399598158675, validation losses: 0.5532717874304418\n",
      "Epoch 6270, reconstruction losses: 0.02874623679675782, regression losses: 0.3264766098488171, validation losses: 0.43695561307855446\n",
      "Epoch 6271, reconstruction losses: 0.029538475727649775, regression losses: 0.20325229322239788, validation losses: 0.9435954906799742\n",
      "Epoch 6272, reconstruction losses: 0.027340858085267754, regression losses: 0.22337519896095387, validation losses: 0.6749370813549447\n",
      "Epoch 6273, reconstruction losses: 0.026186483309800033, regression losses: 0.11295279397449727, validation losses: 0.5816094475086937\n",
      "Epoch 6274, reconstruction losses: 0.0252851757197364, regression losses: 0.26334513067025395, validation losses: 0.751844186858405\n",
      "Epoch 6275, reconstruction losses: 0.02420288561238653, regression losses: 0.15657803732871944, validation losses: 0.9788800445181062\n",
      "Epoch 6276, reconstruction losses: 0.026099277418445282, regression losses: 0.15363841520550714, validation losses: 0.723018617658304\n",
      "Epoch 6277, reconstruction losses: 0.027084663104370015, regression losses: 0.11741212964630933, validation losses: 0.6453576115277402\n",
      "Epoch 6278, reconstruction losses: 0.02648132365447082, regression losses: 0.10716805900126765, validation losses: 0.5518576183140873\n",
      "Epoch 6279, reconstruction losses: 0.027982129584321804, regression losses: 0.12838674329280364, validation losses: 0.5443413473934895\n",
      "Epoch 6280, reconstruction losses: 0.023373112026206233, regression losses: 0.13512447435588218, validation losses: 0.5976594694120195\n",
      "Epoch 6281, reconstruction losses: 0.02566879199333791, regression losses: 0.13695489686998863, validation losses: 0.4733936336592449\n",
      "Epoch 6282, reconstruction losses: 0.02317495395848867, regression losses: 0.11094818018722351, validation losses: 0.4350066961496928\n",
      "Epoch 6283, reconstruction losses: 0.029280816324912085, regression losses: 0.20152033196524996, validation losses: 0.4455671453365726\n",
      "Epoch 6284, reconstruction losses: 0.02543947012626463, regression losses: 0.12173068983796666, validation losses: 0.7312889201455642\n",
      "Epoch 6285, reconstruction losses: 0.026789437501808826, regression losses: 0.1090438544312686, validation losses: 0.8105003951982823\n",
      "Epoch 6286, reconstruction losses: 0.02619091416501997, regression losses: 0.11675076666082942, validation losses: 0.5636641716171366\n",
      "Epoch 6287, reconstruction losses: 0.028160540189614332, regression losses: 0.14275820485516671, validation losses: 0.4581757852827873\n",
      "Epoch 6288, reconstruction losses: 0.028214950364281614, regression losses: 0.13163024119384825, validation losses: 0.4697501401710149\n",
      "Epoch 6289, reconstruction losses: 0.022931501888783963, regression losses: 0.1214391013959285, validation losses: 0.4790417288727882\n",
      "Epoch 6290, reconstruction losses: 0.023414452742221845, regression losses: 0.08224883135648182, validation losses: 0.5550787403596058\n",
      "Epoch 6291, reconstruction losses: 0.02294102084818454, regression losses: 0.1126661185355847, validation losses: 0.6724641062018839\n",
      "Epoch 6292, reconstruction losses: 0.028539431498832684, regression losses: 0.3468767517219692, validation losses: 0.6032855909335783\n",
      "Epoch 6293, reconstruction losses: 0.02611098882004018, regression losses: 0.18578158246972473, validation losses: 0.6511727109382155\n",
      "Epoch 6294, reconstruction losses: 0.024367322310491053, regression losses: 0.12639793148888637, validation losses: 0.531402684346411\n",
      "Epoch 6295, reconstruction losses: 0.02585219877134703, regression losses: 0.1061183354983758, validation losses: 0.4857942828100232\n",
      "Epoch 6296, reconstruction losses: 0.02544942403031675, regression losses: 0.09299918221670767, validation losses: 0.45410051174600197\n",
      "Epoch 6297, reconstruction losses: 0.026281936530997335, regression losses: 0.11986585378094815, validation losses: 0.42716751828536154\n",
      "Epoch 6298, reconstruction losses: 0.026930156983442227, regression losses: 0.15032544291531985, validation losses: 0.46298392434527935\n",
      "Epoch 6299, reconstruction losses: 0.02477202665684147, regression losses: 0.09923936844201614, validation losses: 0.4684586306300516\n",
      "Epoch 6300, reconstruction losses: 0.024298688512563907, regression losses: 0.11054491182075268, validation losses: 0.4514227261705479\n",
      "Epoch 6301, reconstruction losses: 0.026985979695933547, regression losses: 0.11556472929695275, validation losses: 0.46561338964534016\n",
      "Epoch 6302, reconstruction losses: 0.027144700938371638, regression losses: 0.1520845167651933, validation losses: 0.4599323969999812\n",
      "Epoch 6303, reconstruction losses: 0.024438244205888374, regression losses: 0.0915702363766215, validation losses: 0.48776149659307705\n",
      "Epoch 6304, reconstruction losses: 0.026622350078882726, regression losses: 0.11028714837628087, validation losses: 0.4634245125876188\n",
      "Epoch 6305, reconstruction losses: 0.027439425361469885, regression losses: 0.0977431827848397, validation losses: 0.43353772431508175\n",
      "Epoch 6306, reconstruction losses: 0.02889773403856745, regression losses: 0.1360510684314549, validation losses: 0.4637125472309498\n",
      "Epoch 6307, reconstruction losses: 0.02675524755859461, regression losses: 0.365173806773858, validation losses: 0.5750611529118661\n",
      "Epoch 6308, reconstruction losses: 0.025025084736367074, regression losses: 0.1473556276346448, validation losses: 0.7097412251654075\n",
      "Epoch 6309, reconstruction losses: 0.025622370813713928, regression losses: 0.1476335829401699, validation losses: 0.69130084296389\n",
      "Epoch 6310, reconstruction losses: 0.027004587810567787, regression losses: 0.1280916931006954, validation losses: 0.6720026505510667\n",
      "Epoch 6311, reconstruction losses: 0.026062775917051483, regression losses: 0.1462180657874377, validation losses: 0.5560714132802791\n",
      "Epoch 6312, reconstruction losses: 0.02586894966511324, regression losses: 0.12484290107338142, validation losses: 0.5545205496955276\n",
      "Epoch 6313, reconstruction losses: 0.024762811645895666, regression losses: 0.10588297150565903, validation losses: 0.4948327996075481\n",
      "Epoch 6314, reconstruction losses: 0.02857782008466404, regression losses: 0.09171086975476908, validation losses: 0.4765609090736152\n",
      "Epoch 6315, reconstruction losses: 0.024602769847615537, regression losses: 0.1501637549978407, validation losses: 0.48069854918384425\n",
      "Epoch 6316, reconstruction losses: 0.02311826122930432, regression losses: 0.1634184762263019, validation losses: 0.522510427995202\n",
      "Epoch 6317, reconstruction losses: 0.025668777623229316, regression losses: 0.13272700644562574, validation losses: 0.5216172387413748\n",
      "Epoch 6318, reconstruction losses: 0.025505968053975307, regression losses: 0.08871953027961256, validation losses: 0.5039531110964433\n",
      "Epoch 6319, reconstruction losses: 0.022112616616129455, regression losses: 0.17227028763861657, validation losses: 0.4405582532453351\n",
      "Epoch 6320, reconstruction losses: 0.023498603179757962, regression losses: 0.0870474355244884, validation losses: 0.42604325081444233\n",
      "Epoch 6321, reconstruction losses: 0.024239798312668846, regression losses: 0.10287852354957637, validation losses: 0.4148623183474624\n",
      "Epoch 6322, reconstruction losses: 0.02381398480997754, regression losses: 0.10142575074384426, validation losses: 0.42882071358564394\n",
      "Epoch 6323, reconstruction losses: 0.024439390395982204, regression losses: 0.12625434075055786, validation losses: 0.5008027084562582\n",
      "Epoch 6324, reconstruction losses: 0.022908717815191472, regression losses: 0.11571839070780351, validation losses: 0.45353168224915663\n",
      "Epoch 6325, reconstruction losses: 0.02617762593703106, regression losses: 0.14269816844197225, validation losses: 0.4150552698871476\n",
      "Epoch 6326, reconstruction losses: 0.027800153430236247, regression losses: 0.12758333374715625, validation losses: 0.4370774645271367\n",
      "Epoch 6327, reconstruction losses: 0.026338627579271023, regression losses: 0.10608307470805053, validation losses: 0.4203381574412081\n",
      "Epoch 6328, reconstruction losses: 0.025076384490715652, regression losses: 0.13199010413697973, validation losses: 0.4235961108191461\n",
      "Epoch 6329, reconstruction losses: 0.023566596495872207, regression losses: 0.10923070582866846, validation losses: 0.4724645229929866\n",
      "Epoch 6330, reconstruction losses: 0.026874273976372907, regression losses: 0.19963233960537127, validation losses: 0.5321113912951476\n",
      "Epoch 6331, reconstruction losses: 0.024245775961919614, regression losses: 0.14352909616632115, validation losses: 0.5663699950346243\n",
      "Epoch 6332, reconstruction losses: 0.024659545435859978, regression losses: 0.13822315261363127, validation losses: 0.5262121868758824\n",
      "Epoch 6333, reconstruction losses: 0.024413505515331602, regression losses: 0.15036696034921151, validation losses: 0.6884427699833205\n",
      "Epoch 6334, reconstruction losses: 0.025308860652922233, regression losses: 0.14605360394327063, validation losses: 0.5486328134937212\n",
      "Epoch 6335, reconstruction losses: 0.025196018004808845, regression losses: 0.10978105048074738, validation losses: 0.43644812103974506\n",
      "Epoch 6336, reconstruction losses: 0.026892186192722746, regression losses: 0.2932702682895486, validation losses: 0.42162940260889614\n",
      "Epoch 6337, reconstruction losses: 0.025404898289123973, regression losses: 0.13599123462358426, validation losses: 0.5909978492803993\n",
      "Epoch 6338, reconstruction losses: 0.026014059388085386, regression losses: 0.146839827700709, validation losses: 0.5460796480738664\n",
      "Epoch 6339, reconstruction losses: 0.02966018863822635, regression losses: 0.1747713132471404, validation losses: 0.4681957923379703\n",
      "Epoch 6340, reconstruction losses: 0.020742390411747424, regression losses: 0.11252850541374915, validation losses: 0.5309131436134551\n",
      "Epoch 6341, reconstruction losses: 0.02559688378928174, regression losses: 0.09023484818276185, validation losses: 0.4932206092170468\n",
      "Epoch 6342, reconstruction losses: 0.02643876622071698, regression losses: 0.1636873834546136, validation losses: 0.5254653710415995\n",
      "Epoch 6343, reconstruction losses: 0.024431141369684856, regression losses: 0.13656999788821703, validation losses: 0.6288542454011973\n",
      "Epoch 6344, reconstruction losses: 0.026185728389018306, regression losses: 0.1294168046574126, validation losses: 0.5596620146095304\n",
      "Epoch 6345, reconstruction losses: 0.025709550461837614, regression losses: 0.13695687155995018, validation losses: 0.4875539446371607\n",
      "Epoch 6346, reconstruction losses: 0.02595638196061026, regression losses: 0.12397211115624876, validation losses: 0.4986251281494183\n",
      "Epoch 6347, reconstruction losses: 0.026746995243850748, regression losses: 0.1997067651466518, validation losses: 0.5167043867994076\n",
      "Epoch 6348, reconstruction losses: 0.027063972319433277, regression losses: 0.15692316292630165, validation losses: 0.6983111207484874\n",
      "Epoch 6349, reconstruction losses: 0.027329344927996723, regression losses: 0.16846836556136374, validation losses: 0.5084009587816137\n",
      "Epoch 6350, reconstruction losses: 0.026325616082694743, regression losses: 0.11833358013008773, validation losses: 0.4442647657917746\n",
      "Epoch 6351, reconstruction losses: 0.02568122963506152, regression losses: 0.11436478658421173, validation losses: 0.4911641180614585\n",
      "Epoch 6352, reconstruction losses: 0.02429484005246574, regression losses: 0.11154567297305859, validation losses: 0.47618921077214377\n",
      "Epoch 6353, reconstruction losses: 0.0250164931818053, regression losses: 0.12509679637822393, validation losses: 0.4753861441559989\n",
      "Epoch 6354, reconstruction losses: 0.027988144656926922, regression losses: 0.12878664009802154, validation losses: 0.49158560720053884\n",
      "Epoch 6355, reconstruction losses: 0.022896561861615147, regression losses: 0.1202405440369936, validation losses: 0.45686253038813984\n",
      "Epoch 6356, reconstruction losses: 0.026384065028573864, regression losses: 0.11097447426159154, validation losses: 0.4921944782487608\n",
      "Epoch 6357, reconstruction losses: 0.025405123391030564, regression losses: 0.10216960750821129, validation losses: 0.4712062167150794\n",
      "Epoch 6358, reconstruction losses: 0.029025452079772654, regression losses: 0.164021930047915, validation losses: 0.5074554083041826\n",
      "Epoch 6359, reconstruction losses: 0.02383134153224115, regression losses: 0.11950458264518013, validation losses: 0.6563125445426766\n",
      "Epoch 6360, reconstruction losses: 0.025457782172958295, regression losses: 0.11225709924757905, validation losses: 0.5543731537566897\n",
      "Epoch 6361, reconstruction losses: 0.023850416557711186, regression losses: 0.1096191927933346, validation losses: 0.5316527539500883\n",
      "Epoch 6362, reconstruction losses: 0.025103620237445244, regression losses: 0.13405984202162133, validation losses: 0.5417724200380429\n",
      "Epoch 6363, reconstruction losses: 0.023615318168846225, regression losses: 0.14819218711116677, validation losses: 0.5099854614958538\n",
      "Epoch 6364, reconstruction losses: 0.02610876557677335, regression losses: 0.11598396021389414, validation losses: 0.454494736841726\n",
      "Epoch 6365, reconstruction losses: 0.02678168186692694, regression losses: 0.14817241905254572, validation losses: 0.46592263855351357\n",
      "Epoch 6366, reconstruction losses: 0.02645075611297322, regression losses: 0.13847061621398996, validation losses: 0.4378074279750983\n",
      "Epoch 6367, reconstruction losses: 0.024038408983622996, regression losses: 0.11905947974857474, validation losses: 0.42532831227418894\n",
      "Epoch 6368, reconstruction losses: 0.022922148325868273, regression losses: 0.09519487340400085, validation losses: 0.4752078924935784\n",
      "Epoch 6369, reconstruction losses: 0.02649709667559766, regression losses: 0.13162542519465764, validation losses: 0.5027878362449696\n",
      "Epoch 6370, reconstruction losses: 0.02536234825034678, regression losses: 0.1083597461258459, validation losses: 0.4514558221956223\n",
      "Epoch 6371, reconstruction losses: 0.023642784094964644, regression losses: 0.11230720160718664, validation losses: 0.4198591890370784\n",
      "Epoch 6372, reconstruction losses: 0.023625386594627342, regression losses: 0.11055055555398481, validation losses: 0.4398706219466136\n",
      "Epoch 6373, reconstruction losses: 0.02374675093454367, regression losses: 0.11414789731795887, validation losses: 0.43769360154208586\n",
      "Epoch 6374, reconstruction losses: 0.03279554783690328, regression losses: 0.1770243277469215, validation losses: 0.4361290587016813\n",
      "Epoch 6375, reconstruction losses: 0.02420943832060665, regression losses: 0.08560867243667565, validation losses: 0.49101151753023164\n",
      "Epoch 6376, reconstruction losses: 0.030056019609814723, regression losses: 0.19519550392308893, validation losses: 0.4802228484475182\n",
      "Epoch 6377, reconstruction losses: 0.024657173809674558, regression losses: 0.13329007532209505, validation losses: 0.5787748215118962\n",
      "Epoch 6378, reconstruction losses: 0.02543102495292283, regression losses: 0.11925261522422709, validation losses: 0.6320620002995984\n",
      "Epoch 6379, reconstruction losses: 0.02869840396748168, regression losses: 0.16998781720172534, validation losses: 0.5276380582262864\n",
      "Epoch 6380, reconstruction losses: 0.02752036807221944, regression losses: 0.10360623398017738, validation losses: 0.5695119786603217\n",
      "Epoch 6381, reconstruction losses: 0.027639257240427515, regression losses: 0.11626914032465031, validation losses: 0.4962562580739166\n",
      "Epoch 6382, reconstruction losses: 0.025869918627590804, regression losses: 0.10983444250735125, validation losses: 0.644936150094476\n",
      "Epoch 6383, reconstruction losses: 0.022769371615336535, regression losses: 0.11429186277786264, validation losses: 0.6781443364749238\n",
      "Epoch 6384, reconstruction losses: 0.02479846259748794, regression losses: 0.10913197067061767, validation losses: 0.5549609114725913\n",
      "Epoch 6385, reconstruction losses: 0.024470482336337213, regression losses: 0.10918208135831772, validation losses: 0.46581956575229744\n",
      "Epoch 6386, reconstruction losses: 0.023075858011237342, regression losses: 0.10518961483686053, validation losses: 0.47036730979728225\n",
      "Epoch 6387, reconstruction losses: 0.0273139799051881, regression losses: 0.23846947915684663, validation losses: 0.4604409668319429\n",
      "Epoch 6388, reconstruction losses: 0.02677341536193991, regression losses: 0.13586435235191513, validation losses: 0.6028837738628054\n",
      "Epoch 6389, reconstruction losses: 0.030318721816256132, regression losses: 0.19801933347492512, validation losses: 0.47447587651687234\n",
      "Epoch 6390, reconstruction losses: 0.026762748940523853, regression losses: 0.12528476899205607, validation losses: 0.5324120142438838\n",
      "Epoch 6391, reconstruction losses: 0.02774236330631315, regression losses: 0.09842529043169143, validation losses: 0.5808284010707079\n",
      "Epoch 6392, reconstruction losses: 0.025581015722226704, regression losses: 0.13613597097149419, validation losses: 0.578352171339493\n",
      "Epoch 6393, reconstruction losses: 0.024737764150355425, regression losses: 0.09200366888210788, validation losses: 0.5720408268413568\n",
      "Epoch 6394, reconstruction losses: 0.0257459689471867, regression losses: 0.09483311699393461, validation losses: 0.5549231418207258\n",
      "Epoch 6395, reconstruction losses: 0.026262935665418048, regression losses: 0.15375655729490606, validation losses: 0.49167171512048835\n",
      "Epoch 6396, reconstruction losses: 0.024882342406379605, regression losses: 0.11233328747348223, validation losses: 0.5199181928704176\n",
      "Epoch 6397, reconstruction losses: 0.023696284009186407, regression losses: 0.11076503941658494, validation losses: 0.49155412786115843\n",
      "Epoch 6398, reconstruction losses: 0.024903039914365765, regression losses: 0.12180140042672262, validation losses: 0.5537357065860422\n",
      "Epoch 6399, reconstruction losses: 0.023738889536517097, regression losses: 0.09816862675842117, validation losses: 0.5673565239035792\n",
      "Epoch 6400, reconstruction losses: 0.02613127218449742, regression losses: 0.10272032310410358, validation losses: 0.4975816812644671\n",
      "Epoch 6401, reconstruction losses: 0.024191367690124883, regression losses: 0.11922787975817817, validation losses: 0.5002646368138172\n",
      "Epoch 6402, reconstruction losses: 0.023250562631935236, regression losses: 0.13381761977862663, validation losses: 0.47017337131231457\n",
      "Epoch 6403, reconstruction losses: 0.026872931024123546, regression losses: 0.1433216509650242, validation losses: 0.49633111247386313\n",
      "Epoch 6404, reconstruction losses: 0.023702612601864993, regression losses: 0.14001080933776214, validation losses: 0.5201974529896132\n",
      "Epoch 6405, reconstruction losses: 0.022802582594517066, regression losses: 0.09855904062910704, validation losses: 0.465956317491392\n",
      "Epoch 6406, reconstruction losses: 0.024097105288845323, regression losses: 0.09116023179824041, validation losses: 0.45660672313770057\n",
      "Epoch 6407, reconstruction losses: 0.023771642231689073, regression losses: 0.13735160446020278, validation losses: 0.45738143364496503\n",
      "Epoch 6408, reconstruction losses: 0.028001268494955427, regression losses: 0.16362181041306867, validation losses: 0.4093691069205173\n",
      "Epoch 6409, reconstruction losses: 0.023737593936152823, regression losses: 0.12382906968559115, validation losses: 0.4255142658476514\n",
      "Epoch 6410, reconstruction losses: 0.02382706656259156, regression losses: 0.10991596708404307, validation losses: 0.42434090096677624\n",
      "Epoch 6411, reconstruction losses: 0.023256238622244085, regression losses: 0.1526256747476194, validation losses: 0.49764883208911775\n",
      "Epoch 6412, reconstruction losses: 0.02602904915896387, regression losses: 0.11882059090929725, validation losses: 0.5334626250518865\n",
      "Epoch 6413, reconstruction losses: 0.02498984835525396, regression losses: 0.12996159963904627, validation losses: 0.4775698872066403\n",
      "Epoch 6414, reconstruction losses: 0.025268636260179566, regression losses: 0.09804251506497907, validation losses: 0.40927834741833885\n",
      "Epoch 6415, reconstruction losses: 0.027020470797739865, regression losses: 0.13865646289999592, validation losses: 0.41307951501447\n",
      "Epoch 6416, reconstruction losses: 0.02730424054512241, regression losses: 0.15833235181410937, validation losses: 0.4778307103727929\n",
      "Epoch 6417, reconstruction losses: 0.02443623046668463, regression losses: 0.149323871833919, validation losses: 0.5598539450893505\n",
      "Epoch 6418, reconstruction losses: 0.026642533591943428, regression losses: 0.1885983935238401, validation losses: 0.5370497157789005\n",
      "Epoch 6419, reconstruction losses: 0.02576246013829587, regression losses: 0.11491569327293766, validation losses: 0.4776399199005727\n",
      "Epoch 6420, reconstruction losses: 0.026213324339183584, regression losses: 0.11693558866928275, validation losses: 0.4339036645913644\n",
      "Epoch 6421, reconstruction losses: 0.025309851536679112, regression losses: 0.10669454107400521, validation losses: 0.42565369675110676\n",
      "Epoch 6422, reconstruction losses: 0.028200286851407852, regression losses: 0.13452237958416535, validation losses: 0.4275061887319067\n",
      "Epoch 6423, reconstruction losses: 0.022985210970059886, regression losses: 0.13882075064334756, validation losses: 0.4528281329926468\n",
      "Epoch 6424, reconstruction losses: 0.024235990395112067, regression losses: 0.10112509027291929, validation losses: 0.5551029449435416\n",
      "Epoch 6425, reconstruction losses: 0.024626495580247397, regression losses: 0.0965758119847267, validation losses: 0.5700713596007125\n",
      "Epoch 6426, reconstruction losses: 0.0285897143308957, regression losses: 0.3977749218030505, validation losses: 0.5292316498479984\n",
      "Epoch 6427, reconstruction losses: 0.023688184886239645, regression losses: 0.14388292592975063, validation losses: 0.6725108242869741\n",
      "Epoch 6428, reconstruction losses: 0.023331614450374905, regression losses: 0.10920510030300087, validation losses: 0.5402844645645154\n",
      "Epoch 6429, reconstruction losses: 0.021754806474708198, regression losses: 0.10124501744802834, validation losses: 0.5879584347362796\n",
      "Epoch 6430, reconstruction losses: 0.026086068188739108, regression losses: 0.40235726493075186, validation losses: 0.5166860916216486\n",
      "Epoch 6431, reconstruction losses: 0.027841989492640325, regression losses: 0.11138388225184735, validation losses: 0.6321666066267256\n",
      "Epoch 6432, reconstruction losses: 0.025600600692530614, regression losses: 0.3001766850816882, validation losses: 0.7064117339256525\n",
      "Epoch 6433, reconstruction losses: 0.029429168979819856, regression losses: 0.14692649859783397, validation losses: 0.7511493315314864\n",
      "Epoch 6434, reconstruction losses: 0.025352700428201817, regression losses: 0.15137504606358532, validation losses: 0.6991394106853819\n",
      "Epoch 6435, reconstruction losses: 0.026160109365454112, regression losses: 0.09884404359171704, validation losses: 0.8199676808364342\n",
      "Epoch 6436, reconstruction losses: 0.02804412907328452, regression losses: 0.12756448129474615, validation losses: 0.6318609914681704\n",
      "Epoch 6437, reconstruction losses: 0.023824130311740604, regression losses: 0.09420026983173627, validation losses: 0.5485711713223747\n",
      "Epoch 6438, reconstruction losses: 0.0257500341369488, regression losses: 0.10415938597443992, validation losses: 0.5556491609001283\n",
      "Epoch 6439, reconstruction losses: 0.02366238587274379, regression losses: 0.13865469439709172, validation losses: 0.6208382342693587\n",
      "Epoch 6440, reconstruction losses: 0.02379210725179567, regression losses: 0.11901814234132121, validation losses: 0.5437242938013511\n",
      "Epoch 6441, reconstruction losses: 0.024907861316269042, regression losses: 0.12229963978225956, validation losses: 0.5121822822934998\n",
      "Epoch 6442, reconstruction losses: 0.024855147953049928, regression losses: 0.1417909327643366, validation losses: 0.5050066125437938\n",
      "Epoch 6443, reconstruction losses: 0.027360198184420963, regression losses: 0.12093878680175668, validation losses: 0.5228589796730111\n",
      "Epoch 6444, reconstruction losses: 0.02402146550649801, regression losses: 0.12125254457770927, validation losses: 0.4924120046594333\n",
      "Epoch 6445, reconstruction losses: 0.02389603686141111, regression losses: 0.09468898941133769, validation losses: 0.4862967836818242\n",
      "Epoch 6446, reconstruction losses: 0.02660348832429075, regression losses: 0.10432566461326893, validation losses: 0.48470308690842767\n",
      "Epoch 6447, reconstruction losses: 0.026902942138387755, regression losses: 0.16364979457350126, validation losses: 0.4516382316098375\n",
      "Epoch 6448, reconstruction losses: 0.023467890939586438, regression losses: 0.11242231915439184, validation losses: 0.54210685646028\n",
      "Epoch 6449, reconstruction losses: 0.024808070171427804, regression losses: 0.1268685589395533, validation losses: 0.5362244112292056\n",
      "Epoch 6450, reconstruction losses: 0.025119107314540406, regression losses: 0.10444851890023737, validation losses: 0.6292071085027574\n",
      "Epoch 6451, reconstruction losses: 0.025084456012242178, regression losses: 0.13375427767015452, validation losses: 0.6218973746857234\n",
      "Epoch 6452, reconstruction losses: 0.02373353565698416, regression losses: 0.12321595419293478, validation losses: 0.4967279778137579\n",
      "Epoch 6453, reconstruction losses: 0.024553474910639035, regression losses: 0.11810639223838268, validation losses: 0.45468299077445795\n",
      "Epoch 6454, reconstruction losses: 0.02755691310250121, regression losses: 0.10714612537473193, validation losses: 0.43393547681621836\n",
      "Epoch 6455, reconstruction losses: 0.024637397900396863, regression losses: 0.142620087404579, validation losses: 0.45407579372741796\n",
      "Epoch 6456, reconstruction losses: 0.02240753490495313, regression losses: 0.09831645766467527, validation losses: 0.6544749811310965\n",
      "Epoch 6457, reconstruction losses: 0.024699946055560376, regression losses: 0.11605579508387606, validation losses: 0.6000434759372043\n",
      "Epoch 6458, reconstruction losses: 0.024497066603699196, regression losses: 0.10913877238193967, validation losses: 0.5117652699975869\n",
      "Epoch 6459, reconstruction losses: 0.025092630322232152, regression losses: 0.11770092983120883, validation losses: 0.4686022801960478\n",
      "Epoch 6460, reconstruction losses: 0.02607165750977258, regression losses: 0.08948898425447925, validation losses: 0.47477906107281553\n",
      "Epoch 6461, reconstruction losses: 0.025571851041978746, regression losses: 0.1934852789419209, validation losses: 0.530744887099303\n",
      "Epoch 6462, reconstruction losses: 0.02353798693537488, regression losses: 0.10204938889374777, validation losses: 0.664651016857462\n",
      "Epoch 6463, reconstruction losses: 0.025825513041528688, regression losses: 0.23916375715729105, validation losses: 0.5708336721581821\n",
      "Epoch 6464, reconstruction losses: 0.02599424161061428, regression losses: 0.12036373053723803, validation losses: 0.5423228488763667\n",
      "Epoch 6465, reconstruction losses: 0.02410102656308933, regression losses: 0.11755308268338871, validation losses: 0.5290313012178111\n",
      "Epoch 6466, reconstruction losses: 0.023589825906913484, regression losses: 0.10939220127037101, validation losses: 0.43632348411704275\n",
      "Epoch 6467, reconstruction losses: 0.025805635001619177, regression losses: 0.10405730710049531, validation losses: 0.5170889452495404\n",
      "Epoch 6468, reconstruction losses: 0.022726762200815445, regression losses: 0.14299331793845865, validation losses: 0.5535062256769406\n",
      "Epoch 6469, reconstruction losses: 0.02412199373744657, regression losses: 0.11782255371529576, validation losses: 0.48690000245936926\n",
      "Epoch 6470, reconstruction losses: 0.02577374677101011, regression losses: 0.14816051020513185, validation losses: 0.5126453350459947\n",
      "Epoch 6471, reconstruction losses: 0.02301766472086683, regression losses: 0.09173383456250464, validation losses: 0.5553006585187502\n",
      "Epoch 6472, reconstruction losses: 0.025026146752364996, regression losses: 0.12008037574854359, validation losses: 0.49347259522534637\n",
      "Epoch 6473, reconstruction losses: 0.023592359511585552, regression losses: 0.12178857956833641, validation losses: 0.4312354896483699\n",
      "Epoch 6474, reconstruction losses: 0.026409246813177245, regression losses: 0.131815298968473, validation losses: 0.42958951614219887\n",
      "Epoch 6475, reconstruction losses: 0.027009667314209593, regression losses: 0.24038319330817892, validation losses: 0.5556348646617936\n",
      "Epoch 6476, reconstruction losses: 0.02573916593999294, regression losses: 0.14011125055889334, validation losses: 0.7927580914859652\n",
      "Epoch 6477, reconstruction losses: 0.024812393881671065, regression losses: 0.1488361403538922, validation losses: 0.6886674865667572\n",
      "Epoch 6478, reconstruction losses: 0.022637456009615812, regression losses: 0.11561810984659437, validation losses: 0.5272393680381665\n",
      "Epoch 6479, reconstruction losses: 0.027260667014871755, regression losses: 0.1295467109019531, validation losses: 0.47788412285986126\n",
      "Epoch 6480, reconstruction losses: 0.0252048728093221, regression losses: 0.18117322550829082, validation losses: 0.4598093743632781\n",
      "Epoch 6481, reconstruction losses: 0.023267747973134682, regression losses: 0.11541350695304992, validation losses: 0.5178620667599477\n",
      "Epoch 6482, reconstruction losses: 0.024248244290405428, regression losses: 0.10619945751052078, validation losses: 0.5502837349430328\n",
      "Epoch 6483, reconstruction losses: 0.02098003376493304, regression losses: 0.12732591407166224, validation losses: 0.5696833951100514\n",
      "Epoch 6484, reconstruction losses: 0.02442193044401228, regression losses: 0.11132566818144582, validation losses: 0.550939477610518\n",
      "Epoch 6485, reconstruction losses: 0.02470312391443377, regression losses: 0.14595831483626573, validation losses: 0.587451699680777\n",
      "Epoch 6486, reconstruction losses: 0.024202359211218185, regression losses: 0.13277489962997857, validation losses: 0.5979555793482434\n",
      "Epoch 6487, reconstruction losses: 0.026934720718804067, regression losses: 0.16524608277958172, validation losses: 0.4665668028884527\n",
      "Epoch 6488, reconstruction losses: 0.024325165817913514, regression losses: 0.10760475106957294, validation losses: 0.4250082097725544\n",
      "Epoch 6489, reconstruction losses: 0.02692755702167109, regression losses: 0.12151976369701163, validation losses: 0.4147425257887281\n",
      "Epoch 6490, reconstruction losses: 0.026928093885991156, regression losses: 0.11584571059511037, validation losses: 0.4630287978538614\n",
      "Epoch 6491, reconstruction losses: 0.024551175602482784, regression losses: 0.1169990839033196, validation losses: 0.456237834636649\n",
      "Epoch 6492, reconstruction losses: 0.025440410125464406, regression losses: 0.09984539746521576, validation losses: 0.4593805846662531\n",
      "Epoch 6493, reconstruction losses: 0.026106928875879763, regression losses: 0.12145849313099279, validation losses: 0.433245530577619\n",
      "Epoch 6494, reconstruction losses: 0.024750873885015203, regression losses: 0.12452189079684785, validation losses: 0.42192773220347407\n",
      "Epoch 6495, reconstruction losses: 0.026931181907636523, regression losses: 0.11021393098966634, validation losses: 0.47842033419013785\n",
      "Epoch 6496, reconstruction losses: 0.023508182519491255, regression losses: 0.10869946666388816, validation losses: 0.4612415947741499\n",
      "Epoch 6497, reconstruction losses: 0.023099206748933555, regression losses: 0.12234901407493982, validation losses: 0.44577137272007655\n",
      "Epoch 6498, reconstruction losses: 0.022700784911923125, regression losses: 0.10763033961992782, validation losses: 0.43346882638229184\n",
      "Epoch 6499, reconstruction losses: 0.026230238514166566, regression losses: 0.23734676857442077, validation losses: 0.4721914521417559\n",
      "Epoch 6500, reconstruction losses: 0.022910740399845055, regression losses: 0.11901348486869952, validation losses: 0.6272216364825538\n",
      "Epoch 6501, reconstruction losses: 0.025733124958052155, regression losses: 0.10921074853505289, validation losses: 0.5734392785686708\n",
      "Epoch 6502, reconstruction losses: 0.024416163774563557, regression losses: 0.13195752631767757, validation losses: 0.4625590668508999\n",
      "Epoch 6503, reconstruction losses: 0.02951778882229016, regression losses: 0.13099730664357606, validation losses: 0.4472438130510987\n",
      "Epoch 6504, reconstruction losses: 0.02520384030533942, regression losses: 0.11923012333751823, validation losses: 0.45010820310084954\n",
      "Epoch 6505, reconstruction losses: 0.02561885960557374, regression losses: 0.15056924270051136, validation losses: 0.4205341135409214\n",
      "Epoch 6506, reconstruction losses: 0.02314335455133997, regression losses: 0.08924858661883166, validation losses: 0.4510506645831975\n",
      "Epoch 6507, reconstruction losses: 0.02729070278998906, regression losses: 0.14891206068911422, validation losses: 0.5386296270991501\n",
      "Epoch 6508, reconstruction losses: 0.023158405713008787, regression losses: 0.10800028300511995, validation losses: 0.5732605116510004\n",
      "Epoch 6509, reconstruction losses: 0.02531532999763388, regression losses: 0.12830338356492474, validation losses: 0.5810037701046795\n",
      "Epoch 6510, reconstruction losses: 0.022518487896400194, regression losses: 0.14309800835801872, validation losses: 0.4760845946759799\n",
      "Epoch 6511, reconstruction losses: 0.024968058161613883, regression losses: 0.13105707043556983, validation losses: 0.41931229623119953\n",
      "Epoch 6512, reconstruction losses: 0.029018568725528507, regression losses: 0.23235719398525695, validation losses: 0.4955839840939386\n",
      "Epoch 6513, reconstruction losses: 0.02514371759109907, regression losses: 0.10164029692189183, validation losses: 0.7675912238195695\n",
      "Epoch 6514, reconstruction losses: 0.023530728765383854, regression losses: 0.1212851868283871, validation losses: 0.5608486283576424\n",
      "Epoch 6515, reconstruction losses: 0.02376491060816943, regression losses: 0.18081455254920642, validation losses: 0.4374406353648914\n",
      "Epoch 6516, reconstruction losses: 0.02323796559786599, regression losses: 0.10939079123344796, validation losses: 0.4167871506248574\n",
      "Epoch 6517, reconstruction losses: 0.022352601591788306, regression losses: 0.09676671331176893, validation losses: 0.41529409276900137\n",
      "Epoch 6518, reconstruction losses: 0.023350600795673186, regression losses: 0.09768380413537926, validation losses: 0.4928430836966921\n",
      "Epoch 6519, reconstruction losses: 0.024999539207666746, regression losses: 0.1079238037924723, validation losses: 0.49516342040924044\n",
      "Epoch 6520, reconstruction losses: 0.025330868238589516, regression losses: 0.09372956848435948, validation losses: 0.43660983746257725\n",
      "Epoch 6521, reconstruction losses: 0.025916846323945388, regression losses: 0.09577774851270518, validation losses: 0.4300585093865862\n",
      "Epoch 6522, reconstruction losses: 0.024055981518902324, regression losses: 0.11318467836009813, validation losses: 0.44280912622548807\n",
      "Epoch 6523, reconstruction losses: 0.021569027541986415, regression losses: 0.1036567614985817, validation losses: 0.5275422418793136\n",
      "Epoch 6524, reconstruction losses: 0.023483821147066916, regression losses: 0.1413879678855243, validation losses: 0.49084042336977596\n",
      "Epoch 6525, reconstruction losses: 0.026535362558885847, regression losses: 0.12361857534673958, validation losses: 0.4426820411584105\n",
      "Epoch 6526, reconstruction losses: 0.025569736590818525, regression losses: 0.12528025257009895, validation losses: 0.46239640562727213\n",
      "Epoch 6527, reconstruction losses: 0.022678093281741973, regression losses: 0.11585150788840794, validation losses: 0.4882341564702077\n",
      "Epoch 6528, reconstruction losses: 0.027194105529594097, regression losses: 0.13867142536871518, validation losses: 0.46422290046286413\n",
      "Epoch 6529, reconstruction losses: 0.025779828929908048, regression losses: 0.1477468367678103, validation losses: 0.6137617353537684\n",
      "Epoch 6530, reconstruction losses: 0.026335504094964282, regression losses: 0.15196514875495798, validation losses: 0.5342129853120254\n",
      "Epoch 6531, reconstruction losses: 0.027947412933616446, regression losses: 0.13523565121997388, validation losses: 0.45475431169765607\n",
      "Epoch 6532, reconstruction losses: 0.023662898226458742, regression losses: 0.11658716216732046, validation losses: 0.4950331721431906\n",
      "Epoch 6533, reconstruction losses: 0.02469895436141644, regression losses: 0.13221914773762555, validation losses: 0.5291144308622324\n",
      "Epoch 6534, reconstruction losses: 0.02241753789779567, regression losses: 0.13331998632567169, validation losses: 0.5567396744468721\n",
      "Epoch 6535, reconstruction losses: 0.02390140040367557, regression losses: 0.1342260920461028, validation losses: 0.4668965621324437\n",
      "Epoch 6536, reconstruction losses: 0.02789696367614942, regression losses: 0.17422881581810423, validation losses: 0.44411409507858024\n",
      "Epoch 6537, reconstruction losses: 0.023872341703998715, regression losses: 0.08248406929628688, validation losses: 0.4834211880836365\n",
      "Epoch 6538, reconstruction losses: 0.025953891569756728, regression losses: 0.1766129986903538, validation losses: 0.46359106275874545\n",
      "Epoch 6539, reconstruction losses: 0.026511816200979144, regression losses: 0.38831223334218246, validation losses: 0.5676098012136654\n",
      "Epoch 6540, reconstruction losses: 0.022774628827255262, regression losses: 0.14969219376646203, validation losses: 0.8678215311517042\n",
      "Epoch 6541, reconstruction losses: 0.025296506843849178, regression losses: 0.1564285632505773, validation losses: 0.6026570964241434\n",
      "Epoch 6542, reconstruction losses: 0.026685557612036687, regression losses: 0.14494951562880237, validation losses: 0.8351283421530991\n",
      "Epoch 6543, reconstruction losses: 0.023417437750840354, regression losses: 0.1303213424298358, validation losses: 0.6392826880224609\n",
      "Epoch 6544, reconstruction losses: 0.022038762550396856, regression losses: 0.10327143481689728, validation losses: 0.5401609527038367\n",
      "Epoch 6545, reconstruction losses: 0.02298808493237542, regression losses: 0.0968284511441131, validation losses: 0.49396223660256405\n",
      "Epoch 6546, reconstruction losses: 0.025590843879295066, regression losses: 0.1168698809786121, validation losses: 0.4749870562303732\n",
      "Epoch 6547, reconstruction losses: 0.02335186408964219, regression losses: 0.11643536028329751, validation losses: 0.47823955437050536\n",
      "Epoch 6548, reconstruction losses: 0.022432043843733245, regression losses: 0.11486198861716901, validation losses: 0.4966766125474258\n",
      "Epoch 6549, reconstruction losses: 0.028591333759433894, regression losses: 0.10897041256365256, validation losses: 0.4592770155775258\n",
      "Epoch 6550, reconstruction losses: 0.023232323674001576, regression losses: 0.10053572118430566, validation losses: 0.45805416872185195\n",
      "Epoch 6551, reconstruction losses: 0.023935785874784198, regression losses: 0.12548023950578782, validation losses: 0.4930535275037574\n",
      "Epoch 6552, reconstruction losses: 0.022821859088811902, regression losses: 0.10853258747278574, validation losses: 0.5586726616889035\n",
      "Epoch 6553, reconstruction losses: 0.024044831054176034, regression losses: 0.10676336993259543, validation losses: 0.5834816364257291\n",
      "Epoch 6554, reconstruction losses: 0.024268128107888226, regression losses: 0.1582921288996822, validation losses: 0.5772688635595699\n",
      "Epoch 6555, reconstruction losses: 0.024965092891877608, regression losses: 0.10319398752326374, validation losses: 0.5309594493431925\n",
      "Epoch 6556, reconstruction losses: 0.023404656735101247, regression losses: 0.11487657327710984, validation losses: 0.5362314875979494\n",
      "Epoch 6557, reconstruction losses: 0.022731873533591632, regression losses: 0.1369570701205353, validation losses: 0.5109099595375194\n",
      "Epoch 6558, reconstruction losses: 0.023974148000343178, regression losses: 0.0857798446931122, validation losses: 0.5024994864628247\n",
      "Epoch 6559, reconstruction losses: 0.025659859791664363, regression losses: 0.13853285041536517, validation losses: 0.5124122388555684\n",
      "Epoch 6560, reconstruction losses: 0.023960240072813253, regression losses: 0.10438184163364234, validation losses: 0.6309730384853447\n",
      "Epoch 6561, reconstruction losses: 0.024164531674215492, regression losses: 0.13208339955107157, validation losses: 0.48819373777901814\n",
      "Epoch 6562, reconstruction losses: 0.023766002436951622, regression losses: 0.1384924141391315, validation losses: 0.4569633456376006\n",
      "Epoch 6563, reconstruction losses: 0.025024598892011574, regression losses: 0.14490147155879748, validation losses: 0.44555600978601895\n",
      "Epoch 6564, reconstruction losses: 0.025146793625101034, regression losses: 0.11996983576480243, validation losses: 0.5183868207927461\n",
      "Epoch 6565, reconstruction losses: 0.023944234151866882, regression losses: 0.11593334022430293, validation losses: 0.5063584433551822\n",
      "Epoch 6566, reconstruction losses: 0.020968564599839958, regression losses: 0.10461050044208575, validation losses: 0.46772721813979223\n",
      "Epoch 6567, reconstruction losses: 0.023113028904162267, regression losses: 0.12470585486037714, validation losses: 0.45205936005292746\n",
      "Epoch 6568, reconstruction losses: 0.023282793132274757, regression losses: 0.12017165186903192, validation losses: 0.45777415816306494\n",
      "Epoch 6569, reconstruction losses: 0.025586994370264363, regression losses: 0.17196677183083137, validation losses: 0.47597073793843747\n",
      "Epoch 6570, reconstruction losses: 0.022620194169833515, regression losses: 0.1285146683450416, validation losses: 0.6275280557200318\n",
      "Epoch 6571, reconstruction losses: 0.02319220612859029, regression losses: 0.17931683601564669, validation losses: 0.6030948616758309\n",
      "Epoch 6572, reconstruction losses: 0.026906162151764897, regression losses: 0.12799230064676195, validation losses: 0.5913262439781946\n",
      "Epoch 6573, reconstruction losses: 0.02342053773233093, regression losses: 0.12841258792796492, validation losses: 0.4671406134743311\n",
      "Epoch 6574, reconstruction losses: 0.021264223908655233, regression losses: 0.08218724442744789, validation losses: 0.43597033282869874\n",
      "Epoch 6575, reconstruction losses: 0.023080737852095738, regression losses: 0.15472222821528742, validation losses: 0.4743224464327703\n",
      "Epoch 6576, reconstruction losses: 0.027416699092347212, regression losses: 0.14616667689157042, validation losses: 0.48172225888999626\n",
      "Epoch 6577, reconstruction losses: 0.023941027326291345, regression losses: 0.11135390650650576, validation losses: 0.511354575806487\n",
      "Epoch 6578, reconstruction losses: 0.025996475896930337, regression losses: 0.13568455986779807, validation losses: 0.5553188902701287\n",
      "Epoch 6579, reconstruction losses: 0.023051402761992183, regression losses: 0.09708910379252565, validation losses: 0.4697236892122013\n",
      "Epoch 6580, reconstruction losses: 0.024578178334032925, regression losses: 0.13696565276088607, validation losses: 0.4421271339504146\n",
      "Epoch 6581, reconstruction losses: 0.022088370613780876, regression losses: 0.13394912603097525, validation losses: 0.5529172292211745\n",
      "Epoch 6582, reconstruction losses: 0.02521742973994651, regression losses: 0.09943482318374788, validation losses: 0.43231838308153786\n",
      "Epoch 6583, reconstruction losses: 0.023990970799249726, regression losses: 0.1197779066341735, validation losses: 0.43092486656773044\n",
      "Epoch 6584, reconstruction losses: 0.026998747480363853, regression losses: 0.13052912248353182, validation losses: 0.4273535333104319\n",
      "Epoch 6585, reconstruction losses: 0.02327849168206135, regression losses: 0.09871387216455103, validation losses: 0.45190545326695997\n",
      "Epoch 6586, reconstruction losses: 0.026915180413643353, regression losses: 0.28308078457848296, validation losses: 0.5631983698157179\n",
      "Epoch 6587, reconstruction losses: 0.02382426783490233, regression losses: 0.15594631955622118, validation losses: 0.6506695556283876\n",
      "Epoch 6588, reconstruction losses: 0.023404145924048582, regression losses: 0.14895623396348037, validation losses: 0.45152236222697045\n",
      "Epoch 6589, reconstruction losses: 0.022007939271129623, regression losses: 0.14666265860008343, validation losses: 0.5745948717240114\n",
      "Epoch 6590, reconstruction losses: 0.0243458869914946, regression losses: 0.11755868602408887, validation losses: 0.5609292396745881\n",
      "Epoch 6591, reconstruction losses: 0.023901462900732914, regression losses: 0.09297562040811998, validation losses: 0.5405860943790939\n",
      "Epoch 6592, reconstruction losses: 0.02308336815201048, regression losses: 0.12261480879330426, validation losses: 0.5253871413296682\n",
      "Epoch 6593, reconstruction losses: 0.025232952209986937, regression losses: 0.11946076910041155, validation losses: 0.4658532870441928\n",
      "Epoch 6594, reconstruction losses: 0.02645836052415594, regression losses: 0.12107802196968949, validation losses: 0.5310752294512856\n",
      "Epoch 6595, reconstruction losses: 0.024009005416794505, regression losses: 0.10173453419745489, validation losses: 0.5043130473624345\n",
      "Epoch 6596, reconstruction losses: 0.023543129814552446, regression losses: 0.10286277897745336, validation losses: 0.48853987796926823\n",
      "Epoch 6597, reconstruction losses: 0.022705282350745083, regression losses: 0.09632805402702703, validation losses: 0.5558958095299015\n",
      "Epoch 6598, reconstruction losses: 0.027846444302693493, regression losses: 0.15507048129112555, validation losses: 0.5120697803655712\n",
      "Epoch 6599, reconstruction losses: 0.025288696373144053, regression losses: 0.14504505999591258, validation losses: 0.5209057780512494\n",
      "Epoch 6600, reconstruction losses: 0.022611557751987713, regression losses: 0.10598736149349688, validation losses: 0.4841925084420181\n",
      "Epoch 6601, reconstruction losses: 0.02335708508577759, regression losses: 0.0987136006009653, validation losses: 0.4619989290482153\n",
      "Epoch 6602, reconstruction losses: 0.026378131583210083, regression losses: 0.11291274742722598, validation losses: 0.4436076178421685\n",
      "Epoch 6603, reconstruction losses: 0.02385286286182257, regression losses: 0.153116987229793, validation losses: 0.4989387555015786\n",
      "Epoch 6604, reconstruction losses: 0.0223624501409457, regression losses: 0.11889175150389905, validation losses: 0.47051134495099967\n",
      "Epoch 6605, reconstruction losses: 0.02506695951388666, regression losses: 0.10970846454368169, validation losses: 0.5050215753871412\n",
      "Epoch 6606, reconstruction losses: 0.024342770352699272, regression losses: 0.15056638011996354, validation losses: 0.4746741141021008\n",
      "Epoch 6607, reconstruction losses: 0.02414375047647519, regression losses: 0.10308238668201532, validation losses: 0.4193756677227831\n",
      "Epoch 6608, reconstruction losses: 0.023486771952819972, regression losses: 0.127026225937798, validation losses: 0.43865877324222985\n",
      "Epoch 6609, reconstruction losses: 0.02212040219097729, regression losses: 0.09359736258332058, validation losses: 0.4898604151499415\n",
      "Epoch 6610, reconstruction losses: 0.021136405324028322, regression losses: 0.09508774420733598, validation losses: 0.45136285819542565\n",
      "Epoch 6611, reconstruction losses: 0.025548277020517315, regression losses: 0.09400081597654043, validation losses: 0.4162308911589694\n",
      "Epoch 6612, reconstruction losses: 0.02249756111977162, regression losses: 0.09847975673919944, validation losses: 0.4088410419184451\n",
      "Epoch 6613, reconstruction losses: 0.023582480308649855, regression losses: 0.15261840029549123, validation losses: 0.4174832576831918\n",
      "Epoch 6614, reconstruction losses: 0.024955945692346403, regression losses: 0.10749384249606969, validation losses: 0.4708238300514454\n",
      "Epoch 6615, reconstruction losses: 0.025618422257436803, regression losses: 0.21406918357999943, validation losses: 0.4838847233978617\n",
      "Epoch 6616, reconstruction losses: 0.022352278601298764, regression losses: 0.11842732259839092, validation losses: 0.647521756258801\n",
      "Epoch 6617, reconstruction losses: 0.026849910978037576, regression losses: 0.2699783303046134, validation losses: 0.5458517194922957\n",
      "Epoch 6618, reconstruction losses: 0.024256249074257757, regression losses: 0.46186202645888685, validation losses: 0.7223527329003956\n",
      "Epoch 6619, reconstruction losses: 0.023359120126015688, regression losses: 0.15501689769983298, validation losses: 0.6808021192264563\n",
      "Epoch 6620, reconstruction losses: 0.02255861152771985, regression losses: 0.14309641311628168, validation losses: 0.7081657159818664\n",
      "Epoch 6621, reconstruction losses: 0.023061112730071005, regression losses: 0.11393423672766971, validation losses: 0.6999055113831018\n",
      "Epoch 6622, reconstruction losses: 0.023300444587192472, regression losses: 0.10997519780603415, validation losses: 0.5922462286535729\n",
      "Epoch 6623, reconstruction losses: 0.02465469405176469, regression losses: 0.14509371334446539, validation losses: 0.503330510706866\n",
      "Epoch 6624, reconstruction losses: 0.02467129631611059, regression losses: 0.1223131719366796, validation losses: 0.5346975684429667\n",
      "Epoch 6625, reconstruction losses: 0.02279771988258275, regression losses: 0.12255103972418285, validation losses: 0.6317066670934977\n",
      "Epoch 6626, reconstruction losses: 0.023021257744879262, regression losses: 0.08809745424112721, validation losses: 0.5606184141092106\n",
      "Epoch 6627, reconstruction losses: 0.022222696846503423, regression losses: 0.12065508688639758, validation losses: 0.5134629124959192\n",
      "Epoch 6628, reconstruction losses: 0.02257241740017421, regression losses: 0.09009457412865322, validation losses: 0.47654101449870595\n",
      "Epoch 6629, reconstruction losses: 0.02109101298354766, regression losses: 0.10602249668808955, validation losses: 0.47661834872198555\n",
      "Epoch 6630, reconstruction losses: 0.02055000419594876, regression losses: 0.10969019541871912, validation losses: 0.4930848957381829\n",
      "Epoch 6631, reconstruction losses: 0.02112242387075282, regression losses: 0.10786033241083978, validation losses: 0.5051239235869649\n",
      "Epoch 6632, reconstruction losses: 0.02347668850344086, regression losses: 0.10810956106636664, validation losses: 0.5288415705151859\n",
      "Epoch 6633, reconstruction losses: 0.02251033432433757, regression losses: 0.11007724540130016, validation losses: 0.45830092312697324\n",
      "Epoch 6634, reconstruction losses: 0.022513259193804945, regression losses: 0.12194995523964745, validation losses: 0.4560855598014414\n",
      "Epoch 6635, reconstruction losses: 0.023324235727139507, regression losses: 0.11023086835492371, validation losses: 0.4855719519748827\n",
      "Epoch 6636, reconstruction losses: 0.02466467892750742, regression losses: 0.09957553986081089, validation losses: 0.4645151221677009\n",
      "Epoch 6637, reconstruction losses: 0.02152750609582426, regression losses: 0.1069633893424761, validation losses: 0.47985809151369546\n",
      "Epoch 6638, reconstruction losses: 0.022361248838102248, regression losses: 0.1049229051189828, validation losses: 0.4724060415642478\n",
      "Epoch 6639, reconstruction losses: 0.023477682268646605, regression losses: 0.11857143997186224, validation losses: 0.4690316778349858\n",
      "Epoch 6640, reconstruction losses: 0.021859247160873084, regression losses: 0.10078856672672283, validation losses: 0.5180830889473712\n",
      "Epoch 6641, reconstruction losses: 0.02152858725889641, regression losses: 0.11544250057781864, validation losses: 0.5039504447285883\n",
      "Epoch 6642, reconstruction losses: 0.024352065830106427, regression losses: 0.10576539143202014, validation losses: 0.45699750595809696\n",
      "Epoch 6643, reconstruction losses: 0.022831858696736197, regression losses: 0.11973204176360505, validation losses: 0.43226290313817356\n",
      "Epoch 6644, reconstruction losses: 0.022532038058815467, regression losses: 0.08821382411260162, validation losses: 0.4460604899358508\n",
      "Epoch 6645, reconstruction losses: 0.029640760324150105, regression losses: 0.22572208656269532, validation losses: 0.42574930875988515\n",
      "Epoch 6646, reconstruction losses: 0.02236022445288984, regression losses: 0.11482604293883525, validation losses: 0.4621425746014347\n",
      "Epoch 6647, reconstruction losses: 0.027041851362726098, regression losses: 0.37921618029088766, validation losses: 0.44043336013053963\n",
      "Epoch 6648, reconstruction losses: 0.02178281588080207, regression losses: 0.1137093794537685, validation losses: 0.7220998106064093\n",
      "Epoch 6649, reconstruction losses: 0.023858860693884272, regression losses: 0.11683235096373984, validation losses: 0.670344364071222\n",
      "Epoch 6650, reconstruction losses: 0.022533114138494608, regression losses: 0.1525309205339417, validation losses: 0.4814713805317286\n",
      "Epoch 6651, reconstruction losses: 0.023253519222141975, regression losses: 0.11707927592862546, validation losses: 0.5319140445120879\n",
      "Epoch 6652, reconstruction losses: 0.024628478599668865, regression losses: 0.1476457826189164, validation losses: 0.48725187228814537\n",
      "Epoch 6653, reconstruction losses: 0.02474035464896254, regression losses: 0.11736250793670223, validation losses: 0.44937927486946416\n",
      "Epoch 6654, reconstruction losses: 0.023390287843621505, regression losses: 0.11203574781869646, validation losses: 0.5426329092354387\n",
      "Epoch 6655, reconstruction losses: 0.023340550191254045, regression losses: 0.10149622531141447, validation losses: 0.4808966486255737\n",
      "Epoch 6656, reconstruction losses: 0.023949679976172346, regression losses: 0.14635606335454684, validation losses: 0.43392158211921955\n",
      "Epoch 6657, reconstruction losses: 0.02249571992775086, regression losses: 0.10551703722397761, validation losses: 0.533060545341193\n",
      "Epoch 6658, reconstruction losses: 0.02165928850286769, regression losses: 0.14477213255877502, validation losses: 0.48882097826000376\n",
      "Epoch 6659, reconstruction losses: 0.022975472079054152, regression losses: 0.09845907413227498, validation losses: 0.4647111828408061\n",
      "Epoch 6660, reconstruction losses: 0.02367549496462744, regression losses: 0.11419618117817998, validation losses: 0.48888089792341594\n",
      "Epoch 6661, reconstruction losses: 0.02356343654507721, regression losses: 0.114041898655836, validation losses: 0.5013197917038561\n",
      "Epoch 6662, reconstruction losses: 0.022170664975228932, regression losses: 0.12072887601578791, validation losses: 0.44028025978312685\n",
      "Epoch 6663, reconstruction losses: 0.021549853298631537, regression losses: 0.10688983577985918, validation losses: 0.4233910971417728\n",
      "Epoch 6664, reconstruction losses: 0.023376287099537346, regression losses: 0.11499425917092009, validation losses: 0.44320165835808323\n",
      "Epoch 6665, reconstruction losses: 0.022648719398846467, regression losses: 0.09326636777140243, validation losses: 0.49106955175958045\n",
      "Epoch 6666, reconstruction losses: 0.02500894466745289, regression losses: 0.11001084238268408, validation losses: 0.5086845186662022\n",
      "Epoch 6667, reconstruction losses: 0.0273489051346478, regression losses: 0.10101997435339469, validation losses: 0.4682382476019901\n",
      "Epoch 6668, reconstruction losses: 0.02699576307809114, regression losses: 0.22548120496907648, validation losses: 0.442177286468606\n",
      "Epoch 6669, reconstruction losses: 0.025635125951050088, regression losses: 0.11356206135007457, validation losses: 0.6264766840440299\n",
      "Epoch 6670, reconstruction losses: 0.023708148115378073, regression losses: 0.19496358053376597, validation losses: 0.5855058605013395\n",
      "Epoch 6671, reconstruction losses: 0.02234794199493198, regression losses: 0.1143731915285288, validation losses: 0.5201435797251243\n",
      "Epoch 6672, reconstruction losses: 0.024865737571720666, regression losses: 0.11312450590245784, validation losses: 0.5555999755313881\n",
      "Epoch 6673, reconstruction losses: 0.023536675141414536, regression losses: 0.10077920487745176, validation losses: 0.46585576259516415\n",
      "Epoch 6674, reconstruction losses: 0.02509367274593884, regression losses: 0.14583560095981118, validation losses: 0.4632473864092908\n",
      "Epoch 6675, reconstruction losses: 0.025339831548875216, regression losses: 0.14512970793325414, validation losses: 0.6129146745605799\n",
      "Epoch 6676, reconstruction losses: 0.023293268221170914, regression losses: 0.15913623304599667, validation losses: 0.5608998176534004\n",
      "Epoch 6677, reconstruction losses: 0.023758678592019154, regression losses: 0.08964099279456264, validation losses: 0.44552645387145284\n",
      "Epoch 6678, reconstruction losses: 0.023009127708693625, regression losses: 0.12019064958583439, validation losses: 0.4988975406944648\n",
      "Epoch 6679, reconstruction losses: 0.02540902758646722, regression losses: 0.13593193712208934, validation losses: 0.4411536405100046\n",
      "Epoch 6680, reconstruction losses: 0.02208777324085343, regression losses: 0.130395293127693, validation losses: 0.4916891681200176\n",
      "Epoch 6681, reconstruction losses: 0.023976837047453528, regression losses: 0.15177275859830394, validation losses: 0.5221081373474052\n",
      "Epoch 6682, reconstruction losses: 0.023140438240791077, regression losses: 0.12354710899779232, validation losses: 0.5101988267389047\n",
      "Epoch 6683, reconstruction losses: 0.02297141803489297, regression losses: 0.12815909897101302, validation losses: 0.49134897877270245\n",
      "Epoch 6684, reconstruction losses: 0.02319573344871026, regression losses: 0.0758273652050492, validation losses: 0.44617693148719123\n",
      "Epoch 6685, reconstruction losses: 0.024872276396314237, regression losses: 0.13290275575054777, validation losses: 0.44987751047250285\n",
      "Epoch 6686, reconstruction losses: 0.024290399147572063, regression losses: 0.3884176108786742, validation losses: 0.5333054666181678\n",
      "Epoch 6687, reconstruction losses: 0.022880929348729054, regression losses: 0.1880558620488187, validation losses: 0.7016577209821883\n",
      "Epoch 6688, reconstruction losses: 0.02241374987672759, regression losses: 0.1198384911340422, validation losses: 0.49608432592435\n",
      "Epoch 6689, reconstruction losses: 0.02457553167451627, regression losses: 0.12315186323181174, validation losses: 0.49099617959606345\n",
      "Epoch 6690, reconstruction losses: 0.02265392137669022, regression losses: 0.10991067338305868, validation losses: 0.4855009055602096\n",
      "Epoch 6691, reconstruction losses: 0.02738484784535755, regression losses: 0.40579453844480834, validation losses: 0.4657200564487095\n",
      "Epoch 6692, reconstruction losses: 0.021995036759530323, regression losses: 0.12885622537030164, validation losses: 0.6776771870038228\n",
      "Epoch 6693, reconstruction losses: 0.026044870855657747, regression losses: 0.14330919615937426, validation losses: 0.676536813214328\n",
      "Epoch 6694, reconstruction losses: 0.023061920783991646, regression losses: 0.11169803462851827, validation losses: 0.5739718300900619\n",
      "Epoch 6695, reconstruction losses: 0.02004632595921999, regression losses: 0.09993126620212105, validation losses: 0.5208086716789962\n",
      "Epoch 6696, reconstruction losses: 0.025291260984597233, regression losses: 0.13039771008657458, validation losses: 0.47518239080841507\n",
      "Epoch 6697, reconstruction losses: 0.0247819000234856, regression losses: 0.12397287171450255, validation losses: 0.47331451895689564\n",
      "Epoch 6698, reconstruction losses: 0.024172397545310705, regression losses: 0.13385483611430624, validation losses: 0.5842003647821418\n",
      "Epoch 6699, reconstruction losses: 0.024364095878763495, regression losses: 0.14617383266997427, validation losses: 0.5104100658724291\n",
      "Epoch 6700, reconstruction losses: 0.024724255470383545, regression losses: 0.14068596598863656, validation losses: 0.604540898577253\n",
      "Epoch 6701, reconstruction losses: 0.023274665333328396, regression losses: 0.11443253222072727, validation losses: 0.5300917482684847\n",
      "Epoch 6702, reconstruction losses: 0.02535897482872683, regression losses: 0.1244117296133602, validation losses: 0.4991990786049696\n",
      "Epoch 6703, reconstruction losses: 0.02399474419437342, regression losses: 0.15118121349417984, validation losses: 0.5371512707244388\n",
      "Epoch 6704, reconstruction losses: 0.023627966593324463, regression losses: 0.11909409102667427, validation losses: 0.5086476099830874\n",
      "Epoch 6705, reconstruction losses: 0.021078939766805613, regression losses: 0.09914303840064201, validation losses: 0.5004952248520651\n",
      "Epoch 6706, reconstruction losses: 0.023699044831924136, regression losses: 0.19969198795616988, validation losses: 0.4948869071027554\n",
      "Epoch 6707, reconstruction losses: 0.021924223720347448, regression losses: 0.11484015509682728, validation losses: 0.5817940133690299\n",
      "Epoch 6708, reconstruction losses: 0.02142563837458378, regression losses: 0.11451512164242253, validation losses: 0.509405418142875\n",
      "Epoch 6709, reconstruction losses: 0.024974740428578848, regression losses: 0.15799005095562818, validation losses: 0.4625916712381307\n",
      "Epoch 6710, reconstruction losses: 0.020812475169252543, regression losses: 0.11115166759588026, validation losses: 0.5632625106411007\n",
      "Epoch 6711, reconstruction losses: 0.02337632567564318, regression losses: 0.08914857601889266, validation losses: 0.5733818751025911\n",
      "Epoch 6712, reconstruction losses: 0.02371960602001478, regression losses: 0.1207848876153888, validation losses: 0.48251784841564305\n",
      "Epoch 6713, reconstruction losses: 0.020721555797485285, regression losses: 0.10305654173013008, validation losses: 0.44153493373456953\n",
      "Epoch 6714, reconstruction losses: 0.02099605925692488, regression losses: 0.11380500370854647, validation losses: 0.43924320606058437\n",
      "Epoch 6715, reconstruction losses: 0.02243111294958484, regression losses: 0.12054827927454792, validation losses: 0.44641984172918464\n",
      "Epoch 6716, reconstruction losses: 0.022636674110237728, regression losses: 0.1141278393475168, validation losses: 0.48248817724191007\n",
      "Epoch 6717, reconstruction losses: 0.02655103248208608, regression losses: 0.13364018036572303, validation losses: 0.48076817034878505\n",
      "Epoch 6718, reconstruction losses: 0.02608048584583872, regression losses: 0.1362152154544641, validation losses: 0.45005433274694795\n",
      "Epoch 6719, reconstruction losses: 0.022245288095406022, regression losses: 0.0965743823638803, validation losses: 0.4208009277465521\n",
      "Epoch 6720, reconstruction losses: 0.025538543469432747, regression losses: 0.11211977178387812, validation losses: 0.4918457236932127\n",
      "Epoch 6721, reconstruction losses: 0.0220345534388512, regression losses: 0.08565439292629996, validation losses: 0.4576961779631792\n",
      "Epoch 6722, reconstruction losses: 0.023175047236535462, regression losses: 0.12272520882324642, validation losses: 0.4182611238289901\n",
      "Epoch 6723, reconstruction losses: 0.02204302241534735, regression losses: 0.11400029136838875, validation losses: 0.4422384754960269\n",
      "Epoch 6724, reconstruction losses: 0.029166829087712474, regression losses: 0.15817956567498864, validation losses: 0.44539165835644107\n",
      "Epoch 6725, reconstruction losses: 0.02224323949738948, regression losses: 0.09637028384826625, validation losses: 0.45045279949785566\n",
      "Epoch 6726, reconstruction losses: 0.02145586874885155, regression losses: 0.13793906343673604, validation losses: 0.5478328097251488\n",
      "Epoch 6727, reconstruction losses: 0.025114064261561025, regression losses: 0.15991560986606987, validation losses: 0.5459932455137124\n",
      "Epoch 6728, reconstruction losses: 0.02564717505641116, regression losses: 0.10568754138765192, validation losses: 0.5675449128449273\n",
      "Epoch 6729, reconstruction losses: 0.023842580905134657, regression losses: 0.13279996420792722, validation losses: 0.5596026049095146\n",
      "Epoch 6730, reconstruction losses: 0.026645533515236255, regression losses: 0.13652891572138576, validation losses: 0.5010283963477361\n",
      "Epoch 6731, reconstruction losses: 0.024219503300006506, regression losses: 0.3444182948328709, validation losses: 0.5780391993554208\n",
      "Epoch 6732, reconstruction losses: 0.022340234287481768, regression losses: 0.12028698030111296, validation losses: 0.6623776602287584\n",
      "Epoch 6733, reconstruction losses: 0.021578234236653865, regression losses: 0.1256252879482362, validation losses: 0.5674679550667463\n",
      "Epoch 6734, reconstruction losses: 0.022848052846623737, regression losses: 0.1470090436023511, validation losses: 0.4821778551167868\n",
      "Epoch 6735, reconstruction losses: 0.02484660306861528, regression losses: 0.10012396635782915, validation losses: 0.4452540824329551\n",
      "Epoch 6736, reconstruction losses: 0.022622377100296916, regression losses: 0.09645246686170096, validation losses: 0.4180748037336725\n",
      "Epoch 6737, reconstruction losses: 0.021606467363816908, regression losses: 0.11464434479585332, validation losses: 0.42890367334577323\n",
      "Epoch 6738, reconstruction losses: 0.02156004513011752, regression losses: 0.08155514980489748, validation losses: 0.46644292916964875\n",
      "Epoch 6739, reconstruction losses: 0.02521248628999764, regression losses: 0.11396702549783387, validation losses: 0.45155706274540397\n",
      "Epoch 6740, reconstruction losses: 0.023867087436174182, regression losses: 0.0955143581201297, validation losses: 0.41658126223173253\n",
      "Epoch 6741, reconstruction losses: 0.023690680648879907, regression losses: 0.14981393248071342, validation losses: 0.4332737854289822\n",
      "Epoch 6742, reconstruction losses: 0.024072451096969708, regression losses: 0.19618785838089553, validation losses: 0.48887357153977024\n",
      "Epoch 6743, reconstruction losses: 0.02085001789033465, regression losses: 0.09044959800201702, validation losses: 0.5767034210291121\n",
      "Epoch 6744, reconstruction losses: 0.027556332646304263, regression losses: 0.24875336573550194, validation losses: 0.5087122297232238\n",
      "Epoch 6745, reconstruction losses: 0.02706736017126988, regression losses: 0.17685971965935074, validation losses: 0.6351630520949854\n",
      "Epoch 6746, reconstruction losses: 0.025458629428102737, regression losses: 0.16018040532697964, validation losses: 0.5360717052820954\n",
      "Epoch 6747, reconstruction losses: 0.023940689116795495, regression losses: 0.15140878850514294, validation losses: 0.5895212876735332\n",
      "Epoch 6748, reconstruction losses: 0.023206680943023496, regression losses: 0.09493480653712359, validation losses: 0.5317543939696247\n",
      "Epoch 6749, reconstruction losses: 0.026650176116428136, regression losses: 0.11710751476516021, validation losses: 0.47520333296013784\n",
      "Epoch 6750, reconstruction losses: 0.02271687949629873, regression losses: 0.11847848797784835, validation losses: 0.4736315240832766\n",
      "Epoch 6751, reconstruction losses: 0.027253207837061637, regression losses: 0.10743189949753712, validation losses: 0.5312607692010975\n",
      "Epoch 6752, reconstruction losses: 0.024837163672077594, regression losses: 0.1095102779412311, validation losses: 0.5992309523432625\n",
      "Epoch 6753, reconstruction losses: 0.021181985816714776, regression losses: 0.09849312451634766, validation losses: 0.5233969603253749\n",
      "Epoch 6754, reconstruction losses: 0.022144818285955235, regression losses: 0.10340398039969904, validation losses: 0.5079236533314344\n",
      "Epoch 6755, reconstruction losses: 0.022568501687093186, regression losses: 0.07877567752216014, validation losses: 0.5004141861994196\n",
      "Epoch 6756, reconstruction losses: 0.02283669930747942, regression losses: 0.12052839217003948, validation losses: 0.47829665295748514\n",
      "Epoch 6757, reconstruction losses: 0.0256536294201195, regression losses: 0.13634685910130878, validation losses: 0.4833637902331772\n",
      "Epoch 6758, reconstruction losses: 0.02343832866756224, regression losses: 0.10954370253494376, validation losses: 0.5117705290281696\n",
      "Epoch 6759, reconstruction losses: 0.025258825481984326, regression losses: 0.135496173650793, validation losses: 0.5024912299810632\n",
      "Epoch 6760, reconstruction losses: 0.024357374699753683, regression losses: 0.1373355510161231, validation losses: 0.47752267121573466\n",
      "Epoch 6761, reconstruction losses: 0.023492644160657328, regression losses: 0.12244472741794352, validation losses: 0.46178954689445534\n",
      "Epoch 6762, reconstruction losses: 0.024012382264290436, regression losses: 0.10765200975313595, validation losses: 0.47473716887392176\n",
      "Epoch 6763, reconstruction losses: 0.023193270686517806, regression losses: 0.12077810623194554, validation losses: 0.42058830623268695\n",
      "Epoch 6764, reconstruction losses: 0.02367693532985063, regression losses: 0.10611514927481416, validation losses: 0.43423718769389613\n",
      "Epoch 6765, reconstruction losses: 0.023266802459948055, regression losses: 0.11497411195079624, validation losses: 0.5264762783407148\n",
      "Epoch 6766, reconstruction losses: 0.02464866337216953, regression losses: 0.11220198313064644, validation losses: 0.514331366541166\n",
      "Epoch 6767, reconstruction losses: 0.022454603785064545, regression losses: 0.12258962536136414, validation losses: 0.47086676546252787\n",
      "Epoch 6768, reconstruction losses: 0.02074373322324051, regression losses: 0.09636192851016764, validation losses: 0.4289045589937119\n",
      "Epoch 6769, reconstruction losses: 0.02557446588094793, regression losses: 0.12020719544471657, validation losses: 0.4063807634457285\n",
      "Epoch 6770, reconstruction losses: 0.020572684508600454, regression losses: 0.1075702090505933, validation losses: 0.4194380893288648\n",
      "Epoch 6771, reconstruction losses: 0.021961152549607725, regression losses: 0.11135652540218707, validation losses: 0.4141141574715441\n",
      "Epoch 6772, reconstruction losses: 0.026448098019327185, regression losses: 0.14366109057643636, validation losses: 0.45223430800771447\n",
      "Epoch 6773, reconstruction losses: 0.025619125751338453, regression losses: 0.1171303342733804, validation losses: 0.4204917808377714\n",
      "Epoch 6774, reconstruction losses: 0.023531218350398144, regression losses: 0.09796751040417444, validation losses: 0.4025108417414629\n",
      "Epoch 6775, reconstruction losses: 0.023111124641791703, regression losses: 0.11619145904190656, validation losses: 0.42044682520021437\n",
      "Epoch 6776, reconstruction losses: 0.02213787580317994, regression losses: 0.09738597278690951, validation losses: 0.5127170878300193\n",
      "Epoch 6777, reconstruction losses: 0.025313102106750564, regression losses: 0.11813322476421945, validation losses: 0.5122592722955586\n",
      "Epoch 6778, reconstruction losses: 0.023310735757545175, regression losses: 0.12063345595670959, validation losses: 0.49759148222130567\n",
      "Epoch 6779, reconstruction losses: 0.02232738171096363, regression losses: 0.13290281704592938, validation losses: 0.4493226334020347\n",
      "Epoch 6780, reconstruction losses: 0.023728988203001705, regression losses: 0.1034853304344025, validation losses: 0.46749051360095395\n",
      "Epoch 6781, reconstruction losses: 0.023313423538737978, regression losses: 0.11068342385451028, validation losses: 0.48994618392865547\n",
      "Epoch 6782, reconstruction losses: 0.023140003240839205, regression losses: 0.15547209778772467, validation losses: 0.4290536258543198\n",
      "Epoch 6783, reconstruction losses: 0.022188279517860933, regression losses: 0.1215679186517258, validation losses: 0.43145522213069476\n",
      "Epoch 6784, reconstruction losses: 0.025708142062256713, regression losses: 0.15374723780167876, validation losses: 0.5169170462968156\n",
      "Epoch 6785, reconstruction losses: 0.02271719482034767, regression losses: 0.13526549799130022, validation losses: 0.7036754339499963\n",
      "Epoch 6786, reconstruction losses: 0.021241684666196754, regression losses: 0.10699080964843029, validation losses: 0.6104702129104682\n",
      "Epoch 6787, reconstruction losses: 0.026082194306204117, regression losses: 0.21126886714343016, validation losses: 0.5540387684405609\n",
      "Epoch 6788, reconstruction losses: 0.02357458984083162, regression losses: 0.18963235788739968, validation losses: 0.6875568684196287\n",
      "Epoch 6789, reconstruction losses: 0.025203354112258096, regression losses: 0.2123969730333796, validation losses: 0.6022745779290852\n",
      "Epoch 6790, reconstruction losses: 0.02303565067162094, regression losses: 0.11607471869667825, validation losses: 0.5150144165092504\n",
      "Epoch 6791, reconstruction losses: 0.02523840381982, regression losses: 0.10141223988138942, validation losses: 0.5611485019373257\n",
      "Epoch 6792, reconstruction losses: 0.02404950822853233, regression losses: 0.08722142729232338, validation losses: 0.46744883189290204\n",
      "Epoch 6793, reconstruction losses: 0.023271600443238987, regression losses: 0.11130842810395605, validation losses: 0.5053871389115882\n",
      "Epoch 6794, reconstruction losses: 0.022140821321650003, regression losses: 0.11226671731066898, validation losses: 0.5035807336857047\n",
      "Epoch 6795, reconstruction losses: 0.025447992292169163, regression losses: 0.10896832734476154, validation losses: 0.4606649898288627\n",
      "Epoch 6796, reconstruction losses: 0.02287309355343459, regression losses: 0.09244765350902735, validation losses: 0.442533923939573\n",
      "Epoch 6797, reconstruction losses: 0.02492312637697906, regression losses: 0.16112340594838157, validation losses: 0.46888442439214106\n",
      "Epoch 6798, reconstruction losses: 0.02132938854204321, regression losses: 0.08462730338717364, validation losses: 0.5098576830413732\n",
      "Epoch 6799, reconstruction losses: 0.024291141414722855, regression losses: 0.16658245948042236, validation losses: 0.5418610758872563\n",
      "Epoch 6800, reconstruction losses: 0.026127317076149147, regression losses: 0.13513801066513687, validation losses: 0.5219425336632498\n",
      "Epoch 6801, reconstruction losses: 0.02403626184247918, regression losses: 0.13783628146367033, validation losses: 0.44796804979078764\n",
      "Epoch 6802, reconstruction losses: 0.02550619212748736, regression losses: 0.13576218400459797, validation losses: 0.4128122291955699\n",
      "Epoch 6803, reconstruction losses: 0.02493611455681391, regression losses: 0.1450228884945031, validation losses: 0.5650623677800102\n",
      "Epoch 6804, reconstruction losses: 0.023337190056554272, regression losses: 0.1697873384283621, validation losses: 0.70306570334678\n",
      "Epoch 6805, reconstruction losses: 0.025803708385286197, regression losses: 0.1458365336261449, validation losses: 0.44125628023577373\n",
      "Epoch 6806, reconstruction losses: 0.024091096840570137, regression losses: 0.16245126688758615, validation losses: 0.4297462055905129\n",
      "Epoch 6807, reconstruction losses: 0.021214270716145914, regression losses: 0.12155615321934249, validation losses: 0.4292803738725296\n",
      "Epoch 6808, reconstruction losses: 0.023404677891929862, regression losses: 0.1064398944338725, validation losses: 0.46298693645895345\n",
      "Epoch 6809, reconstruction losses: 0.022288078973085244, regression losses: 0.10193459583612044, validation losses: 0.5333478419047568\n",
      "Epoch 6810, reconstruction losses: 0.020875970440437656, regression losses: 0.1182638226375635, validation losses: 0.5088634215285625\n",
      "Epoch 6811, reconstruction losses: 0.02416908852740311, regression losses: 0.12915687942584128, validation losses: 0.4405486184879471\n",
      "Epoch 6812, reconstruction losses: 0.02260444708968067, regression losses: 0.11925494842255809, validation losses: 0.4589983090237757\n",
      "Epoch 6813, reconstruction losses: 0.021062275631409486, regression losses: 0.10512360298910443, validation losses: 0.45490740008694214\n",
      "Epoch 6814, reconstruction losses: 0.020993825096948103, regression losses: 0.09849953950528878, validation losses: 0.44524370829997023\n",
      "Epoch 6815, reconstruction losses: 0.02408335561209868, regression losses: 0.13216908972970792, validation losses: 0.47619963126028997\n",
      "Epoch 6816, reconstruction losses: 0.02105004562638114, regression losses: 0.0831787131913099, validation losses: 0.5279385219849522\n",
      "Epoch 6817, reconstruction losses: 0.021652541861896853, regression losses: 0.10699254544737072, validation losses: 0.5155760381434915\n",
      "Epoch 6818, reconstruction losses: 0.021800257803455583, regression losses: 0.11047836863902959, validation losses: 0.45786002356012223\n",
      "Epoch 6819, reconstruction losses: 0.02276415071143523, regression losses: 0.10789900741666708, validation losses: 0.4693264909850072\n",
      "Epoch 6820, reconstruction losses: 0.03452920314026312, regression losses: 0.18339582206674312, validation losses: 0.48067035750999576\n",
      "Epoch 6821, reconstruction losses: 0.02299624615613081, regression losses: 0.12325303571930354, validation losses: 0.4453764807250299\n",
      "Epoch 6822, reconstruction losses: 0.024579895605464176, regression losses: 0.12134410563636915, validation losses: 0.5028700298537871\n",
      "Epoch 6823, reconstruction losses: 0.022036839107005542, regression losses: 0.15688306353987544, validation losses: 0.5485229906789246\n",
      "Epoch 6824, reconstruction losses: 0.023172314046860248, regression losses: 0.1273006081516727, validation losses: 0.5033100643204288\n",
      "Epoch 6825, reconstruction losses: 0.02355219002717048, regression losses: 0.11454935025044596, validation losses: 0.46673553372764853\n",
      "Epoch 6826, reconstruction losses: 0.02233593546286396, regression losses: 0.10139987269833348, validation losses: 0.48722801879888433\n",
      "Epoch 6827, reconstruction losses: 0.023251387486381066, regression losses: 0.13416741633571766, validation losses: 0.5037845733253732\n",
      "Epoch 6828, reconstruction losses: 0.022603244827327288, regression losses: 0.12935173313605924, validation losses: 0.5144604178140576\n",
      "Epoch 6829, reconstruction losses: 0.02551268250486671, regression losses: 0.15736884898413003, validation losses: 0.5024649735538645\n",
      "Epoch 6830, reconstruction losses: 0.02183098864546137, regression losses: 0.12993491518590644, validation losses: 0.48237097790303834\n",
      "Epoch 6831, reconstruction losses: 0.021227078324588967, regression losses: 0.11945612075142772, validation losses: 0.5036955694653115\n",
      "Epoch 6832, reconstruction losses: 0.022671029894341183, regression losses: 0.09179685645402691, validation losses: 0.5248263382435552\n",
      "Epoch 6833, reconstruction losses: 0.024234811408072873, regression losses: 0.1326176257901337, validation losses: 0.6061447214033843\n",
      "Epoch 6834, reconstruction losses: 0.023032386124810806, regression losses: 0.10724180133914557, validation losses: 0.5368680408709996\n",
      "Epoch 6835, reconstruction losses: 0.02310056977483651, regression losses: 0.11253187750446422, validation losses: 0.46420103927972234\n",
      "Epoch 6836, reconstruction losses: 0.02233661515002049, regression losses: 0.10208218370874313, validation losses: 0.46747885990304083\n",
      "Epoch 6837, reconstruction losses: 0.024284356724158178, regression losses: 0.10150741867991663, validation losses: 0.5315433357819948\n",
      "Epoch 6838, reconstruction losses: 0.024078658691133927, regression losses: 0.10280981852642444, validation losses: 0.46037411156201324\n",
      "Epoch 6839, reconstruction losses: 0.024063911893453676, regression losses: 0.15850165152752516, validation losses: 0.43381455017406706\n",
      "Epoch 6840, reconstruction losses: 0.022631933238906644, regression losses: 0.12269423185117098, validation losses: 0.568590604741664\n",
      "Epoch 6841, reconstruction losses: 0.021473121771049767, regression losses: 0.10432143231867262, validation losses: 0.48693803218446075\n",
      "Epoch 6842, reconstruction losses: 0.02092759517186181, regression losses: 0.08630810144081076, validation losses: 0.4734181442194138\n",
      "Epoch 6843, reconstruction losses: 0.02391955740612649, regression losses: 0.11233788825158042, validation losses: 0.44617155414209864\n",
      "Epoch 6844, reconstruction losses: 0.02580730751037061, regression losses: 0.1501254790656959, validation losses: 0.5101621013404101\n",
      "Epoch 6845, reconstruction losses: 0.021713299723820943, regression losses: 0.10279033545387659, validation losses: 0.40422830596957393\n",
      "Epoch 6846, reconstruction losses: 0.023580533142085018, regression losses: 0.10537980694825579, validation losses: 0.4047775273658655\n",
      "Epoch 6847, reconstruction losses: 0.02736713577166774, regression losses: 0.17006978901226044, validation losses: 0.471013556185387\n",
      "Epoch 6848, reconstruction losses: 0.02389507397922775, regression losses: 0.13797294375978486, validation losses: 0.6270252624584942\n",
      "Epoch 6849, reconstruction losses: 0.02101808478523813, regression losses: 0.10448452825333392, validation losses: 0.4550173769154986\n",
      "Epoch 6850, reconstruction losses: 0.023650035014053952, regression losses: 0.11091112228819115, validation losses: 0.3972294863133296\n",
      "Epoch 6851, reconstruction losses: 0.025242106931027394, regression losses: 0.11595328359191168, validation losses: 0.3929823986071234\n",
      "Epoch 6852, reconstruction losses: 0.019545373068991997, regression losses: 0.09966673859094898, validation losses: 0.4556933128880809\n",
      "Epoch 6853, reconstruction losses: 0.022176053677717498, regression losses: 0.1142912881560374, validation losses: 0.5055251633008783\n",
      "Epoch 6854, reconstruction losses: 0.023120043735719877, regression losses: 0.16213350392898174, validation losses: 0.5052885444128914\n",
      "Epoch 6855, reconstruction losses: 0.0245203579763139, regression losses: 0.13771806989131893, validation losses: 0.42982239766761743\n",
      "Epoch 6856, reconstruction losses: 0.023364539766272605, regression losses: 0.10257694081820068, validation losses: 0.4561318775831066\n",
      "Epoch 6857, reconstruction losses: 0.022670042464697747, regression losses: 0.13201421820006548, validation losses: 0.5329779856359125\n",
      "Epoch 6858, reconstruction losses: 0.024702572221865247, regression losses: 0.10743656744220377, validation losses: 0.44693750454397424\n",
      "Epoch 6859, reconstruction losses: 0.02121162450936096, regression losses: 0.12966033291774434, validation losses: 0.43023587912704825\n",
      "Epoch 6860, reconstruction losses: 0.024073082788088142, regression losses: 0.14763745441415901, validation losses: 0.48085670263360847\n",
      "Epoch 6861, reconstruction losses: 0.028255498316191188, regression losses: 0.27827218877688176, validation losses: 0.6444219269605757\n",
      "Epoch 6862, reconstruction losses: 0.02484744104040229, regression losses: 0.16865244910294158, validation losses: 0.7349239160095886\n",
      "Epoch 6863, reconstruction losses: 0.02357885767821458, regression losses: 0.1322695234181596, validation losses: 0.4863088858775415\n",
      "Epoch 6864, reconstruction losses: 0.028423917154429084, regression losses: 0.14156549498403345, validation losses: 0.45378683147922755\n",
      "Epoch 6865, reconstruction losses: 0.02456951987982557, regression losses: 0.10759861220815009, validation losses: 0.4265022811131843\n",
      "Epoch 6866, reconstruction losses: 0.02434355349060178, regression losses: 0.10692208007122807, validation losses: 0.49046872571309874\n",
      "Epoch 6867, reconstruction losses: 0.024198382064923203, regression losses: 0.17812069685348125, validation losses: 0.5289695488250317\n",
      "Epoch 6868, reconstruction losses: 0.02308506574491009, regression losses: 0.11451457930901524, validation losses: 0.6355743449037152\n",
      "Epoch 6869, reconstruction losses: 0.02372021668661611, regression losses: 0.1147157173652648, validation losses: 0.612573511038965\n",
      "Epoch 6870, reconstruction losses: 0.020843867731240216, regression losses: 0.11163472051432459, validation losses: 0.47305320895708486\n",
      "Epoch 6871, reconstruction losses: 0.02353611337595439, regression losses: 0.10745459804575172, validation losses: 0.41818480204896613\n",
      "Epoch 6872, reconstruction losses: 0.024519002598674598, regression losses: 0.12206763780144539, validation losses: 0.531371928960311\n",
      "Epoch 6873, reconstruction losses: 0.022585842202910978, regression losses: 0.11508709995560985, validation losses: 0.578865843833523\n",
      "Epoch 6874, reconstruction losses: 0.030482209718640574, regression losses: 0.27661531467449685, validation losses: 0.4507382173792236\n",
      "Epoch 6875, reconstruction losses: 0.026862682365291372, regression losses: 0.14995001596379162, validation losses: 0.5935455871754306\n",
      "Epoch 6876, reconstruction losses: 0.02126916661481708, regression losses: 0.14112419193104236, validation losses: 0.49424491696521344\n",
      "Epoch 6877, reconstruction losses: 0.021450774732190984, regression losses: 0.1588540510206104, validation losses: 0.5870024398877193\n",
      "Epoch 6878, reconstruction losses: 0.021959178161896027, regression losses: 0.12479374139226662, validation losses: 0.565756385327922\n",
      "Epoch 6879, reconstruction losses: 0.02028633643020509, regression losses: 0.10567688961234284, validation losses: 0.5237281395895492\n",
      "Epoch 6880, reconstruction losses: 0.02324104078542725, regression losses: 0.1343965786196173, validation losses: 0.45177534653798757\n",
      "Epoch 6881, reconstruction losses: 0.021270188129737307, regression losses: 0.09399417872345027, validation losses: 0.4568252317691984\n",
      "Epoch 6882, reconstruction losses: 0.023101556529771618, regression losses: 0.1025824640843522, validation losses: 0.44082940125904957\n",
      "Epoch 6883, reconstruction losses: 0.020830252650877703, regression losses: 0.10695426070897589, validation losses: 0.48911107869527026\n",
      "Epoch 6884, reconstruction losses: 0.020607030965865084, regression losses: 0.11219749371503554, validation losses: 0.46911040783014557\n",
      "Epoch 6885, reconstruction losses: 0.027812077889962056, regression losses: 0.1700371146617345, validation losses: 0.4726549368883951\n",
      "Epoch 6886, reconstruction losses: 0.024419487961358306, regression losses: 0.11608283879072247, validation losses: 0.6462009047150582\n",
      "Epoch 6887, reconstruction losses: 0.022600165069298503, regression losses: 0.12249346305776804, validation losses: 0.5023146018378968\n",
      "Epoch 6888, reconstruction losses: 0.021701652086409548, regression losses: 0.09491478501765763, validation losses: 0.42259786608815536\n",
      "Epoch 6889, reconstruction losses: 0.024584479916457166, regression losses: 0.08360194606345321, validation losses: 0.42188511590411404\n",
      "Epoch 6890, reconstruction losses: 0.02353464216468661, regression losses: 0.11571910956152347, validation losses: 0.4363733752317024\n",
      "Epoch 6891, reconstruction losses: 0.023868666268798126, regression losses: 0.10462072322125672, validation losses: 0.48292119823729684\n",
      "Epoch 6892, reconstruction losses: 0.024505876545972458, regression losses: 0.10614577279185486, validation losses: 0.5431618558347896\n",
      "Epoch 6893, reconstruction losses: 0.02114840054310229, regression losses: 0.09564372962372655, validation losses: 0.48090564254173707\n",
      "Epoch 6894, reconstruction losses: 0.023566789066134915, regression losses: 0.12990856092584996, validation losses: 0.4258818368355722\n",
      "Epoch 6895, reconstruction losses: 0.02322972641833417, regression losses: 0.098977785466555, validation losses: 0.43487558311886404\n",
      "Epoch 6896, reconstruction losses: 0.022517558486113493, regression losses: 0.12427677678759708, validation losses: 0.42158082399693775\n",
      "Epoch 6897, reconstruction losses: 0.02488953750955117, regression losses: 0.14493555300181665, validation losses: 0.44030462984553187\n",
      "Epoch 6898, reconstruction losses: 0.021360537107186137, regression losses: 0.07123950305185264, validation losses: 0.4779478444303368\n",
      "Epoch 6899, reconstruction losses: 0.02103932234943775, regression losses: 0.12348953941786074, validation losses: 0.4857167760528039\n",
      "Epoch 6900, reconstruction losses: 0.024043500889218455, regression losses: 0.1744618890098934, validation losses: 0.42879293664914436\n",
      "Epoch 6901, reconstruction losses: 0.021485425979310517, regression losses: 0.0916220244795601, validation losses: 0.4066687654990759\n",
      "Epoch 6902, reconstruction losses: 0.024237816424444003, regression losses: 0.1185236377020449, validation losses: 0.41789915947752876\n",
      "Epoch 6903, reconstruction losses: 0.02111410179196973, regression losses: 0.0929557612303052, validation losses: 0.44026477765657557\n",
      "Epoch 6904, reconstruction losses: 0.021954078878329803, regression losses: 0.12504514422749108, validation losses: 0.4598298205576496\n",
      "Epoch 6905, reconstruction losses: 0.02111006883691926, regression losses: 0.12401159314118348, validation losses: 0.5083897886841696\n",
      "Epoch 6906, reconstruction losses: 0.022323021631493335, regression losses: 0.1465170184917565, validation losses: 0.4499502673436317\n",
      "Epoch 6907, reconstruction losses: 0.02363671423349913, regression losses: 0.13478852153514292, validation losses: 0.41196666397138537\n",
      "Epoch 6908, reconstruction losses: 0.027024548983815226, regression losses: 0.1136766259614448, validation losses: 0.41982619496916485\n",
      "Epoch 6909, reconstruction losses: 0.022281570316055814, regression losses: 0.11213325296082248, validation losses: 0.4880700117420609\n",
      "Epoch 6910, reconstruction losses: 0.02329563209693758, regression losses: 0.1498666808476173, validation losses: 0.59195563994924\n",
      "Epoch 6911, reconstruction losses: 0.02440424793557598, regression losses: 0.11444408914921454, validation losses: 0.4852151831523611\n",
      "Epoch 6912, reconstruction losses: 0.021968412501246523, regression losses: 0.12661275661873303, validation losses: 0.4141788207404022\n",
      "Epoch 6913, reconstruction losses: 0.021928770270979937, regression losses: 0.11164324145843232, validation losses: 0.41252829865569046\n",
      "Epoch 6914, reconstruction losses: 0.02277324279992776, regression losses: 0.12083773895090658, validation losses: 0.4544920484435626\n",
      "Epoch 6915, reconstruction losses: 0.023745601478411888, regression losses: 0.1603030571332883, validation losses: 0.5548728422945486\n",
      "Epoch 6916, reconstruction losses: 0.02803823450284241, regression losses: 0.19051464711523253, validation losses: 0.5257474400989853\n",
      "Epoch 6917, reconstruction losses: 0.02543471034945565, regression losses: 0.17374870060675696, validation losses: 0.4668105355035784\n",
      "Epoch 6918, reconstruction losses: 0.022450882302803232, regression losses: 0.11751640630414015, validation losses: 0.5124759968466079\n",
      "Epoch 6919, reconstruction losses: 0.023166500992857598, regression losses: 0.11636298397581457, validation losses: 0.6385330857240414\n",
      "Epoch 6920, reconstruction losses: 0.02154971908929724, regression losses: 0.12016654055748813, validation losses: 0.5902257198073004\n",
      "Epoch 6921, reconstruction losses: 0.0242475853571787, regression losses: 0.0914457578331869, validation losses: 0.4979144324249232\n",
      "Epoch 6922, reconstruction losses: 0.025929209645438364, regression losses: 0.1500609490011925, validation losses: 0.445630891350349\n",
      "Epoch 6923, reconstruction losses: 0.021332314724371675, regression losses: 0.11001382860472278, validation losses: 0.48907595030234213\n",
      "Epoch 6924, reconstruction losses: 0.023399561071652596, regression losses: 0.10791892796554829, validation losses: 0.4791358891872605\n",
      "Epoch 6925, reconstruction losses: 0.02434182234649955, regression losses: 0.34768903605347135, validation losses: 0.5436077290338565\n",
      "Epoch 6926, reconstruction losses: 0.0223623991122493, regression losses: 0.15117195248551557, validation losses: 0.797904527139086\n",
      "Epoch 6927, reconstruction losses: 0.024984489721992634, regression losses: 0.13289340119073656, validation losses: 0.6073041579807674\n",
      "Epoch 6928, reconstruction losses: 0.026154787289340755, regression losses: 0.13781080626513714, validation losses: 0.6067390476084343\n",
      "Epoch 6929, reconstruction losses: 0.022094710424491272, regression losses: 0.14143863970518208, validation losses: 0.6579619337462314\n",
      "Epoch 6930, reconstruction losses: 0.03084927452184532, regression losses: 0.22751173448878906, validation losses: 0.5394750938874042\n",
      "Epoch 6931, reconstruction losses: 0.02564017405627688, regression losses: 0.10875804161781066, validation losses: 0.5609422373789541\n",
      "Epoch 6932, reconstruction losses: 0.025347508083399212, regression losses: 0.15013842175117756, validation losses: 0.548087676454901\n",
      "Epoch 6933, reconstruction losses: 0.02234086884483173, regression losses: 0.10883791228706699, validation losses: 0.5943253182272398\n",
      "Epoch 6934, reconstruction losses: 0.021184747290238698, regression losses: 0.09037018934490586, validation losses: 0.650304207133763\n",
      "Epoch 6935, reconstruction losses: 0.023146033245529787, regression losses: 0.0912609411482345, validation losses: 0.5552225613400004\n",
      "Epoch 6936, reconstruction losses: 0.023930289334259704, regression losses: 0.15445292122206578, validation losses: 0.5093249056768717\n",
      "Epoch 6937, reconstruction losses: 0.02295720577785469, regression losses: 0.11286197039596722, validation losses: 0.5462578153502062\n",
      "Epoch 6938, reconstruction losses: 0.022920474950382918, regression losses: 0.10712851472978607, validation losses: 0.572392018432325\n",
      "Epoch 6939, reconstruction losses: 0.022542560244602952, regression losses: 0.12965088117687706, validation losses: 0.5121280229387397\n",
      "Epoch 6940, reconstruction losses: 0.02059048453268639, regression losses: 0.11100488200720296, validation losses: 0.4434040000794834\n",
      "Epoch 6941, reconstruction losses: 0.026767697115631806, regression losses: 0.52451344190717, validation losses: 0.459264998873693\n",
      "Epoch 6942, reconstruction losses: 0.023110336709509925, regression losses: 0.14212478744043477, validation losses: 0.6862008162143896\n",
      "Epoch 6943, reconstruction losses: 0.02420248756820866, regression losses: 0.15505114098236095, validation losses: 0.5542586361826934\n",
      "Epoch 6944, reconstruction losses: 0.02190950868194049, regression losses: 0.10209334779063668, validation losses: 0.5121576363422462\n",
      "Epoch 6945, reconstruction losses: 0.022163222684642186, regression losses: 0.14191605652563247, validation losses: 0.5679329143579596\n",
      "Epoch 6946, reconstruction losses: 0.024098907171257813, regression losses: 0.11777809708084294, validation losses: 0.6263708439168586\n",
      "Epoch 6947, reconstruction losses: 0.022903428938639083, regression losses: 0.1931885281248495, validation losses: 0.5317737507389091\n",
      "Epoch 6948, reconstruction losses: 0.021219492756871846, regression losses: 0.13301150252959174, validation losses: 0.5522361892268443\n",
      "Epoch 6949, reconstruction losses: 0.024175197379261996, regression losses: 0.12530281227914064, validation losses: 0.4967281972367689\n",
      "Epoch 6950, reconstruction losses: 0.01962620824327612, regression losses: 0.1227673421672818, validation losses: 0.4366702100004026\n",
      "Epoch 6951, reconstruction losses: 0.02255586843801583, regression losses: 0.12334787354961295, validation losses: 0.41096214827536\n",
      "Epoch 6952, reconstruction losses: 0.021663354476617738, regression losses: 0.11183699950655096, validation losses: 0.46398661854021994\n",
      "Epoch 6953, reconstruction losses: 0.02588314096690546, regression losses: 0.1169674396110639, validation losses: 0.45433754921879854\n",
      "Epoch 6954, reconstruction losses: 0.020798232747182253, regression losses: 0.11147986636412478, validation losses: 0.41794975845645993\n",
      "Epoch 6955, reconstruction losses: 0.02344993502667407, regression losses: 0.11649411437318621, validation losses: 0.40889341538348506\n",
      "Epoch 6956, reconstruction losses: 0.019892403094291237, regression losses: 0.10705422882378, validation losses: 0.42278622680652217\n",
      "Epoch 6957, reconstruction losses: 0.020869312279076603, regression losses: 0.10486970155091706, validation losses: 0.4436199966804067\n",
      "Epoch 6958, reconstruction losses: 0.022774252935656714, regression losses: 0.0965201342686984, validation losses: 0.4188984015456829\n",
      "Epoch 6959, reconstruction losses: 0.021219850700347827, regression losses: 0.10931080910209114, validation losses: 0.4101912270651685\n",
      "Epoch 6960, reconstruction losses: 0.02407410453188886, regression losses: 0.10866003791246968, validation losses: 0.42517990790072885\n",
      "Epoch 6961, reconstruction losses: 0.021210010696998377, regression losses: 0.06588558512915392, validation losses: 0.448625843197193\n",
      "Epoch 6962, reconstruction losses: 0.02289362829153687, regression losses: 0.08421366017757546, validation losses: 0.4963112193697284\n",
      "Epoch 6963, reconstruction losses: 0.022218861242785992, regression losses: 0.10002939450709367, validation losses: 0.4418381629709228\n",
      "Epoch 6964, reconstruction losses: 0.020691174670149054, regression losses: 0.10382788293522702, validation losses: 0.42075785270600885\n",
      "Epoch 6965, reconstruction losses: 0.022611314963690853, regression losses: 0.12016334978195217, validation losses: 0.42383880374992416\n",
      "Epoch 6966, reconstruction losses: 0.02426343489954601, regression losses: 0.13452886183706783, validation losses: 0.4673064592841929\n",
      "Epoch 6967, reconstruction losses: 0.024011703139777046, regression losses: 0.12462719010970338, validation losses: 0.572780764901749\n",
      "Epoch 6968, reconstruction losses: 0.02266047497324479, regression losses: 0.11896909776438616, validation losses: 0.562912103989979\n",
      "Epoch 6969, reconstruction losses: 0.02051229461764282, regression losses: 0.10670269199940234, validation losses: 0.4948477603475574\n",
      "Epoch 6970, reconstruction losses: 0.023810817009351563, regression losses: 0.10512306808042483, validation losses: 0.45144005131873727\n",
      "Epoch 6971, reconstruction losses: 0.022777116615255538, regression losses: 0.08751514230081224, validation losses: 0.45185447165775716\n",
      "Epoch 6972, reconstruction losses: 0.02025612633321071, regression losses: 0.14272234528638358, validation losses: 0.5028482744826424\n",
      "Epoch 6973, reconstruction losses: 0.02119975954856289, regression losses: 0.12930978017414635, validation losses: 0.5528426825325048\n",
      "Epoch 6974, reconstruction losses: 0.024934760902849275, regression losses: 0.12185646146145879, validation losses: 0.5392526673830325\n",
      "Epoch 6975, reconstruction losses: 0.024731924185110388, regression losses: 0.11783819351196921, validation losses: 0.5437060999688915\n",
      "Epoch 6976, reconstruction losses: 0.024672315080891988, regression losses: 0.1316336207503732, validation losses: 0.4618263837239875\n",
      "Epoch 6977, reconstruction losses: 0.0250021398263364, regression losses: 0.25396585982833153, validation losses: 0.4627525909895126\n",
      "Epoch 6978, reconstruction losses: 0.02130137461765871, regression losses: 0.12611492786025516, validation losses: 0.8260571349158005\n",
      "Epoch 6979, reconstruction losses: 0.024038074821299816, regression losses: 0.21420932124482528, validation losses: 0.6924468076614033\n",
      "Epoch 6980, reconstruction losses: 0.024151535915988547, regression losses: 0.18185066997305152, validation losses: 0.7159954067538691\n",
      "Epoch 6981, reconstruction losses: 0.02374889468722258, regression losses: 0.11422356046121011, validation losses: 0.7406487246407677\n",
      "Epoch 6982, reconstruction losses: 0.02529819779059611, regression losses: 0.14798737894938807, validation losses: 0.5454476142655735\n",
      "Epoch 6983, reconstruction losses: 0.026299871109149737, regression losses: 0.11166524908133883, validation losses: 0.5079687416848564\n",
      "Epoch 6984, reconstruction losses: 0.026587323625849698, regression losses: 0.19731333731544146, validation losses: 0.5537798405047872\n",
      "Epoch 6985, reconstruction losses: 0.02339614113034325, regression losses: 0.3889953084743306, validation losses: 0.5343027235634998\n",
      "Epoch 6986, reconstruction losses: 0.021687206719440077, regression losses: 0.11349804271836163, validation losses: 0.6739918708083656\n",
      "Epoch 6987, reconstruction losses: 0.023564822695824918, regression losses: 0.12111085906853233, validation losses: 0.573625789482631\n",
      "Epoch 6988, reconstruction losses: 0.023861201408491427, regression losses: 0.11003170836285421, validation losses: 0.5501001371524612\n",
      "Epoch 6989, reconstruction losses: 0.02287117235841382, regression losses: 0.12144219276759903, validation losses: 0.5074126102041218\n",
      "Epoch 6990, reconstruction losses: 0.024086048923608418, regression losses: 0.12856800626836967, validation losses: 0.4883381474492521\n",
      "Epoch 6991, reconstruction losses: 0.020581441446789975, regression losses: 0.10389570457795103, validation losses: 0.5015483398770278\n",
      "Epoch 6992, reconstruction losses: 0.02322333133118434, regression losses: 0.12663291481372987, validation losses: 0.5466847916349004\n",
      "Epoch 6993, reconstruction losses: 0.02399929445127761, regression losses: 0.10531285904674985, validation losses: 0.5126758149552141\n",
      "Epoch 6994, reconstruction losses: 0.025826818841527075, regression losses: 0.11650302296268839, validation losses: 0.46319695728252364\n",
      "Epoch 6995, reconstruction losses: 0.021154315534602286, regression losses: 0.17201145768554765, validation losses: 0.4452773712457076\n",
      "Epoch 6996, reconstruction losses: 0.024149350899992702, regression losses: 0.11115394869502708, validation losses: 0.5005244153731998\n",
      "Epoch 6997, reconstruction losses: 0.021623445155539184, regression losses: 0.13262277270695802, validation losses: 0.49719223817413816\n",
      "Epoch 6998, reconstruction losses: 0.021097413060277515, regression losses: 0.11891064760548246, validation losses: 0.614711659998256\n",
      "Epoch 6999, reconstruction losses: 0.025618741386120598, regression losses: 0.14313769451189345, validation losses: 0.5960062069969695\n",
      "Epoch 7000, reconstruction losses: 0.021299338403598454, regression losses: 0.08258647163914307, validation losses: 0.4960284846105526\n",
      "Epoch 7001, reconstruction losses: 0.02193157196178883, regression losses: 0.1368862763559613, validation losses: 0.4590368012101405\n",
      "Epoch 7002, reconstruction losses: 0.023134514393953823, regression losses: 0.09836174357140107, validation losses: 0.4266608350741735\n",
      "Epoch 7003, reconstruction losses: 0.022535555155846838, regression losses: 0.11798077692328465, validation losses: 0.430880379562545\n",
      "Epoch 7004, reconstruction losses: 0.026796641207855458, regression losses: 0.09291403778218288, validation losses: 0.4513158098395239\n",
      "Epoch 7005, reconstruction losses: 0.02309679737258174, regression losses: 0.11845965975913612, validation losses: 0.4381980115133124\n",
      "Epoch 7006, reconstruction losses: 0.022449111374391397, regression losses: 0.10058708221867063, validation losses: 0.44315073828948576\n",
      "Epoch 7007, reconstruction losses: 0.024373465216027096, regression losses: 0.09619722385589395, validation losses: 0.43867537252018424\n",
      "Epoch 7008, reconstruction losses: 0.024551811136595908, regression losses: 0.16993204866248524, validation losses: 0.44040302226239797\n",
      "Epoch 7009, reconstruction losses: 0.02284558610482719, regression losses: 0.12459910589899667, validation losses: 0.4635150937723489\n",
      "Epoch 7010, reconstruction losses: 0.023714931967636684, regression losses: 0.14573801183471607, validation losses: 0.5374620998238345\n",
      "Epoch 7011, reconstruction losses: 0.023518140662364795, regression losses: 0.1250907509665964, validation losses: 0.5222438888570485\n",
      "Epoch 7012, reconstruction losses: 0.024051733977313312, regression losses: 0.14118377800754395, validation losses: 0.447313549193167\n",
      "Epoch 7013, reconstruction losses: 0.022368654247267777, regression losses: 0.09887662645644954, validation losses: 0.4788464779012148\n",
      "Epoch 7014, reconstruction losses: 0.02471568767265332, regression losses: 0.0895645159253057, validation losses: 0.5401775028605129\n",
      "Epoch 7015, reconstruction losses: 0.024337745155709457, regression losses: 0.13886144923325972, validation losses: 0.50905420181994\n",
      "Epoch 7016, reconstruction losses: 0.023833405947150152, regression losses: 0.13672586665208042, validation losses: 0.5412343670341856\n",
      "Epoch 7017, reconstruction losses: 0.02279708097483236, regression losses: 0.11837834828866904, validation losses: 0.5579477769945517\n",
      "Epoch 7018, reconstruction losses: 0.024368742790976474, regression losses: 0.14085142197850442, validation losses: 0.44587247987113093\n",
      "Epoch 7019, reconstruction losses: 0.021967640050413035, regression losses: 0.12143612414734059, validation losses: 0.4613626692854366\n",
      "Epoch 7020, reconstruction losses: 0.024180934144293773, regression losses: 0.1444932389010477, validation losses: 0.42897169060475226\n",
      "Epoch 7021, reconstruction losses: 0.02180144590780231, regression losses: 0.10523391040490214, validation losses: 0.5392365609742289\n",
      "Epoch 7022, reconstruction losses: 0.025882028675833675, regression losses: 0.31487852211029466, validation losses: 0.5273160903957687\n",
      "Epoch 7023, reconstruction losses: 0.022711869578525185, regression losses: 0.14492153306712904, validation losses: 0.6334757613292271\n",
      "Epoch 7024, reconstruction losses: 0.023207850033568806, regression losses: 0.12933432740758638, validation losses: 0.5141527811014135\n",
      "Epoch 7025, reconstruction losses: 0.02151288061862719, regression losses: 0.10089197178458936, validation losses: 0.47471094166115935\n",
      "Epoch 7026, reconstruction losses: 0.02429797816757406, regression losses: 0.13181921171216268, validation losses: 0.5027038311592258\n",
      "Epoch 7027, reconstruction losses: 0.024729350686593356, regression losses: 0.11766515487587183, validation losses: 0.4666287116462486\n",
      "Epoch 7028, reconstruction losses: 0.022511182643511294, regression losses: 0.10896063257312542, validation losses: 0.4468638879317467\n",
      "Epoch 7029, reconstruction losses: 0.02255496131796645, regression losses: 0.09682641549415924, validation losses: 0.5254469137431176\n",
      "Epoch 7030, reconstruction losses: 0.02208081132809373, regression losses: 0.08852812894889842, validation losses: 0.4799186015454023\n",
      "Epoch 7031, reconstruction losses: 0.024915738705186687, regression losses: 0.11816686737462608, validation losses: 0.41902122376216144\n",
      "Epoch 7032, reconstruction losses: 0.020698721264096893, regression losses: 0.099234890085348, validation losses: 0.4731683768824165\n",
      "Epoch 7033, reconstruction losses: 0.02177777908206893, regression losses: 0.1420101121214553, validation losses: 0.44450153936221665\n",
      "Epoch 7034, reconstruction losses: 0.023194429485289738, regression losses: 0.10996035069498941, validation losses: 0.4390106418649885\n",
      "Epoch 7035, reconstruction losses: 0.023748093641904333, regression losses: 0.1288208742876362, validation losses: 0.46552231992439685\n",
      "Epoch 7036, reconstruction losses: 0.023201573985984162, regression losses: 0.12020339900355043, validation losses: 0.5403215875179409\n",
      "Epoch 7037, reconstruction losses: 0.02291612198743078, regression losses: 0.16097606420464833, validation losses: 0.5063441270017027\n",
      "Epoch 7038, reconstruction losses: 0.021923029328073, regression losses: 0.11409751544663684, validation losses: 0.5501863593756711\n",
      "Epoch 7039, reconstruction losses: 0.02580307731046989, regression losses: 0.1457929254759488, validation losses: 0.42230714572514827\n",
      "Epoch 7040, reconstruction losses: 0.023041946339921068, regression losses: 0.13010726495129804, validation losses: 0.4132778402485686\n",
      "Epoch 7041, reconstruction losses: 0.021740093248459363, regression losses: 0.12749435003486576, validation losses: 0.43883131118211005\n",
      "Epoch 7042, reconstruction losses: 0.02468632514904317, regression losses: 0.14895350941854135, validation losses: 0.5020684513239078\n",
      "Epoch 7043, reconstruction losses: 0.02113568144958156, regression losses: 0.13318527032192934, validation losses: 0.6172913782476342\n",
      "Epoch 7044, reconstruction losses: 0.023262651121718755, regression losses: 0.13300051354757478, validation losses: 0.5415544265738443\n",
      "Epoch 7045, reconstruction losses: 0.024156157904559158, regression losses: 0.14377127013885402, validation losses: 0.4342524417024184\n",
      "Epoch 7046, reconstruction losses: 0.021014780421054032, regression losses: 0.10662603230909239, validation losses: 0.4188969280263971\n",
      "Epoch 7047, reconstruction losses: 0.024510521729706414, regression losses: 0.12036519989603414, validation losses: 0.4768344943707841\n",
      "Epoch 7048, reconstruction losses: 0.02293275543056037, regression losses: 0.12593962310941983, validation losses: 0.4861330523698039\n",
      "Epoch 7049, reconstruction losses: 0.02328307243437455, regression losses: 0.09048108969062914, validation losses: 0.4212604313664824\n",
      "Epoch 7050, reconstruction losses: 0.02451690019529926, regression losses: 0.14016218374022035, validation losses: 0.44478582051282545\n",
      "Epoch 7051, reconstruction losses: 0.022644309306568647, regression losses: 0.12698271042886913, validation losses: 0.4458883400589613\n",
      "Epoch 7052, reconstruction losses: 0.02265959781712818, regression losses: 0.11504163534266292, validation losses: 0.43902993657695333\n",
      "Epoch 7053, reconstruction losses: 0.02375988388640759, regression losses: 0.13358054427850713, validation losses: 0.46726453084352304\n",
      "Epoch 7054, reconstruction losses: 0.024758933176181813, regression losses: 0.1481400696350636, validation losses: 0.5352809229932366\n",
      "Epoch 7055, reconstruction losses: 0.02297696688028635, regression losses: 0.10679263882441893, validation losses: 0.5890185367214236\n",
      "Epoch 7056, reconstruction losses: 0.024907876412238347, regression losses: 0.11093468889863724, validation losses: 0.509728452894784\n",
      "Epoch 7057, reconstruction losses: 0.0210996956037307, regression losses: 0.10740384576748357, validation losses: 0.4377740794668852\n",
      "Epoch 7058, reconstruction losses: 0.02188715116602529, regression losses: 0.11559777870780408, validation losses: 0.4507134346080236\n",
      "Epoch 7059, reconstruction losses: 0.02084223065769518, regression losses: 0.1206517093484612, validation losses: 0.5253845695289475\n",
      "Epoch 7060, reconstruction losses: 0.02011023343434166, regression losses: 0.097786913261661, validation losses: 0.5329688473293059\n",
      "Epoch 7061, reconstruction losses: 0.02501747212713515, regression losses: 0.14569038698913045, validation losses: 0.4587674198498949\n",
      "Epoch 7062, reconstruction losses: 0.026667388678230642, regression losses: 0.21128295044423692, validation losses: 0.4559919525143426\n",
      "Epoch 7063, reconstruction losses: 0.021380838830475504, regression losses: 0.13950510386215803, validation losses: 0.6955681647911154\n",
      "Epoch 7064, reconstruction losses: 0.020173726086931677, regression losses: 0.13704172842276197, validation losses: 0.5751095510771861\n",
      "Epoch 7065, reconstruction losses: 0.02139057229180509, regression losses: 0.09396165278603258, validation losses: 0.4596522068959177\n",
      "Epoch 7066, reconstruction losses: 0.023282045862637622, regression losses: 0.12771435820591484, validation losses: 0.4521137256022173\n",
      "Epoch 7067, reconstruction losses: 0.020077633870599708, regression losses: 0.10954932421251853, validation losses: 0.46011984467684697\n",
      "Epoch 7068, reconstruction losses: 0.021974772479785343, regression losses: 0.07849528692379786, validation losses: 0.4956304705182729\n",
      "Epoch 7069, reconstruction losses: 0.020718842459048484, regression losses: 0.11284789641130312, validation losses: 0.49631041606282855\n",
      "Epoch 7070, reconstruction losses: 0.020062653997406983, regression losses: 0.1599126492625817, validation losses: 0.4392152698631634\n",
      "Epoch 7071, reconstruction losses: 0.021827000961274177, regression losses: 0.12662017401915318, validation losses: 0.4661319804809791\n",
      "Epoch 7072, reconstruction losses: 0.022831312353770415, regression losses: 0.13544167679242824, validation losses: 0.4856130993227529\n",
      "Epoch 7073, reconstruction losses: 0.02444218177036045, regression losses: 0.10726605446318058, validation losses: 0.47770309419576673\n",
      "Epoch 7074, reconstruction losses: 0.02302603572868052, regression losses: 0.11387646815396268, validation losses: 0.4145178928921885\n",
      "Epoch 7075, reconstruction losses: 0.021953114161933473, regression losses: 0.13395217911882135, validation losses: 0.5402168490226752\n",
      "Epoch 7076, reconstruction losses: 0.021360559814987252, regression losses: 0.10220259855333946, validation losses: 0.489956226317711\n",
      "Epoch 7077, reconstruction losses: 0.022660221740060073, regression losses: 0.13920935133645, validation losses: 0.5099640932918689\n",
      "Epoch 7078, reconstruction losses: 0.022050205889012613, regression losses: 0.10889010375636547, validation losses: 0.4914595819604784\n",
      "Epoch 7079, reconstruction losses: 0.02143792535441465, regression losses: 0.0926736698459416, validation losses: 0.43833946975003696\n",
      "Epoch 7080, reconstruction losses: 0.022647354427820458, regression losses: 0.0899815559090364, validation losses: 0.466871097265928\n",
      "Epoch 7081, reconstruction losses: 0.02544819289911944, regression losses: 0.13019318386761902, validation losses: 0.45308207049051796\n",
      "Epoch 7082, reconstruction losses: 0.022861999556302866, regression losses: 0.16469863079944116, validation losses: 0.4589478320321277\n",
      "Epoch 7083, reconstruction losses: 0.021842952088030745, regression losses: 0.12712912525656436, validation losses: 0.5377115823815629\n",
      "Epoch 7084, reconstruction losses: 0.023050440974626902, regression losses: 0.14373225262696201, validation losses: 0.44635030008725235\n",
      "Epoch 7085, reconstruction losses: 0.020965254115072274, regression losses: 0.2078824730842163, validation losses: 0.42936627250430615\n",
      "Epoch 7086, reconstruction losses: 0.023876364964816835, regression losses: 0.09942277473364981, validation losses: 0.416449363457133\n",
      "Epoch 7087, reconstruction losses: 0.02166949879785376, regression losses: 0.11661063941506689, validation losses: 0.43346723350923744\n",
      "Epoch 7088, reconstruction losses: 0.02139771848639523, regression losses: 0.11546723310487575, validation losses: 0.43516959562354485\n",
      "Epoch 7089, reconstruction losses: 0.020678527857015037, regression losses: 0.1077462304771074, validation losses: 0.4322733612378819\n",
      "Epoch 7090, reconstruction losses: 0.021491294974867774, regression losses: 0.11642339160979319, validation losses: 0.46181108748353694\n",
      "Epoch 7091, reconstruction losses: 0.022109586653315742, regression losses: 0.08891976032490526, validation losses: 0.4740247537236158\n",
      "Epoch 7092, reconstruction losses: 0.023022387490441436, regression losses: 0.10527912870846334, validation losses: 0.455647143796811\n",
      "Epoch 7093, reconstruction losses: 0.02067414095099785, regression losses: 0.07326498959543896, validation losses: 0.44247431026596723\n",
      "Epoch 7094, reconstruction losses: 0.0240893189839955, regression losses: 0.3809526234884575, validation losses: 0.44878926041187106\n",
      "Epoch 7095, reconstruction losses: 0.02267904705689991, regression losses: 0.10383938764090375, validation losses: 0.6581565415730247\n",
      "Epoch 7096, reconstruction losses: 0.021791856295153043, regression losses: 0.14828132275555944, validation losses: 0.5387929981283917\n",
      "Epoch 7097, reconstruction losses: 0.023433799315664163, regression losses: 0.12663341028639896, validation losses: 0.5193216345905236\n",
      "Epoch 7098, reconstruction losses: 0.02423054937592083, regression losses: 0.12549400219512624, validation losses: 0.6124691646296427\n",
      "Epoch 7099, reconstruction losses: 0.022145924769061517, regression losses: 0.11357529357615274, validation losses: 0.4558119870496937\n",
      "Epoch 7100, reconstruction losses: 0.022374673946501458, regression losses: 0.12258192337965386, validation losses: 0.49291610945529485\n",
      "Epoch 7101, reconstruction losses: 0.020659868138309986, regression losses: 0.13332406321620405, validation losses: 0.5921890149529107\n",
      "Epoch 7102, reconstruction losses: 0.02187173288237258, regression losses: 0.12022742672161493, validation losses: 0.6116154571632222\n",
      "Epoch 7103, reconstruction losses: 0.021438518033278026, regression losses: 0.1420170068242672, validation losses: 0.512107248331215\n",
      "Epoch 7104, reconstruction losses: 0.02131448504737829, regression losses: 0.0864990117142599, validation losses: 0.43483219275572715\n",
      "Epoch 7105, reconstruction losses: 0.024192206840269296, regression losses: 0.11088773899978391, validation losses: 0.4267688083772918\n",
      "Epoch 7106, reconstruction losses: 0.022681858289170905, regression losses: 0.12306525098168833, validation losses: 0.45085589178054175\n",
      "Epoch 7107, reconstruction losses: 0.019822799519583944, regression losses: 0.10120601373182965, validation losses: 0.5703484673757306\n",
      "Epoch 7108, reconstruction losses: 0.02049351990573271, regression losses: 0.11043979508707026, validation losses: 0.5083800487545966\n",
      "Epoch 7109, reconstruction losses: 0.02189704147032114, regression losses: 0.38669071043695585, validation losses: 0.5335519691752125\n",
      "Epoch 7110, reconstruction losses: 0.02312583653263449, regression losses: 0.1509672148674545, validation losses: 0.7149043629958668\n",
      "Epoch 7111, reconstruction losses: 0.02688447975126701, regression losses: 0.1161423550723013, validation losses: 0.5686839670094332\n",
      "Epoch 7112, reconstruction losses: 0.02465480065429156, regression losses: 0.16474707063680624, validation losses: 0.4963262683558601\n",
      "Epoch 7113, reconstruction losses: 0.021421223195086943, regression losses: 0.10774645675005348, validation losses: 0.5264366015351765\n",
      "Epoch 7114, reconstruction losses: 0.023502091456732346, regression losses: 0.12266590438745362, validation losses: 0.5229588756469112\n",
      "Epoch 7115, reconstruction losses: 0.021779871917839002, regression losses: 0.13217095477271673, validation losses: 0.6060644633715848\n",
      "Epoch 7116, reconstruction losses: 0.02140144805009877, regression losses: 0.1261893984959884, validation losses: 0.6131822410848843\n",
      "Epoch 7117, reconstruction losses: 0.02348790104649965, regression losses: 0.09289624986054987, validation losses: 0.49206832194448785\n",
      "Epoch 7118, reconstruction losses: 0.0206952739876732, regression losses: 0.09595467543521786, validation losses: 0.490194964822678\n",
      "Epoch 7119, reconstruction losses: 0.02230033443320425, regression losses: 0.10544916709270774, validation losses: 0.4800700851898815\n",
      "Epoch 7120, reconstruction losses: 0.023166862489279766, regression losses: 0.10660877869920136, validation losses: 0.534548987292486\n",
      "Epoch 7121, reconstruction losses: 0.024069619368838252, regression losses: 0.14127556719538642, validation losses: 0.6225103145622882\n",
      "Epoch 7122, reconstruction losses: 0.020406878934775254, regression losses: 0.1304174935299089, validation losses: 0.5498167228276865\n",
      "Epoch 7123, reconstruction losses: 0.019505623791135095, regression losses: 0.09915193981174984, validation losses: 0.44367709525927557\n",
      "Epoch 7124, reconstruction losses: 0.021829906871271593, regression losses: 0.11027211115886744, validation losses: 0.4763468298927572\n",
      "Epoch 7125, reconstruction losses: 0.02486864437948057, regression losses: 0.0870630965375334, validation losses: 0.5215736621707586\n",
      "Epoch 7126, reconstruction losses: 0.024636228664027357, regression losses: 0.1244503899726104, validation losses: 0.5155930494850662\n",
      "Epoch 7127, reconstruction losses: 0.022727794312573317, regression losses: 0.12586292954675005, validation losses: 0.4542763118622752\n",
      "Epoch 7128, reconstruction losses: 0.025031020794798683, regression losses: 0.11938544154896488, validation losses: 0.48588247730414424\n",
      "Epoch 7129, reconstruction losses: 0.022394281585863096, regression losses: 0.1406258657383199, validation losses: 0.5103253543969877\n",
      "Epoch 7130, reconstruction losses: 0.02142403906353702, regression losses: 0.13001734472115323, validation losses: 0.5103893537172768\n",
      "Epoch 7131, reconstruction losses: 0.021682989765860822, regression losses: 0.07650920393629645, validation losses: 0.502349687846643\n",
      "Epoch 7132, reconstruction losses: 0.02454270335927567, regression losses: 0.17317577755276253, validation losses: 0.47008031306052056\n",
      "Epoch 7133, reconstruction losses: 0.02146730855349862, regression losses: 0.13165190555228476, validation losses: 0.5086208017025734\n",
      "Epoch 7134, reconstruction losses: 0.023067780373244126, regression losses: 0.24318400442669147, validation losses: 0.45903000649221215\n",
      "Epoch 7135, reconstruction losses: 0.025059142809527202, regression losses: 0.11527365077334661, validation losses: 0.7346947374056679\n",
      "Epoch 7136, reconstruction losses: 0.022794795265444368, regression losses: 0.14826087598840723, validation losses: 0.6312346913641569\n",
      "Epoch 7137, reconstruction losses: 0.02557822229145592, regression losses: 0.17213205823422212, validation losses: 0.5237142001998861\n",
      "Epoch 7138, reconstruction losses: 0.024542338135856188, regression losses: 0.18566624879624355, validation losses: 0.48125662476843484\n",
      "Epoch 7139, reconstruction losses: 0.02309263425952738, regression losses: 0.12602306890987933, validation losses: 0.4207446146271353\n",
      "Epoch 7140, reconstruction losses: 0.022879567348381705, regression losses: 0.11987617416842128, validation losses: 0.5338055876810452\n",
      "Epoch 7141, reconstruction losses: 0.019826894829046073, regression losses: 0.09575762262706286, validation losses: 0.6742784642873689\n",
      "Epoch 7142, reconstruction losses: 0.02825451560471407, regression losses: 0.1386467769955435, validation losses: 0.5385186269313176\n",
      "Epoch 7143, reconstruction losses: 0.023341488465327968, regression losses: 0.15566104704251024, validation losses: 0.4622098519566702\n",
      "Epoch 7144, reconstruction losses: 0.020836010039030482, regression losses: 0.15796583444891973, validation losses: 0.42885665670676915\n",
      "Epoch 7145, reconstruction losses: 0.02174636495651248, regression losses: 0.10344839945759615, validation losses: 0.5831814088480176\n",
      "Epoch 7146, reconstruction losses: 0.019680595165588916, regression losses: 0.11422138246375405, validation losses: 0.5284282549968303\n",
      "Epoch 7147, reconstruction losses: 0.02153793155340374, regression losses: 0.12792471961576052, validation losses: 0.44770910777518197\n",
      "Epoch 7148, reconstruction losses: 0.022951868292695046, regression losses: 0.14917611272700004, validation losses: 0.43960302277686797\n",
      "Epoch 7149, reconstruction losses: 0.02178950337280457, regression losses: 0.10278709231413985, validation losses: 0.4687304236526085\n",
      "Epoch 7150, reconstruction losses: 0.023464073878985775, regression losses: 0.10836851871140045, validation losses: 0.4894293146082206\n",
      "Epoch 7151, reconstruction losses: 0.023759660292651127, regression losses: 0.11680088440054019, validation losses: 0.5055895841690577\n",
      "Epoch 7152, reconstruction losses: 0.020957906240334518, regression losses: 0.11268405313919799, validation losses: 0.46968342752792147\n",
      "Epoch 7153, reconstruction losses: 0.02282643495807174, regression losses: 0.09297542258169159, validation losses: 0.42978476925354514\n",
      "Epoch 7154, reconstruction losses: 0.026505868066883785, regression losses: 0.16558461677766423, validation losses: 0.42252238241335366\n",
      "Epoch 7155, reconstruction losses: 0.020712435077638702, regression losses: 0.09225303585354284, validation losses: 0.6391631074925834\n",
      "Epoch 7156, reconstruction losses: 0.02272904255936739, regression losses: 0.15458551683150065, validation losses: 0.5900746509036551\n",
      "Epoch 7157, reconstruction losses: 0.021176347856589565, regression losses: 0.10803147265309031, validation losses: 0.4511151374624217\n",
      "Epoch 7158, reconstruction losses: 0.023069429139568803, regression losses: 0.09744388366267859, validation losses: 0.4252197241370678\n",
      "Epoch 7159, reconstruction losses: 0.019510823011954632, regression losses: 0.11704800088150641, validation losses: 0.41806342548916176\n",
      "Epoch 7160, reconstruction losses: 0.022541325270282044, regression losses: 0.09937470623857653, validation losses: 0.4223043083355676\n",
      "Epoch 7161, reconstruction losses: 0.02460833649503129, regression losses: 0.11079630927038273, validation losses: 0.41260226302987796\n",
      "Epoch 7162, reconstruction losses: 0.02034121811246795, regression losses: 0.09011607236081007, validation losses: 0.46698235430232443\n",
      "Epoch 7163, reconstruction losses: 0.0216507087184762, regression losses: 0.11788326638885901, validation losses: 0.49176948364214385\n",
      "Epoch 7164, reconstruction losses: 0.022607633928581825, regression losses: 0.11297456797505297, validation losses: 0.4381735997072709\n",
      "Epoch 7165, reconstruction losses: 0.023230193784828452, regression losses: 0.09985661714270251, validation losses: 0.442110522290251\n",
      "Epoch 7166, reconstruction losses: 0.020185773735855554, regression losses: 0.10078568674142066, validation losses: 0.4704739372388439\n",
      "Epoch 7167, reconstruction losses: 0.024570684933529745, regression losses: 0.15148217423838461, validation losses: 0.5354272061734794\n",
      "Epoch 7168, reconstruction losses: 0.022356450963197463, regression losses: 0.10313706664113687, validation losses: 0.5678818180367564\n",
      "Epoch 7169, reconstruction losses: 0.024709479664217257, regression losses: 0.11953952652426901, validation losses: 0.45719603461040054\n",
      "Epoch 7170, reconstruction losses: 0.024114424609265588, regression losses: 0.37211283723575084, validation losses: 0.47089778224862205\n",
      "Epoch 7171, reconstruction losses: 0.023225019258223036, regression losses: 0.18330757206603254, validation losses: 0.6142701123957887\n",
      "Epoch 7172, reconstruction losses: 0.02275356591399727, regression losses: 0.11283761318418516, validation losses: 0.5118311785015351\n",
      "Epoch 7173, reconstruction losses: 0.022696419254964146, regression losses: 0.15837732466268925, validation losses: 0.5185733167186375\n",
      "Epoch 7174, reconstruction losses: 0.02328579856199979, regression losses: 0.10703965762585148, validation losses: 0.5048385556016889\n",
      "Epoch 7175, reconstruction losses: 0.021428249266943453, regression losses: 0.1178311282918988, validation losses: 0.44544855382022175\n",
      "Epoch 7176, reconstruction losses: 0.02113524147843909, regression losses: 0.11768030800379002, validation losses: 0.4633348851446728\n",
      "Epoch 7177, reconstruction losses: 0.02022589227286921, regression losses: 0.09808840314011717, validation losses: 0.47989981234062584\n",
      "Epoch 7178, reconstruction losses: 0.0224590212035981, regression losses: 0.11604426950395694, validation losses: 0.47982030961323785\n",
      "Epoch 7179, reconstruction losses: 0.026221644752852043, regression losses: 0.11010946325311743, validation losses: 0.46565857511878117\n",
      "Epoch 7180, reconstruction losses: 0.025141204413691123, regression losses: 0.1595565375470042, validation losses: 0.43899452309545406\n",
      "Epoch 7181, reconstruction losses: 0.02446992775537757, regression losses: 0.10719126465148829, validation losses: 0.44213745133922616\n",
      "Epoch 7182, reconstruction losses: 0.025104201735737033, regression losses: 0.18435565452998998, validation losses: 0.4723898738635906\n",
      "Epoch 7183, reconstruction losses: 0.021400070570310372, regression losses: 0.10571465078968413, validation losses: 0.5600519385901532\n",
      "Epoch 7184, reconstruction losses: 0.022525418568922918, regression losses: 0.1713497372067735, validation losses: 0.5412374955411438\n",
      "Epoch 7185, reconstruction losses: 0.02198663047059385, regression losses: 0.11290629853562287, validation losses: 0.5887885435309671\n",
      "Epoch 7186, reconstruction losses: 0.025266281072603584, regression losses: 0.11228307997390274, validation losses: 0.6151504488555849\n",
      "Epoch 7187, reconstruction losses: 0.023030211279461255, regression losses: 0.14845293295989812, validation losses: 0.5349606564712809\n",
      "Epoch 7188, reconstruction losses: 0.024384252340177038, regression losses: 0.14685589456061948, validation losses: 0.5561770757679579\n",
      "Epoch 7189, reconstruction losses: 0.021795502745186553, regression losses: 0.14444700339148814, validation losses: 0.5116611348218918\n",
      "Epoch 7190, reconstruction losses: 0.022015046247576883, regression losses: 0.13007623258042664, validation losses: 0.4772205497654089\n",
      "Epoch 7191, reconstruction losses: 0.023224715159100254, regression losses: 0.14082295329837555, validation losses: 0.4798296693585633\n",
      "Epoch 7192, reconstruction losses: 0.02173465253160376, regression losses: 0.11304398027020451, validation losses: 0.49480904392020253\n",
      "Epoch 7193, reconstruction losses: 0.021187351148926177, regression losses: 0.15646806184804157, validation losses: 0.4809323748420863\n",
      "Epoch 7194, reconstruction losses: 0.02021917149972993, regression losses: 0.11894011743786374, validation losses: 0.4734590657460985\n",
      "Epoch 7195, reconstruction losses: 0.02161040256963785, regression losses: 0.09968557372248071, validation losses: 0.45291802058208375\n",
      "Epoch 7196, reconstruction losses: 0.023705135417487363, regression losses: 0.13587160678739846, validation losses: 0.4470006140775481\n",
      "Epoch 7197, reconstruction losses: 0.02154137050333889, regression losses: 0.08977076937450884, validation losses: 0.4714687508150515\n",
      "Epoch 7198, reconstruction losses: 0.025021454907484936, regression losses: 0.13700497508282347, validation losses: 0.48910769287324424\n",
      "Epoch 7199, reconstruction losses: 0.020243735936755387, regression losses: 0.12959722583090214, validation losses: 0.49373657961601275\n",
      "Epoch 7200, reconstruction losses: 0.023717880752014024, regression losses: 0.1742057821331079, validation losses: 0.46329776902332576\n",
      "Epoch 7201, reconstruction losses: 0.019260744047727818, regression losses: 0.1117098438925285, validation losses: 0.4332394546172678\n",
      "Epoch 7202, reconstruction losses: 0.023502439434073836, regression losses: 0.10053448624162206, validation losses: 0.41757097782709807\n",
      "Epoch 7203, reconstruction losses: 0.020415101904921795, regression losses: 0.16692895779683506, validation losses: 0.40039384089085994\n",
      "Epoch 7204, reconstruction losses: 0.022876520981520588, regression losses: 0.0855085152431574, validation losses: 0.44843910452048746\n",
      "Epoch 7205, reconstruction losses: 0.02418340447099751, regression losses: 0.10986240396570414, validation losses: 0.46247963236977746\n",
      "Epoch 7206, reconstruction losses: 0.02258700404262889, regression losses: 0.1226981284636517, validation losses: 0.45219868830327725\n",
      "Epoch 7207, reconstruction losses: 0.0224213774935097, regression losses: 0.12093480375362217, validation losses: 0.4529197616592261\n",
      "Epoch 7208, reconstruction losses: 0.021003776162595224, regression losses: 0.10446857938861447, validation losses: 0.4866577538008452\n",
      "Epoch 7209, reconstruction losses: 0.02282529588398675, regression losses: 0.13412318646998656, validation losses: 0.43028013781449276\n",
      "Epoch 7210, reconstruction losses: 0.022280165240432456, regression losses: 0.11895820905848703, validation losses: 0.47126291275367727\n",
      "Epoch 7211, reconstruction losses: 0.020772418457505517, regression losses: 0.11758230701597411, validation losses: 0.43370840810091676\n",
      "Epoch 7212, reconstruction losses: 0.02448908100065424, regression losses: 0.16261866526648694, validation losses: 0.47205016958337565\n",
      "Epoch 7213, reconstruction losses: 0.02558684243197505, regression losses: 0.11222220234772005, validation losses: 0.6306450697996158\n",
      "Epoch 7214, reconstruction losses: 0.020771897605316655, regression losses: 0.09744380658146774, validation losses: 0.5329023850916186\n",
      "Epoch 7215, reconstruction losses: 0.025261061294369308, regression losses: 0.12240876344498634, validation losses: 0.4323730971910056\n",
      "Epoch 7216, reconstruction losses: 0.025540010469694435, regression losses: 0.12216988016200002, validation losses: 0.4453459748613901\n",
      "Epoch 7217, reconstruction losses: 0.019994380169793186, regression losses: 0.11224813728736914, validation losses: 0.4772435043397716\n",
      "Epoch 7218, reconstruction losses: 0.02346755554182876, regression losses: 0.13471850332082363, validation losses: 0.4750076601464527\n",
      "Epoch 7219, reconstruction losses: 0.021618730121156997, regression losses: 0.0797451693012178, validation losses: 0.45219516277592575\n",
      "Epoch 7220, reconstruction losses: 0.021120545729087704, regression losses: 0.12088313141799303, validation losses: 0.4554760039404262\n",
      "Epoch 7221, reconstruction losses: 0.020638395035912884, regression losses: 0.10585049737553981, validation losses: 0.48309515116060875\n",
      "Epoch 7222, reconstruction losses: 0.021224415330315077, regression losses: 0.09090086527410954, validation losses: 0.49557378872922175\n",
      "Epoch 7223, reconstruction losses: 0.02634955427844357, regression losses: 0.14272027773646412, validation losses: 0.46402972387806785\n",
      "Epoch 7224, reconstruction losses: 0.025239281158494282, regression losses: 0.10865005283368824, validation losses: 0.5158751035540705\n",
      "Epoch 7225, reconstruction losses: 0.02251120649017781, regression losses: 0.16761288453431505, validation losses: 0.5571651552775693\n",
      "Epoch 7226, reconstruction losses: 0.021268900853073834, regression losses: 0.13632332783174728, validation losses: 0.5076165896754677\n",
      "Epoch 7227, reconstruction losses: 0.02262385266514452, regression losses: 0.09136357481802121, validation losses: 0.464677441964545\n",
      "Epoch 7228, reconstruction losses: 0.021459648202808164, regression losses: 0.09185658808727888, validation losses: 0.432129321371065\n",
      "Epoch 7229, reconstruction losses: 0.023526431018459106, regression losses: 0.13179732363119515, validation losses: 0.4220233974866989\n",
      "Epoch 7230, reconstruction losses: 0.024917474988125285, regression losses: 0.16020234218551963, validation losses: 0.43284859642436\n",
      "Epoch 7231, reconstruction losses: 0.02086626933284645, regression losses: 0.1025744620461006, validation losses: 0.4404986397041842\n",
      "Epoch 7232, reconstruction losses: 0.02057512289186411, regression losses: 0.09219314796387502, validation losses: 0.4949025399948144\n",
      "Epoch 7233, reconstruction losses: 0.02053190659279884, regression losses: 0.07411795374636967, validation losses: 0.5290660139391302\n",
      "Epoch 7234, reconstruction losses: 0.026259399692311544, regression losses: 0.14425787822738345, validation losses: 0.5321844331190888\n",
      "Epoch 7235, reconstruction losses: 0.02418164442719315, regression losses: 0.13088796096181585, validation losses: 0.5493815002046859\n",
      "Epoch 7236, reconstruction losses: 0.023510763540987398, regression losses: 0.1229396496909071, validation losses: 0.476353797689408\n",
      "Epoch 7237, reconstruction losses: 0.02514191936814438, regression losses: 0.19619730832250598, validation losses: 0.5266626549980473\n",
      "Epoch 7238, reconstruction losses: 0.020043452049889388, regression losses: 0.12873994790454288, validation losses: 0.8173480590209042\n",
      "Epoch 7239, reconstruction losses: 0.024459338625612795, regression losses: 0.14333335745706902, validation losses: 0.6494415380870273\n",
      "Epoch 7240, reconstruction losses: 0.021979823667413453, regression losses: 0.11608961144301215, validation losses: 0.5245557246567304\n",
      "Epoch 7241, reconstruction losses: 0.023282023243396493, regression losses: 0.11814856176619262, validation losses: 0.46977656575383253\n",
      "Epoch 7242, reconstruction losses: 0.020042378506862184, regression losses: 0.11765997232340505, validation losses: 0.43031408415202926\n",
      "Epoch 7243, reconstruction losses: 0.023729321062211296, regression losses: 0.1374023280851462, validation losses: 0.3991748714920076\n",
      "Epoch 7244, reconstruction losses: 0.02215841664759227, regression losses: 0.10718468600661603, validation losses: 0.4308683626406796\n",
      "Epoch 7245, reconstruction losses: 0.02786062437317783, regression losses: 0.18514983214430997, validation losses: 0.45426777063557633\n",
      "Epoch 7246, reconstruction losses: 0.02074384222348068, regression losses: 0.11443634190258871, validation losses: 0.4596107790251448\n",
      "Epoch 7247, reconstruction losses: 0.02287655809189003, regression losses: 0.13419150830311427, validation losses: 0.4448007228142385\n",
      "Epoch 7248, reconstruction losses: 0.021120043550955828, regression losses: 0.1079909692481569, validation losses: 0.6299724347821307\n",
      "Epoch 7249, reconstruction losses: 0.025456813040064946, regression losses: 0.136820090594055, validation losses: 0.6313004042812841\n",
      "Epoch 7250, reconstruction losses: 0.022151416942018734, regression losses: 0.09995092902174431, validation losses: 0.43118033764536723\n",
      "Epoch 7251, reconstruction losses: 0.021479816826248645, regression losses: 0.11589605046980418, validation losses: 0.41088182656372496\n",
      "Epoch 7252, reconstruction losses: 0.024892471150576717, regression losses: 0.26130939776789125, validation losses: 0.5020969210171669\n",
      "Epoch 7253, reconstruction losses: 0.02156280650703316, regression losses: 0.13257141312370538, validation losses: 0.8886089439698268\n",
      "Epoch 7254, reconstruction losses: 0.024977071923799245, regression losses: 0.16820061892886493, validation losses: 0.5623598492438159\n",
      "Epoch 7255, reconstruction losses: 0.01934631126561035, regression losses: 0.11344958825745804, validation losses: 0.5450525473509321\n",
      "Epoch 7256, reconstruction losses: 0.0206351131081895, regression losses: 0.12880210444444062, validation losses: 0.6854794129011629\n",
      "Epoch 7257, reconstruction losses: 0.022660906771431805, regression losses: 0.12069667660415836, validation losses: 0.5224633287737079\n",
      "Epoch 7258, reconstruction losses: 0.02481359079763694, regression losses: 0.17050720457367274, validation losses: 0.49014614272757334\n",
      "Epoch 7259, reconstruction losses: 0.026036155861258042, regression losses: 0.11938038544146332, validation losses: 0.44738732157673594\n",
      "Epoch 7260, reconstruction losses: 0.02252604784745206, regression losses: 0.10795334422438284, validation losses: 0.44671887632227486\n",
      "Epoch 7261, reconstruction losses: 0.023181076545756844, regression losses: 0.1045733784537054, validation losses: 0.4475176774665692\n",
      "Epoch 7262, reconstruction losses: 0.023795292013512902, regression losses: 0.13371351407599452, validation losses: 0.4666178942369174\n",
      "Epoch 7263, reconstruction losses: 0.021423212157848932, regression losses: 0.10810617341285594, validation losses: 0.47289798728926646\n",
      "Epoch 7264, reconstruction losses: 0.024319652529493814, regression losses: 0.12256378911193055, validation losses: 0.49276879353123976\n",
      "Epoch 7265, reconstruction losses: 0.02255333889633347, regression losses: 0.08482222033313835, validation losses: 0.45275639042878146\n",
      "Epoch 7266, reconstruction losses: 0.023719668458195755, regression losses: 0.12865186897035025, validation losses: 0.429162419981527\n",
      "Epoch 7267, reconstruction losses: 0.021658978169542317, regression losses: 0.12218353875923749, validation losses: 0.4888567612727527\n",
      "Epoch 7268, reconstruction losses: 0.022437269386833936, regression losses: 0.1408123943704175, validation losses: 0.5239930026763754\n",
      "Epoch 7269, reconstruction losses: 0.023473697727495253, regression losses: 0.11937090765287592, validation losses: 0.4675831516740177\n",
      "Epoch 7270, reconstruction losses: 0.02153672651916157, regression losses: 0.09486764734014817, validation losses: 0.5141143915552251\n",
      "Epoch 7271, reconstruction losses: 0.0260557374877093, regression losses: 0.207222188631623, validation losses: 0.6134780456247865\n",
      "Epoch 7272, reconstruction losses: 0.02521402958317781, regression losses: 0.1470104310856275, validation losses: 0.8105002278078816\n",
      "Epoch 7273, reconstruction losses: 0.02318905157116915, regression losses: 0.13611501350875232, validation losses: 0.6731133602097623\n",
      "Epoch 7274, reconstruction losses: 0.023697301993195356, regression losses: 0.1355735687985368, validation losses: 0.6270470588567107\n",
      "Epoch 7275, reconstruction losses: 0.02184485308633847, regression losses: 0.1489120539787815, validation losses: 0.5673441051498962\n",
      "Epoch 7276, reconstruction losses: 0.02120523586720997, regression losses: 0.10124605586593849, validation losses: 0.43749703828096387\n",
      "Epoch 7277, reconstruction losses: 0.02400191538823084, regression losses: 0.11895515184876443, validation losses: 0.46031963839324913\n",
      "Epoch 7278, reconstruction losses: 0.022593683944045376, regression losses: 0.1557681409417449, validation losses: 0.43414493384684655\n",
      "Epoch 7279, reconstruction losses: 0.026575010130554008, regression losses: 0.1460727993043316, validation losses: 0.5558607963432773\n",
      "Epoch 7280, reconstruction losses: 0.027730262101197466, regression losses: 0.4045983493000549, validation losses: 0.44613593837986554\n",
      "Epoch 7281, reconstruction losses: 0.022986338732782708, regression losses: 0.13506511955090145, validation losses: 0.8191428332195985\n",
      "Epoch 7282, reconstruction losses: 0.02214356505329823, regression losses: 0.17820388281131794, validation losses: 0.798611238449211\n",
      "Epoch 7283, reconstruction losses: 0.021045494207189493, regression losses: 0.14233555099117648, validation losses: 0.6642624367162444\n",
      "Epoch 7284, reconstruction losses: 0.022025367893212102, regression losses: 0.11799999574950587, validation losses: 0.5424798525012645\n",
      "Epoch 7285, reconstruction losses: 0.02368841072305184, regression losses: 0.1337241684488566, validation losses: 0.4576109409108613\n",
      "Epoch 7286, reconstruction losses: 0.024148443765750476, regression losses: 0.11744544560936673, validation losses: 0.46651052651890784\n",
      "Epoch 7287, reconstruction losses: 0.02089895636236422, regression losses: 0.10360839365640767, validation losses: 0.50544971284725\n",
      "Epoch 7288, reconstruction losses: 0.021604406703977723, regression losses: 0.16191680608920486, validation losses: 0.5658846569284508\n",
      "Epoch 7289, reconstruction losses: 0.029053724542931335, regression losses: 0.15519126226925584, validation losses: 0.5189678330242629\n",
      "Epoch 7290, reconstruction losses: 0.02091972837797982, regression losses: 0.08934874170321885, validation losses: 0.5220671144286222\n",
      "Epoch 7291, reconstruction losses: 0.02221792915851988, regression losses: 0.09217857198701326, validation losses: 0.4763046863917278\n",
      "Epoch 7292, reconstruction losses: 0.022020848878243134, regression losses: 0.1465070293958882, validation losses: 0.4861373695952291\n",
      "Epoch 7293, reconstruction losses: 0.023165797816156124, regression losses: 0.13493871602803176, validation losses: 0.5740700448524251\n",
      "Epoch 7294, reconstruction losses: 0.02091650547251483, regression losses: 0.09701066695775974, validation losses: 0.4480049196931969\n",
      "Epoch 7295, reconstruction losses: 0.022296162559081595, regression losses: 0.10868134063538529, validation losses: 0.44383849442040807\n",
      "Epoch 7296, reconstruction losses: 0.02227182614451641, regression losses: 0.12265740456693092, validation losses: 0.4543485046243785\n",
      "Epoch 7297, reconstruction losses: 0.023125176260461386, regression losses: 0.15308010188698068, validation losses: 0.5480711760963409\n",
      "Epoch 7298, reconstruction losses: 0.02177626875019663, regression losses: 0.13983922543644195, validation losses: 0.4609997915202611\n",
      "Epoch 7299, reconstruction losses: 0.02052758799102514, regression losses: 0.10324701616417808, validation losses: 0.43125671950008404\n",
      "Epoch 7300, reconstruction losses: 0.0216746161596586, regression losses: 0.1102501716667118, validation losses: 0.4416282265792596\n",
      "Epoch 7301, reconstruction losses: 0.021878334569756203, regression losses: 0.15127913633381188, validation losses: 0.44367580480683794\n",
      "Epoch 7302, reconstruction losses: 0.023238881607149837, regression losses: 0.171938530264189, validation losses: 0.45540293355574046\n",
      "Epoch 7303, reconstruction losses: 0.01983398098592628, regression losses: 0.09920794850132496, validation losses: 0.5096258776683833\n",
      "Epoch 7304, reconstruction losses: 0.021984399008665133, regression losses: 0.11347969114421727, validation losses: 0.47913385248662965\n",
      "Epoch 7305, reconstruction losses: 0.019545686857889287, regression losses: 0.0934475125516936, validation losses: 0.5123529941342146\n",
      "Epoch 7306, reconstruction losses: 0.02066622592839852, regression losses: 0.12271113126367965, validation losses: 0.5039760697636029\n",
      "Epoch 7307, reconstruction losses: 0.023501579960786292, regression losses: 0.34075101493179827, validation losses: 0.4807430441711407\n",
      "Epoch 7308, reconstruction losses: 0.022736224666931037, regression losses: 0.13320187763467023, validation losses: 0.6187116980018728\n",
      "Epoch 7309, reconstruction losses: 0.024320249148564083, regression losses: 0.12184642470837435, validation losses: 0.5178694007681455\n",
      "Epoch 7310, reconstruction losses: 0.022367194300006416, regression losses: 0.10349016735640779, validation losses: 0.482492733892936\n",
      "Epoch 7311, reconstruction losses: 0.025341961185188753, regression losses: 0.16562574949401918, validation losses: 0.5165346416075187\n",
      "Epoch 7312, reconstruction losses: 0.025595692776142827, regression losses: 0.12722591718389517, validation losses: 0.5103899494118322\n",
      "Epoch 7313, reconstruction losses: 0.023031994864694448, regression losses: 0.11904902813067239, validation losses: 0.42602297966166225\n",
      "Epoch 7314, reconstruction losses: 0.01923170321435568, regression losses: 0.13649763278897634, validation losses: 0.44158608403998023\n",
      "Epoch 7315, reconstruction losses: 0.02143109316472168, regression losses: 0.11550636726283994, validation losses: 0.5162427873113553\n",
      "Epoch 7316, reconstruction losses: 0.023993831626949548, regression losses: 0.20359077664799846, validation losses: 0.5194544718343066\n",
      "Epoch 7317, reconstruction losses: 0.02279672659898662, regression losses: 0.11776952862520472, validation losses: 0.5484791811771557\n",
      "Epoch 7318, reconstruction losses: 0.020876727325374787, regression losses: 0.11506486334056419, validation losses: 0.5088448943394379\n",
      "Epoch 7319, reconstruction losses: 0.021038664284217044, regression losses: 0.12922107710857475, validation losses: 0.4489683076810963\n",
      "Epoch 7320, reconstruction losses: 0.01849104579947426, regression losses: 0.1032779356115496, validation losses: 0.4479497306922229\n",
      "Epoch 7321, reconstruction losses: 0.021282317844165066, regression losses: 0.09264025958115556, validation losses: 0.4333611459143857\n",
      "Epoch 7322, reconstruction losses: 0.02020727330257102, regression losses: 0.12361797239549296, validation losses: 0.4281400890014572\n",
      "Epoch 7323, reconstruction losses: 0.020330177844722304, regression losses: 0.10586363774297287, validation losses: 0.42268970122449895\n",
      "Epoch 7324, reconstruction losses: 0.024418552443479635, regression losses: 0.13541832446667498, validation losses: 0.4167429103673771\n",
      "Epoch 7325, reconstruction losses: 0.023830219983942486, regression losses: 0.11086892815861378, validation losses: 0.48982680838430226\n",
      "Epoch 7326, reconstruction losses: 0.021523744178128516, regression losses: 0.12182650322531248, validation losses: 0.4789948406886582\n",
      "Epoch 7327, reconstruction losses: 0.021080986335900505, regression losses: 0.0966537145090512, validation losses: 0.490500809702893\n",
      "Epoch 7328, reconstruction losses: 0.022924857620210883, regression losses: 0.12508931488977934, validation losses: 0.4938412803762154\n",
      "Epoch 7329, reconstruction losses: 0.021100369690135165, regression losses: 0.11496641835496983, validation losses: 0.4178016274070056\n",
      "Epoch 7330, reconstruction losses: 0.021851782810189388, regression losses: 0.09896195068168236, validation losses: 0.4141485009779992\n",
      "Epoch 7331, reconstruction losses: 0.021165352136677633, regression losses: 0.10311984920262895, validation losses: 0.43549073742486766\n",
      "Epoch 7332, reconstruction losses: 0.02242690754738842, regression losses: 0.1095897959411215, validation losses: 0.5020147389764773\n",
      "Epoch 7333, reconstruction losses: 0.025210612942603062, regression losses: 0.14636083562577548, validation losses: 0.583982863090443\n",
      "Epoch 7334, reconstruction losses: 0.02049350772798111, regression losses: 0.14899754799386483, validation losses: 0.5727532171940412\n",
      "Epoch 7335, reconstruction losses: 0.024444263041894017, regression losses: 0.1630942326554091, validation losses: 0.430250983231875\n",
      "Epoch 7336, reconstruction losses: 0.02875385669869082, regression losses: 0.12622473361592548, validation losses: 0.43113760029319603\n",
      "Epoch 7337, reconstruction losses: 0.024385564904882234, regression losses: 0.1552986728707026, validation losses: 0.42242715348961957\n",
      "Epoch 7338, reconstruction losses: 0.02543668194091131, regression losses: 0.1598181878986804, validation losses: 0.5342760053916593\n",
      "Epoch 7339, reconstruction losses: 0.024060339991129984, regression losses: 0.09105975431152713, validation losses: 0.45466629101451955\n",
      "Epoch 7340, reconstruction losses: 0.021631129172749963, regression losses: 0.0953624552706508, validation losses: 0.43788000138778643\n",
      "Epoch 7341, reconstruction losses: 0.024356081423560924, regression losses: 0.12384970836688275, validation losses: 0.44176264770681917\n",
      "Epoch 7342, reconstruction losses: 0.01999591748226155, regression losses: 0.08529982008480572, validation losses: 0.5133157847195279\n",
      "Epoch 7343, reconstruction losses: 0.02209556929762455, regression losses: 0.13999710974448137, validation losses: 0.5215819928528934\n",
      "Epoch 7344, reconstruction losses: 0.021693371680484887, regression losses: 0.10501004477133043, validation losses: 0.5200193741364963\n",
      "Epoch 7345, reconstruction losses: 0.024177500541900293, regression losses: 0.1490150411923685, validation losses: 0.5597851316872284\n",
      "Epoch 7346, reconstruction losses: 0.02296825944982129, regression losses: 0.12860958872550346, validation losses: 0.5948253993165749\n",
      "Epoch 7347, reconstruction losses: 0.021607925668911773, regression losses: 0.07440033796599302, validation losses: 0.5842335841337881\n",
      "Epoch 7348, reconstruction losses: 0.020853706920570484, regression losses: 0.1248501444198231, validation losses: 0.49487280575857734\n",
      "Epoch 7349, reconstruction losses: 0.022172570265285314, regression losses: 0.13988751451712822, validation losses: 0.44448524318790616\n",
      "Epoch 7350, reconstruction losses: 0.021864155351332612, regression losses: 0.14448724974872004, validation losses: 0.4352359879597618\n",
      "Epoch 7351, reconstruction losses: 0.02148130451115244, regression losses: 0.11132360398973226, validation losses: 0.446135535057219\n",
      "Epoch 7352, reconstruction losses: 0.022413656359035167, regression losses: 0.13823991451286755, validation losses: 0.4765247447099384\n",
      "Epoch 7353, reconstruction losses: 0.02354252127186489, regression losses: 0.0995329754438119, validation losses: 0.4980783775696566\n",
      "Epoch 7354, reconstruction losses: 0.02079156144325332, regression losses: 0.10963737368282434, validation losses: 0.44128794612527156\n",
      "Epoch 7355, reconstruction losses: 0.02095309885998925, regression losses: 0.08296141560853776, validation losses: 0.4444306724960382\n",
      "Epoch 7356, reconstruction losses: 0.024158918094606956, regression losses: 0.13956932762417706, validation losses: 0.4652135665971624\n",
      "Epoch 7357, reconstruction losses: 0.021369520654346694, regression losses: 0.10541835832051184, validation losses: 0.44456597220753463\n",
      "Epoch 7358, reconstruction losses: 0.02128951215846892, regression losses: 0.10931050949066827, validation losses: 0.45801934509303244\n",
      "Epoch 7359, reconstruction losses: 0.021195731951007764, regression losses: 0.19550386498416952, validation losses: 0.47846982012389755\n",
      "Epoch 7360, reconstruction losses: 0.020299142783937997, regression losses: 0.10182646262169057, validation losses: 0.4945576852414848\n",
      "Epoch 7361, reconstruction losses: 0.02255908923342693, regression losses: 0.11171334067781075, validation losses: 0.5017134027074434\n",
      "Epoch 7362, reconstruction losses: 0.023069168068243016, regression losses: 0.13941994219588347, validation losses: 0.4844755876617676\n",
      "Epoch 7363, reconstruction losses: 0.023141563368970962, regression losses: 0.14911955598895837, validation losses: 0.50187949310527\n",
      "Epoch 7364, reconstruction losses: 0.021202086828551785, regression losses: 0.14069000035303367, validation losses: 0.43771336941615574\n",
      "Epoch 7365, reconstruction losses: 0.02532884273059409, regression losses: 0.11325269422235515, validation losses: 0.5282267926509243\n",
      "Epoch 7366, reconstruction losses: 0.02322223456397968, regression losses: 0.1424420848092503, validation losses: 0.51337713354177\n",
      "Epoch 7367, reconstruction losses: 0.024099428846917518, regression losses: 0.1531641083560055, validation losses: 0.43909864924513997\n",
      "Epoch 7368, reconstruction losses: 0.02352456026442135, regression losses: 0.1254922672069931, validation losses: 0.5063491010497272\n",
      "Epoch 7369, reconstruction losses: 0.020321364254699645, regression losses: 0.11792116818493341, validation losses: 0.5048831054013618\n",
      "Epoch 7370, reconstruction losses: 0.022909059135755833, regression losses: 0.24539954099653763, validation losses: 0.47781405902661117\n",
      "Epoch 7371, reconstruction losses: 0.02187937991385321, regression losses: 0.13501754844990732, validation losses: 0.5577050163190593\n",
      "Epoch 7372, reconstruction losses: 0.020718858854291675, regression losses: 0.11819159929382766, validation losses: 0.44340564076389427\n",
      "Epoch 7373, reconstruction losses: 0.019744345047932196, regression losses: 0.1336798419061646, validation losses: 0.4769512183081288\n",
      "Epoch 7374, reconstruction losses: 0.021091290924976882, regression losses: 0.10843877404203, validation losses: 0.43982685954341916\n",
      "Epoch 7375, reconstruction losses: 0.020123267305476162, regression losses: 0.10363776425128741, validation losses: 0.45828070480793326\n",
      "Epoch 7376, reconstruction losses: 0.01945503847812371, regression losses: 0.11029305965696212, validation losses: 0.4390524250641254\n",
      "Epoch 7377, reconstruction losses: 0.020108528962349655, regression losses: 0.14213540434937463, validation losses: 0.43376341561785026\n",
      "Epoch 7378, reconstruction losses: 0.03084330296033909, regression losses: 0.4354701928088197, validation losses: 0.42158809685161636\n",
      "Epoch 7379, reconstruction losses: 0.020176957592039833, regression losses: 0.1278509408339891, validation losses: 0.5811244265893785\n",
      "Epoch 7380, reconstruction losses: 0.02360504669180283, regression losses: 0.20019602919014562, validation losses: 0.6560699360607213\n",
      "Epoch 7381, reconstruction losses: 0.026964756394686238, regression losses: 0.4339037531846309, validation losses: 0.7473343047752825\n",
      "Epoch 7382, reconstruction losses: 0.023634292576819108, regression losses: 0.18983790661769734, validation losses: 0.9184251897287125\n",
      "Epoch 7383, reconstruction losses: 0.024448829837426495, regression losses: 0.1393686828176313, validation losses: 0.6310609551952798\n",
      "Epoch 7384, reconstruction losses: 0.024807634840461175, regression losses: 0.21390362669503957, validation losses: 0.5121274049932949\n",
      "Epoch 7385, reconstruction losses: 0.024597090220078225, regression losses: 0.1449801988303197, validation losses: 0.43548714095849106\n",
      "Epoch 7386, reconstruction losses: 0.022923659193189998, regression losses: 0.15301353382932226, validation losses: 0.45109540083261473\n",
      "Epoch 7387, reconstruction losses: 0.024555675888467573, regression losses: 0.13271329832149453, validation losses: 0.6591946906668271\n",
      "Epoch 7388, reconstruction losses: 0.02309702696274754, regression losses: 0.13159690940926225, validation losses: 0.5768380973374583\n",
      "Epoch 7389, reconstruction losses: 0.023726442179255475, regression losses: 0.1456933241421987, validation losses: 0.5757303033400027\n",
      "Epoch 7390, reconstruction losses: 0.01975517808686412, regression losses: 0.11361552784858282, validation losses: 0.5890788501026185\n",
      "Epoch 7391, reconstruction losses: 0.023227410904259987, regression losses: 0.17172271211131235, validation losses: 0.4792735538613086\n",
      "Epoch 7392, reconstruction losses: 0.024390618999991447, regression losses: 0.147436884072647, validation losses: 0.45494804402733047\n",
      "Epoch 7393, reconstruction losses: 0.021084147425403738, regression losses: 0.1321594083093022, validation losses: 0.6236847467469914\n",
      "Epoch 7394, reconstruction losses: 0.019775086986630566, regression losses: 0.09211458114769303, validation losses: 0.6719163084559377\n",
      "Epoch 7395, reconstruction losses: 0.022806378402231358, regression losses: 0.10957695845612023, validation losses: 0.5521663987647837\n",
      "Epoch 7396, reconstruction losses: 0.020269092175920565, regression losses: 0.12099766993091152, validation losses: 0.4420480031009904\n",
      "Epoch 7397, reconstruction losses: 0.022612449633761512, regression losses: 0.0992581648403842, validation losses: 0.42870613150746983\n",
      "Epoch 7398, reconstruction losses: 0.021543869470190304, regression losses: 0.09479844228652014, validation losses: 0.43053151658359445\n",
      "Epoch 7399, reconstruction losses: 0.022787456174378863, regression losses: 0.09613335853634952, validation losses: 0.46358858830784555\n",
      "Epoch 7400, reconstruction losses: 0.022140455688984807, regression losses: 0.13039741246034792, validation losses: 0.44296176339027\n",
      "Epoch 7401, reconstruction losses: 0.022640086944698497, regression losses: 0.13536528373940507, validation losses: 0.46779981279798155\n",
      "Epoch 7402, reconstruction losses: 0.02495875253547216, regression losses: 0.12100761559240206, validation losses: 0.4554344487179908\n",
      "Epoch 7403, reconstruction losses: 0.024593251044682088, regression losses: 0.19953107739963008, validation losses: 0.447370960006298\n",
      "Epoch 7404, reconstruction losses: 0.022568208920053505, regression losses: 0.15352578418430124, validation losses: 0.5510947367234658\n",
      "Epoch 7405, reconstruction losses: 0.02575365235837502, regression losses: 0.1397277735767387, validation losses: 0.5807020578305899\n",
      "Epoch 7406, reconstruction losses: 0.02383596723987669, regression losses: 0.154011037682933, validation losses: 0.4879951300465586\n",
      "Epoch 7407, reconstruction losses: 0.02147022954368993, regression losses: 0.08916205669607502, validation losses: 0.43972241652990945\n",
      "Epoch 7408, reconstruction losses: 0.02180623432976911, regression losses: 0.1232123004311412, validation losses: 0.41899093564656875\n",
      "Epoch 7409, reconstruction losses: 0.020794817471894475, regression losses: 0.10417296934199224, validation losses: 0.40523923015584273\n",
      "Epoch 7410, reconstruction losses: 0.02114998583620173, regression losses: 0.10507846368213622, validation losses: 0.4147059685038331\n",
      "Epoch 7411, reconstruction losses: 0.023447650326528617, regression losses: 0.36117351547192106, validation losses: 0.4395004599430095\n",
      "Epoch 7412, reconstruction losses: 0.024942460068354773, regression losses: 0.14122072792593338, validation losses: 0.673198514303409\n",
      "Epoch 7413, reconstruction losses: 0.021844747651903394, regression losses: 0.12626341507993477, validation losses: 0.7077801312382934\n",
      "Epoch 7414, reconstruction losses: 0.02189766452301494, regression losses: 0.13549534996356735, validation losses: 0.595366391504715\n",
      "Epoch 7415, reconstruction losses: 0.02135997677570485, regression losses: 0.12685960121351697, validation losses: 0.488321896924635\n",
      "Epoch 7416, reconstruction losses: 0.022241020519008507, regression losses: 0.07558644855415854, validation losses: 0.4683452710459059\n",
      "Epoch 7417, reconstruction losses: 0.026365020168092515, regression losses: 0.09852219491711718, validation losses: 0.442010709335081\n",
      "Epoch 7418, reconstruction losses: 0.02682147694367613, regression losses: 0.1491293013688506, validation losses: 0.5274616795994564\n",
      "Epoch 7419, reconstruction losses: 0.022049991102461343, regression losses: 0.2118540933199997, validation losses: 0.6219204997205716\n",
      "Epoch 7420, reconstruction losses: 0.026183484767236195, regression losses: 0.34745554482212593, validation losses: 0.5224287890172892\n",
      "Epoch 7421, reconstruction losses: 0.02448634160470926, regression losses: 0.14301225584178137, validation losses: 0.9279447374467126\n",
      "Epoch 7422, reconstruction losses: 0.0237158022549922, regression losses: 0.14451350368882465, validation losses: 0.7374979346693202\n",
      "Epoch 7423, reconstruction losses: 0.023515481324905885, regression losses: 0.10806895303061206, validation losses: 0.6648229416451736\n",
      "Epoch 7424, reconstruction losses: 0.021937060649974773, regression losses: 0.13966035551832193, validation losses: 0.5808125478289705\n",
      "Epoch 7425, reconstruction losses: 0.022012811024148954, regression losses: 0.11352174852699977, validation losses: 0.487619969280775\n",
      "Epoch 7426, reconstruction losses: 0.020717350972509336, regression losses: 0.13127673103844623, validation losses: 0.4586526325425399\n",
      "Epoch 7427, reconstruction losses: 0.021274316818819045, regression losses: 0.1519850498545173, validation losses: 0.5090652481500652\n",
      "Epoch 7428, reconstruction losses: 0.0186611552788189, regression losses: 0.08471895389406671, validation losses: 0.5588089622510483\n",
      "Epoch 7429, reconstruction losses: 0.02455414939144395, regression losses: 0.115006644884429, validation losses: 0.5342589093582534\n",
      "Epoch 7430, reconstruction losses: 0.021243752467021357, regression losses: 0.09602408464645161, validation losses: 0.5136145324615473\n",
      "Epoch 7431, reconstruction losses: 0.022197517893566027, regression losses: 0.11455503582353341, validation losses: 0.49442950381958806\n",
      "Epoch 7432, reconstruction losses: 0.0193287139769262, regression losses: 0.08261251515850422, validation losses: 0.49700323992548245\n",
      "Epoch 7433, reconstruction losses: 0.020658218279773398, regression losses: 0.08159074030356828, validation losses: 0.4792903903630771\n",
      "Epoch 7434, reconstruction losses: 0.02498590506122285, regression losses: 0.09223723797211555, validation losses: 0.45405685851995287\n",
      "Epoch 7435, reconstruction losses: 0.0217393615581023, regression losses: 0.16425627177927238, validation losses: 0.4523826890159929\n",
      "Epoch 7436, reconstruction losses: 0.027742263300043698, regression losses: 0.15628038860012755, validation losses: 0.4738482689614702\n",
      "Epoch 7437, reconstruction losses: 0.021776276806296693, regression losses: 0.11124388232816253, validation losses: 0.5659427762004485\n",
      "Epoch 7438, reconstruction losses: 0.024313765129527386, regression losses: 0.1504827104765243, validation losses: 0.5638979678924184\n",
      "Epoch 7439, reconstruction losses: 0.023355960953526808, regression losses: 0.114407349497591, validation losses: 0.49991851777382235\n",
      "Epoch 7440, reconstruction losses: 0.02273871782763912, regression losses: 0.13801483645957402, validation losses: 0.4521244891996223\n",
      "Epoch 7441, reconstruction losses: 0.023642953969334187, regression losses: 0.1269877767177905, validation losses: 0.5131828615279729\n",
      "Epoch 7442, reconstruction losses: 0.021483430035993602, regression losses: 0.1280237883666055, validation losses: 0.6240367318446819\n",
      "Epoch 7443, reconstruction losses: 0.02415239489054761, regression losses: 0.2821461501282523, validation losses: 0.610020137790958\n",
      "Epoch 7444, reconstruction losses: 0.020503555732255166, regression losses: 0.14861305959362642, validation losses: 0.600714539110769\n",
      "Epoch 7445, reconstruction losses: 0.02075178853212807, regression losses: 0.12926421887295228, validation losses: 0.5087008864621386\n",
      "Epoch 7446, reconstruction losses: 0.020937322369673154, regression losses: 0.09571663604508655, validation losses: 0.4536634761892992\n",
      "Epoch 7447, reconstruction losses: 0.023889090580391677, regression losses: 0.14840169900803957, validation losses: 0.5317142313800152\n",
      "Epoch 7448, reconstruction losses: 0.024353945132363653, regression losses: 0.16596673858117655, validation losses: 0.5711058907551886\n",
      "Epoch 7449, reconstruction losses: 0.01936196864344734, regression losses: 0.09528601560533388, validation losses: 0.4638505808929249\n",
      "Epoch 7450, reconstruction losses: 0.02344378106745399, regression losses: 0.14309331461317729, validation losses: 0.4414383727955142\n",
      "Epoch 7451, reconstruction losses: 0.021765976772074327, regression losses: 0.18699896775475378, validation losses: 0.5143383396002429\n",
      "Epoch 7452, reconstruction losses: 0.022813023787447748, regression losses: 0.12541642138260592, validation losses: 0.5109567771565031\n",
      "Epoch 7453, reconstruction losses: 0.025152574523477078, regression losses: 0.1993705915135637, validation losses: 0.4606533230385972\n",
      "Epoch 7454, reconstruction losses: 0.022253446400915363, regression losses: 0.1357775082811618, validation losses: 0.6341622627182224\n",
      "Epoch 7455, reconstruction losses: 0.02513825120133576, regression losses: 0.18959889640284522, validation losses: 0.6006455974248239\n",
      "Epoch 7456, reconstruction losses: 0.02094759561953328, regression losses: 0.13882319182924036, validation losses: 0.668440833486353\n",
      "Epoch 7457, reconstruction losses: 0.02295046499248379, regression losses: 0.13955918074479023, validation losses: 0.5643157456187471\n",
      "Epoch 7458, reconstruction losses: 0.019075776125139172, regression losses: 0.11626175871367667, validation losses: 0.4406078720118265\n",
      "Epoch 7459, reconstruction losses: 0.021246949355350864, regression losses: 0.11292685969221952, validation losses: 0.46012528406493075\n",
      "Epoch 7460, reconstruction losses: 0.021621571589933684, regression losses: 0.17845548064748606, validation losses: 0.4743948737129708\n",
      "Epoch 7461, reconstruction losses: 0.020714384489097466, regression losses: 0.10461572280396834, validation losses: 0.4689836428129414\n",
      "Epoch 7462, reconstruction losses: 0.021737107273929954, regression losses: 0.09297512474047989, validation losses: 0.4476370059458003\n",
      "Epoch 7463, reconstruction losses: 0.019523300385011856, regression losses: 0.10443129121913507, validation losses: 0.421555186106139\n",
      "Epoch 7464, reconstruction losses: 0.02006144755407204, regression losses: 0.07748953258228786, validation losses: 0.4274046255225874\n",
      "Epoch 7465, reconstruction losses: 0.02228031852128685, regression losses: 0.09319873150721592, validation losses: 0.4524264629616221\n",
      "Epoch 7466, reconstruction losses: 0.02129223100592953, regression losses: 0.1251911953120151, validation losses: 0.4562378400819715\n",
      "Epoch 7467, reconstruction losses: 0.02342812265861973, regression losses: 0.19245681461519681, validation losses: 0.43162024989106074\n",
      "Epoch 7468, reconstruction losses: 0.023197004281703123, regression losses: 0.10990657588585102, validation losses: 0.4482905185877246\n",
      "Epoch 7469, reconstruction losses: 0.02112857911305696, regression losses: 0.13174103563457154, validation losses: 0.47509325709826133\n",
      "Epoch 7470, reconstruction losses: 0.019188017440513898, regression losses: 0.09542920832696233, validation losses: 0.4586623050113596\n",
      "Epoch 7471, reconstruction losses: 0.022839442333021615, regression losses: 0.0798364083892647, validation losses: 0.4875405339741299\n",
      "Epoch 7472, reconstruction losses: 0.023014501073705593, regression losses: 0.08109797273689627, validation losses: 0.45883306518154354\n",
      "Epoch 7473, reconstruction losses: 0.020694069450272756, regression losses: 0.1099828013011411, validation losses: 0.4383501955377003\n",
      "Epoch 7474, reconstruction losses: 0.020585517909652074, regression losses: 0.07814822064226887, validation losses: 0.43634137143913276\n",
      "Epoch 7475, reconstruction losses: 0.021459347227970722, regression losses: 0.12932546088957694, validation losses: 0.4129344729098223\n",
      "Epoch 7476, reconstruction losses: 0.020932322755722967, regression losses: 0.09073507703377177, validation losses: 0.43615399652304976\n",
      "Epoch 7477, reconstruction losses: 0.02225598311303232, regression losses: 0.11839433951871292, validation losses: 0.43922712961787314\n",
      "Epoch 7478, reconstruction losses: 0.020072785302058135, regression losses: 0.10888952848449068, validation losses: 0.43789810307701715\n",
      "Epoch 7479, reconstruction losses: 0.022062645577637395, regression losses: 0.09265843046006816, validation losses: 0.4656033728731488\n",
      "Epoch 7480, reconstruction losses: 0.023874297357772647, regression losses: 0.11400578702620608, validation losses: 0.498001913412356\n",
      "Epoch 7481, reconstruction losses: 0.02360689575304549, regression losses: 0.09547015769193021, validation losses: 0.49671091533878087\n",
      "Epoch 7482, reconstruction losses: 0.021486869615035466, regression losses: 0.12244011872899081, validation losses: 0.45725100221052317\n",
      "Epoch 7483, reconstruction losses: 0.02158496306879501, regression losses: 0.12263968689089504, validation losses: 0.464167025654612\n",
      "Epoch 7484, reconstruction losses: 0.02071817148395483, regression losses: 0.11979934886855871, validation losses: 0.4678668464213762\n",
      "Epoch 7485, reconstruction losses: 0.02179884609357421, regression losses: 0.10933009210079418, validation losses: 0.4851007367841209\n",
      "Epoch 7486, reconstruction losses: 0.02109518606084719, regression losses: 0.09756399617961756, validation losses: 0.47911981658880903\n",
      "Epoch 7487, reconstruction losses: 0.019312097659155012, regression losses: 0.11492517793489436, validation losses: 0.4429116812463904\n",
      "Epoch 7488, reconstruction losses: 0.02237299847602841, regression losses: 0.12273482962914117, validation losses: 0.45823936535183823\n",
      "Epoch 7489, reconstruction losses: 0.02526910985700678, regression losses: 0.18643427050937061, validation losses: 0.5644593624488262\n",
      "Epoch 7490, reconstruction losses: 0.022451410611162223, regression losses: 0.10667907680663788, validation losses: 0.7242945188625717\n",
      "Epoch 7491, reconstruction losses: 0.0237472181980228, regression losses: 0.15902499298070202, validation losses: 0.6366512980051634\n",
      "Epoch 7492, reconstruction losses: 0.020755100751499795, regression losses: 0.11771998332170769, validation losses: 0.6115653978666621\n",
      "Epoch 7493, reconstruction losses: 0.022546386766639632, regression losses: 0.15072224162973996, validation losses: 0.5655276394779063\n",
      "Epoch 7494, reconstruction losses: 0.020629180255267617, regression losses: 0.12175810418805462, validation losses: 0.5405233838447169\n",
      "Epoch 7495, reconstruction losses: 0.02048152677704494, regression losses: 0.10926272168574526, validation losses: 0.5271675323439314\n",
      "Epoch 7496, reconstruction losses: 0.021346041207348752, regression losses: 0.1197322311416587, validation losses: 0.5245719751055772\n",
      "Epoch 7497, reconstruction losses: 0.02104995295993506, regression losses: 0.12573292066945882, validation losses: 0.4853748782518212\n",
      "Epoch 7498, reconstruction losses: 0.021051579766579617, regression losses: 0.1607899330097965, validation losses: 0.43299330322229285\n",
      "Epoch 7499, reconstruction losses: 0.02410064372290933, regression losses: 0.14206211573827332, validation losses: 0.42256157168218955\n",
      "Epoch 7500, reconstruction losses: 0.02324835431011952, regression losses: 0.14106191630765907, validation losses: 0.41137122144614724\n",
      "Epoch 7501, reconstruction losses: 0.026796365662975774, regression losses: 0.29101365858345607, validation losses: 0.43366142253216156\n",
      "Epoch 7502, reconstruction losses: 0.023646542005181553, regression losses: 0.15044968497133224, validation losses: 0.5801012701181075\n",
      "Epoch 7503, reconstruction losses: 0.023063118606789078, regression losses: 0.13767734308062138, validation losses: 0.5367187760686993\n",
      "Epoch 7504, reconstruction losses: 0.02410506613346963, regression losses: 0.10802235687361621, validation losses: 0.4757939120746488\n",
      "Epoch 7505, reconstruction losses: 0.02265893882324354, regression losses: 0.11775717559815933, validation losses: 0.5095053981839701\n",
      "Epoch 7506, reconstruction losses: 0.021937242557815328, regression losses: 0.15321012422032085, validation losses: 0.517202013303159\n",
      "Epoch 7507, reconstruction losses: 0.023799038970712963, regression losses: 0.11491385851652422, validation losses: 0.44817345733020464\n",
      "Epoch 7508, reconstruction losses: 0.024380265655637764, regression losses: 0.12875333530051897, validation losses: 0.43406774236345086\n",
      "Epoch 7509, reconstruction losses: 0.022282325833248007, regression losses: 0.1491221644743771, validation losses: 0.44266511540858566\n",
      "Epoch 7510, reconstruction losses: 0.019622970744765676, regression losses: 0.11975209669709977, validation losses: 0.4280015650872094\n",
      "Epoch 7511, reconstruction losses: 0.02000843369175442, regression losses: 0.11636198038373646, validation losses: 0.4756146690898037\n",
      "Epoch 7512, reconstruction losses: 0.02329139604886974, regression losses: 0.12800793832243937, validation losses: 0.4832139382256082\n",
      "Epoch 7513, reconstruction losses: 0.021308680910388032, regression losses: 0.1033019888401908, validation losses: 0.5058380927966217\n",
      "Epoch 7514, reconstruction losses: 0.026836169067803166, regression losses: 0.16121037461505328, validation losses: 0.4259225567974573\n",
      "Epoch 7515, reconstruction losses: 0.02155424161665732, regression losses: 0.11150484142234646, validation losses: 0.49827152876413905\n",
      "Epoch 7516, reconstruction losses: 0.022499965947630138, regression losses: 0.1276660918313995, validation losses: 0.48004615813757795\n",
      "Epoch 7517, reconstruction losses: 0.02041589057213393, regression losses: 0.11806938138746916, validation losses: 0.47366301306035197\n",
      "Epoch 7518, reconstruction losses: 0.02504338668457775, regression losses: 0.12637274871491092, validation losses: 0.5415945170486082\n",
      "Epoch 7519, reconstruction losses: 0.021200356659438948, regression losses: 0.09987026864858785, validation losses: 0.5264358827482147\n",
      "Epoch 7520, reconstruction losses: 0.019783504506350053, regression losses: 0.09669145233422881, validation losses: 0.48995281811611924\n",
      "Epoch 7521, reconstruction losses: 0.024076102206169576, regression losses: 0.12150400382603725, validation losses: 0.4974702705342236\n",
      "Epoch 7522, reconstruction losses: 0.02753808827695528, regression losses: 0.1956115535124583, validation losses: 0.5104904583222658\n",
      "Epoch 7523, reconstruction losses: 0.0219974134442191, regression losses: 0.343794676203366, validation losses: 0.4706141837703697\n",
      "Epoch 7524, reconstruction losses: 0.02332220251031534, regression losses: 0.17771229312172135, validation losses: 0.772855314938206\n",
      "Epoch 7525, reconstruction losses: 0.02190954887195899, regression losses: 0.1591030663741915, validation losses: 0.824863967316636\n",
      "Epoch 7526, reconstruction losses: 0.021761062244410465, regression losses: 0.12548032849606927, validation losses: 0.5905536733078418\n",
      "Epoch 7527, reconstruction losses: 0.022001340296471383, regression losses: 0.17492546577126977, validation losses: 0.5447812692195344\n",
      "Epoch 7528, reconstruction losses: 0.02341440077766493, regression losses: 0.14598383304992657, validation losses: 0.4927218009547451\n",
      "Epoch 7529, reconstruction losses: 0.022361517666487217, regression losses: 0.12321496529368015, validation losses: 0.5208195577183237\n",
      "Epoch 7530, reconstruction losses: 0.021981514128066613, regression losses: 0.10480711137126861, validation losses: 0.5023507616521717\n",
      "Epoch 7531, reconstruction losses: 0.022140533121517484, regression losses: 0.14017159009225647, validation losses: 0.45352553438001414\n",
      "Epoch 7532, reconstruction losses: 0.0221540155456818, regression losses: 0.07575956624939267, validation losses: 0.5116499549336273\n",
      "Epoch 7533, reconstruction losses: 0.023810127927412952, regression losses: 0.1481233275370307, validation losses: 0.46200507271273206\n",
      "Epoch 7534, reconstruction losses: 0.023046853846756428, regression losses: 0.1477800170289416, validation losses: 0.4228062230846719\n",
      "Epoch 7535, reconstruction losses: 0.02051635479291189, regression losses: 0.09830551241093026, validation losses: 0.5106165608769634\n",
      "Epoch 7536, reconstruction losses: 0.022138929620202513, regression losses: 0.11443516689171217, validation losses: 0.5441033044358826\n",
      "Epoch 7537, reconstruction losses: 0.02316425774056035, regression losses: 0.11013536362261472, validation losses: 0.4645455724133871\n",
      "Epoch 7538, reconstruction losses: 0.0212769191376752, regression losses: 0.09316370322700943, validation losses: 0.4570818519952961\n",
      "Epoch 7539, reconstruction losses: 0.020930894426838174, regression losses: 0.10494181308379502, validation losses: 0.4623091191337469\n",
      "Epoch 7540, reconstruction losses: 0.02198634651734617, regression losses: 0.10457939735440139, validation losses: 0.48655153801832796\n",
      "Epoch 7541, reconstruction losses: 0.027162386990258525, regression losses: 0.1245607585422326, validation losses: 0.46833709466387696\n",
      "Epoch 7542, reconstruction losses: 0.02566335987887038, regression losses: 0.18587595481349206, validation losses: 0.4850469439490177\n",
      "Epoch 7543, reconstruction losses: 0.027265859322720527, regression losses: 0.3197739362723094, validation losses: 0.4416454533074884\n",
      "Epoch 7544, reconstruction losses: 0.024811468072950663, regression losses: 0.1695902840772289, validation losses: 0.6453646773602322\n",
      "Epoch 7545, reconstruction losses: 0.022657944955039387, regression losses: 0.10704904527823424, validation losses: 0.5501927370721442\n",
      "Epoch 7546, reconstruction losses: 0.022488534030691038, regression losses: 0.1279989547486463, validation losses: 0.6088188886211359\n",
      "Epoch 7547, reconstruction losses: 0.02453936212705001, regression losses: 0.11250389975064162, validation losses: 0.5369899011686642\n",
      "Epoch 7548, reconstruction losses: 0.023420776747094824, regression losses: 0.12529075756637026, validation losses: 0.4638741479100705\n",
      "Epoch 7549, reconstruction losses: 0.020944593297703856, regression losses: 0.11431261032491166, validation losses: 0.437093392090771\n",
      "Epoch 7550, reconstruction losses: 0.021515454623747623, regression losses: 0.1440047736679236, validation losses: 0.4736224680277896\n",
      "Epoch 7551, reconstruction losses: 0.02120218897577369, regression losses: 0.09090090972187491, validation losses: 0.5482492113272767\n",
      "Epoch 7552, reconstruction losses: 0.02273322376100824, regression losses: 0.10062452802583723, validation losses: 0.5147768353336032\n",
      "Epoch 7553, reconstruction losses: 0.02216128469115579, regression losses: 0.1456424413529223, validation losses: 0.45510852394184265\n",
      "Epoch 7554, reconstruction losses: 0.02317688120299794, regression losses: 0.10026151607463155, validation losses: 0.4524874762835076\n",
      "Epoch 7555, reconstruction losses: 0.022619748895260038, regression losses: 0.11689860377773757, validation losses: 0.493213018070265\n",
      "Epoch 7556, reconstruction losses: 0.0215873730375832, regression losses: 0.14679686123527705, validation losses: 0.5549986498364201\n",
      "Epoch 7557, reconstruction losses: 0.02217902555372757, regression losses: 0.14974859131230767, validation losses: 0.5836667271959187\n",
      "Epoch 7558, reconstruction losses: 0.026134870358035404, regression losses: 0.15616319233916948, validation losses: 0.5480486087970022\n",
      "Epoch 7559, reconstruction losses: 0.021423600314545065, regression losses: 0.16538139772657237, validation losses: 0.4901387939288915\n",
      "Epoch 7560, reconstruction losses: 0.02586962768774103, regression losses: 0.11014640086264926, validation losses: 0.5349405905793044\n",
      "Epoch 7561, reconstruction losses: 0.024944259145098326, regression losses: 0.1476485814547719, validation losses: 0.47834954613667996\n",
      "Epoch 7562, reconstruction losses: 0.021072923535702563, regression losses: 0.11993626089746863, validation losses: 0.6109860210528171\n",
      "Epoch 7563, reconstruction losses: 0.02519088732418039, regression losses: 0.20839646256461103, validation losses: 0.5447545056834442\n",
      "Epoch 7564, reconstruction losses: 0.022811266027349945, regression losses: 0.1008830417948304, validation losses: 0.5486755420917755\n",
      "Epoch 7565, reconstruction losses: 0.023321257004917002, regression losses: 0.15319023110164498, validation losses: 0.5258367932265576\n",
      "Epoch 7566, reconstruction losses: 0.02302948018344506, regression losses: 0.12221009134191946, validation losses: 0.4752705878130412\n",
      "Epoch 7567, reconstruction losses: 0.020651972161843096, regression losses: 0.10397307359338255, validation losses: 0.46304716462684103\n",
      "Epoch 7568, reconstruction losses: 0.02191193689618672, regression losses: 0.12224920667014666, validation losses: 0.48296460558132603\n",
      "Epoch 7569, reconstruction losses: 0.02158891986636689, regression losses: 0.11880677986328216, validation losses: 0.44869798808724265\n",
      "Epoch 7570, reconstruction losses: 0.02139295415002719, regression losses: 0.12447663298111004, validation losses: 0.4796364962580126\n",
      "Epoch 7571, reconstruction losses: 0.020937091696012457, regression losses: 0.09378247036945268, validation losses: 0.50214718161932\n",
      "Epoch 7572, reconstruction losses: 0.02209044822509644, regression losses: 0.10596178596180235, validation losses: 0.44951336840001016\n",
      "Epoch 7573, reconstruction losses: 0.02205637362161611, regression losses: 0.12473138700508611, validation losses: 0.4348740506761008\n",
      "Epoch 7574, reconstruction losses: 0.021317595009207786, regression losses: 0.12934270803548262, validation losses: 0.47189082318345527\n",
      "Epoch 7575, reconstruction losses: 0.021050495427590646, regression losses: 0.08218749744961461, validation losses: 0.5460434177945478\n",
      "Epoch 7576, reconstruction losses: 0.02113207802576141, regression losses: 0.11497389081836434, validation losses: 0.4906540227341093\n",
      "Epoch 7577, reconstruction losses: 0.02161975969535708, regression losses: 0.15940240216715196, validation losses: 0.4618583373617148\n",
      "Epoch 7578, reconstruction losses: 0.024181889906342836, regression losses: 0.11716322501853943, validation losses: 0.5688919741753795\n",
      "Epoch 7579, reconstruction losses: 0.023579424491060638, regression losses: 0.10799292775268617, validation losses: 0.5157015659035218\n",
      "Epoch 7580, reconstruction losses: 0.02067079890712747, regression losses: 0.08457014744214975, validation losses: 0.4613228616229924\n",
      "Epoch 7581, reconstruction losses: 0.02193196306612035, regression losses: 0.10744539905870026, validation losses: 0.44794379993313604\n",
      "Epoch 7582, reconstruction losses: 0.021049309703358277, regression losses: 0.11587341334726928, validation losses: 0.43593763328701735\n",
      "Epoch 7583, reconstruction losses: 0.018495521011564053, regression losses: 0.09518421809672535, validation losses: 0.4481480806959355\n",
      "Epoch 7584, reconstruction losses: 0.023377685940560763, regression losses: 0.12844176831012533, validation losses: 0.4573876405397344\n",
      "Epoch 7585, reconstruction losses: 0.021332199159936453, regression losses: 0.1198063489826067, validation losses: 0.43076256713481176\n",
      "Epoch 7586, reconstruction losses: 0.020582949470913554, regression losses: 0.10426444475647809, validation losses: 0.41994000612459936\n",
      "Epoch 7587, reconstruction losses: 0.019800295704166172, regression losses: 0.10868766088678446, validation losses: 0.5003168793441751\n",
      "Epoch 7588, reconstruction losses: 0.022540548352236206, regression losses: 0.14376639904383598, validation losses: 0.5007217385966922\n",
      "Epoch 7589, reconstruction losses: 0.02302355842445397, regression losses: 0.13776135708337245, validation losses: 0.5012496355311016\n",
      "Epoch 7590, reconstruction losses: 0.019618085921318973, regression losses: 0.10949931507406895, validation losses: 0.42953494623386185\n",
      "Epoch 7591, reconstruction losses: 0.02467361313238416, regression losses: 0.12687597786532676, validation losses: 0.4312065357544559\n",
      "Epoch 7592, reconstruction losses: 0.02049224667060297, regression losses: 0.11440990837486008, validation losses: 0.5544061231605385\n",
      "Epoch 7593, reconstruction losses: 0.023179032119339426, regression losses: 0.14767966854380127, validation losses: 0.5038599482332552\n",
      "Epoch 7594, reconstruction losses: 0.022534081410560885, regression losses: 0.1409303511415493, validation losses: 0.5431256356681718\n",
      "Epoch 7595, reconstruction losses: 0.022819565551921675, regression losses: 0.11000458729408337, validation losses: 0.56191105097562\n",
      "Epoch 7596, reconstruction losses: 0.023069379602568864, regression losses: 0.17430559200896573, validation losses: 0.5284871795833666\n",
      "Epoch 7597, reconstruction losses: 0.023185228458430695, regression losses: 0.1570761814725569, validation losses: 0.5258140658601922\n",
      "Epoch 7598, reconstruction losses: 0.025680486247806972, regression losses: 0.13172804836049548, validation losses: 0.43421595942692076\n",
      "Epoch 7599, reconstruction losses: 0.02377421679867932, regression losses: 0.11593481854567815, validation losses: 0.435534446137268\n",
      "Epoch 7600, reconstruction losses: 0.022659178259946074, regression losses: 0.13822587500398673, validation losses: 0.46246392153385774\n",
      "Epoch 7601, reconstruction losses: 0.020133784265676486, regression losses: 0.09400762007163255, validation losses: 0.493282480184486\n",
      "Epoch 7602, reconstruction losses: 0.02120074413595925, regression losses: 0.1353320557709812, validation losses: 0.497834531533523\n",
      "Epoch 7603, reconstruction losses: 0.022066097064213048, regression losses: 0.12163753039808023, validation losses: 0.48390517470947964\n",
      "Epoch 7604, reconstruction losses: 0.023365320252075848, regression losses: 0.120522829945849, validation losses: 0.44432178435176034\n",
      "Epoch 7605, reconstruction losses: 0.021043144672758553, regression losses: 0.10742406560462762, validation losses: 0.45543201086221824\n",
      "Epoch 7606, reconstruction losses: 0.02118052739128586, regression losses: 0.10825787046920507, validation losses: 0.4434202433397458\n",
      "Epoch 7607, reconstruction losses: 0.020830057978363438, regression losses: 0.09702441052682975, validation losses: 0.5172544395039809\n",
      "Epoch 7608, reconstruction losses: 0.02149052225611839, regression losses: 0.11001834657124224, validation losses: 0.5480910407830486\n",
      "Epoch 7609, reconstruction losses: 0.02284867656601009, regression losses: 0.1335134806342252, validation losses: 0.49988245564031464\n",
      "Epoch 7610, reconstruction losses: 0.020575413533795002, regression losses: 0.09159844799372083, validation losses: 0.45516024978052316\n",
      "Epoch 7611, reconstruction losses: 0.0216150955933423, regression losses: 0.13803736826969767, validation losses: 0.49205048322697753\n",
      "Epoch 7612, reconstruction losses: 0.022616333334281022, regression losses: 0.12607917925381007, validation losses: 0.575538864918829\n",
      "Epoch 7613, reconstruction losses: 0.02433476093142592, regression losses: 0.13360473606361775, validation losses: 0.545297514435732\n",
      "Epoch 7614, reconstruction losses: 0.023752742019173455, regression losses: 0.1467352738783628, validation losses: 0.5359818260504647\n",
      "Epoch 7615, reconstruction losses: 0.01984159197647027, regression losses: 0.084430527860521, validation losses: 0.5180788751753022\n",
      "Epoch 7616, reconstruction losses: 0.021616895152015092, regression losses: 0.09987142434127674, validation losses: 0.4759695810622122\n",
      "Epoch 7617, reconstruction losses: 0.020892159030752745, regression losses: 0.11638604865897118, validation losses: 0.49853317467269775\n",
      "Epoch 7618, reconstruction losses: 0.01837828768811707, regression losses: 0.11318015130303082, validation losses: 0.4796708793110953\n",
      "Epoch 7619, reconstruction losses: 0.02245679778011174, regression losses: 0.11437697490801893, validation losses: 0.4466653644725082\n",
      "Epoch 7620, reconstruction losses: 0.023387160732766324, regression losses: 0.22294075951885534, validation losses: 0.47281631324905415\n",
      "Epoch 7621, reconstruction losses: 0.02187412294182452, regression losses: 0.11080959569897914, validation losses: 0.6686612001437577\n",
      "Epoch 7622, reconstruction losses: 0.02254533922992982, regression losses: 0.14711409238542023, validation losses: 0.5466059790905909\n",
      "Epoch 7623, reconstruction losses: 0.022323409505746464, regression losses: 0.11538994688856166, validation losses: 0.4698980526016808\n",
      "Epoch 7624, reconstruction losses: 0.020033623868975073, regression losses: 0.11036347047565426, validation losses: 0.42772032459431675\n",
      "Epoch 7625, reconstruction losses: 0.021690092069822333, regression losses: 0.12441707605849653, validation losses: 0.40807439663550205\n",
      "Epoch 7626, reconstruction losses: 0.02340784922763382, regression losses: 0.10138873753827037, validation losses: 0.4170263132462417\n",
      "Epoch 7627, reconstruction losses: 0.022973366026596994, regression losses: 0.09790469042715526, validation losses: 0.4289392802948982\n",
      "Epoch 7628, reconstruction losses: 0.023312865227589907, regression losses: 0.11483330876738615, validation losses: 0.4232141379809239\n",
      "Epoch 7629, reconstruction losses: 0.021215995074244116, regression losses: 0.1149433702116968, validation losses: 0.4351360301450699\n",
      "Epoch 7630, reconstruction losses: 0.021846657882283963, regression losses: 0.12274259602692658, validation losses: 0.42674873748793074\n",
      "Epoch 7631, reconstruction losses: 0.020148781776119448, regression losses: 0.11916747927334827, validation losses: 0.47271811009372755\n",
      "Epoch 7632, reconstruction losses: 0.02757951561649913, regression losses: 0.15881289608585536, validation losses: 0.44649393005525173\n",
      "Epoch 7633, reconstruction losses: 0.020354572717268204, regression losses: 0.10433389087412417, validation losses: 0.4887629795727465\n",
      "Epoch 7634, reconstruction losses: 0.025325365260496384, regression losses: 0.15902635788477262, validation losses: 0.48250452786165793\n",
      "Epoch 7635, reconstruction losses: 0.02343915462408861, regression losses: 0.1105853203277443, validation losses: 0.46270027829562854\n",
      "Epoch 7636, reconstruction losses: 0.0214127550407415, regression losses: 0.1475131225504828, validation losses: 0.47699127735026015\n",
      "Epoch 7637, reconstruction losses: 0.020775890869353865, regression losses: 0.10667562252945612, validation losses: 0.479486332164757\n",
      "Epoch 7638, reconstruction losses: 0.019725061911053953, regression losses: 0.1015344071383574, validation losses: 0.48926085767772864\n",
      "Epoch 7639, reconstruction losses: 0.022752336443700026, regression losses: 0.10128894537325664, validation losses: 0.44016910680801624\n",
      "Epoch 7640, reconstruction losses: 0.02206894086570864, regression losses: 0.1413705154246439, validation losses: 0.47942303581649776\n",
      "Epoch 7641, reconstruction losses: 0.022598191989013673, regression losses: 0.1153308987104675, validation losses: 0.5361654467453792\n",
      "Epoch 7642, reconstruction losses: 0.021573728313978885, regression losses: 0.11275963949584647, validation losses: 0.5083222507568109\n",
      "Epoch 7643, reconstruction losses: 0.02376152041750856, regression losses: 0.1614189571628404, validation losses: 0.4871126039793143\n",
      "Epoch 7644, reconstruction losses: 0.020290851022347275, regression losses: 0.1082381221751653, validation losses: 0.47875869725781833\n",
      "Epoch 7645, reconstruction losses: 0.02486012621917563, regression losses: 0.1512991962049034, validation losses: 0.4478517985804207\n",
      "Epoch 7646, reconstruction losses: 0.0193784113687473, regression losses: 0.10839722674179054, validation losses: 0.45441053077268234\n",
      "Epoch 7647, reconstruction losses: 0.023225805514565996, regression losses: 0.10449524049176806, validation losses: 0.44588664432724234\n",
      "Epoch 7648, reconstruction losses: 0.02289732131945618, regression losses: 0.10852223781717778, validation losses: 0.46004857993819254\n",
      "Epoch 7649, reconstruction losses: 0.024063320948734156, regression losses: 0.22946396682652967, validation losses: 0.48961079674882346\n",
      "Epoch 7650, reconstruction losses: 0.020911688485393154, regression losses: 0.10601334512839813, validation losses: 0.5956561671058979\n",
      "Epoch 7651, reconstruction losses: 0.02322924354890711, regression losses: 0.13298591391785872, validation losses: 0.5116077677135179\n",
      "Epoch 7652, reconstruction losses: 0.021397984031436848, regression losses: 0.12823197437204545, validation losses: 0.48667650263755124\n",
      "Epoch 7653, reconstruction losses: 0.028039811729659237, regression losses: 0.13621949717908782, validation losses: 0.4482177190742396\n",
      "Epoch 7654, reconstruction losses: 0.02194286394034402, regression losses: 0.11534345456623023, validation losses: 0.4125502341751711\n",
      "Epoch 7655, reconstruction losses: 0.02255689532918284, regression losses: 0.12440892209975514, validation losses: 0.4243728826344213\n",
      "Epoch 7656, reconstruction losses: 0.0238179555701609, regression losses: 0.1067266657096328, validation losses: 0.46362434310457656\n",
      "Epoch 7657, reconstruction losses: 0.021744694274001664, regression losses: 0.13557316895981505, validation losses: 0.4961525687965964\n",
      "Epoch 7658, reconstruction losses: 0.018834143870665492, regression losses: 0.12679883489595703, validation losses: 0.5095010493685292\n",
      "Epoch 7659, reconstruction losses: 0.022490351693868687, regression losses: 0.11328179356652637, validation losses: 0.44625334473729944\n",
      "Epoch 7660, reconstruction losses: 0.021077103918226824, regression losses: 0.10904239841823608, validation losses: 0.49086254056615386\n",
      "Epoch 7661, reconstruction losses: 0.02048073456521936, regression losses: 0.13684740989577843, validation losses: 0.45731192654622\n",
      "Epoch 7662, reconstruction losses: 0.024744664922663993, regression losses: 0.1483985048519491, validation losses: 0.4968720548304674\n",
      "Epoch 7663, reconstruction losses: 0.022076209897959928, regression losses: 0.09845355553541713, validation losses: 0.46103957583515426\n",
      "Epoch 7664, reconstruction losses: 0.026052507490998106, regression losses: 0.2715786456097366, validation losses: 0.45294733783770696\n",
      "Epoch 7665, reconstruction losses: 0.02360606349572212, regression losses: 0.1148051422652769, validation losses: 0.6456772995323936\n",
      "Epoch 7666, reconstruction losses: 0.02122967339226326, regression losses: 0.159213305258736, validation losses: 0.6294025066778978\n",
      "Epoch 7667, reconstruction losses: 0.024234437992552788, regression losses: 0.12837258705725274, validation losses: 0.5858515831145733\n",
      "Epoch 7668, reconstruction losses: 0.025131764371727098, regression losses: 0.1859581562452587, validation losses: 0.5000865146723508\n",
      "Epoch 7669, reconstruction losses: 0.024329068283273525, regression losses: 0.10550839593932151, validation losses: 0.43124245000568184\n",
      "Epoch 7670, reconstruction losses: 0.020134514591814125, regression losses: 0.12132873392299111, validation losses: 0.4186419037536086\n",
      "Epoch 7671, reconstruction losses: 0.023148259590627687, regression losses: 0.11575370984221588, validation losses: 0.46247163864766466\n",
      "Epoch 7672, reconstruction losses: 0.02090032811407011, regression losses: 0.10782070436091104, validation losses: 0.43501510020915346\n",
      "Epoch 7673, reconstruction losses: 0.024526699862605382, regression losses: 0.12771141799915847, validation losses: 0.4229247866229852\n",
      "Epoch 7674, reconstruction losses: 0.02587146696940762, regression losses: 0.16158067641943413, validation losses: 0.40359374046536123\n",
      "Epoch 7675, reconstruction losses: 0.021862789320099878, regression losses: 0.11311340798160197, validation losses: 0.536198636152425\n",
      "Epoch 7676, reconstruction losses: 0.01933249065580763, regression losses: 0.08592599790608477, validation losses: 0.44404510131465746\n",
      "Epoch 7677, reconstruction losses: 0.025759485614714618, regression losses: 0.16526153961042203, validation losses: 0.4310376251655303\n",
      "Epoch 7678, reconstruction losses: 0.023053903278542034, regression losses: 0.12131626351712194, validation losses: 0.43883085596195187\n",
      "Epoch 7679, reconstruction losses: 0.02104976417040707, regression losses: 0.08875927863922228, validation losses: 0.4687504324146094\n",
      "Epoch 7680, reconstruction losses: 0.02467242471414795, regression losses: 0.11854211436096715, validation losses: 0.45321077140682825\n",
      "Epoch 7681, reconstruction losses: 0.021534776759037127, regression losses: 0.1379316348577126, validation losses: 0.4984307987815095\n",
      "Epoch 7682, reconstruction losses: 0.02278507284632031, regression losses: 0.11657478798244786, validation losses: 0.44799880008103515\n",
      "Epoch 7683, reconstruction losses: 0.021451907122977447, regression losses: 0.1088688828159156, validation losses: 0.4478614114534677\n",
      "Epoch 7684, reconstruction losses: 0.022642693467202005, regression losses: 0.12454169127584658, validation losses: 0.44330566772036817\n",
      "Epoch 7685, reconstruction losses: 0.019898422225524313, regression losses: 0.10565578809229698, validation losses: 0.5591259902647838\n",
      "Epoch 7686, reconstruction losses: 0.023654448639289047, regression losses: 0.12185419280781343, validation losses: 0.5463991847177739\n",
      "Epoch 7687, reconstruction losses: 0.02007582837296542, regression losses: 0.13632811893918872, validation losses: 0.42180317875351064\n",
      "Epoch 7688, reconstruction losses: 0.02439159874323355, regression losses: 0.12247767592799198, validation losses: 0.5260886635516404\n",
      "Epoch 7689, reconstruction losses: 0.02468338617646716, regression losses: 0.18830245090441952, validation losses: 0.5254388201761008\n",
      "Epoch 7690, reconstruction losses: 0.021782538726614543, regression losses: 0.09997765934952829, validation losses: 0.46378044422060755\n",
      "Epoch 7691, reconstruction losses: 0.02199750926153867, regression losses: 0.11803016572217691, validation losses: 0.42773044052763526\n",
      "Epoch 7692, reconstruction losses: 0.020465867495294526, regression losses: 0.10817128202599995, validation losses: 0.4352002250001748\n",
      "Epoch 7693, reconstruction losses: 0.02325052479208206, regression losses: 0.1488069801036668, validation losses: 0.4328740713028116\n",
      "Epoch 7694, reconstruction losses: 0.021630990782474335, regression losses: 0.12976596192420453, validation losses: 0.4337999418831634\n",
      "Epoch 7695, reconstruction losses: 0.021292554780513333, regression losses: 0.1552160452816201, validation losses: 0.41903248374998947\n",
      "Epoch 7696, reconstruction losses: 0.023546854453394342, regression losses: 0.15314835169477517, validation losses: 0.4214124435112083\n",
      "Epoch 7697, reconstruction losses: 0.022088665375938125, regression losses: 0.11814338714483165, validation losses: 0.4261822148159671\n",
      "Epoch 7698, reconstruction losses: 0.022159398403721563, regression losses: 0.13317173579667083, validation losses: 0.44913900207505586\n",
      "Epoch 7699, reconstruction losses: 0.023193036134355676, regression losses: 0.16041161425789713, validation losses: 0.4244067693994367\n",
      "Epoch 7700, reconstruction losses: 0.02076198189987053, regression losses: 0.10404914465014915, validation losses: 0.41758042580316923\n",
      "Epoch 7701, reconstruction losses: 0.021620606598961756, regression losses: 0.08834610657769608, validation losses: 0.42613945691292154\n",
      "Epoch 7702, reconstruction losses: 0.02249710333982609, regression losses: 0.10821199503069097, validation losses: 0.44777010683753404\n",
      "Epoch 7703, reconstruction losses: 0.0216139339937658, regression losses: 0.08594376867408943, validation losses: 0.4882282600156927\n",
      "Epoch 7704, reconstruction losses: 0.021775641390839616, regression losses: 0.10265013540796637, validation losses: 0.4843984171143279\n",
      "Epoch 7705, reconstruction losses: 0.022823947781252026, regression losses: 0.10775371404805201, validation losses: 0.49384592483894657\n",
      "Epoch 7706, reconstruction losses: 0.021137241661778133, regression losses: 0.1067833164122262, validation losses: 0.4563894087382455\n",
      "Epoch 7707, reconstruction losses: 0.02229305771685677, regression losses: 0.08923611345439862, validation losses: 0.4654413431710188\n",
      "Epoch 7708, reconstruction losses: 0.01892050168830351, regression losses: 0.08323248929786205, validation losses: 0.5115002378871747\n",
      "Epoch 7709, reconstruction losses: 0.021046708585151754, regression losses: 0.10738759937080515, validation losses: 0.47879758790216465\n",
      "Epoch 7710, reconstruction losses: 0.020456528595193008, regression losses: 0.12048181838967299, validation losses: 0.4616415246631258\n",
      "Epoch 7711, reconstruction losses: 0.02254153439168515, regression losses: 0.11573169491557929, validation losses: 0.493290786420694\n",
      "Epoch 7712, reconstruction losses: 0.021970860171671384, regression losses: 0.09930404167595, validation losses: 0.45179242671689285\n",
      "Epoch 7713, reconstruction losses: 0.02478698829920909, regression losses: 0.13646862670238186, validation losses: 0.4300733216752972\n",
      "Epoch 7714, reconstruction losses: 0.02162765373530583, regression losses: 0.11207244691072885, validation losses: 0.4266239987176262\n",
      "Epoch 7715, reconstruction losses: 0.022193221607698682, regression losses: 0.07997831166573602, validation losses: 0.44338295948155276\n",
      "Epoch 7716, reconstruction losses: 0.022739649346398643, regression losses: 0.10508126531411471, validation losses: 0.5491436075818986\n",
      "Epoch 7717, reconstruction losses: 0.019263079514073137, regression losses: 0.12406181295480082, validation losses: 0.5607606105982769\n",
      "Epoch 7718, reconstruction losses: 0.02436455837121172, regression losses: 0.1661524147590885, validation losses: 0.4675237986654204\n",
      "Epoch 7719, reconstruction losses: 0.021678550672495113, regression losses: 0.1250756084681542, validation losses: 0.4941653646494377\n",
      "Epoch 7720, reconstruction losses: 0.025622065079431863, regression losses: 0.1483336467256618, validation losses: 0.4814772494582811\n",
      "Epoch 7721, reconstruction losses: 0.021606769056944142, regression losses: 0.18526907103765478, validation losses: 0.48286844250176375\n",
      "Epoch 7722, reconstruction losses: 0.022089607779848055, regression losses: 0.11223905323261722, validation losses: 0.47547778293214343\n",
      "Epoch 7723, reconstruction losses: 0.020872386104465426, regression losses: 0.11276349161981178, validation losses: 0.4435210029001886\n",
      "Epoch 7724, reconstruction losses: 0.020045234308366064, regression losses: 0.11672875806006536, validation losses: 0.4408094155404696\n",
      "Epoch 7725, reconstruction losses: 0.020139851061668983, regression losses: 0.10607117398290193, validation losses: 0.4431277645093133\n",
      "Epoch 7726, reconstruction losses: 0.02130937244148416, regression losses: 0.10711908101080042, validation losses: 0.4442067798934304\n",
      "Epoch 7727, reconstruction losses: 0.02254505295165625, regression losses: 0.14337016496613667, validation losses: 0.45061287348958456\n",
      "Epoch 7728, reconstruction losses: 0.02115171994385024, regression losses: 0.09398967028798241, validation losses: 0.5624177944814517\n",
      "Epoch 7729, reconstruction losses: 0.019956728687900212, regression losses: 0.10376907825440677, validation losses: 0.5540683634988882\n",
      "Epoch 7730, reconstruction losses: 0.02259250619983111, regression losses: 0.09571287471359903, validation losses: 0.48492352297737995\n",
      "Epoch 7731, reconstruction losses: 0.023265251914307308, regression losses: 0.09965502437921064, validation losses: 0.4933515333511767\n",
      "Epoch 7732, reconstruction losses: 0.025078331107368696, regression losses: 0.13135702397153864, validation losses: 0.5393276985214525\n",
      "Epoch 7733, reconstruction losses: 0.021875970637573836, regression losses: 0.10744362973906273, validation losses: 0.6261204874720502\n",
      "Epoch 7734, reconstruction losses: 0.022065086262046674, regression losses: 0.12008212919168279, validation losses: 0.5400007563031249\n",
      "Epoch 7735, reconstruction losses: 0.02205556357760682, regression losses: 0.10687803340796845, validation losses: 0.44755926266254525\n",
      "Epoch 7736, reconstruction losses: 0.022351502686225693, regression losses: 0.18046062346522188, validation losses: 0.43699332366146265\n",
      "Epoch 7737, reconstruction losses: 0.025872038819293855, regression losses: 0.1827669413661971, validation losses: 0.4850498864369903\n",
      "Epoch 7738, reconstruction losses: 0.022665277778538696, regression losses: 0.26900551251496935, validation losses: 0.5310261563335024\n",
      "Epoch 7739, reconstruction losses: 0.021677911909765955, regression losses: 0.148084397245915, validation losses: 0.5573374956576846\n",
      "Epoch 7740, reconstruction losses: 0.02054190667764007, regression losses: 0.14170706579807357, validation losses: 0.545138054360621\n",
      "Epoch 7741, reconstruction losses: 0.020582803622805103, regression losses: 0.1190108927604908, validation losses: 0.4944060252996677\n",
      "Epoch 7742, reconstruction losses: 0.02130794419330103, regression losses: 0.12912114456066484, validation losses: 0.4746904372174573\n",
      "Epoch 7743, reconstruction losses: 0.022183867625069242, regression losses: 0.20496823991152258, validation losses: 0.4278487164608265\n",
      "Epoch 7744, reconstruction losses: 0.021654206122753393, regression losses: 0.12784265064614977, validation losses: 0.5738082378038355\n",
      "Epoch 7745, reconstruction losses: 0.0236544656286227, regression losses: 0.12674750914158278, validation losses: 0.5561736516978368\n",
      "Epoch 7746, reconstruction losses: 0.020833199176594534, regression losses: 0.12936609265650836, validation losses: 0.4766888051632997\n",
      "Epoch 7747, reconstruction losses: 0.020575025873301934, regression losses: 0.11911315536435518, validation losses: 0.45811851006881055\n",
      "Epoch 7748, reconstruction losses: 0.024426765448691025, regression losses: 0.22316328178088057, validation losses: 0.4735011452577695\n",
      "Epoch 7749, reconstruction losses: 0.022804239767236972, regression losses: 0.11643555727682559, validation losses: 0.5641169986206818\n",
      "Epoch 7750, reconstruction losses: 0.01989887525924763, regression losses: 0.10722546740723038, validation losses: 0.46336826428705397\n",
      "Epoch 7751, reconstruction losses: 0.021477442062035924, regression losses: 0.13978586802218843, validation losses: 0.5206670736928538\n",
      "Epoch 7752, reconstruction losses: 0.020631270799422587, regression losses: 0.1126777299463098, validation losses: 0.4831558929106661\n",
      "Epoch 7753, reconstruction losses: 0.019342141585248808, regression losses: 0.09562834502627472, validation losses: 0.44647420235433044\n",
      "Epoch 7754, reconstruction losses: 0.02311837402980775, regression losses: 0.12505588223170866, validation losses: 0.42692860841960567\n",
      "Epoch 7755, reconstruction losses: 0.021411131309503027, regression losses: 0.14555845057947786, validation losses: 0.4726001083750017\n",
      "Epoch 7756, reconstruction losses: 0.021855064447696707, regression losses: 0.1327002509745258, validation losses: 0.49887807065288176\n",
      "Epoch 7757, reconstruction losses: 0.026697218218630487, regression losses: 0.17897498245575194, validation losses: 0.5176632332801434\n",
      "Epoch 7758, reconstruction losses: 0.021535001763296573, regression losses: 0.1375242429055865, validation losses: 0.6035887593619249\n",
      "Epoch 7759, reconstruction losses: 0.020974496083016173, regression losses: 0.13074872138083235, validation losses: 0.55401906622468\n",
      "Epoch 7760, reconstruction losses: 0.02274883546741133, regression losses: 0.1372299580704655, validation losses: 0.5965205071535814\n",
      "Epoch 7761, reconstruction losses: 0.023940722923749644, regression losses: 0.14388164216765187, validation losses: 0.5217158009048988\n",
      "Epoch 7762, reconstruction losses: 0.027210130894952674, regression losses: 0.14798032981435488, validation losses: 0.4640012147964708\n",
      "Epoch 7763, reconstruction losses: 0.024287789844972454, regression losses: 0.1624237154354908, validation losses: 0.4717877345455869\n",
      "Epoch 7764, reconstruction losses: 0.0215715043596696, regression losses: 0.11819478428194072, validation losses: 0.5183441628988352\n",
      "Epoch 7765, reconstruction losses: 0.02111488537778684, regression losses: 0.10176608909247437, validation losses: 0.5125515204052739\n",
      "Epoch 7766, reconstruction losses: 0.0212063315468797, regression losses: 0.12947948805697865, validation losses: 0.50011188979988\n",
      "Epoch 7767, reconstruction losses: 0.0239073532742258, regression losses: 0.14518106130236202, validation losses: 0.4957481523794808\n",
      "Epoch 7768, reconstruction losses: 0.022364648618231748, regression losses: 0.08433965134431555, validation losses: 0.49793627503720345\n",
      "Epoch 7769, reconstruction losses: 0.02008190685486358, regression losses: 0.1413955238382858, validation losses: 0.45795798314758834\n",
      "Epoch 7770, reconstruction losses: 0.022973508516616045, regression losses: 0.11716633766139314, validation losses: 0.5222405203472515\n",
      "Epoch 7771, reconstruction losses: 0.02208147790799226, regression losses: 0.10149234283281555, validation losses: 0.5603626047457001\n",
      "Epoch 7772, reconstruction losses: 0.020427310291538853, regression losses: 0.1118535804418794, validation losses: 0.4700961800113396\n",
      "Epoch 7773, reconstruction losses: 0.024096921352229368, regression losses: 0.16617391158848968, validation losses: 0.4237198813520549\n",
      "Epoch 7774, reconstruction losses: 0.022401286478781857, regression losses: 0.10670816042610302, validation losses: 0.48051393409600296\n",
      "Epoch 7775, reconstruction losses: 0.022071795221153677, regression losses: 0.10828339454365947, validation losses: 0.45464507416702393\n",
      "Epoch 7776, reconstruction losses: 0.021072435413805785, regression losses: 0.10998743576743737, validation losses: 0.43622754304695793\n",
      "Epoch 7777, reconstruction losses: 0.02313947373483203, regression losses: 0.1330833304724909, validation losses: 0.46784961725256213\n",
      "Epoch 7778, reconstruction losses: 0.021050977501210932, regression losses: 0.12037856715008563, validation losses: 0.5091302712253616\n",
      "Epoch 7779, reconstruction losses: 0.023940572269544692, regression losses: 0.1523045614487519, validation losses: 0.5677321819089539\n",
      "Epoch 7780, reconstruction losses: 0.020488697960544863, regression losses: 0.10844014198029951, validation losses: 0.5438697571847333\n",
      "Epoch 7781, reconstruction losses: 0.020057505613106104, regression losses: 0.09069191851077837, validation losses: 0.4793137158749983\n",
      "Epoch 7782, reconstruction losses: 0.019235947492877596, regression losses: 0.1740857252567533, validation losses: 0.43224352775842173\n",
      "Epoch 7783, reconstruction losses: 0.023383945420329726, regression losses: 0.15411063807019482, validation losses: 0.4784902025659207\n",
      "Epoch 7784, reconstruction losses: 0.024793471509965352, regression losses: 0.33838306587995315, validation losses: 0.479349020007518\n",
      "Epoch 7785, reconstruction losses: 0.022312869768472063, regression losses: 0.15846421659874982, validation losses: 0.8171192674286347\n",
      "Epoch 7786, reconstruction losses: 0.020649012814249086, regression losses: 0.17156142089378035, validation losses: 0.6760733381487862\n",
      "Epoch 7787, reconstruction losses: 0.020204799537271907, regression losses: 0.1435226650638872, validation losses: 0.6739551149476248\n",
      "Epoch 7788, reconstruction losses: 0.022633311392634158, regression losses: 0.11497706451303798, validation losses: 0.5525367529606016\n",
      "Epoch 7789, reconstruction losses: 0.020017298738091775, regression losses: 0.1118078397835775, validation losses: 0.4456646095510927\n",
      "Epoch 7790, reconstruction losses: 0.023889974010342124, regression losses: 0.13776749852521764, validation losses: 0.4231576745335304\n",
      "Epoch 7791, reconstruction losses: 0.022184937190676532, regression losses: 0.11962921064090967, validation losses: 0.49624651728061187\n",
      "Epoch 7792, reconstruction losses: 0.020611539976480124, regression losses: 0.10471718768575816, validation losses: 0.6009658607526691\n",
      "Epoch 7793, reconstruction losses: 0.021201145089453314, regression losses: 0.11041799249702967, validation losses: 0.5091733752170863\n",
      "Epoch 7794, reconstruction losses: 0.022339035938202002, regression losses: 0.11402750664230218, validation losses: 0.47597809297988736\n",
      "Epoch 7795, reconstruction losses: 0.02017538247269298, regression losses: 0.11562731315082446, validation losses: 0.5281787950976907\n",
      "Epoch 7796, reconstruction losses: 0.02038067566431669, regression losses: 0.08081963828440966, validation losses: 0.5137918026872956\n",
      "Epoch 7797, reconstruction losses: 0.023428179340344753, regression losses: 0.1296595843300274, validation losses: 0.4909718287119158\n",
      "Epoch 7798, reconstruction losses: 0.021974950453162466, regression losses: 0.1356117092315086, validation losses: 0.5183757722764706\n",
      "Epoch 7799, reconstruction losses: 0.024929532217744473, regression losses: 0.11022522521318619, validation losses: 0.49676385076893126\n",
      "Epoch 7800, reconstruction losses: 0.023050451231630232, regression losses: 0.1143522567171268, validation losses: 0.4423754241304483\n",
      "Epoch 7801, reconstruction losses: 0.0219978371901922, regression losses: 0.1239434076871767, validation losses: 0.4293745916452219\n",
      "Epoch 7802, reconstruction losses: 0.02151370575002616, regression losses: 0.09865640497028215, validation losses: 0.5010419144404239\n",
      "Epoch 7803, reconstruction losses: 0.023134542082719218, regression losses: 0.13480674426546047, validation losses: 0.48189159526500913\n",
      "Epoch 7804, reconstruction losses: 0.02326427950955132, regression losses: 0.12391143028924229, validation losses: 0.4367155358121529\n",
      "Epoch 7805, reconstruction losses: 0.020228444460478504, regression losses: 0.09117264873550661, validation losses: 0.4423897445001446\n",
      "Epoch 7806, reconstruction losses: 0.021739626840595556, regression losses: 0.11745413165480194, validation losses: 0.4665595739353877\n",
      "Epoch 7807, reconstruction losses: 0.022757924849432516, regression losses: 0.11235225377359634, validation losses: 0.47544375777852266\n",
      "Epoch 7808, reconstruction losses: 0.023558583200502692, regression losses: 0.13927703733811914, validation losses: 0.4386822791743661\n",
      "Epoch 7809, reconstruction losses: 0.02391113205410453, regression losses: 0.11456318541112556, validation losses: 0.4938836422417666\n",
      "Epoch 7810, reconstruction losses: 0.02293636874920093, regression losses: 0.12322393998830894, validation losses: 0.44227893467763163\n",
      "Epoch 7811, reconstruction losses: 0.023398136901561038, regression losses: 0.0988329876577186, validation losses: 0.42083924303826037\n",
      "Epoch 7812, reconstruction losses: 0.021149374036575727, regression losses: 0.14789905805936346, validation losses: 0.4094118958220829\n",
      "Epoch 7813, reconstruction losses: 0.02151360279485929, regression losses: 0.10204245523381705, validation losses: 0.42533106830011164\n",
      "Epoch 7814, reconstruction losses: 0.021470730790537913, regression losses: 0.1236107815807927, validation losses: 0.42529447985551727\n",
      "Epoch 7815, reconstruction losses: 0.02146843425112251, regression losses: 0.09807140570471914, validation losses: 0.47168453468493154\n",
      "Epoch 7816, reconstruction losses: 0.02027968749200654, regression losses: 0.0952778537285938, validation losses: 0.4967890204640452\n",
      "Epoch 7817, reconstruction losses: 0.021160650195733283, regression losses: 0.11546205761365616, validation losses: 0.49641572602574185\n",
      "Epoch 7818, reconstruction losses: 0.022758571996813057, regression losses: 0.12468919779887308, validation losses: 0.4738519204220057\n",
      "Epoch 7819, reconstruction losses: 0.022486816159425514, regression losses: 0.10487488655652674, validation losses: 0.522847362632791\n",
      "Epoch 7820, reconstruction losses: 0.02108423464339486, regression losses: 0.10320590315233266, validation losses: 0.4900895520473568\n",
      "Epoch 7821, reconstruction losses: 0.020939387576390595, regression losses: 0.1431409493945797, validation losses: 0.49571705763892193\n",
      "Epoch 7822, reconstruction losses: 0.024718014608328304, regression losses: 0.13215796614420453, validation losses: 0.7354937740571263\n",
      "Epoch 7823, reconstruction losses: 0.024483657180468483, regression losses: 0.20668113514535702, validation losses: 0.5671495327611931\n",
      "Epoch 7824, reconstruction losses: 0.019851322016673844, regression losses: 0.10199380456478851, validation losses: 0.5382735444709563\n",
      "Epoch 7825, reconstruction losses: 0.023965861362681817, regression losses: 0.21544904953776894, validation losses: 0.4646316006849124\n",
      "Epoch 7826, reconstruction losses: 0.023268785504225634, regression losses: 0.1662322181450498, validation losses: 0.6909920437839039\n",
      "Epoch 7827, reconstruction losses: 0.02242209448491624, regression losses: 0.12754418509208487, validation losses: 0.804090206344128\n",
      "Epoch 7828, reconstruction losses: 0.022192069281271168, regression losses: 0.15989832262999476, validation losses: 0.5874252697174318\n",
      "Epoch 7829, reconstruction losses: 0.021114875433407093, regression losses: 0.14139283982687617, validation losses: 0.5795698808530276\n",
      "Epoch 7830, reconstruction losses: 0.02171652238135682, regression losses: 0.1270562512966708, validation losses: 0.5440585705202208\n",
      "Epoch 7831, reconstruction losses: 0.020876340452056923, regression losses: 0.13680470587677107, validation losses: 0.4259855165157251\n",
      "Epoch 7832, reconstruction losses: 0.02342946918095737, regression losses: 0.12616731436274575, validation losses: 0.4646232879196963\n",
      "Epoch 7833, reconstruction losses: 0.02038609206817764, regression losses: 0.11485738983756584, validation losses: 0.4543004118552689\n",
      "Epoch 7834, reconstruction losses: 0.022822896922527883, regression losses: 0.11536436452265504, validation losses: 0.4505605961644553\n",
      "Epoch 7835, reconstruction losses: 0.02222987042907385, regression losses: 0.10792649928591073, validation losses: 0.4870501544735163\n",
      "Epoch 7836, reconstruction losses: 0.019031252301089503, regression losses: 0.11469963352457604, validation losses: 0.4213848833504818\n",
      "Epoch 7837, reconstruction losses: 0.019214314852819745, regression losses: 0.08072702669849617, validation losses: 0.4147984857398789\n",
      "Epoch 7838, reconstruction losses: 0.025664104885175607, regression losses: 0.18982358861339582, validation losses: 0.44670628223850256\n",
      "Epoch 7839, reconstruction losses: 0.022092396416214695, regression losses: 0.14761273999102104, validation losses: 0.517863257798345\n",
      "Epoch 7840, reconstruction losses: 0.020765998408865134, regression losses: 0.13467197736416925, validation losses: 0.48167526081599155\n",
      "Epoch 7841, reconstruction losses: 0.020116516163396606, regression losses: 0.10990255002440616, validation losses: 0.5070306712629938\n",
      "Epoch 7842, reconstruction losses: 0.023266438574813853, regression losses: 0.10267577561206967, validation losses: 0.47906312356136677\n",
      "Epoch 7843, reconstruction losses: 0.022334730316800534, regression losses: 0.09433181739821411, validation losses: 0.4262044018159839\n",
      "Epoch 7844, reconstruction losses: 0.02104263669671292, regression losses: 0.0993949853556767, validation losses: 0.4211754648839313\n",
      "Epoch 7845, reconstruction losses: 0.022279747115409494, regression losses: 0.10336930186121594, validation losses: 0.41711132445705346\n",
      "Epoch 7846, reconstruction losses: 0.02292887397188744, regression losses: 0.12012666969902316, validation losses: 0.428887388624888\n",
      "Epoch 7847, reconstruction losses: 0.022377175705901, regression losses: 0.12249529755254933, validation losses: 0.4717597264289603\n",
      "Epoch 7848, reconstruction losses: 0.022579689187798183, regression losses: 0.1547574648738329, validation losses: 0.46846056625453497\n",
      "Epoch 7849, reconstruction losses: 0.0212228894386415, regression losses: 0.1440450058561634, validation losses: 0.4236494204335918\n",
      "Epoch 7850, reconstruction losses: 0.02304888856945172, regression losses: 0.14634167138587867, validation losses: 0.45687766233052424\n",
      "Epoch 7851, reconstruction losses: 0.020920004648073448, regression losses: 0.10240430462724695, validation losses: 0.44311506561982483\n",
      "Epoch 7852, reconstruction losses: 0.02637985971753081, regression losses: 0.4599147080306536, validation losses: 0.501929752323992\n",
      "Epoch 7853, reconstruction losses: 0.02474816986047617, regression losses: 0.18059208458925796, validation losses: 0.8399870045631724\n",
      "Epoch 7854, reconstruction losses: 0.02007527656555758, regression losses: 0.1535594683676546, validation losses: 0.5647210422656126\n",
      "Epoch 7855, reconstruction losses: 0.022648442428946425, regression losses: 0.15743954469860544, validation losses: 0.5209272346048157\n",
      "Epoch 7856, reconstruction losses: 0.021244705186739515, regression losses: 0.11466395819350625, validation losses: 0.6450752844717457\n",
      "Epoch 7857, reconstruction losses: 0.022500454674623527, regression losses: 0.13257748752697934, validation losses: 0.6597140386169773\n",
      "Epoch 7858, reconstruction losses: 0.02193701280362366, regression losses: 0.09305674101522787, validation losses: 0.5457067953742061\n",
      "Epoch 7859, reconstruction losses: 0.022157769678529123, regression losses: 0.08132139701375181, validation losses: 0.45338267779536884\n",
      "Epoch 7860, reconstruction losses: 0.02294141025734652, regression losses: 0.12659566389019594, validation losses: 0.44360304480273305\n",
      "Epoch 7861, reconstruction losses: 0.023201142281301202, regression losses: 0.11705121387588291, validation losses: 0.4782074853342541\n",
      "Epoch 7862, reconstruction losses: 0.02138888953235948, regression losses: 0.12187293200565157, validation losses: 0.4975981908299153\n",
      "Epoch 7863, reconstruction losses: 0.026728488060272303, regression losses: 0.13917699558673846, validation losses: 0.481108716349229\n",
      "Epoch 7864, reconstruction losses: 0.0214966968982286, regression losses: 0.1035118289121247, validation losses: 0.45858686290516615\n",
      "Epoch 7865, reconstruction losses: 0.023326543694082953, regression losses: 0.12360706272319151, validation losses: 0.5003857921910497\n",
      "Epoch 7866, reconstruction losses: 0.021956954315959943, regression losses: 0.11472817652885477, validation losses: 0.5132663305040392\n",
      "Epoch 7867, reconstruction losses: 0.02254070916589467, regression losses: 0.1608489246921916, validation losses: 0.44008694357104533\n",
      "Epoch 7868, reconstruction losses: 0.02143647587068797, regression losses: 0.11765035919037276, validation losses: 0.43894990123081706\n",
      "Epoch 7869, reconstruction losses: 0.022892808415787294, regression losses: 0.09189458077772321, validation losses: 0.46567366261224835\n",
      "Epoch 7870, reconstruction losses: 0.0242750121462343, regression losses: 0.15236095399895733, validation losses: 0.5042438571964847\n",
      "Epoch 7871, reconstruction losses: 0.021450684167144324, regression losses: 0.11481471581184932, validation losses: 0.5029090625838321\n",
      "Epoch 7872, reconstruction losses: 0.021165303683270072, regression losses: 0.08390838022739165, validation losses: 0.43694105486370255\n",
      "Epoch 7873, reconstruction losses: 0.019409774563809053, regression losses: 0.1160504509087198, validation losses: 0.4303939161090647\n",
      "Epoch 7874, reconstruction losses: 0.020390412415247645, regression losses: 0.11770619717841213, validation losses: 0.45219887844733714\n",
      "Epoch 7875, reconstruction losses: 0.02056319727102776, regression losses: 0.11603096707637403, validation losses: 0.4589965112504698\n",
      "Epoch 7876, reconstruction losses: 0.021093943780185052, regression losses: 0.1262456611809664, validation losses: 0.4470261843325641\n",
      "Epoch 7877, reconstruction losses: 0.023388808363164735, regression losses: 0.1096595868187103, validation losses: 0.4526489045364248\n",
      "Epoch 7878, reconstruction losses: 0.02043499963564312, regression losses: 0.12353412051855686, validation losses: 0.4662790635432003\n",
      "Epoch 7879, reconstruction losses: 0.02175430297866519, regression losses: 0.1043214971235505, validation losses: 0.4976686990523919\n",
      "Epoch 7880, reconstruction losses: 0.021974355971439846, regression losses: 0.1027786353473123, validation losses: 0.4792214645212264\n",
      "Epoch 7881, reconstruction losses: 0.022560614584032454, regression losses: 0.09764396560442734, validation losses: 0.4874211209371036\n",
      "Epoch 7882, reconstruction losses: 0.027570432175319466, regression losses: 0.19882681388884144, validation losses: 0.49528860371830846\n",
      "Epoch 7883, reconstruction losses: 0.022741692173883027, regression losses: 0.09841424130384774, validation losses: 0.5722281632833853\n",
      "Epoch 7884, reconstruction losses: 0.020739633613719933, regression losses: 0.10629889815650032, validation losses: 0.6120890466051663\n",
      "Epoch 7885, reconstruction losses: 0.02247821537976808, regression losses: 0.10986662373372823, validation losses: 0.5822225830332222\n",
      "Epoch 7886, reconstruction losses: 0.02131749012945154, regression losses: 0.2543265545963262, validation losses: 0.525474903096749\n",
      "Epoch 7887, reconstruction losses: 0.020521520258188805, regression losses: 0.13682061623961383, validation losses: 0.5442154015895581\n",
      "Epoch 7888, reconstruction losses: 0.023754227895069466, regression losses: 0.14322866607751344, validation losses: 0.4378405892833877\n",
      "Epoch 7889, reconstruction losses: 0.02235382361029391, regression losses: 0.11854617715322052, validation losses: 0.5599061372486038\n",
      "Epoch 7890, reconstruction losses: 0.022345142357650644, regression losses: 0.15189912068967384, validation losses: 0.6532352159425092\n",
      "Epoch 7891, reconstruction losses: 0.02299252173355125, regression losses: 0.1346181185849095, validation losses: 0.4241564755002756\n",
      "Epoch 7892, reconstruction losses: 0.024289992078318588, regression losses: 0.16151720906644318, validation losses: 0.40965284557349924\n",
      "Epoch 7893, reconstruction losses: 0.020373658009061726, regression losses: 0.10240627387987375, validation losses: 0.5157870249554277\n",
      "Epoch 7894, reconstruction losses: 0.020610261760594106, regression losses: 0.14196394949354685, validation losses: 0.47825807178219903\n",
      "Epoch 7895, reconstruction losses: 0.02207471170482298, regression losses: 0.09884866041127549, validation losses: 0.4875470049059958\n",
      "Epoch 7896, reconstruction losses: 0.02577065244728945, regression losses: 0.11656958801765215, validation losses: 0.5130231671094276\n",
      "Epoch 7897, reconstruction losses: 0.02377478943312772, regression losses: 0.1554760573444939, validation losses: 0.4714446134932471\n",
      "Epoch 7898, reconstruction losses: 0.027481221839667887, regression losses: 0.13259418026178552, validation losses: 0.46579447404753105\n",
      "Epoch 7899, reconstruction losses: 0.021950849947529147, regression losses: 0.10382332114781123, validation losses: 0.434331519429077\n",
      "Epoch 7900, reconstruction losses: 0.021626059814367625, regression losses: 0.11210280361383007, validation losses: 0.4439169910059418\n",
      "Epoch 7901, reconstruction losses: 0.023330104729426922, regression losses: 0.10798891196533338, validation losses: 0.5177086909973555\n",
      "Epoch 7902, reconstruction losses: 0.027189116359057984, regression losses: 0.1839060613215527, validation losses: 0.5091949126134757\n",
      "Epoch 7903, reconstruction losses: 0.019273928834093623, regression losses: 0.13055427827983762, validation losses: 0.6060780839971983\n",
      "Epoch 7904, reconstruction losses: 0.025437942125677664, regression losses: 0.1654215515294976, validation losses: 0.4576006111028224\n",
      "Epoch 7905, reconstruction losses: 0.022359828940775706, regression losses: 0.12514496239524875, validation losses: 0.4967177178369929\n",
      "Epoch 7906, reconstruction losses: 0.022324991684773563, regression losses: 0.11540656889951031, validation losses: 0.5143406045175027\n",
      "Epoch 7907, reconstruction losses: 0.02233787659002392, regression losses: 0.10518226122203736, validation losses: 0.5014340152551696\n",
      "Epoch 7908, reconstruction losses: 0.021544650248535635, regression losses: 0.09402457262668533, validation losses: 0.4929127922389448\n",
      "Epoch 7909, reconstruction losses: 0.020910728582650553, regression losses: 0.10751583549789046, validation losses: 0.46531146255110367\n",
      "Epoch 7910, reconstruction losses: 0.020614712234939117, regression losses: 0.08898004243085442, validation losses: 0.4650966613147494\n",
      "Epoch 7911, reconstruction losses: 0.021416752417664685, regression losses: 0.10635753876912965, validation losses: 0.4969669064264705\n",
      "Epoch 7912, reconstruction losses: 0.025065861102975075, regression losses: 0.13146943073141984, validation losses: 0.506384016760626\n",
      "Epoch 7913, reconstruction losses: 0.02128186057302772, regression losses: 0.0953865831324045, validation losses: 0.4657589290703108\n",
      "Epoch 7914, reconstruction losses: 0.019544879396845457, regression losses: 0.09275754363371377, validation losses: 0.42999035643665817\n",
      "Epoch 7915, reconstruction losses: 0.02483126136303225, regression losses: 0.12464581080805326, validation losses: 0.4688931495995027\n",
      "Epoch 7916, reconstruction losses: 0.022659681753165243, regression losses: 0.09566770157912707, validation losses: 0.5226790767091246\n",
      "Epoch 7917, reconstruction losses: 0.019491510460848797, regression losses: 0.09454773908870713, validation losses: 0.5157940417890868\n",
      "Epoch 7918, reconstruction losses: 0.025924035536672857, regression losses: 0.18020330562678094, validation losses: 0.49973839356376054\n",
      "Epoch 7919, reconstruction losses: 0.018729281144905224, regression losses: 0.1018248047526648, validation losses: 0.45861574579088926\n",
      "Epoch 7920, reconstruction losses: 0.02063380784407381, regression losses: 0.10093432701379533, validation losses: 0.42389111303517507\n",
      "Epoch 7921, reconstruction losses: 0.024173502592504347, regression losses: 0.09671916167115113, validation losses: 0.4207254336464592\n",
      "Epoch 7922, reconstruction losses: 0.023185309866134346, regression losses: 0.1210274912738795, validation losses: 0.42036871651674895\n",
      "Epoch 7923, reconstruction losses: 0.021938735357689, regression losses: 0.10877628611243213, validation losses: 0.4395580246262858\n",
      "Epoch 7924, reconstruction losses: 0.022742743721444122, regression losses: 0.1063475264899056, validation losses: 0.44720123537456663\n",
      "Epoch 7925, reconstruction losses: 0.021824128522332648, regression losses: 0.12101453380806412, validation losses: 0.4691538133813307\n",
      "Epoch 7926, reconstruction losses: 0.02121992583976235, regression losses: 0.1119116925672938, validation losses: 0.4568104322113055\n",
      "Epoch 7927, reconstruction losses: 0.02156308810028182, regression losses: 0.12516883464957726, validation losses: 0.442842938970029\n",
      "Epoch 7928, reconstruction losses: 0.022074263174695446, regression losses: 0.1114174675735152, validation losses: 0.4711507039065606\n",
      "Epoch 7929, reconstruction losses: 0.023462905499812715, regression losses: 0.12708866519705947, validation losses: 0.5519864870514016\n",
      "Epoch 7930, reconstruction losses: 0.021766435857436244, regression losses: 0.09507643027985473, validation losses: 0.5409912097365607\n",
      "Epoch 7931, reconstruction losses: 0.020753832749293464, regression losses: 0.1166421437003233, validation losses: 0.4485494211590758\n",
      "Epoch 7932, reconstruction losses: 0.021305822792389247, regression losses: 0.09559054602470642, validation losses: 0.41586415618545375\n",
      "Epoch 7933, reconstruction losses: 0.0257655272527614, regression losses: 0.11974486704066697, validation losses: 0.472011173836381\n",
      "Epoch 7934, reconstruction losses: 0.022440542780680847, regression losses: 0.1274495560403122, validation losses: 0.5402347670626877\n",
      "Epoch 7935, reconstruction losses: 0.02216908235471527, regression losses: 0.12638951105756158, validation losses: 0.5356776074019892\n",
      "Epoch 7936, reconstruction losses: 0.023497664896645176, regression losses: 0.11421318323968968, validation losses: 0.44415417270230295\n",
      "Epoch 7937, reconstruction losses: 0.02198706985045636, regression losses: 0.14172207549888535, validation losses: 0.4210182045181635\n",
      "Epoch 7938, reconstruction losses: 0.019350692244041817, regression losses: 0.09544631914279438, validation losses: 0.4771408921614187\n",
      "Epoch 7939, reconstruction losses: 0.022545948302412293, regression losses: 0.39295512140994276, validation losses: 0.478450858344556\n",
      "Epoch 7940, reconstruction losses: 0.022062216051310566, regression losses: 0.17287535827775166, validation losses: 0.6904664026219999\n",
      "Epoch 7941, reconstruction losses: 0.020900095684931373, regression losses: 0.11655862066996459, validation losses: 0.5540702096328588\n",
      "Epoch 7942, reconstruction losses: 0.02079272320324932, regression losses: 0.11045370203995163, validation losses: 0.47767141877609665\n",
      "Epoch 7943, reconstruction losses: 0.020304678915607506, regression losses: 0.14104410395416908, validation losses: 0.48508031149039543\n",
      "Epoch 7944, reconstruction losses: 0.020246516186171806, regression losses: 0.09273808096752412, validation losses: 0.45782994784709147\n",
      "Epoch 7945, reconstruction losses: 0.023410211541981953, regression losses: 0.16784116794271586, validation losses: 0.4652477565570226\n",
      "Epoch 7946, reconstruction losses: 0.021566739926821798, regression losses: 0.10717121162514083, validation losses: 0.5153988970244144\n",
      "Epoch 7947, reconstruction losses: 0.020225769408975944, regression losses: 0.10423783125026202, validation losses: 0.47640066473239107\n",
      "Epoch 7948, reconstruction losses: 0.01994516138186469, regression losses: 0.09248557380022068, validation losses: 0.43852922033044683\n",
      "Epoch 7949, reconstruction losses: 0.01987672099026236, regression losses: 0.09980658436285582, validation losses: 0.42639586781894473\n",
      "Epoch 7950, reconstruction losses: 0.032098845708604815, regression losses: 0.13829802769874855, validation losses: 0.4408537052452374\n",
      "Epoch 7951, reconstruction losses: 0.02273165777949182, regression losses: 0.11452456789532084, validation losses: 0.4326569272822136\n",
      "Epoch 7952, reconstruction losses: 0.0219880553437445, regression losses: 0.12437954931670982, validation losses: 0.4460684553439198\n",
      "Epoch 7953, reconstruction losses: 0.021309128306990756, regression losses: 0.11072375092450068, validation losses: 0.5324974194821306\n",
      "Epoch 7954, reconstruction losses: 0.020676122673224922, regression losses: 0.10879019442901558, validation losses: 0.5151503648450168\n",
      "Epoch 7955, reconstruction losses: 0.023640578202626824, regression losses: 0.11870363944946918, validation losses: 0.46400047504345804\n",
      "Epoch 7956, reconstruction losses: 0.021604054171733354, regression losses: 0.08763233426256002, validation losses: 0.4655454837093739\n",
      "Epoch 7957, reconstruction losses: 0.020943363877295028, regression losses: 0.09250049755863343, validation losses: 0.47807529913036956\n",
      "Epoch 7958, reconstruction losses: 0.021089783922109185, regression losses: 0.11030713649812575, validation losses: 0.4794685929411057\n",
      "Epoch 7959, reconstruction losses: 0.02189743073964031, regression losses: 0.09646808872641222, validation losses: 0.4972768780312786\n",
      "Epoch 7960, reconstruction losses: 0.022643411356581142, regression losses: 0.1189529585966185, validation losses: 0.5013169425790902\n",
      "Epoch 7961, reconstruction losses: 0.021878743559366583, regression losses: 0.10510396386011066, validation losses: 0.5099217252416596\n",
      "Epoch 7962, reconstruction losses: 0.021187660732526974, regression losses: 0.10247197466152937, validation losses: 0.4551399011227997\n",
      "Epoch 7963, reconstruction losses: 0.023874624651735964, regression losses: 0.18643041951464195, validation losses: 0.4196638313952507\n",
      "Epoch 7964, reconstruction losses: 0.022061761052906626, regression losses: 0.13134807474876273, validation losses: 0.5186774083050626\n",
      "Epoch 7965, reconstruction losses: 0.021345719430336647, regression losses: 0.14109101782818348, validation losses: 0.4689287266743805\n",
      "Epoch 7966, reconstruction losses: 0.02050690520505145, regression losses: 0.10540880007749756, validation losses: 0.488422121777224\n",
      "Epoch 7967, reconstruction losses: 0.021319433702794165, regression losses: 0.10184091993196263, validation losses: 0.5564625597881688\n",
      "Epoch 7968, reconstruction losses: 0.01921884560910866, regression losses: 0.10352999307000424, validation losses: 0.5099232850849331\n",
      "Epoch 7969, reconstruction losses: 0.02178408493252874, regression losses: 0.11903197631833502, validation losses: 0.4551486186537951\n",
      "Epoch 7970, reconstruction losses: 0.02821920574126434, regression losses: 0.12394070897917683, validation losses: 0.41317922016067987\n",
      "Epoch 7971, reconstruction losses: 0.023200391665114888, regression losses: 0.12179767444204118, validation losses: 0.42359375346953454\n",
      "Epoch 7972, reconstruction losses: 0.0218151506307174, regression losses: 0.12907356876004872, validation losses: 0.43033796149406056\n",
      "Epoch 7973, reconstruction losses: 0.020551440411579056, regression losses: 0.09093076180094055, validation losses: 0.5223581798873633\n",
      "Epoch 7974, reconstruction losses: 0.027116666945710265, regression losses: 0.11756621159681531, validation losses: 0.5292099159081592\n",
      "Epoch 7975, reconstruction losses: 0.022159456283110703, regression losses: 0.10154884823174844, validation losses: 0.43869627859297333\n",
      "Epoch 7976, reconstruction losses: 0.021479681702850275, regression losses: 0.12502007151738537, validation losses: 0.4355809226647701\n",
      "Epoch 7977, reconstruction losses: 0.022728554716533338, regression losses: 0.10721460453930967, validation losses: 0.49388726231712804\n",
      "Epoch 7978, reconstruction losses: 0.019020343613357842, regression losses: 0.10814394859784693, validation losses: 0.5483480127388615\n",
      "Epoch 7979, reconstruction losses: 0.021618145599588117, regression losses: 0.10675764069301569, validation losses: 0.494138572757703\n",
      "Epoch 7980, reconstruction losses: 0.019603534088623243, regression losses: 0.0894287813744678, validation losses: 0.48949683758414986\n",
      "Epoch 7981, reconstruction losses: 0.02291086355358892, regression losses: 0.12059525790437273, validation losses: 0.4564931224357373\n",
      "Epoch 7982, reconstruction losses: 0.02081510185737688, regression losses: 0.1107637456594086, validation losses: 0.41288562194645245\n",
      "Epoch 7983, reconstruction losses: 0.02167807856703866, regression losses: 0.0885428993786222, validation losses: 0.4419214898306746\n",
      "Epoch 7984, reconstruction losses: 0.019979167505546788, regression losses: 0.08750709705046054, validation losses: 0.4704490119861143\n",
      "Epoch 7985, reconstruction losses: 0.02555565582938897, regression losses: 0.2511448913328662, validation losses: 0.4422037244704862\n",
      "Epoch 7986, reconstruction losses: 0.022866228217706577, regression losses: 0.16297315229695197, validation losses: 0.7431178192345385\n",
      "Epoch 7987, reconstruction losses: 0.024387109273494058, regression losses: 0.18686256238220553, validation losses: 0.6451398854315717\n",
      "Epoch 7988, reconstruction losses: 0.022697690585249248, regression losses: 0.1537895437668728, validation losses: 0.7038035011042146\n",
      "Epoch 7989, reconstruction losses: 0.022419828491479648, regression losses: 0.11997732098419928, validation losses: 0.4790971582908702\n",
      "Epoch 7990, reconstruction losses: 0.019635305332722817, regression losses: 0.09804841086294683, validation losses: 0.3859870200041072\n",
      "Epoch 7991, reconstruction losses: 0.021344718591326854, regression losses: 0.09547370661882074, validation losses: 0.40810316770806637\n",
      "Epoch 7992, reconstruction losses: 0.02305737195384782, regression losses: 0.1401199588056317, validation losses: 0.4878253795127905\n",
      "Epoch 7993, reconstruction losses: 0.021717905407734606, regression losses: 0.13837560636129914, validation losses: 0.5982262259243472\n",
      "Epoch 7994, reconstruction losses: 0.019827636061682863, regression losses: 0.08976054427233228, validation losses: 0.5044925549996581\n",
      "Epoch 7995, reconstruction losses: 0.023946550250381164, regression losses: 0.12930129371951593, validation losses: 0.4309574589673093\n",
      "Epoch 7996, reconstruction losses: 0.02471640799260502, regression losses: 0.11981912982135814, validation losses: 0.4379636606892349\n",
      "Epoch 7997, reconstruction losses: 0.02204930942380088, regression losses: 0.16299960764546534, validation losses: 0.42255012558546534\n",
      "Epoch 7998, reconstruction losses: 0.022491601675718183, regression losses: 0.18488742547990555, validation losses: 0.530581381912223\n",
      "Epoch 7999, reconstruction losses: 0.025095867626699346, regression losses: 0.13734917282016693, validation losses: 0.5770427895164563\n",
      "Epoch 8000, reconstruction losses: 0.026032256249900406, regression losses: 0.4964396877247647, validation losses: 0.48208010593351097\n",
      "Epoch 8001, reconstruction losses: 0.025353389171733527, regression losses: 0.24277354285203703, validation losses: 0.7280518359789916\n",
      "Epoch 8002, reconstruction losses: 0.0208289798801685, regression losses: 0.11577236453115312, validation losses: 0.608835072089691\n",
      "Epoch 8003, reconstruction losses: 0.023744014116328416, regression losses: 0.17580271814984827, validation losses: 0.6202188863644025\n",
      "Epoch 8004, reconstruction losses: 0.026816243088729905, regression losses: 0.17597613805950654, validation losses: 0.47305840510764835\n",
      "Epoch 8005, reconstruction losses: 0.0269773272289537, regression losses: 0.17849540576966538, validation losses: 0.4211460108851244\n",
      "Epoch 8006, reconstruction losses: 0.020066166015064123, regression losses: 0.10623585628037578, validation losses: 0.5201564398042409\n",
      "Epoch 8007, reconstruction losses: 0.021573301136720933, regression losses: 0.14262226793161625, validation losses: 0.4862216734219743\n",
      "Epoch 8008, reconstruction losses: 0.019404968490570485, regression losses: 0.09983767492951666, validation losses: 0.46480121572383987\n",
      "Epoch 8009, reconstruction losses: 0.02107472571460809, regression losses: 0.09617500131972063, validation losses: 0.5262591862394328\n",
      "Epoch 8010, reconstruction losses: 0.020358480660473847, regression losses: 0.09839827131331218, validation losses: 0.5409750307426712\n",
      "Epoch 8011, reconstruction losses: 0.023859341863958886, regression losses: 0.10404714196600032, validation losses: 0.4947587123067909\n",
      "Epoch 8012, reconstruction losses: 0.022137432983278152, regression losses: 0.1216148763251444, validation losses: 0.46789134811311894\n",
      "Epoch 8013, reconstruction losses: 0.023045914398431955, regression losses: 0.1050304247343291, validation losses: 0.4877425699156144\n",
      "Epoch 8014, reconstruction losses: 0.02174455524423445, regression losses: 0.10535022719068016, validation losses: 0.49397889999029126\n",
      "Epoch 8015, reconstruction losses: 0.01966352952040561, regression losses: 0.10133895103571028, validation losses: 0.4526060953290866\n",
      "Epoch 8016, reconstruction losses: 0.02275228083610967, regression losses: 0.12090920459345966, validation losses: 0.5052261364753403\n",
      "Epoch 8017, reconstruction losses: 0.024576646536882144, regression losses: 0.17858954107269895, validation losses: 0.5882806710455157\n",
      "Epoch 8018, reconstruction losses: 0.021249413513888985, regression losses: 0.09993760127711729, validation losses: 0.7331326737730223\n",
      "Epoch 8019, reconstruction losses: 0.019797511067718186, regression losses: 0.1641010115992566, validation losses: 0.4941561393456875\n",
      "Epoch 8020, reconstruction losses: 0.02284296947863413, regression losses: 0.12248886959677079, validation losses: 0.44773934996732806\n",
      "Epoch 8021, reconstruction losses: 0.020621235653356797, regression losses: 0.10639769030272915, validation losses: 0.4408335358751745\n",
      "Epoch 8022, reconstruction losses: 0.02407723384921184, regression losses: 0.16259978774616568, validation losses: 0.47512504417668716\n",
      "Epoch 8023, reconstruction losses: 0.020899564501789845, regression losses: 0.10494706806828497, validation losses: 0.5814679358031818\n",
      "Epoch 8024, reconstruction losses: 0.022850362912233257, regression losses: 0.1198261188557273, validation losses: 0.575901566743539\n",
      "Epoch 8025, reconstruction losses: 0.02202710397436434, regression losses: 0.10777856803093797, validation losses: 0.5332877813045888\n",
      "Epoch 8026, reconstruction losses: 0.021013156943396786, regression losses: 0.1347172745859713, validation losses: 0.4497082641697462\n",
      "Epoch 8027, reconstruction losses: 0.023548107432360372, regression losses: 0.1669419030605925, validation losses: 0.43187180996085184\n",
      "Epoch 8028, reconstruction losses: 0.021073813040911014, regression losses: 0.12034163323594654, validation losses: 0.46211281942242755\n",
      "Epoch 8029, reconstruction losses: 0.023907792279660327, regression losses: 0.3228277702336158, validation losses: 0.5256447558998939\n",
      "Epoch 8030, reconstruction losses: 0.022340288908963418, regression losses: 0.1322908108485216, validation losses: 0.7240827701947553\n",
      "Epoch 8031, reconstruction losses: 0.024506356176562043, regression losses: 0.12683543281333784, validation losses: 0.6128749112424736\n",
      "Epoch 8032, reconstruction losses: 0.021030923265296757, regression losses: 0.14832045636578353, validation losses: 0.4481290417374797\n",
      "Epoch 8033, reconstruction losses: 0.02093379418374898, regression losses: 0.1161693479305148, validation losses: 0.48275429053626356\n",
      "Epoch 8034, reconstruction losses: 0.023224817432293467, regression losses: 0.1336398633351582, validation losses: 0.46541050560293934\n",
      "Epoch 8035, reconstruction losses: 0.021664376561881842, regression losses: 0.1081783128412761, validation losses: 0.4340719245694383\n",
      "Epoch 8036, reconstruction losses: 0.020572336760745928, regression losses: 0.11207838677262058, validation losses: 0.5213991985771189\n",
      "Epoch 8037, reconstruction losses: 0.023926644833135596, regression losses: 0.13726693725027467, validation losses: 0.5164161975296357\n",
      "Epoch 8038, reconstruction losses: 0.02087172837350114, regression losses: 0.10566025841545938, validation losses: 0.49162125281018154\n",
      "Epoch 8039, reconstruction losses: 0.021478157362877545, regression losses: 0.14904690210258598, validation losses: 0.48570934901629315\n",
      "Epoch 8040, reconstruction losses: 0.023121710337762894, regression losses: 0.1063806844975993, validation losses: 0.439846263422264\n",
      "Epoch 8041, reconstruction losses: 0.025578717781258413, regression losses: 0.2284643425049679, validation losses: 0.4501464921716332\n",
      "Epoch 8042, reconstruction losses: 0.02497475148159947, regression losses: 0.11827535779198825, validation losses: 0.6119823796343493\n",
      "Epoch 8043, reconstruction losses: 0.02241372153646992, regression losses: 0.13448344547813496, validation losses: 0.5511666760512094\n",
      "Epoch 8044, reconstruction losses: 0.025284787437921816, regression losses: 0.11142003280731291, validation losses: 0.4643530302672115\n",
      "Epoch 8045, reconstruction losses: 0.021898801365767877, regression losses: 0.11777290648769818, validation losses: 0.45852792150368143\n",
      "Epoch 8046, reconstruction losses: 0.01962305982332375, regression losses: 0.08842808928722698, validation losses: 0.5003804794602174\n",
      "Epoch 8047, reconstruction losses: 0.02123279816107988, regression losses: 0.10366899178519999, validation losses: 0.5261871768784819\n",
      "Epoch 8048, reconstruction losses: 0.023873220679597313, regression losses: 0.19599928003610728, validation losses: 0.48664684475196157\n",
      "Epoch 8049, reconstruction losses: 0.02096585545964142, regression losses: 0.12045723491275406, validation losses: 0.4878109946152135\n",
      "Epoch 8050, reconstruction losses: 0.020721604775685565, regression losses: 0.155245731291114, validation losses: 0.4732905718592613\n",
      "Epoch 8051, reconstruction losses: 0.02042277154849636, regression losses: 0.09381088621421454, validation losses: 0.5155340517251046\n",
      "Epoch 8052, reconstruction losses: 0.02292001162590557, regression losses: 0.14185300605971915, validation losses: 0.5374123788984242\n",
      "Epoch 8053, reconstruction losses: 0.029489803219848634, regression losses: 0.1518071164224341, validation losses: 0.5315839870299004\n",
      "Epoch 8054, reconstruction losses: 0.02090943097235866, regression losses: 0.08980785372221742, validation losses: 0.42524034887217554\n",
      "Epoch 8055, reconstruction losses: 0.019958140827752706, regression losses: 0.12065994995471001, validation losses: 0.41876269216842266\n",
      "Epoch 8056, reconstruction losses: 0.02135419393159595, regression losses: 0.1883319755895105, validation losses: 0.4473178249660361\n",
      "Epoch 8057, reconstruction losses: 0.022111072326038428, regression losses: 0.13059706026433696, validation losses: 0.5824560355724124\n",
      "Epoch 8058, reconstruction losses: 0.021145067615231813, regression losses: 0.1488700771616034, validation losses: 0.5262586280811511\n",
      "Epoch 8059, reconstruction losses: 0.01843229242776123, regression losses: 0.1229487902746279, validation losses: 0.4968205050015258\n",
      "Epoch 8060, reconstruction losses: 0.021740537072414426, regression losses: 0.11585209362641562, validation losses: 0.5286344787759985\n",
      "Epoch 8061, reconstruction losses: 0.02314737654441416, regression losses: 0.12221630358054479, validation losses: 0.5108288076922318\n",
      "Epoch 8062, reconstruction losses: 0.022009156531233517, regression losses: 0.09001865879519, validation losses: 0.47586661852816886\n",
      "Epoch 8063, reconstruction losses: 0.02417817595284848, regression losses: 0.15085806466460763, validation losses: 0.48271036936702294\n",
      "Epoch 8064, reconstruction losses: 0.0230703688198486, regression losses: 0.15106191138741404, validation losses: 0.5969775730294224\n",
      "Epoch 8065, reconstruction losses: 0.02230354141123531, regression losses: 0.12111547088875707, validation losses: 0.5812378143100667\n",
      "Epoch 8066, reconstruction losses: 0.02401920770496125, regression losses: 0.11709410399039742, validation losses: 0.5321289260166747\n",
      "Epoch 8067, reconstruction losses: 0.02112167346618332, regression losses: 0.10017774424841723, validation losses: 0.49427178223242174\n",
      "Epoch 8068, reconstruction losses: 0.020142785326566333, regression losses: 0.10690937362610084, validation losses: 0.49019921333791416\n",
      "Epoch 8069, reconstruction losses: 0.021211979125648057, regression losses: 0.13012967656369884, validation losses: 0.4947269607356776\n",
      "Epoch 8070, reconstruction losses: 0.022949033733466937, regression losses: 0.1452905717666556, validation losses: 0.5195413571008775\n",
      "Epoch 8071, reconstruction losses: 0.019851210812322544, regression losses: 0.10124539803123124, validation losses: 0.45687757217944436\n",
      "Epoch 8072, reconstruction losses: 0.021402688026214634, regression losses: 0.11236461930369115, validation losses: 0.4635018318604488\n",
      "Epoch 8073, reconstruction losses: 0.023356406591714212, regression losses: 0.09844483844194521, validation losses: 0.4934291665355046\n",
      "Epoch 8074, reconstruction losses: 0.02178743124690545, regression losses: 0.12493338829234141, validation losses: 0.5539122829365272\n",
      "Epoch 8075, reconstruction losses: 0.02218581996828246, regression losses: 0.10110625682847686, validation losses: 0.6363058936428159\n",
      "Epoch 8076, reconstruction losses: 0.020949309406018257, regression losses: 0.11387594317018657, validation losses: 0.49913300288442547\n",
      "Epoch 8077, reconstruction losses: 0.022586699501162114, regression losses: 0.08996844718681786, validation losses: 0.4540372405461461\n",
      "Epoch 8078, reconstruction losses: 0.0215582898025793, regression losses: 0.1024947006689792, validation losses: 0.4445672281034795\n",
      "Epoch 8079, reconstruction losses: 0.024132468964546454, regression losses: 0.09601886456117027, validation losses: 0.4476107878791523\n",
      "Epoch 8080, reconstruction losses: 0.020757706624774115, regression losses: 0.12581251417275707, validation losses: 0.5199241927089344\n",
      "Epoch 8081, reconstruction losses: 0.0218259074615251, regression losses: 0.1025236637880239, validation losses: 0.5955906429529333\n",
      "Epoch 8082, reconstruction losses: 0.02484232308839382, regression losses: 0.12123548904068707, validation losses: 0.4850862191865982\n",
      "Epoch 8083, reconstruction losses: 0.02264078559732333, regression losses: 0.15623139888905477, validation losses: 0.4495384553286834\n",
      "Epoch 8084, reconstruction losses: 0.02284729273481847, regression losses: 0.11057323760333239, validation losses: 0.4701533689667625\n",
      "Epoch 8085, reconstruction losses: 0.02113771809774718, regression losses: 0.10585633053447796, validation losses: 0.4867568906767351\n",
      "Epoch 8086, reconstruction losses: 0.02140948459175776, regression losses: 0.10686280667513334, validation losses: 0.5200669451749274\n",
      "Epoch 8087, reconstruction losses: 0.021851613547606705, regression losses: 0.149924391624275, validation losses: 0.5965913684563254\n",
      "Epoch 8088, reconstruction losses: 0.02227253054890962, regression losses: 0.09994307045590155, validation losses: 0.5713599043125723\n",
      "Epoch 8089, reconstruction losses: 0.020313947895991957, regression losses: 0.09302727119128469, validation losses: 0.5254403632223286\n",
      "Epoch 8090, reconstruction losses: 0.01979785569519048, regression losses: 0.12624912641516245, validation losses: 0.5193379437495839\n",
      "Epoch 8091, reconstruction losses: 0.019688070205323097, regression losses: 0.11320314416730373, validation losses: 0.4913539089327335\n",
      "Epoch 8092, reconstruction losses: 0.021865197647506718, regression losses: 0.12465556912821196, validation losses: 0.5341926171655486\n",
      "Epoch 8093, reconstruction losses: 0.022646347288876288, regression losses: 0.11743171479123081, validation losses: 0.5960508822877929\n",
      "Epoch 8094, reconstruction losses: 0.02283976638830831, regression losses: 0.15290361038870165, validation losses: 0.5377456504974137\n",
      "Epoch 8095, reconstruction losses: 0.02231246832725367, regression losses: 0.14259111374791011, validation losses: 0.4635522695609873\n",
      "Epoch 8096, reconstruction losses: 0.01974036214759849, regression losses: 0.12677845999488954, validation losses: 0.4494031576817722\n",
      "Epoch 8097, reconstruction losses: 0.02207398123747236, regression losses: 0.09305926030229593, validation losses: 0.4728140726692394\n",
      "Epoch 8098, reconstruction losses: 0.02251475044685422, regression losses: 0.1541335713532072, validation losses: 0.4702684515103686\n",
      "Epoch 8099, reconstruction losses: 0.022632375390412657, regression losses: 0.11607611789618193, validation losses: 0.46857345026053054\n",
      "Epoch 8100, reconstruction losses: 0.019955705493295728, regression losses: 0.11640889748603352, validation losses: 0.4791004611671877\n",
      "Epoch 8101, reconstruction losses: 0.019262558980428973, regression losses: 0.08606097019659599, validation losses: 0.43891994273546625\n",
      "Epoch 8102, reconstruction losses: 0.02124289760179527, regression losses: 0.13682698974642177, validation losses: 0.40676621951671615\n",
      "Epoch 8103, reconstruction losses: 0.022066629094979733, regression losses: 0.14271155297743995, validation losses: 0.42103528906821647\n",
      "Epoch 8104, reconstruction losses: 0.020294654902121432, regression losses: 0.11081842972359635, validation losses: 0.4294426663914772\n",
      "Epoch 8105, reconstruction losses: 0.021684803079659625, regression losses: 0.122569225195132, validation losses: 0.44938936841911253\n",
      "Epoch 8106, reconstruction losses: 0.023425103191316847, regression losses: 0.12998833601511833, validation losses: 0.5088826589545462\n",
      "Epoch 8107, reconstruction losses: 0.022044212265509205, regression losses: 0.11812188886602602, validation losses: 0.5239581685883392\n",
      "Epoch 8108, reconstruction losses: 0.019470629391067473, regression losses: 0.09647806173032467, validation losses: 0.5150159511870981\n",
      "Epoch 8109, reconstruction losses: 0.01947079768041046, regression losses: 0.11273100993975271, validation losses: 0.47566749682446097\n",
      "Epoch 8110, reconstruction losses: 0.024517997036150534, regression losses: 0.12429823720639813, validation losses: 0.4473909730901531\n",
      "Epoch 8111, reconstruction losses: 0.02146498643805889, regression losses: 0.13263108804319984, validation losses: 0.434173515268339\n",
      "Epoch 8112, reconstruction losses: 0.024382931412863944, regression losses: 0.12760393812697834, validation losses: 0.4447106463426379\n",
      "Epoch 8113, reconstruction losses: 0.023193061504351978, regression losses: 0.09996138957561797, validation losses: 0.5655569546831668\n",
      "Epoch 8114, reconstruction losses: 0.02212779929971544, regression losses: 0.12155588690568157, validation losses: 0.597161337060416\n",
      "Epoch 8115, reconstruction losses: 0.021949895192766387, regression losses: 0.11546153883387797, validation losses: 0.5268906609317439\n",
      "Epoch 8116, reconstruction losses: 0.021228913548214857, regression losses: 0.13247202688990148, validation losses: 0.47104980229745286\n",
      "Epoch 8117, reconstruction losses: 0.02063442142133321, regression losses: 0.15016206699724222, validation losses: 0.4492441821262046\n",
      "Epoch 8118, reconstruction losses: 0.02033456438949325, regression losses: 0.10943132540880314, validation losses: 0.4773617385613958\n",
      "Epoch 8119, reconstruction losses: 0.024775738966836873, regression losses: 0.13490762761417996, validation losses: 0.46094854648870204\n",
      "Epoch 8120, reconstruction losses: 0.02164006773332902, regression losses: 0.1356517335763441, validation losses: 0.46579639564083947\n",
      "Epoch 8121, reconstruction losses: 0.02410731974310172, regression losses: 0.21067521363248543, validation losses: 0.3910077246613047\n",
      "Epoch 8122, reconstruction losses: 0.019652607214999243, regression losses: 0.12306992772653363, validation losses: 0.5953456457784146\n",
      "Epoch 8123, reconstruction losses: 0.02415899561633458, regression losses: 0.17859285109988335, validation losses: 0.5200149402050727\n",
      "Epoch 8124, reconstruction losses: 0.023680344317327157, regression losses: 0.11986520798944286, validation losses: 0.4356897979712747\n",
      "Epoch 8125, reconstruction losses: 0.02134492831875326, regression losses: 0.10977994979519225, validation losses: 0.4501609091340456\n",
      "Epoch 8126, reconstruction losses: 0.026107433793873508, regression losses: 0.1968608160522483, validation losses: 0.4085927149929819\n",
      "Epoch 8127, reconstruction losses: 0.02373906137971128, regression losses: 0.0902534383963928, validation losses: 0.4987171424912043\n",
      "Epoch 8128, reconstruction losses: 0.021797573020063084, regression losses: 0.13591016544313983, validation losses: 0.4780796143098426\n",
      "Epoch 8129, reconstruction losses: 0.022003059223637184, regression losses: 0.10813674806312573, validation losses: 0.4217240273697809\n",
      "Epoch 8130, reconstruction losses: 0.02356387092423012, regression losses: 0.26798675256016663, validation losses: 0.45845044528977824\n",
      "Epoch 8131, reconstruction losses: 0.02291140471014677, regression losses: 0.15148375342060746, validation losses: 0.6698116540585424\n",
      "Epoch 8132, reconstruction losses: 0.02276886830322236, regression losses: 0.12832280304917593, validation losses: 0.6890369852815712\n",
      "Epoch 8133, reconstruction losses: 0.0233940515667524, regression losses: 0.17120594247628204, validation losses: 0.5682611131208162\n",
      "Epoch 8134, reconstruction losses: 0.021760511762279333, regression losses: 0.10708577765728924, validation losses: 0.571075764429907\n",
      "Epoch 8135, reconstruction losses: 0.02299301079226719, regression losses: 0.14574316627440223, validation losses: 0.5856266461432322\n",
      "Epoch 8136, reconstruction losses: 0.02416000992482664, regression losses: 0.12374260089929898, validation losses: 0.5603708068364409\n",
      "Epoch 8137, reconstruction losses: 0.022503274980303755, regression losses: 0.1816112454273367, validation losses: 0.4580512715257096\n",
      "Epoch 8138, reconstruction losses: 0.02459546984352065, regression losses: 0.16987937808901774, validation losses: 0.5751095103458674\n",
      "Epoch 8139, reconstruction losses: 0.01915919034422023, regression losses: 0.15241979384054125, validation losses: 0.8519468553648115\n",
      "Epoch 8140, reconstruction losses: 0.02081588895317214, regression losses: 0.113225757919968, validation losses: 0.7457168066620182\n",
      "Epoch 8141, reconstruction losses: 0.02374248167724679, regression losses: 0.16832809446535885, validation losses: 0.6103626194434981\n",
      "Epoch 8142, reconstruction losses: 0.02073882718074709, regression losses: 0.12260886429701444, validation losses: 0.50044986338983\n",
      "Epoch 8143, reconstruction losses: 0.020619405610168052, regression losses: 0.1078321386839382, validation losses: 0.4138758650894309\n",
      "Epoch 8144, reconstruction losses: 0.0208217348387276, regression losses: 0.1376108639173471, validation losses: 0.45993077594814213\n",
      "Epoch 8145, reconstruction losses: 0.022661035619506466, regression losses: 0.12110059039835364, validation losses: 0.4988272660717284\n",
      "Epoch 8146, reconstruction losses: 0.026376137159394703, regression losses: 0.13980136601560467, validation losses: 0.4757833654350646\n",
      "Epoch 8147, reconstruction losses: 0.021273181436413612, regression losses: 0.10123798990071826, validation losses: 0.42268012813404787\n",
      "Epoch 8148, reconstruction losses: 0.020843236133348767, regression losses: 0.12314069514105067, validation losses: 0.42023870387204454\n",
      "Epoch 8149, reconstruction losses: 0.023365817408693087, regression losses: 0.256091631935322, validation losses: 0.5250412767888355\n",
      "Epoch 8150, reconstruction losses: 0.021814380115009177, regression losses: 0.12421590743948877, validation losses: 0.8992203414894601\n",
      "Epoch 8151, reconstruction losses: 0.024716592734673793, regression losses: 0.1798551271378709, validation losses: 0.6665306900653916\n",
      "Epoch 8152, reconstruction losses: 0.02027199112801934, regression losses: 0.14264824828679212, validation losses: 0.5700652135365696\n",
      "Epoch 8153, reconstruction losses: 0.019921869585430723, regression losses: 0.13160613724159315, validation losses: 0.621252386482069\n",
      "Epoch 8154, reconstruction losses: 0.022538437181561167, regression losses: 0.15888341820152654, validation losses: 0.4760646175692939\n",
      "Epoch 8155, reconstruction losses: 0.02113757879375621, regression losses: 0.0976606097315115, validation losses: 0.45916886554480635\n",
      "Epoch 8156, reconstruction losses: 0.020528108549473716, regression losses: 0.09882832206291534, validation losses: 0.5174934633563294\n",
      "Epoch 8157, reconstruction losses: 0.02016485378217421, regression losses: 0.1128827657781286, validation losses: 0.5092317395017709\n",
      "Epoch 8158, reconstruction losses: 0.02285613430399478, regression losses: 0.10133950577800853, validation losses: 0.42902145413438714\n",
      "Epoch 8159, reconstruction losses: 0.022740069931594886, regression losses: 0.10196626501768195, validation losses: 0.39572511957608203\n",
      "Epoch 8160, reconstruction losses: 0.021862279368338327, regression losses: 0.10967236363842832, validation losses: 0.42917509276708726\n",
      "Epoch 8161, reconstruction losses: 0.026807260905783947, regression losses: 0.20476263788007054, validation losses: 0.4597799074263432\n",
      "Epoch 8162, reconstruction losses: 0.02663443775113325, regression losses: 0.13404786275050246, validation losses: 0.5170393760625319\n",
      "Epoch 8163, reconstruction losses: 0.020589835718925566, regression losses: 0.12824583519507182, validation losses: 0.43761774584315\n",
      "Epoch 8164, reconstruction losses: 0.025368223452913185, regression losses: 0.11949002606475918, validation losses: 0.5235942452759614\n",
      "Epoch 8165, reconstruction losses: 0.019706208841870403, regression losses: 0.0993748695894071, validation losses: 0.575485576625515\n",
      "Epoch 8166, reconstruction losses: 0.019952578822899893, regression losses: 0.11738219330165997, validation losses: 0.4861807725182521\n",
      "Epoch 8167, reconstruction losses: 0.01958564031144685, regression losses: 0.08055135244174932, validation losses: 0.4363397595139709\n",
      "Epoch 8168, reconstruction losses: 0.020751831662307735, regression losses: 0.11057461699606728, validation losses: 0.4181826637944573\n",
      "Epoch 8169, reconstruction losses: 0.01898554609651549, regression losses: 0.13195744342258964, validation losses: 0.4419670562794425\n",
      "Epoch 8170, reconstruction losses: 0.025857609299888756, regression losses: 0.139152659081083, validation losses: 0.4790348798275149\n",
      "Epoch 8171, reconstruction losses: 0.021354757164045262, regression losses: 0.10349689582196436, validation losses: 0.4381085653810563\n",
      "Epoch 8172, reconstruction losses: 0.02276516670635305, regression losses: 0.11258814020061444, validation losses: 0.43251467825056367\n",
      "Epoch 8173, reconstruction losses: 0.021168348359715015, regression losses: 0.1346556796180155, validation losses: 0.4467903077834734\n",
      "Epoch 8174, reconstruction losses: 0.02126655942759958, regression losses: 0.1236067671674584, validation losses: 0.4801883112618373\n",
      "Epoch 8175, reconstruction losses: 0.02132686634015956, regression losses: 0.1040776028896868, validation losses: 0.5150504378043694\n",
      "Epoch 8176, reconstruction losses: 0.019479738950226356, regression losses: 0.09775065122959577, validation losses: 0.4856244994714458\n",
      "Epoch 8177, reconstruction losses: 0.020537936031880866, regression losses: 0.08978116900570109, validation losses: 0.4488656265959938\n",
      "Epoch 8178, reconstruction losses: 0.02219419188715588, regression losses: 0.13807723459080548, validation losses: 0.43729605264572513\n",
      "Epoch 8179, reconstruction losses: 0.020919048506233058, regression losses: 0.12420440928140829, validation losses: 0.5641216996338364\n",
      "Epoch 8180, reconstruction losses: 0.023650341007350514, regression losses: 0.143065383334397, validation losses: 0.5871740862770022\n",
      "Epoch 8181, reconstruction losses: 0.02029844974460729, regression losses: 0.10441972194323008, validation losses: 0.4847536604803835\n",
      "Epoch 8182, reconstruction losses: 0.020487171200362756, regression losses: 0.1315658286501507, validation losses: 0.45377277457799037\n",
      "Epoch 8183, reconstruction losses: 0.022542545357602375, regression losses: 0.07144708348339594, validation losses: 0.43954448636005705\n",
      "Epoch 8184, reconstruction losses: 0.0199611951856141, regression losses: 0.09307378133330377, validation losses: 0.4514798719341573\n",
      "Epoch 8185, reconstruction losses: 0.02174610333997322, regression losses: 0.1497223962660332, validation losses: 0.4568441684941994\n",
      "Epoch 8186, reconstruction losses: 0.020619073041879227, regression losses: 0.11427410057882027, validation losses: 0.4422445017901919\n",
      "Epoch 8187, reconstruction losses: 0.021112631211392664, regression losses: 0.10415382865295471, validation losses: 0.47449333257462223\n",
      "Epoch 8188, reconstruction losses: 0.025849434646107797, regression losses: 0.26205385307782103, validation losses: 0.4691753631942883\n",
      "Epoch 8189, reconstruction losses: 0.02331864202594025, regression losses: 0.1103233687899669, validation losses: 0.5663455883893198\n",
      "Epoch 8190, reconstruction losses: 0.021325556629155418, regression losses: 0.12310384643912245, validation losses: 0.4463347784421009\n",
      "Epoch 8191, reconstruction losses: 0.021810026590112677, regression losses: 0.1309000042709784, validation losses: 0.43802306105046773\n",
      "Epoch 8192, reconstruction losses: 0.02201525167347267, regression losses: 0.10208967613737963, validation losses: 0.48630463620913456\n",
      "Epoch 8193, reconstruction losses: 0.024983417494352355, regression losses: 0.18327282270165007, validation losses: 0.4237603214680124\n",
      "Epoch 8194, reconstruction losses: 0.020762873374898818, regression losses: 0.11245133536044707, validation losses: 0.44636278386501893\n",
      "Epoch 8195, reconstruction losses: 0.021218864318084216, regression losses: 0.11457957587904033, validation losses: 0.4221293684380227\n",
      "Epoch 8196, reconstruction losses: 0.022002847719500816, regression losses: 0.11116118430638527, validation losses: 0.4428200834192202\n",
      "Epoch 8197, reconstruction losses: 0.02188355585358889, regression losses: 0.09430196680227404, validation losses: 0.4419307116274148\n",
      "Epoch 8198, reconstruction losses: 0.018516575420051886, regression losses: 0.08635831079610953, validation losses: 0.46255530530562206\n",
      "Epoch 8199, reconstruction losses: 0.021126583091921097, regression losses: 0.11223517506693792, validation losses: 0.46087814526602533\n",
      "Epoch 8200, reconstruction losses: 0.019485237722288443, regression losses: 0.10356852055813456, validation losses: 0.43101944565183503\n",
      "Epoch 8201, reconstruction losses: 0.024500507238055025, regression losses: 0.12985839274704625, validation losses: 0.4196564609180668\n",
      "Epoch 8202, reconstruction losses: 0.02464897954307444, regression losses: 0.11936873796362087, validation losses: 0.4442499730709375\n",
      "Epoch 8203, reconstruction losses: 0.020918156547275805, regression losses: 0.08093871928432671, validation losses: 0.42201654059092814\n",
      "Epoch 8204, reconstruction losses: 0.021666717831271942, regression losses: 0.11907768603073329, validation losses: 0.4461802167588699\n",
      "Epoch 8205, reconstruction losses: 0.021692619226370148, regression losses: 0.10136180770700498, validation losses: 0.44689302578498197\n",
      "Epoch 8206, reconstruction losses: 0.027259225008489936, regression losses: 0.17249763192038534, validation losses: 0.44743792494396223\n",
      "Epoch 8207, reconstruction losses: 0.02055590480129993, regression losses: 0.10243902461761623, validation losses: 0.4740896623409568\n",
      "Epoch 8208, reconstruction losses: 0.020402766490618496, regression losses: 0.11702493486891988, validation losses: 0.43436703114349534\n",
      "Epoch 8209, reconstruction losses: 0.025602495495428115, regression losses: 0.11404703053707914, validation losses: 0.4599795164073294\n",
      "Epoch 8210, reconstruction losses: 0.02116019909203748, regression losses: 0.07529830582410035, validation losses: 0.4791813004126489\n",
      "Epoch 8211, reconstruction losses: 0.02393233092066352, regression losses: 0.1706767364466244, validation losses: 0.48456911574307165\n",
      "Epoch 8212, reconstruction losses: 0.020671561680173103, regression losses: 0.13844227936657472, validation losses: 0.4985865087092165\n",
      "Epoch 8213, reconstruction losses: 0.023689306549213605, regression losses: 0.1572341674908364, validation losses: 0.49261574880330794\n",
      "Epoch 8214, reconstruction losses: 0.02093264959966521, regression losses: 0.11586648153582099, validation losses: 0.4614089166309003\n",
      "Epoch 8215, reconstruction losses: 0.021143904947984765, regression losses: 0.09718346682041114, validation losses: 0.4613762605329836\n",
      "Epoch 8216, reconstruction losses: 0.02283210013289099, regression losses: 0.1500090834823081, validation losses: 0.4364861997983829\n",
      "Epoch 8217, reconstruction losses: 0.01938850553820595, regression losses: 0.08499426501835071, validation losses: 0.4877300229418761\n",
      "Epoch 8218, reconstruction losses: 0.020565190814520618, regression losses: 0.12569562716996127, validation losses: 0.4666575385960452\n",
      "Epoch 8219, reconstruction losses: 0.02007845838212079, regression losses: 0.12665240214833817, validation losses: 0.4129684377034381\n",
      "Epoch 8220, reconstruction losses: 0.021014155178965672, regression losses: 0.08960243163481013, validation losses: 0.4157726446194686\n",
      "Epoch 8221, reconstruction losses: 0.022272051354625826, regression losses: 0.10997418019421598, validation losses: 0.45935855443309626\n",
      "Epoch 8222, reconstruction losses: 0.02073699922639249, regression losses: 0.09337707679568244, validation losses: 0.44482874696483227\n",
      "Epoch 8223, reconstruction losses: 0.02333309299343222, regression losses: 0.09270829116073226, validation losses: 0.49642660699031566\n",
      "Epoch 8224, reconstruction losses: 0.021860982514710428, regression losses: 0.16564346823077372, validation losses: 0.5182765721797478\n",
      "Epoch 8225, reconstruction losses: 0.021686181261541614, regression losses: 0.11622871880152524, validation losses: 0.4678328255733583\n",
      "Epoch 8226, reconstruction losses: 0.02319175547001095, regression losses: 0.20382005510268397, validation losses: 0.42815849673307227\n",
      "Epoch 8227, reconstruction losses: 0.02489707746428887, regression losses: 0.1901980694236639, validation losses: 0.5798476661350725\n",
      "Epoch 8228, reconstruction losses: 0.02756959002205303, regression losses: 0.13157679698573804, validation losses: 0.4907286835382063\n",
      "Epoch 8229, reconstruction losses: 0.022237897029921606, regression losses: 0.12219154031039096, validation losses: 0.44223333629451766\n",
      "Epoch 8230, reconstruction losses: 0.02247948215739027, regression losses: 0.09815243755348936, validation losses: 0.4504361477194466\n",
      "Epoch 8231, reconstruction losses: 0.02119399665293458, regression losses: 0.08810900567551394, validation losses: 0.49493016514123295\n",
      "Epoch 8232, reconstruction losses: 0.024501655657912794, regression losses: 0.17546241370605398, validation losses: 0.5384768829780164\n",
      "Epoch 8233, reconstruction losses: 0.02196330624825747, regression losses: 0.11627817142867618, validation losses: 0.5414510936526014\n",
      "Epoch 8234, reconstruction losses: 0.02104255955063055, regression losses: 0.1639627250351619, validation losses: 0.49737364959020747\n",
      "Epoch 8235, reconstruction losses: 0.021113356544611276, regression losses: 0.12463678547224112, validation losses: 0.5018825837383025\n",
      "Epoch 8236, reconstruction losses: 0.022868712479186353, regression losses: 0.1548126408710363, validation losses: 0.610335155703553\n",
      "Epoch 8237, reconstruction losses: 0.02082886394491363, regression losses: 0.10556751039260076, validation losses: 0.6770949053084163\n",
      "Epoch 8238, reconstruction losses: 0.022892488331596784, regression losses: 0.10215432404376738, validation losses: 0.5256046100364473\n",
      "Epoch 8239, reconstruction losses: 0.020242670568076424, regression losses: 0.0920225072405523, validation losses: 0.5067733215512809\n",
      "Epoch 8240, reconstruction losses: 0.02329078955297697, regression losses: 0.1375789911725441, validation losses: 0.537775466069001\n",
      "Epoch 8241, reconstruction losses: 0.02308840430028263, regression losses: 0.27929441601361227, validation losses: 0.5180374842509475\n",
      "Epoch 8242, reconstruction losses: 0.024480911118610733, regression losses: 0.1110985901165192, validation losses: 0.5987690507683181\n",
      "Epoch 8243, reconstruction losses: 0.019646217553126857, regression losses: 0.15491907868943672, validation losses: 0.5821492194276086\n",
      "Epoch 8244, reconstruction losses: 0.020544029684289818, regression losses: 0.1144594518892452, validation losses: 0.5153455386831106\n",
      "Epoch 8245, reconstruction losses: 0.01998320221650119, regression losses: 0.09193679169967928, validation losses: 0.6554091541583669\n",
      "Epoch 8246, reconstruction losses: 0.022577118624786452, regression losses: 0.16889659443243932, validation losses: 0.5754145102356374\n",
      "Epoch 8247, reconstruction losses: 0.023991137317653375, regression losses: 0.12297760287407752, validation losses: 0.5542791509775699\n",
      "Epoch 8248, reconstruction losses: 0.021213989932602394, regression losses: 0.12147058344576475, validation losses: 0.45390151916143995\n",
      "Epoch 8249, reconstruction losses: 0.01890826468953437, regression losses: 0.10545841481754091, validation losses: 0.43837398843930514\n",
      "Epoch 8250, reconstruction losses: 0.02022804536340872, regression losses: 0.11103147146082934, validation losses: 0.4152101972092978\n",
      "Epoch 8251, reconstruction losses: 0.021757834435481554, regression losses: 0.13658425422421466, validation losses: 0.43094326269300276\n",
      "Epoch 8252, reconstruction losses: 0.0237537481055903, regression losses: 0.11798356626352967, validation losses: 0.44773310699310703\n",
      "Epoch 8253, reconstruction losses: 0.024581768759372236, regression losses: 0.13435454890379137, validation losses: 0.4891606248922261\n",
      "Epoch 8254, reconstruction losses: 0.023167902384252145, regression losses: 0.17509993946330119, validation losses: 0.5487146576054007\n",
      "Epoch 8255, reconstruction losses: 0.021408799153559557, regression losses: 0.10881471576542572, validation losses: 0.5896975317413449\n",
      "Epoch 8256, reconstruction losses: 0.02120881670493354, regression losses: 0.11743418103671534, validation losses: 0.5407522458461343\n",
      "Epoch 8257, reconstruction losses: 0.022147638381681704, regression losses: 0.1365183002502258, validation losses: 0.4720163653343686\n",
      "Epoch 8258, reconstruction losses: 0.019412965273356814, regression losses: 0.12029491817444639, validation losses: 0.4339095303554543\n",
      "Epoch 8259, reconstruction losses: 0.022086434213585398, regression losses: 0.1072393336299841, validation losses: 0.4261916221492479\n",
      "Epoch 8260, reconstruction losses: 0.021620878036557194, regression losses: 0.14143206091489258, validation losses: 0.4261687782992387\n",
      "Epoch 8261, reconstruction losses: 0.019908059725902212, regression losses: 0.11961390315284588, validation losses: 0.45912657408483437\n",
      "Epoch 8262, reconstruction losses: 0.021253215469744426, regression losses: 0.09902567455500526, validation losses: 0.43975142178164284\n",
      "Epoch 8263, reconstruction losses: 0.021613374093304206, regression losses: 0.10162402155432576, validation losses: 0.46141793330110453\n",
      "Epoch 8264, reconstruction losses: 0.022406354977809483, regression losses: 0.16342146373448813, validation losses: 0.4340275442974724\n",
      "Epoch 8265, reconstruction losses: 0.01908702402350406, regression losses: 0.09797054107153798, validation losses: 0.42597541619022933\n",
      "Epoch 8266, reconstruction losses: 0.0235166110708326, regression losses: 0.11773502947771806, validation losses: 0.44363352683866053\n",
      "Epoch 8267, reconstruction losses: 0.02459011263234697, regression losses: 0.12588244139581917, validation losses: 0.44661798365493455\n",
      "Epoch 8268, reconstruction losses: 0.02220904038476915, regression losses: 0.10179167889543564, validation losses: 0.45257669251372146\n",
      "Epoch 8269, reconstruction losses: 0.024399319352705257, regression losses: 0.13822122565451883, validation losses: 0.4379460729057748\n",
      "Epoch 8270, reconstruction losses: 0.021588892674699017, regression losses: 0.10419909374125419, validation losses: 0.46244115036391703\n",
      "Epoch 8271, reconstruction losses: 0.02282499704167227, regression losses: 0.08738701914023747, validation losses: 0.5011401449732827\n",
      "Epoch 8272, reconstruction losses: 0.02205431939419522, regression losses: 0.09421414378915204, validation losses: 0.49181969268858194\n",
      "Epoch 8273, reconstruction losses: 0.022975942201089623, regression losses: 0.09036689495425895, validation losses: 0.4523206367125431\n",
      "Epoch 8274, reconstruction losses: 0.019867056481387924, regression losses: 0.11425414941063278, validation losses: 0.43399994317708473\n",
      "Epoch 8275, reconstruction losses: 0.021928765736069777, regression losses: 0.11278232137332439, validation losses: 0.442393591149944\n",
      "Epoch 8276, reconstruction losses: 0.021217728041612604, regression losses: 0.11380074344669781, validation losses: 0.4668004240207356\n",
      "Epoch 8277, reconstruction losses: 0.020775199351498713, regression losses: 0.1061785646952131, validation losses: 0.47151407264561973\n",
      "Epoch 8278, reconstruction losses: 0.023158558296905385, regression losses: 0.10546377396723336, validation losses: 0.4601017624660413\n",
      "Epoch 8279, reconstruction losses: 0.022181007839259696, regression losses: 0.10273201075246642, validation losses: 0.4638953477071221\n",
      "Epoch 8280, reconstruction losses: 0.022223333114231955, regression losses: 0.111331370020597, validation losses: 0.44386346294324797\n",
      "Epoch 8281, reconstruction losses: 0.022687919361129752, regression losses: 0.11148686372282922, validation losses: 0.4302829889410023\n",
      "Epoch 8282, reconstruction losses: 0.024747929088976765, regression losses: 0.11670352439456055, validation losses: 0.4363365737223044\n",
      "Epoch 8283, reconstruction losses: 0.020362390357107046, regression losses: 0.09459706475943952, validation losses: 0.4907963968276432\n",
      "Epoch 8284, reconstruction losses: 0.02595504941785854, regression losses: 0.08682243341104064, validation losses: 0.5294206249830564\n",
      "Epoch 8285, reconstruction losses: 0.020414355533252347, regression losses: 0.11506552478028949, validation losses: 0.46930631883157586\n",
      "Epoch 8286, reconstruction losses: 0.02047727635467026, regression losses: 0.11703739170388283, validation losses: 0.44741522962171243\n",
      "Epoch 8287, reconstruction losses: 0.021760587567809856, regression losses: 0.10729122739553998, validation losses: 0.46735822721565756\n",
      "Epoch 8288, reconstruction losses: 0.02137815120407073, regression losses: 0.138312926480616, validation losses: 0.4340529680294105\n",
      "Epoch 8289, reconstruction losses: 0.020313692906700903, regression losses: 0.09504901213749478, validation losses: 0.4564803312135503\n",
      "Epoch 8290, reconstruction losses: 0.01888996878652136, regression losses: 0.10300197931318691, validation losses: 0.474540232624211\n",
      "Epoch 8291, reconstruction losses: 0.01989985033925145, regression losses: 0.07846094185458075, validation losses: 0.4877731085015184\n",
      "Epoch 8292, reconstruction losses: 0.020400612824343963, regression losses: 0.10523134640238527, validation losses: 0.4605892521655296\n",
      "Epoch 8293, reconstruction losses: 0.021202003409680578, regression losses: 0.12694340639010054, validation losses: 0.4316755435924118\n",
      "Epoch 8294, reconstruction losses: 0.023379198691002162, regression losses: 0.16904849648254558, validation losses: 0.4381122438052453\n",
      "Epoch 8295, reconstruction losses: 0.02296410683564608, regression losses: 0.1487038063554359, validation losses: 0.5000571876156952\n",
      "Epoch 8296, reconstruction losses: 0.022183908406653102, regression losses: 0.12461161102156189, validation losses: 0.4375019707661051\n",
      "Epoch 8297, reconstruction losses: 0.0213813460938323, regression losses: 0.1122414279985379, validation losses: 0.42717814439291546\n",
      "Epoch 8298, reconstruction losses: 0.022206065776553253, regression losses: 0.21487238947246917, validation losses: 0.425437467033624\n",
      "Epoch 8299, reconstruction losses: 0.02420588284584569, regression losses: 0.1115453373143854, validation losses: 0.518837216078715\n",
      "Epoch 8300, reconstruction losses: 0.018991086851531634, regression losses: 0.11389158573763195, validation losses: 0.5036705748015545\n",
      "Epoch 8301, reconstruction losses: 0.020534932563380813, regression losses: 0.14015914046746036, validation losses: 0.46321338780570753\n",
      "Epoch 8302, reconstruction losses: 0.023112752152240172, regression losses: 0.15190109700351498, validation losses: 0.4494659908512678\n",
      "Epoch 8303, reconstruction losses: 0.021287625347783588, regression losses: 0.09381749506677817, validation losses: 0.4563529543728228\n",
      "Epoch 8304, reconstruction losses: 0.02204757452348722, regression losses: 0.12794900025036918, validation losses: 0.529266352186952\n",
      "Epoch 8305, reconstruction losses: 0.023185826350913222, regression losses: 0.14718658806413953, validation losses: 0.5506122654740708\n",
      "Epoch 8306, reconstruction losses: 0.022170859425553413, regression losses: 0.11681485163018937, validation losses: 0.6104826725693462\n",
      "Epoch 8307, reconstruction losses: 0.024091415142724726, regression losses: 0.13838091512937784, validation losses: 0.5076006117062145\n",
      "Epoch 8308, reconstruction losses: 0.020645417987103606, regression losses: 0.10710180446505535, validation losses: 0.5497331760119086\n",
      "Epoch 8309, reconstruction losses: 0.02231340893382296, regression losses: 0.11012522762529181, validation losses: 0.541767536493511\n",
      "Epoch 8310, reconstruction losses: 0.019887385165832255, regression losses: 0.12786113991884912, validation losses: 0.4729310897739873\n",
      "Epoch 8311, reconstruction losses: 0.025206519912756808, regression losses: 0.16077646697122702, validation losses: 0.5106400901071958\n",
      "Epoch 8312, reconstruction losses: 0.023728895597019437, regression losses: 0.19433016815940063, validation losses: 0.5295262681963271\n",
      "Epoch 8313, reconstruction losses: 0.020158538768928657, regression losses: 0.1456356437616878, validation losses: 0.6363448674841854\n",
      "Epoch 8314, reconstruction losses: 0.02367398522433896, regression losses: 0.15530812960291895, validation losses: 0.5169791009047279\n",
      "Epoch 8315, reconstruction losses: 0.022613593161605057, regression losses: 0.11436960637264565, validation losses: 0.4355196398561091\n",
      "Epoch 8316, reconstruction losses: 0.022864926752171083, regression losses: 0.11903905561009809, validation losses: 0.4327148204135028\n",
      "Epoch 8317, reconstruction losses: 0.020590809738176525, regression losses: 0.09481831324713907, validation losses: 0.4350060674089589\n",
      "Epoch 8318, reconstruction losses: 0.02226205435421088, regression losses: 0.09857620119022814, validation losses: 0.43936277385046896\n",
      "Epoch 8319, reconstruction losses: 0.02284958538832882, regression losses: 0.13110486323807327, validation losses: 0.4600835245844692\n",
      "Epoch 8320, reconstruction losses: 0.02070420626947834, regression losses: 0.11707190420470007, validation losses: 0.4361567695663054\n",
      "Epoch 8321, reconstruction losses: 0.021117136670055842, regression losses: 0.1264719019623332, validation losses: 0.43836513008275274\n",
      "Epoch 8322, reconstruction losses: 0.021169235788966935, regression losses: 0.09638890786486747, validation losses: 0.4318514651585218\n",
      "Epoch 8323, reconstruction losses: 0.02055336970258523, regression losses: 0.12016863524854285, validation losses: 0.4212994508194807\n",
      "Epoch 8324, reconstruction losses: 0.02117380152169654, regression losses: 0.11554679170506055, validation losses: 0.4275284870902978\n",
      "Epoch 8325, reconstruction losses: 0.021466462711232176, regression losses: 0.14370792758895956, validation losses: 0.47389399292199935\n",
      "Epoch 8326, reconstruction losses: 0.022444764418355297, regression losses: 0.09875316980438432, validation losses: 0.4803715546870167\n",
      "Epoch 8327, reconstruction losses: 0.021101105008996434, regression losses: 0.10021332525815879, validation losses: 0.4431064678431\n",
      "Epoch 8328, reconstruction losses: 0.020005784630273193, regression losses: 0.10049173606042575, validation losses: 0.4352041995229148\n",
      "Epoch 8329, reconstruction losses: 0.024432041170140084, regression losses: 0.10126097248344272, validation losses: 0.4413317078243735\n",
      "Epoch 8330, reconstruction losses: 0.021189920019973954, regression losses: 0.11733251999658721, validation losses: 0.44689092286449117\n",
      "Epoch 8331, reconstruction losses: 0.01906571294487163, regression losses: 0.08615557683482929, validation losses: 0.5277694424068897\n",
      "Epoch 8332, reconstruction losses: 0.024578858031362262, regression losses: 0.12050522504263989, validation losses: 0.5337870955076416\n",
      "Epoch 8333, reconstruction losses: 0.02273363342894119, regression losses: 0.14209146293565939, validation losses: 0.4782014141831777\n",
      "Epoch 8334, reconstruction losses: 0.025172185178275096, regression losses: 0.18611452422272967, validation losses: 0.5982903562856566\n",
      "Epoch 8335, reconstruction losses: 0.022240259622255235, regression losses: 0.1289029747249879, validation losses: 0.6701445440814051\n",
      "Epoch 8336, reconstruction losses: 0.021950352767589283, regression losses: 0.15171977759261765, validation losses: 0.4683413954383192\n",
      "Epoch 8337, reconstruction losses: 0.021221929374895226, regression losses: 0.12007438081257764, validation losses: 0.5093209460923525\n",
      "Epoch 8338, reconstruction losses: 0.020088436578833923, regression losses: 0.10268009443738432, validation losses: 0.5927512888890263\n",
      "Epoch 8339, reconstruction losses: 0.02296662959212667, regression losses: 0.12207040192205655, validation losses: 0.5873661021642638\n",
      "Epoch 8340, reconstruction losses: 0.025552091452668554, regression losses: 0.1334252919143094, validation losses: 0.5227514099176669\n",
      "Epoch 8341, reconstruction losses: 0.027245595633407206, regression losses: 0.1410563878316144, validation losses: 0.42348531584421495\n",
      "Epoch 8342, reconstruction losses: 0.023034129085273518, regression losses: 0.12177818259399144, validation losses: 0.46509972157303725\n",
      "Epoch 8343, reconstruction losses: 0.021284275169371453, regression losses: 0.11775172822729331, validation losses: 0.42747559157918114\n",
      "Epoch 8344, reconstruction losses: 0.02314348941115341, regression losses: 0.10625123505305167, validation losses: 0.5096245861312697\n",
      "Epoch 8345, reconstruction losses: 0.020173638497319686, regression losses: 0.09960222410898835, validation losses: 0.5681405990742298\n",
      "Epoch 8346, reconstruction losses: 0.021553357021526418, regression losses: 0.11873601020923108, validation losses: 0.5390416728379018\n",
      "Epoch 8347, reconstruction losses: 0.020645399928966746, regression losses: 0.12062841639565015, validation losses: 0.46458960641117564\n",
      "Epoch 8348, reconstruction losses: 0.021603792760836574, regression losses: 0.096734649030774, validation losses: 0.4515861524307928\n",
      "Epoch 8349, reconstruction losses: 0.019821479296781797, regression losses: 0.11269613100384253, validation losses: 0.4469061372917221\n",
      "Epoch 8350, reconstruction losses: 0.02053902035847155, regression losses: 0.12120207367887663, validation losses: 0.4627728396203702\n",
      "Epoch 8351, reconstruction losses: 0.021612454594514975, regression losses: 0.11021612870707667, validation losses: 0.4631613828864823\n",
      "Epoch 8352, reconstruction losses: 0.023047973306624427, regression losses: 0.13131090443132404, validation losses: 0.48198238144797606\n",
      "Epoch 8353, reconstruction losses: 0.021150753183688427, regression losses: 0.2045093577966729, validation losses: 0.5382176893603456\n",
      "Epoch 8354, reconstruction losses: 0.0225156237940875, regression losses: 0.12584109644716926, validation losses: 0.47973379578521297\n",
      "Epoch 8355, reconstruction losses: 0.020922198386031016, regression losses: 0.12457494088331209, validation losses: 0.5481551406827337\n",
      "Epoch 8356, reconstruction losses: 0.02115178615038491, regression losses: 0.10034444783033984, validation losses: 0.5703908712122364\n",
      "Epoch 8357, reconstruction losses: 0.021791251492466107, regression losses: 0.11077989700515846, validation losses: 0.47637169638108795\n",
      "Epoch 8358, reconstruction losses: 0.020954720440342196, regression losses: 0.0754634144081161, validation losses: 0.44178958037681415\n",
      "Epoch 8359, reconstruction losses: 0.024551657574619974, regression losses: 0.12285319517746031, validation losses: 0.41666528862641034\n",
      "Epoch 8360, reconstruction losses: 0.020777395052844976, regression losses: 0.11677957844786208, validation losses: 0.461344271762418\n",
      "Epoch 8361, reconstruction losses: 0.02212980098943691, regression losses: 0.10238637378205337, validation losses: 0.4450038867126406\n",
      "Epoch 8362, reconstruction losses: 0.024799851368784747, regression losses: 0.14282420415562164, validation losses: 0.42581118751182023\n",
      "Epoch 8363, reconstruction losses: 0.022572894922940852, regression losses: 0.10379673702907945, validation losses: 0.49694402896722684\n",
      "Epoch 8364, reconstruction losses: 0.020312128493753225, regression losses: 0.11946401101124349, validation losses: 0.4897109316823173\n",
      "Epoch 8365, reconstruction losses: 0.025418567190821032, regression losses: 0.09916723823298254, validation losses: 0.4389880170014787\n",
      "Epoch 8366, reconstruction losses: 0.01993266960983029, regression losses: 0.09790280488275914, validation losses: 0.43920557889852185\n",
      "Epoch 8367, reconstruction losses: 0.024616559931669384, regression losses: 0.16873034351965638, validation losses: 0.44519344184890747\n",
      "Epoch 8368, reconstruction losses: 0.023347692225155706, regression losses: 0.15019170854439426, validation losses: 0.4993528972472615\n",
      "Epoch 8369, reconstruction losses: 0.021073586305944837, regression losses: 0.12933987439014247, validation losses: 0.5076376563177738\n",
      "Epoch 8370, reconstruction losses: 0.022893040139023293, regression losses: 0.1613311500783974, validation losses: 0.4233957078964885\n",
      "Epoch 8371, reconstruction losses: 0.023420858791308057, regression losses: 0.14804437918119256, validation losses: 0.5317870283815904\n",
      "Epoch 8372, reconstruction losses: 0.021328597103579983, regression losses: 0.1144726387981025, validation losses: 0.4959655425499775\n",
      "Epoch 8373, reconstruction losses: 0.020650027798376887, regression losses: 0.14376504635994913, validation losses: 0.4678591094821955\n",
      "Epoch 8374, reconstruction losses: 0.02001105964540597, regression losses: 0.10657375547591462, validation losses: 0.4675340212681284\n",
      "Epoch 8375, reconstruction losses: 0.020252540228554532, regression losses: 0.1036244084704398, validation losses: 0.44927201190257887\n",
      "Epoch 8376, reconstruction losses: 0.023863669340567828, regression losses: 0.09905279156335231, validation losses: 0.4679888300903752\n",
      "Epoch 8377, reconstruction losses: 0.022068818694231555, regression losses: 0.10341524324341475, validation losses: 0.44828646886622825\n",
      "Epoch 8378, reconstruction losses: 0.02307752395585612, regression losses: 0.07593971074137629, validation losses: 0.44022978862166456\n",
      "Epoch 8379, reconstruction losses: 0.02391395239032236, regression losses: 0.14709164712636458, validation losses: 0.46049658028501184\n",
      "Epoch 8380, reconstruction losses: 0.020394799742364626, regression losses: 0.10964839832597463, validation losses: 0.45194828994361813\n",
      "Epoch 8381, reconstruction losses: 0.020731785155462232, regression losses: 0.12424800197046604, validation losses: 0.45547518766350353\n",
      "Epoch 8382, reconstruction losses: 0.020213223100628282, regression losses: 0.0998712344034437, validation losses: 0.4997272322532801\n",
      "Epoch 8383, reconstruction losses: 0.021957259522312783, regression losses: 0.09693006521739121, validation losses: 0.45109814267679305\n",
      "Epoch 8384, reconstruction losses: 0.020659168285759994, regression losses: 0.11829476467905492, validation losses: 0.4209341677130779\n",
      "Epoch 8385, reconstruction losses: 0.020028737916625208, regression losses: 0.12919856814967823, validation losses: 0.4441065056848022\n",
      "Epoch 8386, reconstruction losses: 0.023082280269017777, regression losses: 0.14429650832664115, validation losses: 0.5649880607778937\n",
      "Epoch 8387, reconstruction losses: 0.02204996868228883, regression losses: 0.10444657448315593, validation losses: 0.5035817364719385\n",
      "Epoch 8388, reconstruction losses: 0.022412944193904473, regression losses: 0.11710148293531564, validation losses: 0.4283882237714797\n",
      "Epoch 8389, reconstruction losses: 0.021803850315433693, regression losses: 0.1229116245741203, validation losses: 0.42059913749135647\n",
      "Epoch 8390, reconstruction losses: 0.020763026965335187, regression losses: 0.09552216139304864, validation losses: 0.4369374659182012\n",
      "Epoch 8391, reconstruction losses: 0.01967809572389567, regression losses: 0.09905554865805229, validation losses: 0.5219641439746241\n",
      "Epoch 8392, reconstruction losses: 0.024727723345519127, regression losses: 0.13652823024405697, validation losses: 0.5184672907262824\n",
      "Epoch 8393, reconstruction losses: 0.021892474467201984, regression losses: 0.09325987215212579, validation losses: 0.45952026214755554\n",
      "Epoch 8394, reconstruction losses: 0.022103148438381074, regression losses: 0.10051995659886127, validation losses: 0.4423255484681768\n",
      "Epoch 8395, reconstruction losses: 0.02277482769267156, regression losses: 0.12522769779418025, validation losses: 0.44251306026848425\n",
      "Epoch 8396, reconstruction losses: 0.021603136460815575, regression losses: 0.10899581313593051, validation losses: 0.4251086102708251\n",
      "Epoch 8397, reconstruction losses: 0.022361559055417344, regression losses: 0.15486394705694334, validation losses: 0.4768467707949471\n",
      "Epoch 8398, reconstruction losses: 0.023860387372457374, regression losses: 0.1365302146289462, validation losses: 0.5362349231069151\n",
      "Epoch 8399, reconstruction losses: 0.024193224058477375, regression losses: 0.1727730610924063, validation losses: 0.501340491152636\n",
      "Epoch 8400, reconstruction losses: 0.020294202306211213, regression losses: 0.11674549509154032, validation losses: 0.4636048541698698\n",
      "Epoch 8401, reconstruction losses: 0.022970386328431305, regression losses: 0.11552811787630159, validation losses: 0.43414231866463493\n",
      "Epoch 8402, reconstruction losses: 0.022590102699465247, regression losses: 0.1669219833912034, validation losses: 0.41527157167298256\n",
      "Epoch 8403, reconstruction losses: 0.019951765719978254, regression losses: 0.10768087057945472, validation losses: 0.4325133619699767\n",
      "Epoch 8404, reconstruction losses: 0.022233349041947733, regression losses: 0.09568020781373195, validation losses: 0.528538220302699\n",
      "Epoch 8405, reconstruction losses: 0.02127680767178348, regression losses: 0.12180391417671874, validation losses: 0.5641295619250845\n",
      "Epoch 8406, reconstruction losses: 0.01895647120492538, regression losses: 0.14324432208164423, validation losses: 0.4620883290121858\n",
      "Epoch 8407, reconstruction losses: 0.01834449462820181, regression losses: 0.07589452783981648, validation losses: 0.4084208326936562\n",
      "Epoch 8408, reconstruction losses: 0.020165607563888563, regression losses: 0.11251719928962425, validation losses: 0.3996764843297934\n",
      "Epoch 8409, reconstruction losses: 0.02142952369569402, regression losses: 0.13795162251918378, validation losses: 0.43233119331238534\n",
      "Epoch 8410, reconstruction losses: 0.02072143420270616, regression losses: 0.12011792242509378, validation losses: 0.47753256353507156\n",
      "Epoch 8411, reconstruction losses: 0.022554816350407004, regression losses: 0.11901947215168275, validation losses: 0.44513042939252323\n",
      "Epoch 8412, reconstruction losses: 0.019952460863419584, regression losses: 0.09889320361981856, validation losses: 0.4135649777462468\n",
      "Epoch 8413, reconstruction losses: 0.021275911129870907, regression losses: 0.09695665328357238, validation losses: 0.4129154335385134\n",
      "Epoch 8414, reconstruction losses: 0.021704520517442157, regression losses: 0.10441112395668928, validation losses: 0.41552729530123755\n",
      "Epoch 8415, reconstruction losses: 0.02108969932756389, regression losses: 0.10408920028085486, validation losses: 0.4768172659241403\n",
      "Epoch 8416, reconstruction losses: 0.022410874605077784, regression losses: 0.1036301679310154, validation losses: 0.5018906096620761\n",
      "Epoch 8417, reconstruction losses: 0.022781682039807807, regression losses: 0.1036705784174308, validation losses: 0.4706752688301415\n",
      "Epoch 8418, reconstruction losses: 0.01963947664207278, regression losses: 0.08628620066164368, validation losses: 0.44585092817974553\n",
      "Epoch 8419, reconstruction losses: 0.01868435868782342, regression losses: 0.0789186130634697, validation losses: 0.44381067461730167\n",
      "Epoch 8420, reconstruction losses: 0.02112480918837535, regression losses: 0.11565901869163069, validation losses: 0.43378771984719794\n",
      "Epoch 8421, reconstruction losses: 0.02106201912959447, regression losses: 0.12743300092962062, validation losses: 0.4474233101092104\n",
      "Epoch 8422, reconstruction losses: 0.021408066573806936, regression losses: 0.11949531842649322, validation losses: 0.47994779052066294\n",
      "Epoch 8423, reconstruction losses: 0.022681746522967353, regression losses: 0.11840934010221423, validation losses: 0.47392133768253725\n",
      "Epoch 8424, reconstruction losses: 0.019232671965732084, regression losses: 0.09919790754137985, validation losses: 0.434895796970918\n",
      "Epoch 8425, reconstruction losses: 0.01937149668433625, regression losses: 0.13206603999011823, validation losses: 0.45111029192274343\n",
      "Epoch 8426, reconstruction losses: 0.02178305567500462, regression losses: 0.1061235754806228, validation losses: 0.4998909369703737\n",
      "Epoch 8427, reconstruction losses: 0.022835307961274934, regression losses: 0.07184287219324463, validation losses: 0.510150628152034\n",
      "Epoch 8428, reconstruction losses: 0.019143785801760564, regression losses: 0.10898216050903678, validation losses: 0.4796043999498143\n",
      "Epoch 8429, reconstruction losses: 0.023357188466171856, regression losses: 0.11608154169280174, validation losses: 0.4713709552722773\n",
      "Epoch 8430, reconstruction losses: 0.02126134260880476, regression losses: 0.11840544680915067, validation losses: 0.4484716846872594\n",
      "Epoch 8431, reconstruction losses: 0.020599622405302373, regression losses: 0.09091615859725447, validation losses: 0.48575309477454354\n",
      "Epoch 8432, reconstruction losses: 0.022493277062788513, regression losses: 0.15244291095226156, validation losses: 0.5246191153418241\n",
      "Epoch 8433, reconstruction losses: 0.021627852168002153, regression losses: 0.12361528544829622, validation losses: 0.46268398340017053\n",
      "Epoch 8434, reconstruction losses: 0.020585852888844434, regression losses: 0.1365862830980334, validation losses: 0.4553282557623258\n",
      "Epoch 8435, reconstruction losses: 0.023389586990241656, regression losses: 0.12064627509713567, validation losses: 0.4467964926844272\n",
      "Epoch 8436, reconstruction losses: 0.022302884411261485, regression losses: 0.1219055688685156, validation losses: 0.43551630476564257\n",
      "Epoch 8437, reconstruction losses: 0.02249169871511843, regression losses: 0.17778406516192902, validation losses: 0.4432946733434912\n",
      "Epoch 8438, reconstruction losses: 0.020628531311491567, regression losses: 0.10285757351505193, validation losses: 0.5294083327951752\n",
      "Epoch 8439, reconstruction losses: 0.021351876611845892, regression losses: 0.10719134767446989, validation losses: 0.5594739300348845\n",
      "Epoch 8440, reconstruction losses: 0.0205962787675353, regression losses: 0.13356478775861527, validation losses: 0.46048401000764344\n",
      "Epoch 8441, reconstruction losses: 0.021863619163804072, regression losses: 0.07795243032387666, validation losses: 0.45664997701950694\n",
      "Epoch 8442, reconstruction losses: 0.02455322294990778, regression losses: 0.21855008356323155, validation losses: 0.46341837048668894\n",
      "Epoch 8443, reconstruction losses: 0.021582538709962625, regression losses: 0.1447717766640175, validation losses: 0.6245227466020556\n",
      "Epoch 8444, reconstruction losses: 0.024265514395292037, regression losses: 0.216975206162473, validation losses: 0.5425580620082747\n",
      "Epoch 8445, reconstruction losses: 0.023141127952118343, regression losses: 0.11319809121761773, validation losses: 0.6162633789264005\n",
      "Epoch 8446, reconstruction losses: 0.02028117358739077, regression losses: 0.11729609986128685, validation losses: 0.48166741340463853\n",
      "Epoch 8447, reconstruction losses: 0.021862479829872637, regression losses: 0.12224918948131017, validation losses: 0.4278470908679931\n",
      "Epoch 8448, reconstruction losses: 0.024591295558358137, regression losses: 0.12809767513235382, validation losses: 0.4783749234093506\n",
      "Epoch 8449, reconstruction losses: 0.02275156151969887, regression losses: 0.0980226101147138, validation losses: 0.4505936721766712\n",
      "Epoch 8450, reconstruction losses: 0.026241235282730715, regression losses: 0.2282437463545652, validation losses: 0.4813501573184701\n",
      "Epoch 8451, reconstruction losses: 0.019882350485065, regression losses: 0.17880985662550383, validation losses: 0.8070093386666858\n",
      "Epoch 8452, reconstruction losses: 0.020261232884215954, regression losses: 0.14074121707620688, validation losses: 0.4580646154385196\n",
      "Epoch 8453, reconstruction losses: 0.021085805340057447, regression losses: 0.11342635959719488, validation losses: 0.4289282117160048\n",
      "Epoch 8454, reconstruction losses: 0.02252319714614348, regression losses: 0.09306424984930842, validation losses: 0.3997146152139652\n",
      "Epoch 8455, reconstruction losses: 0.02031262233063416, regression losses: 0.0861171490468823, validation losses: 0.3976494426261154\n",
      "Epoch 8456, reconstruction losses: 0.02152376939692959, regression losses: 0.10092254406670315, validation losses: 0.4077128670610128\n",
      "Epoch 8457, reconstruction losses: 0.020907139408682156, regression losses: 0.11460810549512207, validation losses: 0.4588352470481947\n",
      "Epoch 8458, reconstruction losses: 0.019735584058497922, regression losses: 0.11547075408552801, validation losses: 0.4936345752774734\n",
      "Epoch 8459, reconstruction losses: 0.025057657615528535, regression losses: 0.11666221215648798, validation losses: 0.42237352576051124\n",
      "Epoch 8460, reconstruction losses: 0.019120760064446414, regression losses: 0.09215237463071264, validation losses: 0.4075453223164697\n",
      "Epoch 8461, reconstruction losses: 0.022424752273813398, regression losses: 0.18023195700044403, validation losses: 0.414730319564524\n",
      "Epoch 8462, reconstruction losses: 0.022232297707654447, regression losses: 0.09851366922688835, validation losses: 0.6469659915068072\n",
      "Epoch 8463, reconstruction losses: 0.024509167099586213, regression losses: 0.11575165028234616, validation losses: 0.6305962375772196\n",
      "Epoch 8464, reconstruction losses: 0.025079677086739683, regression losses: 0.15761732958546726, validation losses: 0.4770197765053598\n",
      "Epoch 8465, reconstruction losses: 0.022976858126521216, regression losses: 0.13185100380192402, validation losses: 0.44389984246214104\n",
      "Epoch 8466, reconstruction losses: 0.02176493678524874, regression losses: 0.14365698429578622, validation losses: 0.519075051508774\n",
      "Epoch 8467, reconstruction losses: 0.022219288645212595, regression losses: 0.12253642563456174, validation losses: 0.5583393625627794\n",
      "Epoch 8468, reconstruction losses: 0.021777616662269537, regression losses: 0.14567997563009935, validation losses: 0.4746738197836169\n",
      "Epoch 8469, reconstruction losses: 0.021398743082667808, regression losses: 0.12137347015142698, validation losses: 0.49838788752344354\n",
      "Epoch 8470, reconstruction losses: 0.023763610032543583, regression losses: 0.11855335969561297, validation losses: 0.4720451198870775\n",
      "Epoch 8471, reconstruction losses: 0.01891353097491029, regression losses: 0.12805063712710768, validation losses: 0.5131414337528291\n",
      "Epoch 8472, reconstruction losses: 0.020233459116455108, regression losses: 0.09870138128563503, validation losses: 0.4532974466836452\n",
      "Epoch 8473, reconstruction losses: 0.023114497471889234, regression losses: 0.13892928514216385, validation losses: 0.42923933394009456\n",
      "Epoch 8474, reconstruction losses: 0.020173541890601967, regression losses: 0.11178252849865103, validation losses: 0.4764737014816204\n",
      "Epoch 8475, reconstruction losses: 0.022000683332834843, regression losses: 0.1344625203933411, validation losses: 0.506967572243944\n",
      "Epoch 8476, reconstruction losses: 0.02110148912279575, regression losses: 0.13222278297881984, validation losses: 0.4963984348308995\n",
      "Epoch 8477, reconstruction losses: 0.021943096856195915, regression losses: 0.14777281134427667, validation losses: 0.47649257325923716\n",
      "Epoch 8478, reconstruction losses: 0.021812512677806397, regression losses: 0.16743091512363964, validation losses: 0.5389809234720165\n",
      "Epoch 8479, reconstruction losses: 0.020815813484070446, regression losses: 0.12055767444550927, validation losses: 0.61999352830265\n",
      "Epoch 8480, reconstruction losses: 0.022208193176883186, regression losses: 0.15813277867346692, validation losses: 0.47054277792905624\n",
      "Epoch 8481, reconstruction losses: 0.022869835000614465, regression losses: 0.34175554650106593, validation losses: 0.4998315797162261\n",
      "Epoch 8482, reconstruction losses: 0.020111612833639225, regression losses: 0.13166117103271757, validation losses: 0.6152417628562511\n",
      "Epoch 8483, reconstruction losses: 0.02023838127915845, regression losses: 0.1414871191674543, validation losses: 0.7578042450870605\n",
      "Epoch 8484, reconstruction losses: 0.021538581932308815, regression losses: 0.1898583878204924, validation losses: 0.6285650207506855\n",
      "Epoch 8485, reconstruction losses: 0.026540041783191817, regression losses: 0.14934815396528436, validation losses: 0.6376842768722017\n",
      "Epoch 8486, reconstruction losses: 0.021506594818006652, regression losses: 0.1068875507003371, validation losses: 0.4505012132893913\n",
      "Epoch 8487, reconstruction losses: 0.022929695646654202, regression losses: 0.13365303061117292, validation losses: 0.4525972657997513\n",
      "Epoch 8488, reconstruction losses: 0.02257686917208404, regression losses: 0.10157630518592688, validation losses: 0.48987420486665567\n",
      "Epoch 8489, reconstruction losses: 0.02498690300182442, regression losses: 0.13890503832873102, validation losses: 0.4307095769619532\n",
      "Epoch 8490, reconstruction losses: 0.027726990920365797, regression losses: 0.1677299940730522, validation losses: 0.5426779215875748\n",
      "Epoch 8491, reconstruction losses: 0.02070462997857642, regression losses: 0.12137047593468576, validation losses: 0.44608592373002737\n",
      "Epoch 8492, reconstruction losses: 0.02085367147295618, regression losses: 0.10898126594814357, validation losses: 0.45648352984693213\n",
      "Epoch 8493, reconstruction losses: 0.01894838174661856, regression losses: 0.10718257124592492, validation losses: 0.5190848387195488\n",
      "Epoch 8494, reconstruction losses: 0.020983004548953334, regression losses: 0.11047474621542686, validation losses: 0.5088735190008843\n",
      "Epoch 8495, reconstruction losses: 0.020638442519896286, regression losses: 0.09845043048749942, validation losses: 0.5036705654824826\n",
      "Epoch 8496, reconstruction losses: 0.02047695701686925, regression losses: 0.10730523213472187, validation losses: 0.4676119493689274\n",
      "Epoch 8497, reconstruction losses: 0.02240782949138988, regression losses: 0.11189652102683934, validation losses: 0.46360762032152747\n",
      "Epoch 8498, reconstruction losses: 0.022686142066517024, regression losses: 0.12107800043441017, validation losses: 0.49622186365643506\n",
      "Epoch 8499, reconstruction losses: 0.024880271481408922, regression losses: 0.15722418633252566, validation losses: 0.512814292746407\n",
      "Epoch 8500, reconstruction losses: 0.020775756886919485, regression losses: 0.11944836446847674, validation losses: 0.44659465192338643\n",
      "Epoch 8501, reconstruction losses: 0.01901749007939084, regression losses: 0.11006509583527291, validation losses: 0.46620619811049235\n",
      "Epoch 8502, reconstruction losses: 0.021461599218305934, regression losses: 0.13648555853080818, validation losses: 0.4601427090879377\n",
      "Epoch 8503, reconstruction losses: 0.02249896728416007, regression losses: 0.08674624917100647, validation losses: 0.45160456522069503\n",
      "Epoch 8504, reconstruction losses: 0.021688124382325456, regression losses: 0.10290635688961015, validation losses: 0.4422302584889101\n",
      "Epoch 8505, reconstruction losses: 0.02068310254835387, regression losses: 0.3781336948565683, validation losses: 0.4714415852131284\n",
      "Epoch 8506, reconstruction losses: 0.024071307094476677, regression losses: 0.12128477830833748, validation losses: 0.5775206785769743\n",
      "Epoch 8507, reconstruction losses: 0.021493096470062686, regression losses: 0.12906364275539767, validation losses: 0.553387888063049\n",
      "Epoch 8508, reconstruction losses: 0.021650593749033793, regression losses: 0.15097596190700907, validation losses: 0.49357006950860394\n",
      "Epoch 8509, reconstruction losses: 0.02065188781450461, regression losses: 0.11141518531305593, validation losses: 0.5372306421425493\n",
      "Epoch 8510, reconstruction losses: 0.01996810361723111, regression losses: 0.08303126236810057, validation losses: 0.4783595809433062\n",
      "Epoch 8511, reconstruction losses: 0.018424638310221425, regression losses: 0.10484187699119688, validation losses: 0.4546959736489747\n",
      "Epoch 8512, reconstruction losses: 0.022949256967520124, regression losses: 0.09010621368190991, validation losses: 0.46465055236036457\n",
      "Epoch 8513, reconstruction losses: 0.02103488989360071, regression losses: 0.1213495356813417, validation losses: 0.4993048231967526\n",
      "Epoch 8514, reconstruction losses: 0.021033407984812957, regression losses: 0.14043125377589177, validation losses: 0.48241299375983626\n",
      "Epoch 8515, reconstruction losses: 0.02140180357942005, regression losses: 0.10755553939722007, validation losses: 0.43219456527851063\n",
      "Epoch 8516, reconstruction losses: 0.022098893914229, regression losses: 0.14744715723453158, validation losses: 0.4163457443176507\n",
      "Epoch 8517, reconstruction losses: 0.022936333930368598, regression losses: 0.10707798001240987, validation losses: 0.42613964887103084\n",
      "Epoch 8518, reconstruction losses: 0.02476891855665181, regression losses: 0.15209130096898069, validation losses: 0.4185167785111355\n",
      "Epoch 8519, reconstruction losses: 0.02255622031840946, regression losses: 0.11438725599452955, validation losses: 0.4857878313291456\n",
      "Epoch 8520, reconstruction losses: 0.022752084059136975, regression losses: 0.1221751115145017, validation losses: 0.5176508552046128\n",
      "Epoch 8521, reconstruction losses: 0.022567700100066215, regression losses: 0.10849657792735498, validation losses: 0.5790208089818738\n",
      "Epoch 8522, reconstruction losses: 0.02287967589008119, regression losses: 0.12438763442520753, validation losses: 0.47678370942149273\n",
      "Epoch 8523, reconstruction losses: 0.025133064033195963, regression losses: 0.13606390815612912, validation losses: 0.48318793734360777\n",
      "Epoch 8524, reconstruction losses: 0.019920963984507035, regression losses: 0.10715109472628544, validation losses: 0.5495126013494226\n",
      "Epoch 8525, reconstruction losses: 0.023047836511695605, regression losses: 0.11214949981128054, validation losses: 0.5092334553362918\n",
      "Epoch 8526, reconstruction losses: 0.020343004916469832, regression losses: 0.11754347567810969, validation losses: 0.5728476089541231\n",
      "Epoch 8527, reconstruction losses: 0.022265020169023233, regression losses: 0.1218727089580683, validation losses: 0.5579457925713713\n",
      "Epoch 8528, reconstruction losses: 0.02000243250831134, regression losses: 0.11420613781399241, validation losses: 0.456990764574156\n",
      "Epoch 8529, reconstruction losses: 0.022736286734153472, regression losses: 0.13311292823853604, validation losses: 0.500820813969941\n",
      "Epoch 8530, reconstruction losses: 0.021585008105235975, regression losses: 0.1354032042107056, validation losses: 0.5208016472271222\n",
      "Epoch 8531, reconstruction losses: 0.020740125727715077, regression losses: 0.11103026662247949, validation losses: 0.4829507916698089\n",
      "Epoch 8532, reconstruction losses: 0.020375861062965645, regression losses: 0.10185981215234079, validation losses: 0.466296554653185\n",
      "Epoch 8533, reconstruction losses: 0.021222726139284446, regression losses: 0.10068570255803595, validation losses: 0.45116822745517265\n",
      "Epoch 8534, reconstruction losses: 0.024798709691255076, regression losses: 0.16115588409103848, validation losses: 0.4624342512163361\n",
      "Epoch 8535, reconstruction losses: 0.02328481752258129, regression losses: 0.1369379456333008, validation losses: 0.578901739632135\n",
      "Epoch 8536, reconstruction losses: 0.023872401867741953, regression losses: 0.11293571996240738, validation losses: 0.6579676875977786\n",
      "Epoch 8537, reconstruction losses: 0.023570022283208012, regression losses: 0.20907100851823696, validation losses: 0.44278346059779705\n",
      "Epoch 8538, reconstruction losses: 0.02307329888005788, regression losses: 0.13680094913177812, validation losses: 0.4173028081184872\n",
      "Epoch 8539, reconstruction losses: 0.019763798695897335, regression losses: 0.1128786215165877, validation losses: 0.4748720199546995\n",
      "Epoch 8540, reconstruction losses: 0.021577531535351847, regression losses: 0.1319357595731259, validation losses: 0.4268335931331967\n",
      "Epoch 8541, reconstruction losses: 0.022147221523755613, regression losses: 0.1203692061228994, validation losses: 0.4724522214732309\n",
      "Epoch 8542, reconstruction losses: 0.020365576921899338, regression losses: 0.12423040871673295, validation losses: 0.4565668605076003\n",
      "Epoch 8543, reconstruction losses: 0.020601253686603566, regression losses: 0.11081238205908073, validation losses: 0.4193877818976023\n",
      "Epoch 8544, reconstruction losses: 0.022225660877199727, regression losses: 0.14205016179763208, validation losses: 0.4055383805543013\n",
      "Epoch 8545, reconstruction losses: 0.022378208534697526, regression losses: 0.14536712789139727, validation losses: 0.401332742235899\n",
      "Epoch 8546, reconstruction losses: 0.024210372362631436, regression losses: 0.16489394873121604, validation losses: 0.48726118616127945\n",
      "Epoch 8547, reconstruction losses: 0.024802367328002294, regression losses: 0.20694084299979704, validation losses: 0.4704642992100194\n",
      "Epoch 8548, reconstruction losses: 0.02252008276685796, regression losses: 0.13119181155357276, validation losses: 0.4226676936975376\n",
      "Epoch 8549, reconstruction losses: 0.021855670458530603, regression losses: 0.13875318306716655, validation losses: 0.4266368851291777\n",
      "Epoch 8550, reconstruction losses: 0.01986771923165466, regression losses: 0.09829248826836495, validation losses: 0.45409511795594876\n",
      "Epoch 8551, reconstruction losses: 0.018942349326684857, regression losses: 0.09596758966420184, validation losses: 0.4442687901382929\n",
      "Epoch 8552, reconstruction losses: 0.019052408835922182, regression losses: 0.06844523320049853, validation losses: 0.44694249004167186\n",
      "Epoch 8553, reconstruction losses: 0.021816547327192782, regression losses: 0.09513608591532406, validation losses: 0.4686342456264831\n",
      "Epoch 8554, reconstruction losses: 0.020762607425172552, regression losses: 0.114814542011539, validation losses: 0.47508361163482027\n",
      "Epoch 8555, reconstruction losses: 0.0238778936408562, regression losses: 0.12050704670780049, validation losses: 0.4747477209739488\n",
      "Epoch 8556, reconstruction losses: 0.020253471774122934, regression losses: 0.16279980642935502, validation losses: 0.44608972728214374\n",
      "Epoch 8557, reconstruction losses: 0.02556350899955065, regression losses: 0.14820328687376255, validation losses: 0.4462699298739759\n",
      "Epoch 8558, reconstruction losses: 0.023790655119482435, regression losses: 0.1634441006609384, validation losses: 0.4751101351692336\n",
      "Epoch 8559, reconstruction losses: 0.023922338460952357, regression losses: 0.14663740016068136, validation losses: 0.4758115431518598\n",
      "Epoch 8560, reconstruction losses: 0.021551036550307563, regression losses: 0.0896832606745247, validation losses: 0.44054458332038315\n",
      "Epoch 8561, reconstruction losses: 0.01958428516807481, regression losses: 0.0925141448964947, validation losses: 0.4231791904574214\n",
      "Epoch 8562, reconstruction losses: 0.02438623873462708, regression losses: 0.14259493105319965, validation losses: 0.4300121588079038\n",
      "Epoch 8563, reconstruction losses: 0.02127626788188426, regression losses: 0.10836213514719836, validation losses: 0.4971183204941872\n",
      "Epoch 8564, reconstruction losses: 0.021545665272457805, regression losses: 0.10885518573543283, validation losses: 0.5401153589138636\n",
      "Epoch 8565, reconstruction losses: 0.02328510411103709, regression losses: 0.16155791624732502, validation losses: 0.5053164083399\n",
      "Epoch 8566, reconstruction losses: 0.020340091894010634, regression losses: 0.10085340766968538, validation losses: 0.48447895045790984\n",
      "Epoch 8567, reconstruction losses: 0.019796435100470057, regression losses: 0.08881400022954493, validation losses: 0.4531776081643043\n",
      "Epoch 8568, reconstruction losses: 0.02331415360885245, regression losses: 0.1223202951334328, validation losses: 0.44706809768688505\n",
      "Epoch 8569, reconstruction losses: 0.02226916931545924, regression losses: 0.15255196040502836, validation losses: 0.46354991717770083\n",
      "Epoch 8570, reconstruction losses: 0.02131440089001324, regression losses: 0.11904547330190614, validation losses: 0.4865194040892496\n",
      "Epoch 8571, reconstruction losses: 0.020928933526090064, regression losses: 0.18642574036196674, validation losses: 0.4566972154898177\n",
      "Epoch 8572, reconstruction losses: 0.021817029006457073, regression losses: 0.11970174988968159, validation losses: 0.4343609246109167\n",
      "Epoch 8573, reconstruction losses: 0.023465254420159384, regression losses: 0.12633956494174955, validation losses: 0.43544943797230323\n",
      "Epoch 8574, reconstruction losses: 0.023604345914387787, regression losses: 0.10149327835271918, validation losses: 0.4697502923574563\n",
      "Epoch 8575, reconstruction losses: 0.023843810030460325, regression losses: 0.09471838697177912, validation losses: 0.4805563394665457\n",
      "Epoch 8576, reconstruction losses: 0.02192809093607823, regression losses: 0.12623970871999615, validation losses: 0.4861473554946242\n",
      "Epoch 8577, reconstruction losses: 0.022104008605558965, regression losses: 0.13440878459272917, validation losses: 0.5264285566361784\n",
      "Epoch 8578, reconstruction losses: 0.02045104067720382, regression losses: 0.12764084285667132, validation losses: 0.5463219975102358\n",
      "Epoch 8579, reconstruction losses: 0.020383318094806147, regression losses: 0.11523642284217664, validation losses: 0.48637180245978034\n",
      "Epoch 8580, reconstruction losses: 0.028788881508010268, regression losses: 0.1378780626869276, validation losses: 0.4666138682458486\n",
      "Epoch 8581, reconstruction losses: 0.02252615561726718, regression losses: 0.12128710484099144, validation losses: 0.4581426411639487\n",
      "Epoch 8582, reconstruction losses: 0.019817194993617816, regression losses: 0.10244862903198879, validation losses: 0.4524013156914769\n",
      "Epoch 8583, reconstruction losses: 0.023187792920874573, regression losses: 0.12409088892043839, validation losses: 0.48436760542869345\n",
      "Epoch 8584, reconstruction losses: 0.024383349075173345, regression losses: 0.13605252266345308, validation losses: 0.48430897478873974\n",
      "Epoch 8585, reconstruction losses: 0.019420102799257242, regression losses: 0.09269326753710509, validation losses: 0.41715233593018564\n",
      "Epoch 8586, reconstruction losses: 0.02137680289664603, regression losses: 0.12312010394660183, validation losses: 0.41900795861498974\n",
      "Epoch 8587, reconstruction losses: 0.021038766110306698, regression losses: 0.11350992172809422, validation losses: 0.4966156708972151\n",
      "Epoch 8588, reconstruction losses: 0.02306550632504809, regression losses: 0.11530167679051541, validation losses: 0.5229647472450303\n",
      "Epoch 8589, reconstruction losses: 0.022868010188657452, regression losses: 0.11592354221007074, validation losses: 0.49402116221515385\n",
      "Epoch 8590, reconstruction losses: 0.020202641926338444, regression losses: 0.10051955647612593, validation losses: 0.4892901949375117\n",
      "Epoch 8591, reconstruction losses: 0.021935973239277217, regression losses: 0.10819433113057475, validation losses: 0.4500905012854622\n",
      "Epoch 8592, reconstruction losses: 0.02113287118612571, regression losses: 0.11291527409949582, validation losses: 0.42226816223234714\n",
      "Epoch 8593, reconstruction losses: 0.02270815152272845, regression losses: 0.179811987285828, validation losses: 0.47664222204338147\n",
      "Epoch 8594, reconstruction losses: 0.020911744743883166, regression losses: 0.12517892943840836, validation losses: 0.5806295792212097\n",
      "Epoch 8595, reconstruction losses: 0.02037481968288096, regression losses: 0.1229455170207586, validation losses: 0.5969780724447308\n",
      "Epoch 8596, reconstruction losses: 0.02390980238611838, regression losses: 0.11203942177606552, validation losses: 0.5802697453880062\n",
      "Epoch 8597, reconstruction losses: 0.02156870946773652, regression losses: 0.1127631760601141, validation losses: 0.5275822288697931\n",
      "Epoch 8598, reconstruction losses: 0.021054420321081877, regression losses: 0.13423740302521783, validation losses: 0.47616539176540035\n",
      "Epoch 8599, reconstruction losses: 0.024765550183211773, regression losses: 0.13832457398442471, validation losses: 0.4803380647693433\n",
      "Epoch 8600, reconstruction losses: 0.02166013269071143, regression losses: 0.12470720115959645, validation losses: 0.5403750077540918\n",
      "Epoch 8601, reconstruction losses: 0.02072758327607277, regression losses: 0.12728504784215583, validation losses: 0.5107013686104038\n",
      "Epoch 8602, reconstruction losses: 0.0210705792761589, regression losses: 0.11325369882534371, validation losses: 0.46365027484194243\n",
      "Epoch 8603, reconstruction losses: 0.019449474980257838, regression losses: 0.10043666603471735, validation losses: 0.4981554333617986\n",
      "Epoch 8604, reconstruction losses: 0.02010137922789545, regression losses: 0.13131021565731346, validation losses: 0.47161426427899866\n",
      "Epoch 8605, reconstruction losses: 0.024145556080777297, regression losses: 0.18898649955480473, validation losses: 0.44804835763608525\n",
      "Epoch 8606, reconstruction losses: 0.023505596475501614, regression losses: 0.13568856538922602, validation losses: 0.589175108224519\n",
      "Epoch 8607, reconstruction losses: 0.024238773030868785, regression losses: 0.12914933657976346, validation losses: 0.5654468904048792\n",
      "Epoch 8608, reconstruction losses: 0.022151821723342156, regression losses: 0.09042522141814631, validation losses: 0.46442734675517977\n",
      "Epoch 8609, reconstruction losses: 0.02192139279303516, regression losses: 0.1375029092642572, validation losses: 0.4423718447244817\n",
      "Epoch 8610, reconstruction losses: 0.021811287065844724, regression losses: 0.1340424035854054, validation losses: 0.4417826330516875\n",
      "Epoch 8611, reconstruction losses: 0.020884529489183325, regression losses: 0.11268352323339653, validation losses: 0.4160672332240829\n",
      "Epoch 8612, reconstruction losses: 0.020054866713428304, regression losses: 0.13883094920295908, validation losses: 0.43113909188632726\n",
      "Epoch 8613, reconstruction losses: 0.023464814221139507, regression losses: 0.12584308628976887, validation losses: 0.5033867271246771\n",
      "Epoch 8614, reconstruction losses: 0.01955127955641919, regression losses: 0.10458492484841364, validation losses: 0.5780492728609548\n",
      "Epoch 8615, reconstruction losses: 0.021238852700409268, regression losses: 0.15241536611487058, validation losses: 0.5307279463210596\n",
      "Epoch 8616, reconstruction losses: 0.023183735956300404, regression losses: 0.10299120221436325, validation losses: 0.4406058838393916\n",
      "Epoch 8617, reconstruction losses: 0.024513536676413674, regression losses: 0.12163283775297634, validation losses: 0.4163314776257493\n",
      "Epoch 8618, reconstruction losses: 0.02188616540126924, regression losses: 0.13264764482480132, validation losses: 0.4822430905743532\n",
      "Epoch 8619, reconstruction losses: 0.02275430876210701, regression losses: 0.12283442375067309, validation losses: 0.47099792364054166\n",
      "Epoch 8620, reconstruction losses: 0.01992615612867778, regression losses: 0.1336803194776716, validation losses: 0.48397489852585807\n",
      "Epoch 8621, reconstruction losses: 0.0205251053695082, regression losses: 0.13764883923433932, validation losses: 0.4747444671984146\n",
      "Epoch 8622, reconstruction losses: 0.02340462592195556, regression losses: 0.11351472452445772, validation losses: 0.42942687556249304\n",
      "Epoch 8623, reconstruction losses: 0.02361827198221459, regression losses: 0.11309822413476794, validation losses: 0.4438351218530628\n",
      "Epoch 8624, reconstruction losses: 0.019963318016783346, regression losses: 0.1115671549413547, validation losses: 0.4673687767785753\n",
      "Epoch 8625, reconstruction losses: 0.019048698942027393, regression losses: 0.12139378639557535, validation losses: 0.4803772123339083\n",
      "Epoch 8626, reconstruction losses: 0.024760307937290435, regression losses: 0.36627169145403243, validation losses: 0.4679876944628977\n",
      "Epoch 8627, reconstruction losses: 0.020147187243808224, regression losses: 0.13505157878683668, validation losses: 0.6169873851234353\n",
      "Epoch 8628, reconstruction losses: 0.01908510763459757, regression losses: 0.13592971802718987, validation losses: 0.5520239417364909\n",
      "Epoch 8629, reconstruction losses: 0.021074660233451205, regression losses: 0.12017794294379841, validation losses: 0.5228760909254476\n",
      "Epoch 8630, reconstruction losses: 0.02338858134745032, regression losses: 0.09286363897340294, validation losses: 0.44903130696606924\n",
      "Epoch 8631, reconstruction losses: 0.02139857010628603, regression losses: 0.11104417975862818, validation losses: 0.44014597407393197\n",
      "Epoch 8632, reconstruction losses: 0.023270736565371958, regression losses: 0.10665579910095738, validation losses: 0.45007518953509307\n",
      "Epoch 8633, reconstruction losses: 0.022964014431519904, regression losses: 0.09365069699790933, validation losses: 0.47372835646687006\n",
      "Epoch 8634, reconstruction losses: 0.026360765018467618, regression losses: 0.12227953955290011, validation losses: 0.5117327623667262\n",
      "Epoch 8635, reconstruction losses: 0.021119780558509684, regression losses: 0.14455125043170441, validation losses: 0.45227819169894956\n",
      "Epoch 8636, reconstruction losses: 0.01927125791933047, regression losses: 0.0857715695619369, validation losses: 0.46310526826382287\n",
      "Epoch 8637, reconstruction losses: 0.02256535553365904, regression losses: 0.11489647754213282, validation losses: 0.495016282082937\n",
      "Epoch 8638, reconstruction losses: 0.024845263592096673, regression losses: 0.14207422761583366, validation losses: 0.512925684979565\n",
      "Epoch 8639, reconstruction losses: 0.01926746561689634, regression losses: 0.12787776884788268, validation losses: 0.4459803376187832\n",
      "Epoch 8640, reconstruction losses: 0.020257098495080797, regression losses: 0.08139789132663093, validation losses: 0.44189326908581505\n",
      "Epoch 8641, reconstruction losses: 0.020688629699753283, regression losses: 0.09963291608216668, validation losses: 0.47833508040558553\n",
      "Epoch 8642, reconstruction losses: 0.022484192435330345, regression losses: 0.07462542582487794, validation losses: 0.4827425062790239\n",
      "Epoch 8643, reconstruction losses: 0.020559633759496047, regression losses: 0.12351746815545654, validation losses: 0.4643649695894974\n",
      "Epoch 8644, reconstruction losses: 0.02111593359267477, regression losses: 0.10692559963567655, validation losses: 0.45984385269904227\n",
      "Epoch 8645, reconstruction losses: 0.020898275308838747, regression losses: 0.10712991933244928, validation losses: 0.5300840545424343\n",
      "Epoch 8646, reconstruction losses: 0.022819553959327176, regression losses: 0.1280162003784532, validation losses: 0.49870212690841015\n",
      "Epoch 8647, reconstruction losses: 0.023574715794119665, regression losses: 0.3894234624236817, validation losses: 0.44102850943327115\n",
      "Epoch 8648, reconstruction losses: 0.023242846634490943, regression losses: 0.14158809113412402, validation losses: 0.660489839846266\n",
      "Epoch 8649, reconstruction losses: 0.024599758275671207, regression losses: 0.15036525754441296, validation losses: 0.5428720330286276\n",
      "Epoch 8650, reconstruction losses: 0.023728023922096803, regression losses: 0.09723927016730832, validation losses: 0.5289852938891533\n",
      "Epoch 8651, reconstruction losses: 0.020819142008992986, regression losses: 0.11664816368106985, validation losses: 0.526752140955177\n",
      "Epoch 8652, reconstruction losses: 0.021837972520793034, regression losses: 0.12168658681289268, validation losses: 0.445690064525077\n",
      "Epoch 8653, reconstruction losses: 0.02321261893054047, regression losses: 0.19284651022860652, validation losses: 0.43344489377961326\n",
      "Epoch 8654, reconstruction losses: 0.02082333686320129, regression losses: 0.08624126094638783, validation losses: 0.4688642223049835\n",
      "Epoch 8655, reconstruction losses: 0.02132369033764373, regression losses: 0.12150806952400041, validation losses: 0.48968610733667195\n",
      "Epoch 8656, reconstruction losses: 0.022401293833348955, regression losses: 0.09591448020871217, validation losses: 0.495723634767844\n",
      "Epoch 8657, reconstruction losses: 0.01953902551207011, regression losses: 0.090459496105793, validation losses: 0.4119375222636343\n",
      "Epoch 8658, reconstruction losses: 0.0203233986890308, regression losses: 0.12636261207806251, validation losses: 0.40367656734701385\n",
      "Epoch 8659, reconstruction losses: 0.020002345808039678, regression losses: 0.0984433658506006, validation losses: 0.43302204835711366\n",
      "Epoch 8660, reconstruction losses: 0.021437095101737507, regression losses: 0.10774877483655376, validation losses: 0.4973449097976987\n",
      "Epoch 8661, reconstruction losses: 0.022212903647210642, regression losses: 0.12478823836497668, validation losses: 0.5486143347957795\n",
      "Epoch 8662, reconstruction losses: 0.02188654093650461, regression losses: 0.10292067689291227, validation losses: 0.5000560420517738\n",
      "Epoch 8663, reconstruction losses: 0.02372289713895504, regression losses: 0.1077145940760098, validation losses: 0.43867962938757965\n",
      "Epoch 8664, reconstruction losses: 0.024497486413279375, regression losses: 0.10828092733728711, validation losses: 0.42358590963765064\n",
      "Epoch 8665, reconstruction losses: 0.021725755727394006, regression losses: 0.10592416984171522, validation losses: 0.46485673852462994\n",
      "Epoch 8666, reconstruction losses: 0.022916922865931156, regression losses: 0.11135842769921724, validation losses: 0.44301659216167366\n",
      "Epoch 8667, reconstruction losses: 0.01921858803925759, regression losses: 0.10969956747370888, validation losses: 0.4150508021063684\n",
      "Epoch 8668, reconstruction losses: 0.022254488028818617, regression losses: 0.15278191727174717, validation losses: 0.409882358060241\n",
      "Epoch 8669, reconstruction losses: 0.022702184390146596, regression losses: 0.12596357286444382, validation losses: 0.46274253652940733\n",
      "Epoch 8670, reconstruction losses: 0.02453447519167572, regression losses: 0.10907491082145802, validation losses: 0.42904729787592144\n",
      "Epoch 8671, reconstruction losses: 0.020814239249738374, regression losses: 0.12255187796911561, validation losses: 0.47370035821860557\n",
      "Epoch 8672, reconstruction losses: 0.02514323233566759, regression losses: 0.13066130632630807, validation losses: 0.42253367491664195\n",
      "Epoch 8673, reconstruction losses: 0.02400192129831932, regression losses: 0.17342016065030877, validation losses: 0.4232523258518923\n",
      "Epoch 8674, reconstruction losses: 0.020929260151172892, regression losses: 0.11270651886168657, validation losses: 0.647850224715942\n",
      "Epoch 8675, reconstruction losses: 0.021146206970697058, regression losses: 0.12267343258243829, validation losses: 0.5603139923290383\n",
      "Epoch 8676, reconstruction losses: 0.023743690036858098, regression losses: 0.12500888386584758, validation losses: 0.477666468345365\n",
      "Epoch 8677, reconstruction losses: 0.02091952549422571, regression losses: 0.1099833355811838, validation losses: 0.535060317228952\n",
      "Epoch 8678, reconstruction losses: 0.024707498531052925, regression losses: 0.14449372121709791, validation losses: 0.45526571142091965\n",
      "Epoch 8679, reconstruction losses: 0.021403173542364887, regression losses: 0.12687757771061184, validation losses: 0.4446093237691989\n",
      "Epoch 8680, reconstruction losses: 0.019972597937623137, regression losses: 0.13891077595590207, validation losses: 0.488824191122004\n",
      "Epoch 8681, reconstruction losses: 0.02164828545199979, regression losses: 0.12426800711463798, validation losses: 0.4824496866341478\n",
      "Epoch 8682, reconstruction losses: 0.02078140718268725, regression losses: 0.10725988447581611, validation losses: 0.47782256824054353\n",
      "Epoch 8683, reconstruction losses: 0.024431937361101785, regression losses: 0.17433970751738032, validation losses: 0.47266723234523406\n",
      "Epoch 8684, reconstruction losses: 0.021487981348227568, regression losses: 0.10246147628691771, validation losses: 0.45481144230699255\n",
      "Epoch 8685, reconstruction losses: 0.021475123567110007, regression losses: 0.09005001219571913, validation losses: 0.4596847869122028\n",
      "Epoch 8686, reconstruction losses: 0.022254043578431564, regression losses: 0.09343041018659133, validation losses: 0.4596208590494062\n",
      "Epoch 8687, reconstruction losses: 0.02096750132572612, regression losses: 0.1030488321914876, validation losses: 0.4765624296664003\n",
      "Epoch 8688, reconstruction losses: 0.022348575060919463, regression losses: 0.1468593608936916, validation losses: 0.47479527290143253\n",
      "Epoch 8689, reconstruction losses: 0.023471541024220305, regression losses: 0.1368948788613568, validation losses: 0.47445745902159253\n",
      "Epoch 8690, reconstruction losses: 0.018820892252073996, regression losses: 0.10228345052605248, validation losses: 0.47467792420111454\n",
      "Epoch 8691, reconstruction losses: 0.020046986696447642, regression losses: 0.08122105365033949, validation losses: 0.43534887643922454\n",
      "Epoch 8692, reconstruction losses: 0.024865448010384282, regression losses: 0.13224401685723483, validation losses: 0.40721258983115555\n",
      "Epoch 8693, reconstruction losses: 0.021339853663170972, regression losses: 0.13533113187074516, validation losses: 0.3976601527172193\n",
      "Epoch 8694, reconstruction losses: 0.025355878224716497, regression losses: 0.10914229117157931, validation losses: 0.42993885390092956\n",
      "Epoch 8695, reconstruction losses: 0.018296130291089275, regression losses: 0.104513886070756, validation losses: 0.4805902521792166\n",
      "Epoch 8696, reconstruction losses: 0.02908714078595335, regression losses: 0.5703727171585597, validation losses: 0.4859613584675526\n",
      "Epoch 8697, reconstruction losses: 0.023789890015915756, regression losses: 0.11482006844681689, validation losses: 0.9232877264066159\n",
      "Epoch 8698, reconstruction losses: 0.02045510527875221, regression losses: 0.17804563184335898, validation losses: 0.9291036469432286\n",
      "Epoch 8699, reconstruction losses: 0.02077166765695124, regression losses: 0.1619546746248447, validation losses: 0.6174937033047628\n",
      "Epoch 8700, reconstruction losses: 0.019997969429365166, regression losses: 0.11870828335435159, validation losses: 0.44739228965831734\n",
      "Epoch 8701, reconstruction losses: 0.0238558009060611, regression losses: 0.1421535937546199, validation losses: 0.43382359988269137\n",
      "Epoch 8702, reconstruction losses: 0.021662931357012947, regression losses: 0.11112826278410148, validation losses: 0.49104863777405217\n",
      "Epoch 8703, reconstruction losses: 0.022219852568459663, regression losses: 0.11925493195407208, validation losses: 0.45892154011175823\n",
      "Epoch 8704, reconstruction losses: 0.021049189290776295, regression losses: 0.11505136943695055, validation losses: 0.41186393345642336\n",
      "Epoch 8705, reconstruction losses: 0.023148461868204212, regression losses: 0.1896599914796152, validation losses: 0.43045355369763805\n",
      "Epoch 8706, reconstruction losses: 0.020342553288312856, regression losses: 0.11528954681165156, validation losses: 0.5018269085737119\n",
      "Epoch 8707, reconstruction losses: 0.02178173742655978, regression losses: 0.1180099727306447, validation losses: 0.48610322785756876\n",
      "Epoch 8708, reconstruction losses: 0.020845634096857146, regression losses: 0.13552325158544576, validation losses: 0.42247648928643233\n",
      "Epoch 8709, reconstruction losses: 0.019755572533122774, regression losses: 0.11334993707503205, validation losses: 0.4467612037956432\n",
      "Epoch 8710, reconstruction losses: 0.023424780946617787, regression losses: 0.09528910352055285, validation losses: 0.42433870139423613\n",
      "Epoch 8711, reconstruction losses: 0.023220846601767115, regression losses: 0.1067394908014686, validation losses: 0.45509713017089815\n",
      "Epoch 8712, reconstruction losses: 0.020452561690711857, regression losses: 0.09999701390513248, validation losses: 0.5132765033906255\n",
      "Epoch 8713, reconstruction losses: 0.022987260321218634, regression losses: 0.12605654230850566, validation losses: 0.5532245845358101\n",
      "Epoch 8714, reconstruction losses: 0.029678274280205322, regression losses: 0.17694442824371864, validation losses: 0.49820902310394705\n",
      "Epoch 8715, reconstruction losses: 0.022783456500240534, regression losses: 0.4180346518844346, validation losses: 0.5441245520149188\n",
      "Epoch 8716, reconstruction losses: 0.02340311080768613, regression losses: 0.21356749414319504, validation losses: 0.7020028138674994\n",
      "Epoch 8717, reconstruction losses: 0.024414798012390437, regression losses: 0.18600079564355054, validation losses: 1.107576582914305\n",
      "Epoch 8718, reconstruction losses: 0.02030737173074285, regression losses: 0.16134634524754732, validation losses: 0.8721979858416946\n",
      "Epoch 8719, reconstruction losses: 0.024791802358181597, regression losses: 0.17296070456251927, validation losses: 0.6990970989998984\n",
      "Epoch 8720, reconstruction losses: 0.01815609388892407, regression losses: 0.08068116732614096, validation losses: 0.5761232468824635\n",
      "Epoch 8721, reconstruction losses: 0.023689101450794843, regression losses: 0.14509658130872738, validation losses: 0.4765950443444843\n",
      "Epoch 8722, reconstruction losses: 0.021054704615940785, regression losses: 0.11470061468550502, validation losses: 0.5107390325727484\n",
      "Epoch 8723, reconstruction losses: 0.024598827576350783, regression losses: 0.10650870583494493, validation losses: 0.5860731468283833\n",
      "Epoch 8724, reconstruction losses: 0.02306809645005473, regression losses: 0.1200738561134169, validation losses: 0.6198589836510534\n",
      "Epoch 8725, reconstruction losses: 0.02510082855201107, regression losses: 0.13187484829454627, validation losses: 0.6167847252510767\n",
      "Epoch 8726, reconstruction losses: 0.021637086959162603, regression losses: 0.16371277397011197, validation losses: 0.5434333223428954\n",
      "Epoch 8727, reconstruction losses: 0.02266851501075257, regression losses: 0.124272909712241, validation losses: 0.5218129610972744\n",
      "Epoch 8728, reconstruction losses: 0.02403426976948348, regression losses: 0.10301917489399753, validation losses: 0.4508957881934821\n",
      "Epoch 8729, reconstruction losses: 0.019865803407975068, regression losses: 0.0845518570147101, validation losses: 0.44801292146498645\n",
      "Epoch 8730, reconstruction losses: 0.022316268180273074, regression losses: 0.12285535683591817, validation losses: 0.4848019213192799\n",
      "Epoch 8731, reconstruction losses: 0.022827974344439745, regression losses: 0.14100149832371164, validation losses: 0.5441248142111758\n",
      "Epoch 8732, reconstruction losses: 0.019873215531135045, regression losses: 0.10253291601642885, validation losses: 0.5374322171403757\n",
      "Epoch 8733, reconstruction losses: 0.021260035769370283, regression losses: 0.1038529276613202, validation losses: 0.43547403913230165\n",
      "Epoch 8734, reconstruction losses: 0.02517791118928294, regression losses: 0.149434429529446, validation losses: 0.42445120056014424\n",
      "Epoch 8735, reconstruction losses: 0.022094242463209277, regression losses: 0.0922863373129443, validation losses: 0.5024499117837941\n",
      "Epoch 8736, reconstruction losses: 0.02174212887178817, regression losses: 0.08078318097182127, validation losses: 0.5395923658050882\n",
      "Epoch 8737, reconstruction losses: 0.024544874984361066, regression losses: 0.15220494230977327, validation losses: 0.4952869039109544\n",
      "Epoch 8738, reconstruction losses: 0.01872674309203945, regression losses: 0.09995881553147312, validation losses: 0.49710395662789897\n",
      "Epoch 8739, reconstruction losses: 0.022211402696898544, regression losses: 0.15946762147444205, validation losses: 0.4366354683859099\n",
      "Epoch 8740, reconstruction losses: 0.023147546070966696, regression losses: 0.0949757919025279, validation losses: 0.42079702643951267\n",
      "Epoch 8741, reconstruction losses: 0.02153761207803324, regression losses: 0.13424815462303127, validation losses: 0.4289309740428531\n",
      "Epoch 8742, reconstruction losses: 0.021935926425127546, regression losses: 0.1474477124327627, validation losses: 0.5083242353789634\n",
      "Epoch 8743, reconstruction losses: 0.021084536025924912, regression losses: 0.11111454778030978, validation losses: 0.5188433864163707\n",
      "Epoch 8744, reconstruction losses: 0.02193500134076245, regression losses: 0.12186699670073768, validation losses: 0.45711054562335485\n",
      "Epoch 8745, reconstruction losses: 0.02191109738104858, regression losses: 0.11361910139511747, validation losses: 0.4384158770071828\n",
      "Epoch 8746, reconstruction losses: 0.02366103527339629, regression losses: 0.27703181669086047, validation losses: 0.46905366705319723\n",
      "Epoch 8747, reconstruction losses: 0.027618904842225175, regression losses: 0.3762273302649922, validation losses: 0.6033597678748623\n",
      "Epoch 8748, reconstruction losses: 0.020489107422809554, regression losses: 0.14519069815927188, validation losses: 0.726698481797273\n",
      "Epoch 8749, reconstruction losses: 0.025114924220783517, regression losses: 0.20942044240949625, validation losses: 0.9176205568324322\n",
      "Epoch 8750, reconstruction losses: 0.026822139220559173, regression losses: 0.18410226606830488, validation losses: 0.7480903724242174\n",
      "Epoch 8751, reconstruction losses: 0.024169677921227997, regression losses: 0.15465260546333087, validation losses: 0.5964782603903195\n",
      "Epoch 8752, reconstruction losses: 0.02135984640690184, regression losses: 0.1303327935574755, validation losses: 0.5305103380149094\n",
      "Epoch 8753, reconstruction losses: 0.021541215230999954, regression losses: 0.12408689902269134, validation losses: 0.401458493040951\n",
      "Epoch 8754, reconstruction losses: 0.021008953305308706, regression losses: 0.09316681015067939, validation losses: 0.4114011913102465\n",
      "Epoch 8755, reconstruction losses: 0.019465169301700024, regression losses: 0.13488861729688265, validation losses: 0.48348210871104497\n",
      "Epoch 8756, reconstruction losses: 0.019667308258189027, regression losses: 0.10736060433791837, validation losses: 0.4865973065762354\n",
      "Epoch 8757, reconstruction losses: 0.022688795707525352, regression losses: 0.12356630246590641, validation losses: 0.44661197943294695\n",
      "Epoch 8758, reconstruction losses: 0.02353064311045346, regression losses: 0.13130094761496314, validation losses: 0.4274575685148711\n",
      "Epoch 8759, reconstruction losses: 0.022901686827282188, regression losses: 0.14832412985103047, validation losses: 0.48513479153257894\n",
      "Epoch 8760, reconstruction losses: 0.02151781270957981, regression losses: 0.14377205671800877, validation losses: 0.48027135263465126\n",
      "Epoch 8761, reconstruction losses: 0.01992542169236903, regression losses: 0.08534268205547528, validation losses: 0.46141758651967835\n",
      "Epoch 8762, reconstruction losses: 0.020677766321905145, regression losses: 0.10697775485280077, validation losses: 0.43694470481143066\n",
      "Epoch 8763, reconstruction losses: 0.020562209809848332, regression losses: 0.09888452930708216, validation losses: 0.43286426412898055\n",
      "Epoch 8764, reconstruction losses: 0.020529172601317, regression losses: 0.09084257905430014, validation losses: 0.4340715507656767\n",
      "Epoch 8765, reconstruction losses: 0.021149761053416163, regression losses: 0.12248266571712928, validation losses: 0.43404611144139826\n",
      "Epoch 8766, reconstruction losses: 0.02176015481380731, regression losses: 0.09924149525459444, validation losses: 0.4655678781261514\n",
      "Epoch 8767, reconstruction losses: 0.020267412462034562, regression losses: 0.08899723336535077, validation losses: 0.4752578270695539\n",
      "Epoch 8768, reconstruction losses: 0.0178633034369376, regression losses: 0.10391512614944756, validation losses: 0.4551835823675843\n",
      "Epoch 8769, reconstruction losses: 0.02024377439220442, regression losses: 0.12163334153971883, validation losses: 0.44745293841693967\n",
      "Epoch 8770, reconstruction losses: 0.0238668932159613, regression losses: 0.12113444952116356, validation losses: 0.41887148835111393\n",
      "Epoch 8771, reconstruction losses: 0.022207805681561783, regression losses: 0.12512654703465226, validation losses: 0.4140146738942797\n",
      "Epoch 8772, reconstruction losses: 0.022983045898873716, regression losses: 0.0961119651863503, validation losses: 0.4367448250505298\n",
      "Epoch 8773, reconstruction losses: 0.02536772918877582, regression losses: 0.1382456367069786, validation losses: 0.44174862879083887\n",
      "Epoch 8774, reconstruction losses: 0.01983183624913508, regression losses: 0.09536020736567567, validation losses: 0.4698765250016545\n",
      "Epoch 8775, reconstruction losses: 0.023332990701043728, regression losses: 0.16390098431291716, validation losses: 0.4389253380027369\n",
      "Epoch 8776, reconstruction losses: 0.022652032012587565, regression losses: 0.1056887738213774, validation losses: 0.5155925933843118\n",
      "Epoch 8777, reconstruction losses: 0.022134787494808027, regression losses: 0.1495432933420095, validation losses: 0.5152175650612575\n",
      "Epoch 8778, reconstruction losses: 0.022974972110024087, regression losses: 0.13550920000427277, validation losses: 0.538449933549584\n",
      "Epoch 8779, reconstruction losses: 0.021220029774927096, regression losses: 0.1334325922952867, validation losses: 0.5373737575547315\n",
      "Epoch 8780, reconstruction losses: 0.019281679316494976, regression losses: 0.09797900917892924, validation losses: 0.41985094811888707\n",
      "Epoch 8781, reconstruction losses: 0.022394945537642586, regression losses: 0.15630681238882735, validation losses: 0.4375217728134778\n",
      "Epoch 8782, reconstruction losses: 0.021884217185257213, regression losses: 0.09904799787693136, validation losses: 0.5910035384185137\n",
      "Epoch 8783, reconstruction losses: 0.02056365987509304, regression losses: 0.11290180732088695, validation losses: 0.5870948582520474\n",
      "Epoch 8784, reconstruction losses: 0.020939794502126633, regression losses: 0.11978589003320705, validation losses: 0.48160303019383355\n",
      "Epoch 8785, reconstruction losses: 0.02027769217942324, regression losses: 0.09606508041495221, validation losses: 0.4245474208623401\n",
      "Epoch 8786, reconstruction losses: 0.020423570238758904, regression losses: 0.1048172173417131, validation losses: 0.4213316415546865\n",
      "Epoch 8787, reconstruction losses: 0.020615679416446774, regression losses: 0.12282301439699118, validation losses: 0.43120846724348083\n",
      "Epoch 8788, reconstruction losses: 0.019805177678258894, regression losses: 0.13799889492721445, validation losses: 0.46533659575427233\n",
      "Epoch 8789, reconstruction losses: 0.02122818486122495, regression losses: 0.08904802300706714, validation losses: 0.4922945263371449\n",
      "Epoch 8790, reconstruction losses: 0.022852348473054996, regression losses: 0.10505614692872516, validation losses: 0.4687594950163996\n",
      "Epoch 8791, reconstruction losses: 0.02165690659129492, regression losses: 0.11657810186023067, validation losses: 0.4493260802379129\n",
      "Epoch 8792, reconstruction losses: 0.021883405592241317, regression losses: 0.11442547013310211, validation losses: 0.4423638546008851\n",
      "Epoch 8793, reconstruction losses: 0.01886662766294067, regression losses: 0.10427683261936756, validation losses: 0.43995259530091424\n",
      "Epoch 8794, reconstruction losses: 0.021636940554575282, regression losses: 0.1108594899162626, validation losses: 0.5105193349701538\n",
      "Epoch 8795, reconstruction losses: 0.020249643704038842, regression losses: 0.10242876014961379, validation losses: 0.4507606239704854\n",
      "Epoch 8796, reconstruction losses: 0.02305906465395703, regression losses: 0.08433508027709753, validation losses: 0.4391781623847242\n",
      "Epoch 8797, reconstruction losses: 0.019850095244509303, regression losses: 0.09772264048005973, validation losses: 0.43967981784080334\n",
      "Epoch 8798, reconstruction losses: 0.022339481554953786, regression losses: 0.12967790129767848, validation losses: 0.4243086655231347\n",
      "Epoch 8799, reconstruction losses: 0.020647572652884253, regression losses: 0.10410070198691349, validation losses: 0.4519734700962578\n",
      "Epoch 8800, reconstruction losses: 0.02437269440453177, regression losses: 0.11709403158734386, validation losses: 0.44854860292754606\n",
      "Epoch 8801, reconstruction losses: 0.02196491020321842, regression losses: 0.1253018026013597, validation losses: 0.43209885663484315\n",
      "Epoch 8802, reconstruction losses: 0.020845826311660785, regression losses: 0.12274377994711123, validation losses: 0.43576671748833196\n",
      "Epoch 8803, reconstruction losses: 0.018978813511710636, regression losses: 0.0936588151735194, validation losses: 0.4697839026016163\n",
      "Epoch 8804, reconstruction losses: 0.023217705645156607, regression losses: 0.17182819409634487, validation losses: 0.4798239171096278\n",
      "Epoch 8805, reconstruction losses: 0.019848419912111337, regression losses: 0.10184571808009361, validation losses: 0.4747594486916606\n",
      "Epoch 8806, reconstruction losses: 0.024613118152390707, regression losses: 0.16948539095809267, validation losses: 0.4299904878244181\n",
      "Epoch 8807, reconstruction losses: 0.020838083602840562, regression losses: 0.09264933440770971, validation losses: 0.491912893209519\n",
      "Epoch 8808, reconstruction losses: 0.02137354067528099, regression losses: 0.1208806593492839, validation losses: 0.4960443388711616\n",
      "Epoch 8809, reconstruction losses: 0.02141949765687888, regression losses: 0.10753411910893612, validation losses: 0.4499924828138287\n",
      "Epoch 8810, reconstruction losses: 0.020618361328438077, regression losses: 0.11468480275844166, validation losses: 0.45973965825798974\n",
      "Epoch 8811, reconstruction losses: 0.0192316324228108, regression losses: 0.09045284005934542, validation losses: 0.5167875339101555\n",
      "Epoch 8812, reconstruction losses: 0.01974602379719738, regression losses: 0.0981466828138153, validation losses: 0.5010918856163847\n",
      "Epoch 8813, reconstruction losses: 0.021166188646119872, regression losses: 0.09190120852385368, validation losses: 0.44918685698413163\n",
      "Epoch 8814, reconstruction losses: 0.022604128899897907, regression losses: 0.1584379257359951, validation losses: 0.4271553178796247\n",
      "Epoch 8815, reconstruction losses: 0.021467717912217923, regression losses: 0.1128745179354029, validation losses: 0.44092453790688\n",
      "Epoch 8816, reconstruction losses: 0.02164540911934676, regression losses: 0.0910040273343534, validation losses: 0.4716109991233609\n",
      "Epoch 8817, reconstruction losses: 0.022236964792946002, regression losses: 0.1052910239424852, validation losses: 0.4707818412796615\n",
      "Epoch 8818, reconstruction losses: 0.020340970481622093, regression losses: 0.11544682766930907, validation losses: 0.5279437649496536\n",
      "Epoch 8819, reconstruction losses: 0.0189025880185215, regression losses: 0.08468630648991772, validation losses: 0.5300470255214826\n",
      "Epoch 8820, reconstruction losses: 0.02050359182341181, regression losses: 0.12630279281139484, validation losses: 0.43397485425026716\n",
      "Epoch 8821, reconstruction losses: 0.021119463399389367, regression losses: 0.13415929840746912, validation losses: 0.422326228390742\n",
      "Epoch 8822, reconstruction losses: 0.02091244588924731, regression losses: 0.10967913241208609, validation losses: 0.4354798275190741\n",
      "Epoch 8823, reconstruction losses: 0.02305339251501897, regression losses: 0.20294441493709328, validation losses: 0.4108311509247897\n",
      "Epoch 8824, reconstruction losses: 0.02274292577357258, regression losses: 0.15575611670858686, validation losses: 0.48842908599098306\n",
      "Epoch 8825, reconstruction losses: 0.021609323956624692, regression losses: 0.10739861687477881, validation losses: 0.4259591465057923\n",
      "Epoch 8826, reconstruction losses: 0.020786202520826733, regression losses: 0.12506848476064678, validation losses: 0.4961319001367192\n",
      "Epoch 8827, reconstruction losses: 0.020646025151872884, regression losses: 0.1339523433981856, validation losses: 0.4923675008018993\n",
      "Epoch 8828, reconstruction losses: 0.023672477012612193, regression losses: 0.11832497270887748, validation losses: 0.5340587676336335\n",
      "Epoch 8829, reconstruction losses: 0.023499426130970655, regression losses: 0.10957286537719316, validation losses: 0.48561107105349616\n",
      "Epoch 8830, reconstruction losses: 0.024047436618551542, regression losses: 0.13800060238074918, validation losses: 0.44079554823200895\n",
      "Epoch 8831, reconstruction losses: 0.02273963020257519, regression losses: 0.10785313279403612, validation losses: 0.45259802270870614\n",
      "Epoch 8832, reconstruction losses: 0.02092973635004288, regression losses: 0.10963141639402504, validation losses: 0.42688010513491204\n",
      "Epoch 8833, reconstruction losses: 0.02308040558623214, regression losses: 0.14990661036047653, validation losses: 0.46809817284280564\n",
      "Epoch 8834, reconstruction losses: 0.020916994138167652, regression losses: 0.09259747542794382, validation losses: 0.6246362808473471\n",
      "Epoch 8835, reconstruction losses: 0.02099263216062409, regression losses: 0.10607623075531138, validation losses: 0.5470628250539606\n",
      "Epoch 8836, reconstruction losses: 0.019575088972846485, regression losses: 0.08561316395113774, validation losses: 0.4567395973097455\n",
      "Epoch 8837, reconstruction losses: 0.022914350066833684, regression losses: 0.10489701054973087, validation losses: 0.44237365255912847\n",
      "Epoch 8838, reconstruction losses: 0.023400650559824515, regression losses: 0.23836458400854688, validation losses: 0.4182393983176323\n",
      "Epoch 8839, reconstruction losses: 0.020465961432586378, regression losses: 0.09997327478955238, validation losses: 0.6365362663961054\n",
      "Epoch 8840, reconstruction losses: 0.02019155918985531, regression losses: 0.12593871111673027, validation losses: 0.6246734953067385\n",
      "Epoch 8841, reconstruction losses: 0.020611226048951017, regression losses: 0.14273934113867906, validation losses: 0.5225885386816799\n",
      "Epoch 8842, reconstruction losses: 0.018925199356062804, regression losses: 0.09840393134027191, validation losses: 0.57444607916593\n",
      "Epoch 8843, reconstruction losses: 0.021861790543026463, regression losses: 0.11879077031829209, validation losses: 0.537019187271244\n",
      "Epoch 8844, reconstruction losses: 0.019223700889477814, regression losses: 0.11942614169811723, validation losses: 0.48527721293249876\n",
      "Epoch 8845, reconstruction losses: 0.021059396492273723, regression losses: 0.1081900862028583, validation losses: 0.45776277566394874\n",
      "Epoch 8846, reconstruction losses: 0.022588210802789964, regression losses: 0.11388252323843008, validation losses: 0.44960978093357645\n",
      "Epoch 8847, reconstruction losses: 0.02124299113612287, regression losses: 0.08663549419769209, validation losses: 0.4546823971253468\n",
      "Epoch 8848, reconstruction losses: 0.01954312626332206, regression losses: 0.09019422178660372, validation losses: 0.47040785173435606\n",
      "Epoch 8849, reconstruction losses: 0.022438086181863, regression losses: 0.1192755717394419, validation losses: 0.46550700203717793\n",
      "Epoch 8850, reconstruction losses: 0.021975013239913528, regression losses: 0.0935454807938581, validation losses: 0.44709542158162774\n",
      "Epoch 8851, reconstruction losses: 0.020984268687037018, regression losses: 0.11362631979619146, validation losses: 0.44781849944865393\n",
      "Epoch 8852, reconstruction losses: 0.020309448934896605, regression losses: 0.0989443376236908, validation losses: 0.47880917558767644\n",
      "Epoch 8853, reconstruction losses: 0.022341175341425906, regression losses: 0.09918272451474189, validation losses: 0.43917702828417254\n",
      "Epoch 8854, reconstruction losses: 0.02176883442212761, regression losses: 0.09180644401646985, validation losses: 0.4209284908319478\n",
      "Epoch 8855, reconstruction losses: 0.022341617225834914, regression losses: 0.16306168511651611, validation losses: 0.43628726140932866\n",
      "Epoch 8856, reconstruction losses: 0.022571101779129597, regression losses: 0.07219326473486729, validation losses: 0.5156575716886691\n",
      "Epoch 8857, reconstruction losses: 0.02147854927741176, regression losses: 0.12730662179950392, validation losses: 0.4861360390650815\n",
      "Epoch 8858, reconstruction losses: 0.020410951192703152, regression losses: 0.14425464339450633, validation losses: 0.43065353622313574\n",
      "Epoch 8859, reconstruction losses: 0.020970032036577615, regression losses: 0.1049463414401462, validation losses: 0.4732831932135756\n",
      "Epoch 8860, reconstruction losses: 0.019575914573273536, regression losses: 0.09841345220035816, validation losses: 0.47810955880435746\n",
      "Epoch 8861, reconstruction losses: 0.022874570995174648, regression losses: 0.10646152494702574, validation losses: 0.4681266675199788\n",
      "Epoch 8862, reconstruction losses: 0.024181675994383138, regression losses: 0.17923822682985419, validation losses: 0.43252153116088016\n",
      "Epoch 8863, reconstruction losses: 0.02442682645936757, regression losses: 0.14383639021148334, validation losses: 0.5152864682443046\n",
      "Epoch 8864, reconstruction losses: 0.02149730596604574, regression losses: 0.14015128364129315, validation losses: 0.5219219987905637\n",
      "Epoch 8865, reconstruction losses: 0.01942021147276967, regression losses: 0.11331657565829956, validation losses: 0.43343165207684625\n",
      "Epoch 8866, reconstruction losses: 0.022863689403413656, regression losses: 0.15219290679008754, validation losses: 0.5532519688458428\n",
      "Epoch 8867, reconstruction losses: 0.023570963823831944, regression losses: 0.11270061255576991, validation losses: 0.6011276064058003\n",
      "Epoch 8868, reconstruction losses: 0.022322667528991848, regression losses: 0.13270137277850524, validation losses: 0.503398631368241\n",
      "Epoch 8869, reconstruction losses: 0.020438081004642467, regression losses: 0.08696513868745137, validation losses: 0.41970808745968075\n",
      "Epoch 8870, reconstruction losses: 0.021915096065284082, regression losses: 0.14955016328009085, validation losses: 0.40512493987097625\n",
      "Epoch 8871, reconstruction losses: 0.02192438258435282, regression losses: 0.12824527462251106, validation losses: 0.41840314596307815\n",
      "Epoch 8872, reconstruction losses: 0.023348586908103642, regression losses: 0.1107099589504855, validation losses: 0.5315943740926301\n",
      "Epoch 8873, reconstruction losses: 0.02017474572404073, regression losses: 0.10334861091822994, validation losses: 0.5561727766262174\n",
      "Epoch 8874, reconstruction losses: 0.0204972797587995, regression losses: 0.11162951184319751, validation losses: 0.46423926043517555\n",
      "Epoch 8875, reconstruction losses: 0.02141952091281403, regression losses: 0.13944880318327893, validation losses: 0.42793648263353534\n",
      "Epoch 8876, reconstruction losses: 0.020024124982474002, regression losses: 0.12522397694581933, validation losses: 0.4903842173560964\n",
      "Epoch 8877, reconstruction losses: 0.021480310755536178, regression losses: 0.10379409705437859, validation losses: 0.4865616588673933\n",
      "Epoch 8878, reconstruction losses: 0.02372746764517413, regression losses: 0.12023038296285035, validation losses: 0.4669628587231398\n",
      "Epoch 8879, reconstruction losses: 0.021555100628021743, regression losses: 0.09339956595289761, validation losses: 0.45449837626261635\n",
      "Epoch 8880, reconstruction losses: 0.020583340460835542, regression losses: 0.14460932961513367, validation losses: 0.46670648760075745\n",
      "Epoch 8881, reconstruction losses: 0.018785994037949547, regression losses: 0.10536214152065386, validation losses: 0.44290673412151516\n",
      "Epoch 8882, reconstruction losses: 0.02139951718427884, regression losses: 0.0898830457257239, validation losses: 0.4373025534209623\n",
      "Epoch 8883, reconstruction losses: 0.018756329380080292, regression losses: 0.10493950417998807, validation losses: 0.4438083676039115\n",
      "Epoch 8884, reconstruction losses: 0.023669445283683144, regression losses: 0.10622641539166047, validation losses: 0.506819044282844\n",
      "Epoch 8885, reconstruction losses: 0.021181181281137874, regression losses: 0.11713614509850276, validation losses: 0.6359534000769951\n",
      "Epoch 8886, reconstruction losses: 0.022906945148984906, regression losses: 0.09082007127728507, validation losses: 0.5866018854608216\n",
      "Epoch 8887, reconstruction losses: 0.022586904916868742, regression losses: 0.13131886300745532, validation losses: 0.4694655994927468\n",
      "Epoch 8888, reconstruction losses: 0.01925683752542282, regression losses: 0.09616258723375021, validation losses: 0.4363270567594035\n",
      "Epoch 8889, reconstruction losses: 0.024175588777631287, regression losses: 0.12882877478221166, validation losses: 0.43786246425112413\n",
      "Epoch 8890, reconstruction losses: 0.022559058908911602, regression losses: 0.14267749462828241, validation losses: 0.4115420839784098\n",
      "Epoch 8891, reconstruction losses: 0.026298199001494417, regression losses: 0.16295116083605787, validation losses: 0.4232781232894448\n",
      "Epoch 8892, reconstruction losses: 0.020726886813141585, regression losses: 0.08330219269749907, validation losses: 0.6060904959307898\n",
      "Epoch 8893, reconstruction losses: 0.018316325247064082, regression losses: 0.10080254188543365, validation losses: 0.6036296505001812\n",
      "Epoch 8894, reconstruction losses: 0.027654633540103515, regression losses: 0.13922028145297274, validation losses: 0.5060440226379326\n",
      "Epoch 8895, reconstruction losses: 0.021839201168073166, regression losses: 0.1328105880623757, validation losses: 0.5428352925650366\n",
      "Epoch 8896, reconstruction losses: 0.020462529416034, regression losses: 0.11295834356635381, validation losses: 0.4824134052361116\n",
      "Epoch 8897, reconstruction losses: 0.01908666257357655, regression losses: 0.0864488271196644, validation losses: 0.5006288787613595\n",
      "Epoch 8898, reconstruction losses: 0.021817250461680253, regression losses: 0.09257667060835253, validation losses: 0.4924799454998099\n",
      "Epoch 8899, reconstruction losses: 0.020806626885255034, regression losses: 0.13081556556919913, validation losses: 0.45349598593841056\n",
      "Epoch 8900, reconstruction losses: 0.02109767963466301, regression losses: 0.11517433472064527, validation losses: 0.4478730821326618\n",
      "Epoch 8901, reconstruction losses: 0.019632984521713987, regression losses: 0.08156224871389789, validation losses: 0.4346393089665135\n",
      "Epoch 8902, reconstruction losses: 0.020197510921311626, regression losses: 0.09725047605761362, validation losses: 0.4372362436685775\n",
      "Epoch 8903, reconstruction losses: 0.02418658344806238, regression losses: 0.11282399185420178, validation losses: 0.42814456538300405\n",
      "Epoch 8904, reconstruction losses: 0.02072637325010239, regression losses: 0.12206863247572362, validation losses: 0.4424769053029704\n",
      "Epoch 8905, reconstruction losses: 0.02089349326780864, regression losses: 0.08627237018407674, validation losses: 0.45849776328265585\n",
      "Epoch 8906, reconstruction losses: 0.022674340431271176, regression losses: 0.3622293187547976, validation losses: 0.43979082971837113\n",
      "Epoch 8907, reconstruction losses: 0.024121932824403836, regression losses: 0.15103308290645354, validation losses: 0.7096399105431013\n",
      "Epoch 8908, reconstruction losses: 0.02090140085933325, regression losses: 0.13433680443598964, validation losses: 0.7122335618932701\n",
      "Epoch 8909, reconstruction losses: 0.02355254059948102, regression losses: 0.1550287106981556, validation losses: 0.7177330904843999\n",
      "Epoch 8910, reconstruction losses: 0.022302182379357383, regression losses: 0.1276781850942597, validation losses: 0.5703669116860772\n",
      "Epoch 8911, reconstruction losses: 0.022755130755117044, regression losses: 0.13726523752969588, validation losses: 0.49687707143583043\n",
      "Epoch 8912, reconstruction losses: 0.019235715628188963, regression losses: 0.1047541364264453, validation losses: 0.4933449112860906\n",
      "Epoch 8913, reconstruction losses: 0.019787602020734207, regression losses: 0.19140148988150057, validation losses: 0.4516132288660612\n",
      "Epoch 8914, reconstruction losses: 0.025801460549266825, regression losses: 0.11103154421302552, validation losses: 0.6864063477958469\n",
      "Epoch 8915, reconstruction losses: 0.020497189676640205, regression losses: 0.15003994105547952, validation losses: 0.83289749315516\n",
      "Epoch 8916, reconstruction losses: 0.025688501413538734, regression losses: 0.16866632071492024, validation losses: 0.6340030735726092\n",
      "Epoch 8917, reconstruction losses: 0.021607834735396098, regression losses: 0.10435502550259808, validation losses: 0.597629351774182\n",
      "Epoch 8918, reconstruction losses: 0.02686060534574409, regression losses: 0.17210021405821124, validation losses: 0.5388215675489513\n",
      "Epoch 8919, reconstruction losses: 0.019977298997982253, regression losses: 0.10468549651241146, validation losses: 0.5419016312237239\n",
      "Epoch 8920, reconstruction losses: 0.021333196693405276, regression losses: 0.1252208482934937, validation losses: 0.5099527594282679\n",
      "Epoch 8921, reconstruction losses: 0.02060970461260914, regression losses: 0.10844484636445124, validation losses: 0.5585839421888031\n",
      "Epoch 8922, reconstruction losses: 0.022786831845162413, regression losses: 0.3338071665846365, validation losses: 0.5522945705046551\n",
      "Epoch 8923, reconstruction losses: 0.021366197182381436, regression losses: 0.13291061568000728, validation losses: 0.6237416210266098\n",
      "Epoch 8924, reconstruction losses: 0.021827225168476367, regression losses: 0.12837392834370567, validation losses: 0.506603678644387\n",
      "Epoch 8925, reconstruction losses: 0.019013492999952347, regression losses: 0.11895927785871326, validation losses: 0.5093628448838167\n",
      "Epoch 8926, reconstruction losses: 0.019103472148223763, regression losses: 0.15674698466505546, validation losses: 0.5239397847887838\n",
      "Epoch 8927, reconstruction losses: 0.02569954247930386, regression losses: 0.2209462771424937, validation losses: 0.536352446179263\n",
      "Epoch 8928, reconstruction losses: 0.020820988139710717, regression losses: 0.13262359332766227, validation losses: 0.6182653259292202\n",
      "Epoch 8929, reconstruction losses: 0.01880792913045671, regression losses: 0.11119615873253469, validation losses: 0.6217508759675646\n",
      "Epoch 8930, reconstruction losses: 0.019962217580476758, regression losses: 0.09154726082542163, validation losses: 0.5301297051715176\n",
      "Epoch 8931, reconstruction losses: 0.021558036651024133, regression losses: 0.14040468168450285, validation losses: 0.4666562207977957\n",
      "Epoch 8932, reconstruction losses: 0.022524389586392073, regression losses: 0.19534790172273658, validation losses: 0.45488179101554793\n",
      "Epoch 8933, reconstruction losses: 0.022818784392678173, regression losses: 0.14935245056552318, validation losses: 0.5260334268370717\n",
      "Epoch 8934, reconstruction losses: 0.01946423430274198, regression losses: 0.15681747623003553, validation losses: 0.5962038092461281\n",
      "Epoch 8935, reconstruction losses: 0.022937822496224853, regression losses: 0.1203479680721373, validation losses: 0.5551238695575487\n",
      "Epoch 8936, reconstruction losses: 0.020893373263813696, regression losses: 0.11612345437912468, validation losses: 0.534273038391058\n",
      "Epoch 8937, reconstruction losses: 0.02058363666865267, regression losses: 0.13977224079889972, validation losses: 0.4902873750467277\n",
      "Epoch 8938, reconstruction losses: 0.022316861189233848, regression losses: 0.144115919595653, validation losses: 0.47231950828625735\n",
      "Epoch 8939, reconstruction losses: 0.020268400448886496, regression losses: 0.09261665632323833, validation losses: 0.5830171307506808\n",
      "Epoch 8940, reconstruction losses: 0.025202928382609104, regression losses: 0.16674178518046429, validation losses: 0.4738922376564075\n",
      "Epoch 8941, reconstruction losses: 0.0209947136964488, regression losses: 0.09727790095932078, validation losses: 0.4505172672088346\n",
      "Epoch 8942, reconstruction losses: 0.02285714507037339, regression losses: 0.13571875252393872, validation losses: 0.4641825102877163\n",
      "Epoch 8943, reconstruction losses: 0.023360180548388555, regression losses: 0.15933497084635181, validation losses: 0.5310679631102488\n",
      "Epoch 8944, reconstruction losses: 0.021609242942585233, regression losses: 0.10685990714582398, validation losses: 0.49563448158732953\n",
      "Epoch 8945, reconstruction losses: 0.02210734057623192, regression losses: 0.12448003451659176, validation losses: 0.4186936456664108\n",
      "Epoch 8946, reconstruction losses: 0.021568675796078393, regression losses: 0.12601142053425796, validation losses: 0.45590670290407453\n",
      "Epoch 8947, reconstruction losses: 0.022428845796670652, regression losses: 0.14378139379701324, validation losses: 0.46877466906558196\n",
      "Epoch 8948, reconstruction losses: 0.020041085413986113, regression losses: 0.12512764961274522, validation losses: 0.6221278265768648\n",
      "Epoch 8949, reconstruction losses: 0.02396735071835135, regression losses: 0.11634772038889779, validation losses: 0.6117574569727376\n",
      "Epoch 8950, reconstruction losses: 0.021769297032121732, regression losses: 0.14891441994823837, validation losses: 0.45714207799816986\n",
      "Epoch 8951, reconstruction losses: 0.020085840023485586, regression losses: 0.11564966347289019, validation losses: 0.460460034448401\n",
      "Epoch 8952, reconstruction losses: 0.022878729727630547, regression losses: 0.1259787856027673, validation losses: 0.47042135400793683\n",
      "Epoch 8953, reconstruction losses: 0.022565814574943766, regression losses: 0.12308557269231347, validation losses: 0.5317655689910269\n",
      "Epoch 8954, reconstruction losses: 0.023379002634482286, regression losses: 0.2145170654146039, validation losses: 0.4777770714389463\n",
      "Epoch 8955, reconstruction losses: 0.023085238209834512, regression losses: 0.14010884164676551, validation losses: 0.5175867008686351\n",
      "Epoch 8956, reconstruction losses: 0.022148421862203272, regression losses: 0.1264445924859259, validation losses: 0.4938754893952975\n",
      "Epoch 8957, reconstruction losses: 0.020485037437779265, regression losses: 0.11045976966467734, validation losses: 0.5180710002237584\n",
      "Epoch 8958, reconstruction losses: 0.02213932386722179, regression losses: 0.15255040746056564, validation losses: 0.4760561155309778\n",
      "Epoch 8959, reconstruction losses: 0.0242785823633716, regression losses: 0.1467609827773126, validation losses: 0.4527297150857105\n",
      "Epoch 8960, reconstruction losses: 0.02018803146833316, regression losses: 0.09959767061230876, validation losses: 0.5307365283100048\n",
      "Epoch 8961, reconstruction losses: 0.021771435357968487, regression losses: 0.14375659391275228, validation losses: 0.5419216303580057\n",
      "Epoch 8962, reconstruction losses: 0.02076974498432181, regression losses: 0.1421259112456526, validation losses: 0.44940973590133493\n",
      "Epoch 8963, reconstruction losses: 0.0205075947452971, regression losses: 0.124298850490823, validation losses: 0.4353744943138461\n",
      "Epoch 8964, reconstruction losses: 0.024485113700476766, regression losses: 0.15767380611153076, validation losses: 0.427448240709854\n",
      "Epoch 8965, reconstruction losses: 0.02156608234091921, regression losses: 0.11047923270783573, validation losses: 0.5062743794747498\n",
      "Epoch 8966, reconstruction losses: 0.021189306011628356, regression losses: 0.12275210524690561, validation losses: 0.5030939027294943\n",
      "Epoch 8967, reconstruction losses: 0.02158451993028735, regression losses: 0.15173109540286636, validation losses: 0.5204364804132735\n",
      "Epoch 8968, reconstruction losses: 0.022167041812063828, regression losses: 0.1145544617344027, validation losses: 0.4628466417479279\n",
      "Epoch 8969, reconstruction losses: 0.021103841422042007, regression losses: 0.0998744212999409, validation losses: 0.4708630771387291\n",
      "Epoch 8970, reconstruction losses: 0.02077968667444317, regression losses: 0.13007814867403877, validation losses: 0.4680583220848821\n",
      "Epoch 8971, reconstruction losses: 0.021265745671847195, regression losses: 0.09975745061639542, validation losses: 0.4405656427451422\n",
      "Epoch 8972, reconstruction losses: 0.019782919768331342, regression losses: 0.0990170209650496, validation losses: 0.43455565491257303\n",
      "Epoch 8973, reconstruction losses: 0.021865323086068682, regression losses: 0.12331877267507406, validation losses: 0.4286665302780244\n",
      "Epoch 8974, reconstruction losses: 0.02099463509300208, regression losses: 0.10641657435351004, validation losses: 0.4157545313615581\n",
      "Epoch 8975, reconstruction losses: 0.020612575848311457, regression losses: 0.09959274539438757, validation losses: 0.4277371642933571\n",
      "Epoch 8976, reconstruction losses: 0.02237970862900914, regression losses: 0.10518210786945582, validation losses: 0.44926205504715744\n",
      "Epoch 8977, reconstruction losses: 0.01911941932023437, regression losses: 0.10539791835907152, validation losses: 0.45037733247337775\n",
      "Epoch 8978, reconstruction losses: 0.01968463139951485, regression losses: 0.11742184919241416, validation losses: 0.44813102432025054\n",
      "Epoch 8979, reconstruction losses: 0.02369530147572802, regression losses: 0.10847208083630124, validation losses: 0.4487707373893274\n",
      "Epoch 8980, reconstruction losses: 0.022676282504738382, regression losses: 0.36595365867358776, validation losses: 0.4710793686779461\n",
      "Epoch 8981, reconstruction losses: 0.024640636919042766, regression losses: 0.1563144704014325, validation losses: 0.6665452325945228\n",
      "Epoch 8982, reconstruction losses: 0.023205580543334846, regression losses: 0.14970324262430512, validation losses: 0.5370277718954096\n",
      "Epoch 8983, reconstruction losses: 0.02279041426539901, regression losses: 0.1045261819899865, validation losses: 0.5438323318695261\n",
      "Epoch 8984, reconstruction losses: 0.018186330663390836, regression losses: 0.09604600308288454, validation losses: 0.4951043703222258\n",
      "Epoch 8985, reconstruction losses: 0.02554857143136382, regression losses: 0.301366592122219, validation losses: 0.4447887747679833\n",
      "Epoch 8986, reconstruction losses: 0.019700617325490912, regression losses: 0.11942867746597602, validation losses: 0.5131566209439961\n",
      "Epoch 8987, reconstruction losses: 0.020907043459056335, regression losses: 0.11167187513111941, validation losses: 0.4720785434581975\n",
      "Epoch 8988, reconstruction losses: 0.022035427237593448, regression losses: 0.125135348237969, validation losses: 0.456357051242138\n",
      "Epoch 8989, reconstruction losses: 0.02092482362015889, regression losses: 0.12840909963994138, validation losses: 0.46442441610424734\n",
      "Epoch 8990, reconstruction losses: 0.021293324476260013, regression losses: 0.09778032527940893, validation losses: 0.45774742034241134\n",
      "Epoch 8991, reconstruction losses: 0.021345970838791955, regression losses: 0.12450256586315328, validation losses: 0.4299772799705816\n",
      "Epoch 8992, reconstruction losses: 0.0229648255634353, regression losses: 0.09333260024553497, validation losses: 0.4789735109964467\n",
      "Epoch 8993, reconstruction losses: 0.021987610006413052, regression losses: 0.14878078640452003, validation losses: 0.4846169949295755\n",
      "Epoch 8994, reconstruction losses: 0.018865026944393376, regression losses: 0.10238841854314161, validation losses: 0.42597199157830246\n",
      "Epoch 8995, reconstruction losses: 0.023770022191321582, regression losses: 0.1742035703784249, validation losses: 0.4114344704914341\n",
      "Epoch 8996, reconstruction losses: 0.021052010635011466, regression losses: 0.10780044369492169, validation losses: 0.5243397477692031\n",
      "Epoch 8997, reconstruction losses: 0.021845283873521318, regression losses: 0.13253498578406228, validation losses: 0.5203094299729287\n",
      "Epoch 8998, reconstruction losses: 0.021219365780952702, regression losses: 0.10901262172366234, validation losses: 0.4234432572828781\n",
      "Epoch 8999, reconstruction losses: 0.02455073581780207, regression losses: 0.1289743427645326, validation losses: 0.39986607016808384\n",
      "Epoch 9000, reconstruction losses: 0.01931034967828189, regression losses: 0.1213585545733035, validation losses: 0.4495537501842412\n",
      "Epoch 9001, reconstruction losses: 0.02024839692187218, regression losses: 0.09008964702479169, validation losses: 0.4722606904836788\n",
      "Epoch 9002, reconstruction losses: 0.022727793230096077, regression losses: 0.12131945751584335, validation losses: 0.45392216013162234\n",
      "Epoch 9003, reconstruction losses: 0.021054641671844256, regression losses: 0.11316405479102443, validation losses: 0.4265184162514639\n",
      "Epoch 9004, reconstruction losses: 0.020867871280646634, regression losses: 0.1081751537140162, validation losses: 0.4375958039229282\n",
      "Epoch 9005, reconstruction losses: 0.02326491450480887, regression losses: 0.19970549587229441, validation losses: 0.43941630954711475\n",
      "Epoch 9006, reconstruction losses: 0.01788708554333702, regression losses: 0.10535279838608247, validation losses: 0.514011652508899\n",
      "Epoch 9007, reconstruction losses: 0.020448753088754476, regression losses: 0.1333584785988386, validation losses: 0.43673681552949406\n",
      "Epoch 9008, reconstruction losses: 0.018280250212331598, regression losses: 0.08893478210360237, validation losses: 0.4042268545949981\n",
      "Epoch 9009, reconstruction losses: 0.022204889503317768, regression losses: 0.1322527582877541, validation losses: 0.40419913045592426\n",
      "Epoch 9010, reconstruction losses: 0.022368052781916257, regression losses: 0.14322335716659593, validation losses: 0.495641713831234\n",
      "Epoch 9011, reconstruction losses: 0.022570716752603266, regression losses: 0.12351466395651392, validation losses: 0.5401822544542765\n",
      "Epoch 9012, reconstruction losses: 0.020154601757788954, regression losses: 0.11311714674311792, validation losses: 0.4997730343291372\n",
      "Epoch 9013, reconstruction losses: 0.021722709565386834, regression losses: 0.11494165699552988, validation losses: 0.470795490404404\n",
      "Epoch 9014, reconstruction losses: 0.024658980529974558, regression losses: 0.393669053565319, validation losses: 0.4442025898738945\n",
      "Epoch 9015, reconstruction losses: 0.023879931996184642, regression losses: 0.3536604233819086, validation losses: 0.5942293426731413\n",
      "Epoch 9016, reconstruction losses: 0.019399847408364767, regression losses: 0.13869873461421622, validation losses: 1.0439825202430082\n",
      "Epoch 9017, reconstruction losses: 0.021067923064951772, regression losses: 0.17388591358142164, validation losses: 0.8968699420385505\n",
      "Epoch 9018, reconstruction losses: 0.025428734105814803, regression losses: 0.1840456649490011, validation losses: 0.6778091910129759\n",
      "Epoch 9019, reconstruction losses: 0.020676289694994205, regression losses: 0.11187868075130451, validation losses: 0.47356395494635195\n",
      "Epoch 9020, reconstruction losses: 0.021975919782539738, regression losses: 0.1564534447631665, validation losses: 0.44510572640343044\n",
      "Epoch 9021, reconstruction losses: 0.020860299206456236, regression losses: 0.11616669712714076, validation losses: 0.45865620358632564\n",
      "Epoch 9022, reconstruction losses: 0.023086981063868105, regression losses: 0.12111390474714558, validation losses: 0.4851456979022703\n",
      "Epoch 9023, reconstruction losses: 0.022887345565250985, regression losses: 0.14014324054967747, validation losses: 0.5542319907777403\n",
      "Epoch 9024, reconstruction losses: 0.02199771338930701, regression losses: 0.10251905431604733, validation losses: 0.6130691890016187\n",
      "Epoch 9025, reconstruction losses: 0.022795689518155107, regression losses: 0.1245600115268191, validation losses: 0.5276256003464622\n",
      "Epoch 9026, reconstruction losses: 0.023070654018996682, regression losses: 0.13433989074187494, validation losses: 0.4488695408740718\n",
      "Epoch 9027, reconstruction losses: 0.022602035400387424, regression losses: 0.08521071714554952, validation losses: 0.46445826351438935\n",
      "Epoch 9028, reconstruction losses: 0.021938037675815873, regression losses: 0.10240642310522377, validation losses: 0.4574011255244786\n",
      "Epoch 9029, reconstruction losses: 0.02096739676198428, regression losses: 0.13531900263053281, validation losses: 0.4804606104999329\n",
      "Epoch 9030, reconstruction losses: 0.019379245028266722, regression losses: 0.10031277290002324, validation losses: 0.4799372151147437\n",
      "Epoch 9031, reconstruction losses: 0.02203517688366729, regression losses: 0.07713129451749455, validation losses: 0.46471557404436786\n",
      "Epoch 9032, reconstruction losses: 0.025753814188571582, regression losses: 0.12299913876513788, validation losses: 0.44856891715334524\n",
      "Epoch 9033, reconstruction losses: 0.02006195573434963, regression losses: 0.1073028089063639, validation losses: 0.4583624264472272\n",
      "Epoch 9034, reconstruction losses: 0.020997661955447288, regression losses: 0.12189489466807944, validation losses: 0.477980197521869\n",
      "Epoch 9035, reconstruction losses: 0.023626374792809095, regression losses: 0.10748324893302055, validation losses: 0.4887419036136868\n",
      "Epoch 9036, reconstruction losses: 0.023099821547614276, regression losses: 0.3416348909468804, validation losses: 0.5057157393867733\n",
      "Epoch 9037, reconstruction losses: 0.021698046174641383, regression losses: 0.11938554692686891, validation losses: 0.7766202913302855\n",
      "Epoch 9038, reconstruction losses: 0.021361735517404466, regression losses: 0.12378713134297736, validation losses: 0.6651756650726641\n",
      "Epoch 9039, reconstruction losses: 0.02136019658105265, regression losses: 0.12579974675468322, validation losses: 0.5496331888649688\n",
      "Epoch 9040, reconstruction losses: 0.023003953168429618, regression losses: 0.11746191930280445, validation losses: 0.47061036540641626\n",
      "Epoch 9041, reconstruction losses: 0.025195229760008524, regression losses: 0.16977314726326354, validation losses: 0.4746702196281338\n",
      "Epoch 9042, reconstruction losses: 0.024781304837303265, regression losses: 0.1118305562506447, validation losses: 0.5574773594487508\n",
      "Epoch 9043, reconstruction losses: 0.022393565645746336, regression losses: 0.12636059219322204, validation losses: 0.5809794565053423\n",
      "Epoch 9044, reconstruction losses: 0.019814663753425762, regression losses: 0.108975382226821, validation losses: 0.499664713042393\n",
      "Epoch 9045, reconstruction losses: 0.019271469062593874, regression losses: 0.09221929672414879, validation losses: 0.4511686395911735\n",
      "Epoch 9046, reconstruction losses: 0.01964352396529319, regression losses: 0.09512305311804883, validation losses: 0.4901383125133393\n",
      "Epoch 9047, reconstruction losses: 0.020709646143354715, regression losses: 0.1348129123741988, validation losses: 0.4895714858898976\n",
      "Epoch 9048, reconstruction losses: 0.024110535680885975, regression losses: 0.12213891254198193, validation losses: 0.4224401754565804\n",
      "Epoch 9049, reconstruction losses: 0.022346221104478762, regression losses: 0.13737492877312676, validation losses: 0.4211429736939459\n",
      "Epoch 9050, reconstruction losses: 0.02139906283299137, regression losses: 0.15078579006675788, validation losses: 0.4414121905458669\n",
      "Epoch 9051, reconstruction losses: 0.022654590154294763, regression losses: 0.1185951949120978, validation losses: 0.5053388357299295\n",
      "Epoch 9052, reconstruction losses: 0.02263138722099236, regression losses: 0.11980969194790854, validation losses: 0.6109261461721818\n",
      "Epoch 9053, reconstruction losses: 0.019652014387530923, regression losses: 0.10478176868539639, validation losses: 0.5540060079148869\n",
      "Epoch 9054, reconstruction losses: 0.019048091711634574, regression losses: 0.10737118522415522, validation losses: 0.49569220871107733\n",
      "Epoch 9055, reconstruction losses: 0.020638138762905114, regression losses: 0.12855636653168168, validation losses: 0.4759577340852612\n",
      "Epoch 9056, reconstruction losses: 0.022587210844888208, regression losses: 0.1548349904579546, validation losses: 0.5115201558232072\n",
      "Epoch 9057, reconstruction losses: 0.020143151996842742, regression losses: 0.11992019865419044, validation losses: 0.4380504723745593\n",
      "Epoch 9058, reconstruction losses: 0.02016936188856523, regression losses: 0.09882160502752486, validation losses: 0.4353623123869411\n",
      "Epoch 9059, reconstruction losses: 0.020357113300238282, regression losses: 0.10426783959733979, validation losses: 0.4688311153742928\n",
      "Epoch 9060, reconstruction losses: 0.020727082643609937, regression losses: 0.11826265931612404, validation losses: 0.5316222556416073\n",
      "Epoch 9061, reconstruction losses: 0.019485320813027607, regression losses: 0.11644771798508594, validation losses: 0.5591272702102457\n",
      "Epoch 9062, reconstruction losses: 0.03007781435317365, regression losses: 0.13675221845605162, validation losses: 0.4886303169652623\n",
      "Epoch 9063, reconstruction losses: 0.02333742829195777, regression losses: 0.12971703353586078, validation losses: 0.43915079372755966\n",
      "Epoch 9064, reconstruction losses: 0.023202135341510114, regression losses: 0.11362063104634132, validation losses: 0.47662103651102933\n",
      "Epoch 9065, reconstruction losses: 0.022254097154817607, regression losses: 0.11462550517798972, validation losses: 0.5424812645779181\n",
      "Epoch 9066, reconstruction losses: 0.022235963678747188, regression losses: 0.12347221534119661, validation losses: 0.5337085829582696\n",
      "Epoch 9067, reconstruction losses: 0.02101477927379891, regression losses: 0.10125639639109975, validation losses: 0.5339463617097836\n",
      "Epoch 9068, reconstruction losses: 0.025236686440029736, regression losses: 0.1606982024672713, validation losses: 0.527436538136906\n",
      "Epoch 9069, reconstruction losses: 0.022436133876701115, regression losses: 0.21313182575747014, validation losses: 0.5650672129197216\n",
      "Epoch 9070, reconstruction losses: 0.024859838206482063, regression losses: 0.14419739049562416, validation losses: 0.6492797034206144\n",
      "Epoch 9071, reconstruction losses: 0.020392782278393615, regression losses: 0.14894661851032903, validation losses: 0.6350115647482867\n",
      "Epoch 9072, reconstruction losses: 0.023684089830777695, regression losses: 0.17875274710414552, validation losses: 0.47852682303260885\n",
      "Epoch 9073, reconstruction losses: 0.02004307171569923, regression losses: 0.14355736135314623, validation losses: 0.5404230909775526\n",
      "Epoch 9074, reconstruction losses: 0.021614114228900475, regression losses: 0.12713703093959572, validation losses: 0.5458174681265249\n",
      "Epoch 9075, reconstruction losses: 0.020968916635655543, regression losses: 0.10710435727785775, validation losses: 0.49827058460030293\n",
      "Epoch 9076, reconstruction losses: 0.023098679367720237, regression losses: 0.1475320852580682, validation losses: 0.4724137519971805\n",
      "Epoch 9077, reconstruction losses: 0.020983460417363795, regression losses: 0.11484210425046754, validation losses: 0.524818064982044\n",
      "Epoch 9078, reconstruction losses: 0.020204598059151105, regression losses: 0.11596636636572351, validation losses: 0.48283868923285383\n",
      "Epoch 9079, reconstruction losses: 0.021589655971179875, regression losses: 0.14902718991890407, validation losses: 0.48104813207103286\n",
      "Epoch 9080, reconstruction losses: 0.023316988871616158, regression losses: 0.10501378144258977, validation losses: 0.4455506284859898\n",
      "Epoch 9081, reconstruction losses: 0.0216685963256048, regression losses: 0.11667351775331612, validation losses: 0.4527357677265776\n",
      "Epoch 9082, reconstruction losses: 0.02315334548273289, regression losses: 0.15124254802873127, validation losses: 0.47958076090598123\n",
      "Epoch 9083, reconstruction losses: 0.023140770470285295, regression losses: 0.10710763721711432, validation losses: 0.4688209467460123\n",
      "Epoch 9084, reconstruction losses: 0.026709901527172047, regression losses: 0.11959035484696755, validation losses: 0.47186101094944155\n",
      "Epoch 9085, reconstruction losses: 0.02175813072796884, regression losses: 0.10532760252832958, validation losses: 0.4380340469938382\n",
      "Epoch 9086, reconstruction losses: 0.02082223017221883, regression losses: 0.1045331949951727, validation losses: 0.4413546282725066\n",
      "Epoch 9087, reconstruction losses: 0.021996622049295644, regression losses: 0.16611913458168256, validation losses: 0.45203877030356143\n",
      "Epoch 9088, reconstruction losses: 0.022174075148143596, regression losses: 0.1194018791646309, validation losses: 0.49540896993176375\n",
      "Epoch 9089, reconstruction losses: 0.021324782506413374, regression losses: 0.12904809287402913, validation losses: 0.4794311373648728\n",
      "Epoch 9090, reconstruction losses: 0.024117958296416747, regression losses: 0.1104378413978235, validation losses: 0.4664905075514264\n",
      "Epoch 9091, reconstruction losses: 0.0240659932652311, regression losses: 0.11225862342590673, validation losses: 0.4746168736216166\n",
      "Epoch 9092, reconstruction losses: 0.02195714875152861, regression losses: 0.13121298703774056, validation losses: 0.4381696422439706\n",
      "Epoch 9093, reconstruction losses: 0.020832560786559803, regression losses: 0.11272412301752172, validation losses: 0.5020136784467907\n",
      "Epoch 9094, reconstruction losses: 0.020133771960079563, regression losses: 0.11195052478683472, validation losses: 0.5790292615964658\n",
      "Epoch 9095, reconstruction losses: 0.021605042090654798, regression losses: 0.11058314547815722, validation losses: 0.6858872531650998\n",
      "Epoch 9096, reconstruction losses: 0.019668953422287437, regression losses: 0.09785913952606748, validation losses: 0.5900059344417357\n",
      "Epoch 9097, reconstruction losses: 0.02020296811733437, regression losses: 0.09805135260396715, validation losses: 0.5036850943986416\n",
      "Epoch 9098, reconstruction losses: 0.02191162514690169, regression losses: 0.10209308962762284, validation losses: 0.4818592617149553\n",
      "Epoch 9099, reconstruction losses: 0.020159059958434845, regression losses: 0.08892914336782458, validation losses: 0.47099655653366\n",
      "Epoch 9100, reconstruction losses: 0.02056692754762595, regression losses: 0.1205571544866502, validation losses: 0.4709926609551332\n",
      "Epoch 9101, reconstruction losses: 0.02230795696083962, regression losses: 0.13886815436266353, validation losses: 0.4443813245946135\n",
      "Epoch 9102, reconstruction losses: 0.02211570016811422, regression losses: 0.1346679343611416, validation losses: 0.487118282792556\n",
      "Epoch 9103, reconstruction losses: 0.01937719762476257, regression losses: 0.10819562079517725, validation losses: 0.5238372098348822\n",
      "Epoch 9104, reconstruction losses: 0.02483439915805127, regression losses: 0.14138719435418295, validation losses: 0.4541008366380063\n",
      "Epoch 9105, reconstruction losses: 0.02030474208541024, regression losses: 0.10941765670950054, validation losses: 0.4391913832882224\n",
      "Epoch 9106, reconstruction losses: 0.020697543422748575, regression losses: 0.13491679121291186, validation losses: 0.44100492934085866\n",
      "Epoch 9107, reconstruction losses: 0.020002597404473625, regression losses: 0.12154503511763169, validation losses: 0.4552304607573417\n",
      "Epoch 9108, reconstruction losses: 0.019910339446067724, regression losses: 0.10163828817751829, validation losses: 0.5020125386118391\n",
      "Epoch 9109, reconstruction losses: 0.02047008113376428, regression losses: 0.10045263996337059, validation losses: 0.48554368778571183\n",
      "Epoch 9110, reconstruction losses: 0.02822710640680212, regression losses: 0.2883991684020496, validation losses: 0.45307063889273913\n",
      "Epoch 9111, reconstruction losses: 0.025059035108974385, regression losses: 0.1362277768703465, validation losses: 0.5378725900279182\n",
      "Epoch 9112, reconstruction losses: 0.02342762126398487, regression losses: 0.1207218408293135, validation losses: 0.456009116257434\n",
      "Epoch 9113, reconstruction losses: 0.021514189312554065, regression losses: 0.10827425530419603, validation losses: 0.5133039058588776\n",
      "Epoch 9114, reconstruction losses: 0.02186449072098623, regression losses: 0.11333598165425426, validation losses: 0.5872006338924238\n",
      "Epoch 9115, reconstruction losses: 0.02175172487853234, regression losses: 0.11328200248330343, validation losses: 0.5757603042872806\n",
      "Epoch 9116, reconstruction losses: 0.01917669978303609, regression losses: 0.09506886534189944, validation losses: 0.4715081545605772\n",
      "Epoch 9117, reconstruction losses: 0.021957276710151827, regression losses: 0.1254501773274443, validation losses: 0.4257626917489362\n",
      "Epoch 9118, reconstruction losses: 0.01943386412860669, regression losses: 0.1488840876889574, validation losses: 0.43215076327687374\n",
      "Epoch 9119, reconstruction losses: 0.021146901537260725, regression losses: 0.219412378904697, validation losses: 0.4382956864712897\n",
      "Epoch 9120, reconstruction losses: 0.029298320584392423, regression losses: 0.18753805226135167, validation losses: 0.5511569389346609\n",
      "Epoch 9121, reconstruction losses: 0.020728767147271013, regression losses: 0.10863647448331776, validation losses: 0.5937122724351263\n",
      "Epoch 9122, reconstruction losses: 0.02030262682272878, regression losses: 0.17527946162468783, validation losses: 0.5115192931847664\n",
      "Epoch 9123, reconstruction losses: 0.021568313983801445, regression losses: 0.11134301601058566, validation losses: 0.45377905666436497\n",
      "Epoch 9124, reconstruction losses: 0.022093188962346477, regression losses: 0.1044255550869117, validation losses: 0.5436462371130901\n",
      "Epoch 9125, reconstruction losses: 0.02307534342818257, regression losses: 0.12405914767235598, validation losses: 0.44793990790304483\n",
      "Epoch 9126, reconstruction losses: 0.02420951580836348, regression losses: 0.09301565640119437, validation losses: 0.41943825033214865\n",
      "Epoch 9127, reconstruction losses: 0.02320894451601757, regression losses: 0.2463473582166284, validation losses: 0.4281296431947897\n",
      "Epoch 9128, reconstruction losses: 0.027401281840012212, regression losses: 0.18324998031488268, validation losses: 0.5394792507902545\n",
      "Epoch 9129, reconstruction losses: 0.023083420926341202, regression losses: 0.11480083766846733, validation losses: 0.4851500599698214\n",
      "Epoch 9130, reconstruction losses: 0.020234142283500376, regression losses: 0.12439973327663374, validation losses: 0.5294502633912264\n",
      "Epoch 9131, reconstruction losses: 0.022108998982704006, regression losses: 0.11886558114757982, validation losses: 0.45762826191538386\n",
      "Epoch 9132, reconstruction losses: 0.019660477699822553, regression losses: 0.09980088230300042, validation losses: 0.4405418703359762\n",
      "Epoch 9133, reconstruction losses: 0.02089033679642451, regression losses: 0.1291255579676191, validation losses: 0.4217982087357012\n",
      "Epoch 9134, reconstruction losses: 0.02561837574966072, regression losses: 0.1609134450216426, validation losses: 0.4083488991898129\n",
      "Epoch 9135, reconstruction losses: 0.02102935278944124, regression losses: 0.14911076156376396, validation losses: 0.5132509849863197\n",
      "Epoch 9136, reconstruction losses: 0.01992309143855327, regression losses: 0.12821883890691937, validation losses: 0.4482493278793546\n",
      "Epoch 9137, reconstruction losses: 0.02012149030868239, regression losses: 0.12892420555075576, validation losses: 0.5268388389149818\n",
      "Epoch 9138, reconstruction losses: 0.019583901607242504, regression losses: 0.11535075293050388, validation losses: 0.45275892743051516\n",
      "Epoch 9139, reconstruction losses: 0.022863733672061976, regression losses: 0.0797773538966181, validation losses: 0.4250776850474209\n",
      "Epoch 9140, reconstruction losses: 0.021662972086620956, regression losses: 0.10526375590588698, validation losses: 0.42278329737470305\n",
      "Epoch 9141, reconstruction losses: 0.019836339252847876, regression losses: 0.10795044361544626, validation losses: 0.44853101484348573\n",
      "Epoch 9142, reconstruction losses: 0.02011030777313007, regression losses: 0.1073344752838466, validation losses: 0.51507403295117\n",
      "Epoch 9143, reconstruction losses: 0.020652281120061435, regression losses: 0.08523255989023663, validation losses: 0.4952639530476881\n",
      "Epoch 9144, reconstruction losses: 0.021684008491866108, regression losses: 0.12967643346864938, validation losses: 0.4343170398188832\n",
      "Epoch 9145, reconstruction losses: 0.019699602224045112, regression losses: 0.09667498316598479, validation losses: 0.42887023329530716\n",
      "Epoch 9146, reconstruction losses: 0.021350372218311195, regression losses: 0.1556973746252106, validation losses: 0.4450166252122226\n",
      "Epoch 9147, reconstruction losses: 0.02142846419561816, regression losses: 0.09653423290134333, validation losses: 0.5238381795228773\n",
      "Epoch 9148, reconstruction losses: 0.021281991562859027, regression losses: 0.11590053192424248, validation losses: 0.5240140328907092\n",
      "Epoch 9149, reconstruction losses: 0.02293474806477245, regression losses: 0.13551416773027003, validation losses: 0.45370390304927893\n",
      "Epoch 9150, reconstruction losses: 0.022168927762330287, regression losses: 0.1338407392098635, validation losses: 0.44250141629587886\n",
      "Epoch 9151, reconstruction losses: 0.019710658030420505, regression losses: 0.11007894716249887, validation losses: 0.432085295167456\n",
      "Epoch 9152, reconstruction losses: 0.018900161107678864, regression losses: 0.1480550694367483, validation losses: 0.4845261149599849\n",
      "Epoch 9153, reconstruction losses: 0.023221224839863698, regression losses: 0.13963305026449604, validation losses: 0.4897489085385577\n",
      "Epoch 9154, reconstruction losses: 0.021934783157527022, regression losses: 0.10644329496757302, validation losses: 0.45077992800380046\n",
      "Epoch 9155, reconstruction losses: 0.020646962258914606, regression losses: 0.11702194687817111, validation losses: 0.4360451989918101\n",
      "Epoch 9156, reconstruction losses: 0.02321514715571849, regression losses: 0.12768731152446405, validation losses: 0.44679055350129915\n",
      "Epoch 9157, reconstruction losses: 0.022531045408802075, regression losses: 0.11424404773295867, validation losses: 0.44075699960122633\n",
      "Epoch 9158, reconstruction losses: 0.022945603950357708, regression losses: 0.2426286205056616, validation losses: 0.4279527771821222\n",
      "Epoch 9159, reconstruction losses: 0.0217692575470866, regression losses: 0.11035921828547604, validation losses: 0.5111604526818115\n",
      "Epoch 9160, reconstruction losses: 0.023422578757528418, regression losses: 0.11842975453390532, validation losses: 0.5962517142621099\n",
      "Epoch 9161, reconstruction losses: 0.021070800909326497, regression losses: 0.12529888000619455, validation losses: 0.5189492384939485\n",
      "Epoch 9162, reconstruction losses: 0.021769798146811188, regression losses: 0.10121972380111036, validation losses: 0.5043691585087756\n",
      "Epoch 9163, reconstruction losses: 0.023356714421698593, regression losses: 0.1493449851846005, validation losses: 0.506925721085878\n",
      "Epoch 9164, reconstruction losses: 0.020628537179299425, regression losses: 0.08337476201748982, validation losses: 0.4993651227870093\n",
      "Epoch 9165, reconstruction losses: 0.021471793285821484, regression losses: 0.10171523634523326, validation losses: 0.4818332173263762\n",
      "Epoch 9166, reconstruction losses: 0.02333702595552915, regression losses: 0.10306603850862325, validation losses: 0.4906282411734463\n",
      "Epoch 9167, reconstruction losses: 0.02225682956705387, regression losses: 0.12395792857439666, validation losses: 0.48390100134632746\n",
      "Epoch 9168, reconstruction losses: 0.020661969312760643, regression losses: 0.10739189123134975, validation losses: 0.5019094674497803\n",
      "Epoch 9169, reconstruction losses: 0.022172381044164642, regression losses: 0.12204950784373203, validation losses: 0.5083799664890345\n",
      "Epoch 9170, reconstruction losses: 0.02324328524152793, regression losses: 0.09323393868210114, validation losses: 0.4864453200063889\n",
      "Epoch 9171, reconstruction losses: 0.020824887287341592, regression losses: 0.09044753724112278, validation losses: 0.46497131505184636\n",
      "Epoch 9172, reconstruction losses: 0.02108765854575493, regression losses: 0.14704669665158704, validation losses: 0.4557082810741615\n",
      "Epoch 9173, reconstruction losses: 0.021701245018813802, regression losses: 0.15943056335567513, validation losses: 0.44557195221887586\n",
      "Epoch 9174, reconstruction losses: 0.024285086919665688, regression losses: 0.07822496609174857, validation losses: 0.4745066041344848\n",
      "Epoch 9175, reconstruction losses: 0.021848006394050587, regression losses: 0.11913319073672779, validation losses: 0.4658926649736663\n",
      "Epoch 9176, reconstruction losses: 0.02260162311242617, regression losses: 0.1270161868584697, validation losses: 0.4575700658265364\n",
      "Epoch 9177, reconstruction losses: 0.021017785315346656, regression losses: 0.12136381746183361, validation losses: 0.46770335312086286\n",
      "Epoch 9178, reconstruction losses: 0.02214578285656972, regression losses: 0.11367841556004894, validation losses: 0.4579959993003738\n",
      "Epoch 9179, reconstruction losses: 0.02349607182494037, regression losses: 0.13716437960703384, validation losses: 0.4690275877131148\n",
      "Epoch 9180, reconstruction losses: 0.01843860148626189, regression losses: 0.08699973595631498, validation losses: 0.4584035840971741\n",
      "Epoch 9181, reconstruction losses: 0.021850874624880195, regression losses: 0.10841131455977013, validation losses: 0.44494625576088837\n",
      "Epoch 9182, reconstruction losses: 0.022487356132860806, regression losses: 0.11616532685097761, validation losses: 0.5084677105351431\n",
      "Epoch 9183, reconstruction losses: 0.02291398102194707, regression losses: 0.11498187428718681, validation losses: 0.5725150959829096\n",
      "Epoch 9184, reconstruction losses: 0.019594365006812078, regression losses: 0.1140082562008811, validation losses: 0.5183996132970965\n",
      "Epoch 9185, reconstruction losses: 0.023622129266866493, regression losses: 0.12307190850947514, validation losses: 0.4648075220383321\n",
      "Epoch 9186, reconstruction losses: 0.022458672203340323, regression losses: 0.11133879836548122, validation losses: 0.4409177739081197\n",
      "Epoch 9187, reconstruction losses: 0.023572473340396825, regression losses: 0.3405594268865915, validation losses: 0.44064288278523944\n",
      "Epoch 9188, reconstruction losses: 0.02059335041417065, regression losses: 0.1311508398161285, validation losses: 0.6485999123168399\n",
      "Epoch 9189, reconstruction losses: 0.020689517096063474, regression losses: 0.13897782458785748, validation losses: 0.5773586102441238\n",
      "Epoch 9190, reconstruction losses: 0.018015760518521048, regression losses: 0.10048885614184175, validation losses: 0.5841097268087391\n",
      "Epoch 9191, reconstruction losses: 0.02028408727145019, regression losses: 0.1156855143663313, validation losses: 0.6694995491618374\n",
      "Epoch 9192, reconstruction losses: 0.02140998986970073, regression losses: 0.12540625485044135, validation losses: 0.5635648972924883\n",
      "Epoch 9193, reconstruction losses: 0.02023998382981405, regression losses: 0.09715253099709505, validation losses: 0.4859470058653418\n",
      "Epoch 9194, reconstruction losses: 0.02053695280319915, regression losses: 0.11644150107895027, validation losses: 0.49203013298644444\n",
      "Epoch 9195, reconstruction losses: 0.021346469245244668, regression losses: 0.10780864855558733, validation losses: 0.4457889609358369\n",
      "Epoch 9196, reconstruction losses: 0.021453807278396297, regression losses: 0.1522828775513823, validation losses: 0.4587773657463523\n",
      "Epoch 9197, reconstruction losses: 0.0183438618208997, regression losses: 0.12502073129570637, validation losses: 0.4999038620549521\n",
      "Epoch 9198, reconstruction losses: 0.020405127656491776, regression losses: 0.12838476825717818, validation losses: 0.47581752502915453\n",
      "Epoch 9199, reconstruction losses: 0.0205522558953542, regression losses: 0.10526008913131726, validation losses: 0.44913200509907847\n",
      "Epoch 9200, reconstruction losses: 0.020162404989514687, regression losses: 0.1091399442251079, validation losses: 0.43673662936830615\n",
      "Epoch 9201, reconstruction losses: 0.021787240193085533, regression losses: 0.11865560870974154, validation losses: 0.46901936479501055\n",
      "Epoch 9202, reconstruction losses: 0.019595622297625733, regression losses: 0.19573202791295888, validation losses: 0.5316424682439906\n",
      "Epoch 9203, reconstruction losses: 0.022966272960271997, regression losses: 0.13466812129848402, validation losses: 0.5219961155678323\n",
      "Epoch 9204, reconstruction losses: 0.021845857818531857, regression losses: 0.09981471420150421, validation losses: 0.4785033025663561\n",
      "Epoch 9205, reconstruction losses: 0.020019142097511336, regression losses: 0.11836683314508906, validation losses: 0.42548451080687577\n",
      "Epoch 9206, reconstruction losses: 0.019342334418434585, regression losses: 0.08764076910455272, validation losses: 0.42602745938654185\n",
      "Epoch 9207, reconstruction losses: 0.020122821221163406, regression losses: 0.1296762362529103, validation losses: 0.41791695921343935\n",
      "Epoch 9208, reconstruction losses: 0.019315616657162363, regression losses: 0.07458394703781993, validation losses: 0.40936642019307873\n",
      "Epoch 9209, reconstruction losses: 0.02074519405552903, regression losses: 0.15135957233875325, validation losses: 0.42192481675189575\n",
      "Epoch 9210, reconstruction losses: 0.018196420074964467, regression losses: 0.08725580310276532, validation losses: 0.4785470523002654\n",
      "Epoch 9211, reconstruction losses: 0.020326726503582186, regression losses: 0.12796891554413098, validation losses: 0.4673883953515627\n",
      "Epoch 9212, reconstruction losses: 0.02057443360751793, regression losses: 0.11559619770717086, validation losses: 0.4284490766731234\n",
      "Epoch 9213, reconstruction losses: 0.021230913011889698, regression losses: 0.12894738001162048, validation losses: 0.45001723333447413\n",
      "Epoch 9214, reconstruction losses: 0.019001828348362365, regression losses: 0.09366749686540493, validation losses: 0.43247136541344666\n",
      "Epoch 9215, reconstruction losses: 0.018489848922985063, regression losses: 0.0791629069586657, validation losses: 0.42785264963831426\n",
      "Epoch 9216, reconstruction losses: 0.022076175920692036, regression losses: 0.14437736501765214, validation losses: 0.4327206983711399\n",
      "Epoch 9217, reconstruction losses: 0.022910743618597917, regression losses: 0.09261274427301297, validation losses: 0.5067037503041896\n",
      "Epoch 9218, reconstruction losses: 0.020813332864310103, regression losses: 0.12246608694451139, validation losses: 0.5729911010643175\n",
      "Epoch 9219, reconstruction losses: 0.01971019514940236, regression losses: 0.10805925506978145, validation losses: 0.5925190769723856\n",
      "Epoch 9220, reconstruction losses: 0.021018884630434633, regression losses: 0.1861286964254537, validation losses: 0.5303974137631124\n",
      "Epoch 9221, reconstruction losses: 0.020697862328377975, regression losses: 0.09780437404122415, validation losses: 0.5365235879569594\n",
      "Epoch 9222, reconstruction losses: 0.020191649059103662, regression losses: 0.1307772287002748, validation losses: 0.5856153752544843\n",
      "Epoch 9223, reconstruction losses: 0.021688661813125454, regression losses: 0.11189486493331101, validation losses: 0.5532089726935354\n",
      "Epoch 9224, reconstruction losses: 0.020190622572034408, regression losses: 0.09156778883482794, validation losses: 0.5186192398312501\n",
      "Epoch 9225, reconstruction losses: 0.023187641606047627, regression losses: 0.11313003851467625, validation losses: 0.517662817313478\n",
      "Epoch 9226, reconstruction losses: 0.021536821203048048, regression losses: 0.17775933739405197, validation losses: 0.5548817263350132\n",
      "Epoch 9227, reconstruction losses: 0.022677759632580965, regression losses: 0.10537460060835763, validation losses: 0.4912867073133252\n",
      "Epoch 9228, reconstruction losses: 0.01902539574155726, regression losses: 0.12964810496708304, validation losses: 0.42856394363330774\n",
      "Epoch 9229, reconstruction losses: 0.020286594480633857, regression losses: 0.1047528590486333, validation losses: 0.42804934171346226\n",
      "Epoch 9230, reconstruction losses: 0.022252569309354993, regression losses: 0.1403735644408417, validation losses: 0.502565955985882\n",
      "Epoch 9231, reconstruction losses: 0.022580229001425547, regression losses: 0.1561651627764785, validation losses: 0.5728636161675147\n",
      "Epoch 9232, reconstruction losses: 0.02344919761451036, regression losses: 0.10486704757828799, validation losses: 0.5490569236565986\n",
      "Epoch 9233, reconstruction losses: 0.0228744046906644, regression losses: 0.3344211393560804, validation losses: 0.44866827591954767\n",
      "Epoch 9234, reconstruction losses: 0.020869970557152746, regression losses: 0.12086045719038599, validation losses: 0.5109953034325742\n",
      "Epoch 9235, reconstruction losses: 0.02235470092205331, regression losses: 0.10267870348128831, validation losses: 0.4998382847527434\n",
      "Epoch 9236, reconstruction losses: 0.019316683345932093, regression losses: 0.0952880006993891, validation losses: 0.49697284762604516\n",
      "Epoch 9237, reconstruction losses: 0.02060080818120684, regression losses: 0.10137434186114198, validation losses: 0.5395285270435125\n",
      "Epoch 9238, reconstruction losses: 0.027599437941256286, regression losses: 0.11540837491387687, validation losses: 0.5553205646027645\n",
      "Epoch 9239, reconstruction losses: 0.01953667610242843, regression losses: 0.09803145421442819, validation losses: 0.48787112104108743\n",
      "Epoch 9240, reconstruction losses: 0.022920110474836657, regression losses: 0.1713657157190009, validation losses: 0.4821834513044449\n",
      "Epoch 9241, reconstruction losses: 0.02280471533178899, regression losses: 0.11833839961196134, validation losses: 0.560269755446978\n",
      "Epoch 9242, reconstruction losses: 0.020257383241884103, regression losses: 0.14242213536589293, validation losses: 0.6289815478192291\n",
      "Epoch 9243, reconstruction losses: 0.019596396599922888, regression losses: 0.11188939772976135, validation losses: 0.6592515007262288\n",
      "Epoch 9244, reconstruction losses: 0.02069139307182368, regression losses: 0.1353850959756205, validation losses: 0.48496195467252995\n",
      "Epoch 9245, reconstruction losses: 0.01970434056486753, regression losses: 0.10363990339797427, validation losses: 0.41324167788978117\n",
      "Epoch 9246, reconstruction losses: 0.020908218138713304, regression losses: 0.12579465577772134, validation losses: 0.4257139756771117\n",
      "Epoch 9247, reconstruction losses: 0.021088434372632848, regression losses: 0.12301269267349485, validation losses: 0.4411411547489553\n",
      "Epoch 9248, reconstruction losses: 0.020792687750004417, regression losses: 0.09961466709272894, validation losses: 0.5128998900369084\n",
      "Epoch 9249, reconstruction losses: 0.021090691851538352, regression losses: 0.10755789695984166, validation losses: 0.502423990444152\n",
      "Epoch 9250, reconstruction losses: 0.020903360369937656, regression losses: 0.1069184929568929, validation losses: 0.4370301359773023\n",
      "Epoch 9251, reconstruction losses: 0.020275123669375658, regression losses: 0.11395368201327186, validation losses: 0.4201079020545069\n",
      "Epoch 9252, reconstruction losses: 0.03247032963703924, regression losses: 0.08521198403759597, validation losses: 0.4351938122388475\n",
      "Epoch 9253, reconstruction losses: 0.02226695529546016, regression losses: 0.14547490233503582, validation losses: 0.4730920605386515\n",
      "Epoch 9254, reconstruction losses: 0.02401289996008188, regression losses: 0.11788161455593596, validation losses: 0.518066283887261\n",
      "Epoch 9255, reconstruction losses: 0.021464512973844822, regression losses: 0.14512995916307983, validation losses: 0.46774244591682945\n",
      "Epoch 9256, reconstruction losses: 0.02195834229255829, regression losses: 0.12065650808808352, validation losses: 0.45737065101603147\n",
      "Epoch 9257, reconstruction losses: 0.022152796232964872, regression losses: 0.11351826988027654, validation losses: 0.502371304020001\n",
      "Epoch 9258, reconstruction losses: 0.02132110803711832, regression losses: 0.0838510439821485, validation losses: 0.4971451854467066\n",
      "Epoch 9259, reconstruction losses: 0.023449468694620647, regression losses: 0.1385322208359271, validation losses: 0.48936610737234604\n",
      "Epoch 9260, reconstruction losses: 0.018857279290122656, regression losses: 0.09546735074970614, validation losses: 0.5516529893490699\n",
      "Epoch 9261, reconstruction losses: 0.023644947574456943, regression losses: 0.12889625582775868, validation losses: 0.514773754943538\n",
      "Epoch 9262, reconstruction losses: 0.02327529631477786, regression losses: 0.13455540749911943, validation losses: 0.4694516568857788\n",
      "Epoch 9263, reconstruction losses: 0.026149132343264353, regression losses: 0.18961948086050961, validation losses: 0.6024117266126444\n",
      "Epoch 9264, reconstruction losses: 0.022291864350930717, regression losses: 0.1360777395615263, validation losses: 0.6863290099389844\n",
      "Epoch 9265, reconstruction losses: 0.01933121520141571, regression losses: 0.10557255912616084, validation losses: 0.48306521210322545\n",
      "Epoch 9266, reconstruction losses: 0.02374422774344754, regression losses: 0.3698219509696554, validation losses: 0.5241016485474483\n",
      "Epoch 9267, reconstruction losses: 0.020807589808298107, regression losses: 0.11255859892164355, validation losses: 0.7738821128458018\n",
      "Epoch 9268, reconstruction losses: 0.02333740646345458, regression losses: 0.17288092757450862, validation losses: 0.6091649028277444\n",
      "Epoch 9269, reconstruction losses: 0.02424956698247798, regression losses: 0.12300304283629654, validation losses: 0.6060836558916426\n",
      "Epoch 9270, reconstruction losses: 0.018991946475082892, regression losses: 0.09094756690237261, validation losses: 0.49784192558007556\n",
      "Epoch 9271, reconstruction losses: 0.023124372719919968, regression losses: 0.1635575550258516, validation losses: 0.44205160830762585\n",
      "Epoch 9272, reconstruction losses: 0.02068454366691516, regression losses: 0.10589582692723128, validation losses: 0.490294814650225\n",
      "Epoch 9273, reconstruction losses: 0.021973126802207487, regression losses: 0.11214297473595364, validation losses: 0.5287484069037045\n",
      "Epoch 9274, reconstruction losses: 0.019122035734112336, regression losses: 0.08686531775385929, validation losses: 0.5853514692685438\n",
      "Epoch 9275, reconstruction losses: 0.01984672073941189, regression losses: 0.13310276097081425, validation losses: 0.5208648558752461\n",
      "Epoch 9276, reconstruction losses: 0.021879165403116085, regression losses: 0.1274393736017534, validation losses: 0.44754091901957765\n",
      "Epoch 9277, reconstruction losses: 0.018147943019987067, regression losses: 0.11476471533819346, validation losses: 0.432211977529359\n",
      "Epoch 9278, reconstruction losses: 0.018624419556238375, regression losses: 0.08010821793370863, validation losses: 0.4401845266944846\n",
      "Epoch 9279, reconstruction losses: 0.02206621113340589, regression losses: 0.12515559812779486, validation losses: 0.4487220903471307\n",
      "Epoch 9280, reconstruction losses: 0.019991057837053093, regression losses: 0.10107305978377457, validation losses: 0.456076150882699\n",
      "Epoch 9281, reconstruction losses: 0.020996440256015755, regression losses: 0.12083183730961577, validation losses: 0.4872808130518303\n",
      "Epoch 9282, reconstruction losses: 0.02435680053221698, regression losses: 0.13878624976761217, validation losses: 0.5054198798305038\n",
      "Epoch 9283, reconstruction losses: 0.023905543448909397, regression losses: 0.12945233240022636, validation losses: 0.5162327600254655\n",
      "Epoch 9284, reconstruction losses: 0.02173154939550291, regression losses: 0.12271290972480149, validation losses: 0.43361150626920586\n",
      "Epoch 9285, reconstruction losses: 0.02306600849285774, regression losses: 0.09819799898785339, validation losses: 0.44143402531269416\n",
      "Epoch 9286, reconstruction losses: 0.021013053489393977, regression losses: 0.08664542046842669, validation losses: 0.44344154046659673\n",
      "Epoch 9287, reconstruction losses: 0.02280282119937939, regression losses: 0.10822319961714752, validation losses: 0.4837892023771776\n",
      "Epoch 9288, reconstruction losses: 0.020632832725624214, regression losses: 0.12388295273020788, validation losses: 0.4838071712539447\n",
      "Epoch 9289, reconstruction losses: 0.0225637694436625, regression losses: 0.11466261599763479, validation losses: 0.45175142823119585\n",
      "Epoch 9290, reconstruction losses: 0.022346891341689913, regression losses: 0.13756412057953044, validation losses: 0.4717131940696757\n",
      "Epoch 9291, reconstruction losses: 0.019746746217971275, regression losses: 0.19551002584980748, validation losses: 0.4567497840199707\n",
      "Epoch 9292, reconstruction losses: 0.0197737737584946, regression losses: 0.1271996940572312, validation losses: 0.4981688660613755\n",
      "Epoch 9293, reconstruction losses: 0.025034751222850895, regression losses: 0.3360446895019874, validation losses: 0.4554676856309741\n",
      "Epoch 9294, reconstruction losses: 0.019847288637727955, regression losses: 0.12309545977444336, validation losses: 0.5608824924256189\n",
      "Epoch 9295, reconstruction losses: 0.02158097739618329, regression losses: 0.12538979208635867, validation losses: 0.5240492229126655\n",
      "Epoch 9296, reconstruction losses: 0.02433649012588628, regression losses: 0.3093118234894411, validation losses: 0.4871231715815683\n",
      "Epoch 9297, reconstruction losses: 0.023957641436835462, regression losses: 0.14567888212108765, validation losses: 0.9297033665571203\n",
      "Epoch 9298, reconstruction losses: 0.022797028438558277, regression losses: 0.1661537110884256, validation losses: 0.7093591772147756\n",
      "Epoch 9299, reconstruction losses: 0.023897747440069846, regression losses: 0.24310373190181067, validation losses: 0.5075066884025343\n",
      "Epoch 9300, reconstruction losses: 0.023288226001818957, regression losses: 0.08788517821562394, validation losses: 0.7726542637375455\n",
      "Epoch 9301, reconstruction losses: 0.023879357094189, regression losses: 0.15797972640068703, validation losses: 0.8100990757074145\n",
      "Epoch 9302, reconstruction losses: 0.02168265590705228, regression losses: 0.17173668188263425, validation losses: 0.6789333318372821\n",
      "Epoch 9303, reconstruction losses: 0.022776426739738963, regression losses: 0.13829615818310417, validation losses: 0.5883365249709095\n",
      "Epoch 9304, reconstruction losses: 0.021826594751540748, regression losses: 0.12146931308618994, validation losses: 0.4648831622494927\n",
      "Epoch 9305, reconstruction losses: 0.022149696692360544, regression losses: 0.156306131029746, validation losses: 0.44498573398491864\n",
      "Epoch 9306, reconstruction losses: 0.02148369619419596, regression losses: 0.10587500632445665, validation losses: 0.5924744797413396\n",
      "Epoch 9307, reconstruction losses: 0.020739118761523304, regression losses: 0.12133037850653836, validation losses: 0.5726860721830762\n",
      "Epoch 9308, reconstruction losses: 0.02050961399418421, regression losses: 0.2159543299780813, validation losses: 0.4746881159571086\n",
      "Epoch 9309, reconstruction losses: 0.020373182164477394, regression losses: 0.11157428669741891, validation losses: 0.4577244875518225\n",
      "Epoch 9310, reconstruction losses: 0.02697758653081965, regression losses: 0.13666348165645467, validation losses: 0.4179524018545921\n",
      "Epoch 9311, reconstruction losses: 0.020910923811203203, regression losses: 0.09462119367682377, validation losses: 0.4653470719969192\n",
      "Epoch 9312, reconstruction losses: 0.019467408837751762, regression losses: 0.12458352694975508, validation losses: 0.4697129094872008\n",
      "Epoch 9313, reconstruction losses: 0.020771827419416963, regression losses: 0.08668864845112757, validation losses: 0.44789988492143373\n",
      "Epoch 9314, reconstruction losses: 0.02304903809917334, regression losses: 0.13356865788023978, validation losses: 0.4348185602744718\n",
      "Epoch 9315, reconstruction losses: 0.021864279177802773, regression losses: 0.1012973922612499, validation losses: 0.4346703578863231\n",
      "Epoch 9316, reconstruction losses: 0.021841195615783227, regression losses: 0.14113409695517015, validation losses: 0.42195906945531153\n",
      "Epoch 9317, reconstruction losses: 0.01920743566117315, regression losses: 0.12240235028879916, validation losses: 0.4413208524780867\n",
      "Epoch 9318, reconstruction losses: 0.0221180348469133, regression losses: 0.11134834768473978, validation losses: 0.4494575743734162\n",
      "Epoch 9319, reconstruction losses: 0.018988142335833274, regression losses: 0.0816159697846929, validation losses: 0.43800268915894885\n",
      "Epoch 9320, reconstruction losses: 0.01944612759394932, regression losses: 0.11285688176754675, validation losses: 0.4506774391497985\n",
      "Epoch 9321, reconstruction losses: 0.021255023927320447, regression losses: 0.0979648461141617, validation losses: 0.4579920193719222\n",
      "Epoch 9322, reconstruction losses: 0.02328549161608025, regression losses: 0.1565715031648667, validation losses: 0.5276490072132726\n",
      "Epoch 9323, reconstruction losses: 0.023233280464664274, regression losses: 0.11232746423336579, validation losses: 0.47197162302439494\n",
      "Epoch 9324, reconstruction losses: 0.01959302512746137, regression losses: 0.10025450635751058, validation losses: 0.41014250060681906\n",
      "Epoch 9325, reconstruction losses: 0.023292887886309937, regression losses: 0.11874423359165559, validation losses: 0.42426697282464426\n",
      "Epoch 9326, reconstruction losses: 0.02177141025532538, regression losses: 0.10520978374698943, validation losses: 0.4921018831072562\n",
      "Epoch 9327, reconstruction losses: 0.01870230286906706, regression losses: 0.10890409203338898, validation losses: 0.43727369482120415\n",
      "Epoch 9328, reconstruction losses: 0.02097470694521034, regression losses: 0.07088493813530017, validation losses: 0.42683359777143104\n",
      "Epoch 9329, reconstruction losses: 0.021802781257257615, regression losses: 0.13439656389383844, validation losses: 0.4075673112603823\n",
      "Epoch 9330, reconstruction losses: 0.019984402944438817, regression losses: 0.10514379656748225, validation losses: 0.42461901734877516\n",
      "Epoch 9331, reconstruction losses: 0.01988405103303141, regression losses: 0.09769878780551705, validation losses: 0.453544041377962\n",
      "Epoch 9332, reconstruction losses: 0.02248651145679056, regression losses: 0.13754348533245353, validation losses: 0.48015179896385213\n",
      "Epoch 9333, reconstruction losses: 0.02116853040401185, regression losses: 0.1179631402589913, validation losses: 0.5224010822801193\n",
      "Epoch 9334, reconstruction losses: 0.022992342940538722, regression losses: 0.11954131216732612, validation losses: 0.43146628820834954\n",
      "Epoch 9335, reconstruction losses: 0.022218605383903713, regression losses: 0.10679477008523088, validation losses: 0.44847671872268124\n",
      "Epoch 9336, reconstruction losses: 0.022530851810721796, regression losses: 0.16502852201572604, validation losses: 0.49013456061715804\n",
      "Epoch 9337, reconstruction losses: 0.02179350182561275, regression losses: 0.11714811318932151, validation losses: 0.42233486311105695\n",
      "Epoch 9338, reconstruction losses: 0.022199213461898216, regression losses: 0.09661684530918285, validation losses: 0.4484016953687932\n",
      "Epoch 9339, reconstruction losses: 0.02228156186313941, regression losses: 0.12256768389263131, validation losses: 0.4639316287162792\n",
      "Epoch 9340, reconstruction losses: 0.024174451070363423, regression losses: 0.11450365590731175, validation losses: 0.5507778873171784\n",
      "Epoch 9341, reconstruction losses: 0.021041264474116146, regression losses: 0.11529884922758794, validation losses: 0.5002456621575306\n",
      "Epoch 9342, reconstruction losses: 0.022981674235486988, regression losses: 0.08386072814528947, validation losses: 0.4627316353683312\n",
      "Epoch 9343, reconstruction losses: 0.021022918402179, regression losses: 0.09299071609226846, validation losses: 0.5030695661404238\n",
      "Epoch 9344, reconstruction losses: 0.019785042567276142, regression losses: 0.13663644936511019, validation losses: 0.4923099629244666\n",
      "Epoch 9345, reconstruction losses: 0.019283000562719053, regression losses: 0.10999806101855865, validation losses: 0.47086992297016406\n",
      "Epoch 9346, reconstruction losses: 0.021609493900223563, regression losses: 0.12283724633569416, validation losses: 0.47585522603389324\n",
      "Epoch 9347, reconstruction losses: 0.02035390878343103, regression losses: 0.15503439126110127, validation losses: 0.4408714767516167\n",
      "Epoch 9348, reconstruction losses: 0.019859025676031653, regression losses: 0.11748526992260325, validation losses: 0.44192108004371294\n",
      "Epoch 9349, reconstruction losses: 0.02312477651071067, regression losses: 0.12225410309529927, validation losses: 0.4657985586854122\n",
      "Epoch 9350, reconstruction losses: 0.02018455023293031, regression losses: 0.13858656370993905, validation losses: 0.4707587377570831\n",
      "Epoch 9351, reconstruction losses: 0.021760084981237385, regression losses: 0.19112108994572574, validation losses: 0.511156626341318\n",
      "Epoch 9352, reconstruction losses: 0.02167689059204811, regression losses: 0.09820637413173117, validation losses: 0.7301192539931345\n",
      "Epoch 9353, reconstruction losses: 0.021468823511838316, regression losses: 0.18370629379837589, validation losses: 0.6312170463390177\n",
      "Epoch 9354, reconstruction losses: 0.02197419343123927, regression losses: 0.14769060444622456, validation losses: 0.6421246763532297\n",
      "Epoch 9355, reconstruction losses: 0.020984738480447518, regression losses: 0.1406168754140329, validation losses: 0.5631401899091795\n",
      "Epoch 9356, reconstruction losses: 0.02001627589368184, regression losses: 0.13112089494249207, validation losses: 0.4740860709588561\n",
      "Epoch 9357, reconstruction losses: 0.020276356009877504, regression losses: 0.1000182330645455, validation losses: 0.44564138078685533\n",
      "Epoch 9358, reconstruction losses: 0.02071873703809212, regression losses: 0.13127520590094183, validation losses: 0.45829892796827026\n",
      "Epoch 9359, reconstruction losses: 0.022015779045902482, regression losses: 0.11884608089596732, validation losses: 0.49161080877119534\n",
      "Epoch 9360, reconstruction losses: 0.021471392788060643, regression losses: 0.13696688045589053, validation losses: 0.5296078185288511\n",
      "Epoch 9361, reconstruction losses: 0.028336586837402006, regression losses: 0.3495379502360596, validation losses: 0.5984242604745321\n",
      "Epoch 9362, reconstruction losses: 0.02014736073737103, regression losses: 0.1330288517656778, validation losses: 0.7678743840774159\n",
      "Epoch 9363, reconstruction losses: 0.020155241216591856, regression losses: 0.13689367100692176, validation losses: 0.562779168968832\n",
      "Epoch 9364, reconstruction losses: 0.02292764681256388, regression losses: 0.15585275338771495, validation losses: 0.5642337759662779\n",
      "Epoch 9365, reconstruction losses: 0.020657277124194427, regression losses: 0.12134695863032884, validation losses: 0.5587680238598703\n",
      "Epoch 9366, reconstruction losses: 0.020722914286152763, regression losses: 0.11537316902445767, validation losses: 0.5227553919679061\n",
      "Epoch 9367, reconstruction losses: 0.0200048402390798, regression losses: 0.11353584804470987, validation losses: 0.5510384810543956\n",
      "Epoch 9368, reconstruction losses: 0.02063864679406653, regression losses: 0.1053223983142956, validation losses: 0.5432504315945395\n",
      "Epoch 9369, reconstruction losses: 0.022456992700392146, regression losses: 0.11264641342639443, validation losses: 0.48394557154532114\n",
      "Epoch 9370, reconstruction losses: 0.019369881003776797, regression losses: 0.08880649711385993, validation losses: 0.5028688716226013\n",
      "Epoch 9371, reconstruction losses: 0.020508671858027756, regression losses: 0.08983463074008151, validation losses: 0.4842353043165961\n",
      "Epoch 9372, reconstruction losses: 0.02130210400149522, regression losses: 0.11010736152028616, validation losses: 0.4347392927522814\n",
      "Epoch 9373, reconstruction losses: 0.02112802598272309, regression losses: 0.09808092626261265, validation losses: 0.3987075738325704\n",
      "Epoch 9374, reconstruction losses: 0.020123559840768704, regression losses: 0.09203316320043434, validation losses: 0.3948641790359365\n",
      "Epoch 9375, reconstruction losses: 0.019459665669601934, regression losses: 0.10385053440617302, validation losses: 0.4081549086384159\n",
      "Epoch 9376, reconstruction losses: 0.019371131091198184, regression losses: 0.09113635754495099, validation losses: 0.43593089128602164\n",
      "Epoch 9377, reconstruction losses: 0.019780139000744375, regression losses: 0.1384782327554067, validation losses: 0.4438150699382769\n",
      "Epoch 9378, reconstruction losses: 0.01889263617342934, regression losses: 0.12357512454726931, validation losses: 0.4296451502809167\n",
      "Epoch 9379, reconstruction losses: 0.020143655903148178, regression losses: 0.13292682481240864, validation losses: 0.41242698178222315\n",
      "Epoch 9380, reconstruction losses: 0.021887495659928348, regression losses: 0.09955091206568466, validation losses: 0.4778547853103187\n",
      "Epoch 9381, reconstruction losses: 0.02469680326657417, regression losses: 0.18283020612535267, validation losses: 0.44369731237191706\n",
      "Epoch 9382, reconstruction losses: 0.022625568589624386, regression losses: 0.1360438087994538, validation losses: 0.5486696678073921\n",
      "Epoch 9383, reconstruction losses: 0.021814956455222318, regression losses: 0.10178390591678087, validation losses: 0.5668227851887188\n",
      "Epoch 9384, reconstruction losses: 0.020717363853140703, regression losses: 0.11763505161609773, validation losses: 0.4341013446002373\n",
      "Epoch 9385, reconstruction losses: 0.021046996743526513, regression losses: 0.13112530234123207, validation losses: 0.4277749316342522\n",
      "Epoch 9386, reconstruction losses: 0.019039188424717624, regression losses: 0.11145805996931755, validation losses: 0.5165594425589288\n",
      "Epoch 9387, reconstruction losses: 0.019715625032529688, regression losses: 0.09269830164161348, validation losses: 0.4361479416970393\n",
      "Epoch 9388, reconstruction losses: 0.02164710019305054, regression losses: 0.13686744488000563, validation losses: 0.4385641868009579\n",
      "Epoch 9389, reconstruction losses: 0.02111631060154731, regression losses: 0.11131875222243462, validation losses: 0.6235129647004126\n",
      "Epoch 9390, reconstruction losses: 0.02069876348804831, regression losses: 0.1572535610650324, validation losses: 0.5798455328243171\n",
      "Epoch 9391, reconstruction losses: 0.019887849751776786, regression losses: 0.1230705543987739, validation losses: 0.4623640738988344\n",
      "Epoch 9392, reconstruction losses: 0.02013001179211256, regression losses: 0.11498326230121493, validation losses: 0.4590555928969153\n",
      "Epoch 9393, reconstruction losses: 0.019028272941848924, regression losses: 0.0982614902213578, validation losses: 0.4300087624037807\n",
      "Epoch 9394, reconstruction losses: 0.022904059698369488, regression losses: 0.08188252358700725, validation losses: 0.4023745083795101\n",
      "Epoch 9395, reconstruction losses: 0.021940376675810377, regression losses: 0.13356711854425035, validation losses: 0.415238385568537\n",
      "Epoch 9396, reconstruction losses: 0.020436576308001865, regression losses: 0.12035445480368712, validation losses: 0.45408564384223415\n",
      "Epoch 9397, reconstruction losses: 0.018436428200648912, regression losses: 0.14628939943826433, validation losses: 0.4979166757946822\n",
      "Epoch 9398, reconstruction losses: 0.02296820627416455, regression losses: 0.11276777093905778, validation losses: 0.461912844623526\n",
      "Epoch 9399, reconstruction losses: 0.01977835034849893, regression losses: 0.10630040054675599, validation losses: 0.4659782121979318\n",
      "Epoch 9400, reconstruction losses: 0.02103930887640434, regression losses: 0.12355326729725571, validation losses: 0.44346222127057167\n",
      "Epoch 9401, reconstruction losses: 0.019783293702419307, regression losses: 0.0955737395973615, validation losses: 0.4443486427629692\n",
      "Epoch 9402, reconstruction losses: 0.01930669939549306, regression losses: 0.10906265950299325, validation losses: 0.46617187277461586\n",
      "Epoch 9403, reconstruction losses: 0.021283474182481953, regression losses: 0.3356666040953609, validation losses: 0.5103323509291756\n",
      "Epoch 9404, reconstruction losses: 0.019518429241920394, regression losses: 0.12407725579878497, validation losses: 0.7517278017258925\n",
      "Epoch 9405, reconstruction losses: 0.021041298775282685, regression losses: 0.11916262827709535, validation losses: 0.6815689744906688\n",
      "Epoch 9406, reconstruction losses: 0.021013498897230923, regression losses: 0.13621340977261065, validation losses: 0.5652596331212776\n",
      "Epoch 9407, reconstruction losses: 0.01998770950940907, regression losses: 0.11413304828048558, validation losses: 0.5168769685651653\n",
      "Epoch 9408, reconstruction losses: 0.02100486030993743, regression losses: 0.112876282576611, validation losses: 0.48919460282014016\n",
      "Epoch 9409, reconstruction losses: 0.02161562235662754, regression losses: 0.11603191999601292, validation losses: 0.4742845549139756\n",
      "Epoch 9410, reconstruction losses: 0.01881503302064616, regression losses: 0.11261094220747442, validation losses: 0.44355256611547705\n",
      "Epoch 9411, reconstruction losses: 0.01925106733455325, regression losses: 0.10063005973350597, validation losses: 0.46880804859981134\n",
      "Epoch 9412, reconstruction losses: 0.023295560811644824, regression losses: 0.36727031696115275, validation losses: 0.48768503054095924\n",
      "Epoch 9413, reconstruction losses: 0.020611901408453624, regression losses: 0.11439944893986849, validation losses: 0.6256885245301496\n",
      "Epoch 9414, reconstruction losses: 0.021300269340635496, regression losses: 0.24881225338908286, validation losses: 0.5778067634056083\n",
      "Epoch 9415, reconstruction losses: 0.022093490585787405, regression losses: 0.11537908643443777, validation losses: 0.6610619277851342\n",
      "Epoch 9416, reconstruction losses: 0.02483036010173205, regression losses: 0.20765034696275414, validation losses: 0.5996972184550527\n",
      "Epoch 9417, reconstruction losses: 0.019157936882640836, regression losses: 0.10305305354338534, validation losses: 0.5661063001770497\n",
      "Epoch 9418, reconstruction losses: 0.0199739293901453, regression losses: 0.14780160599874478, validation losses: 0.5607042996150426\n",
      "Epoch 9419, reconstruction losses: 0.020682984312976334, regression losses: 0.10335390181341082, validation losses: 0.4745820392364513\n",
      "Epoch 9420, reconstruction losses: 0.02452846301134191, regression losses: 0.1358038395417848, validation losses: 0.48503497311549437\n",
      "Epoch 9421, reconstruction losses: 0.019481015014433785, regression losses: 0.1109217242917124, validation losses: 0.4936784490000091\n",
      "Epoch 9422, reconstruction losses: 0.021495703229140968, regression losses: 0.13183135349602182, validation losses: 0.43436785872253414\n",
      "Epoch 9423, reconstruction losses: 0.022716564084104315, regression losses: 0.1105062721324533, validation losses: 0.4607380809459669\n",
      "Epoch 9424, reconstruction losses: 0.024159679507599643, regression losses: 0.12419576090807466, validation losses: 0.48861467786273094\n",
      "Epoch 9425, reconstruction losses: 0.02015726535525064, regression losses: 0.10496638875465407, validation losses: 0.45662449023422724\n",
      "Epoch 9426, reconstruction losses: 0.018848335969365693, regression losses: 0.10490786183522956, validation losses: 0.45545283321546426\n",
      "Epoch 9427, reconstruction losses: 0.02110925396554679, regression losses: 0.10560581089432862, validation losses: 0.45322829452720775\n",
      "Epoch 9428, reconstruction losses: 0.022993337259474486, regression losses: 0.13621211582109968, validation losses: 0.44727540604918525\n",
      "Epoch 9429, reconstruction losses: 0.020896195410273825, regression losses: 0.1290942397743121, validation losses: 0.4530791538254836\n",
      "Epoch 9430, reconstruction losses: 0.020268275509056292, regression losses: 0.12283407764334743, validation losses: 0.4578074277355735\n",
      "Epoch 9431, reconstruction losses: 0.024596542567123764, regression losses: 0.16075438021842703, validation losses: 0.4934163061505459\n",
      "Epoch 9432, reconstruction losses: 0.023062754698767417, regression losses: 0.37046289642993635, validation losses: 0.4609599883035293\n",
      "Epoch 9433, reconstruction losses: 0.019684721441164062, regression losses: 0.13862605100301995, validation losses: 0.5571401635219914\n",
      "Epoch 9434, reconstruction losses: 0.022264467896357536, regression losses: 0.13037029689127946, validation losses: 0.5498466765057166\n",
      "Epoch 9435, reconstruction losses: 0.020249467004994696, regression losses: 0.0860107448499079, validation losses: 0.5503622990738242\n",
      "Epoch 9436, reconstruction losses: 0.022210440700269278, regression losses: 0.17196912434598177, validation losses: 0.5367210676785117\n",
      "Epoch 9437, reconstruction losses: 0.02203522641036806, regression losses: 0.14226272211161237, validation losses: 0.5816933159694702\n",
      "Epoch 9438, reconstruction losses: 0.02052931798757671, regression losses: 0.10027815825340923, validation losses: 0.5530921928684153\n",
      "Epoch 9439, reconstruction losses: 0.017848992363907162, regression losses: 0.09152174469675074, validation losses: 0.5185296362434583\n",
      "Epoch 9440, reconstruction losses: 0.02430649722042562, regression losses: 0.2797181127608719, validation losses: 0.4920877710411401\n",
      "Epoch 9441, reconstruction losses: 0.01987055103079708, regression losses: 0.09128641824751135, validation losses: 0.6537444290665101\n",
      "Epoch 9442, reconstruction losses: 0.02326463983854247, regression losses: 0.1716563166668599, validation losses: 0.6187433865591039\n",
      "Epoch 9443, reconstruction losses: 0.021457593629164776, regression losses: 0.10827279999761935, validation losses: 0.5465194552726945\n",
      "Epoch 9444, reconstruction losses: 0.020596458617901586, regression losses: 0.10139154789972765, validation losses: 0.5058180441976846\n",
      "Epoch 9445, reconstruction losses: 0.020291187797456915, regression losses: 0.09192719683917412, validation losses: 0.5331807910974584\n",
      "Epoch 9446, reconstruction losses: 0.02330779839020253, regression losses: 0.1220649272300244, validation losses: 0.47633637531881784\n",
      "Epoch 9447, reconstruction losses: 0.02189633550732684, regression losses: 0.11427537814222916, validation losses: 0.4444331021847113\n",
      "Epoch 9448, reconstruction losses: 0.02269463332758176, regression losses: 0.10900861666536603, validation losses: 0.4456383031710907\n",
      "Epoch 9449, reconstruction losses: 0.02008370302019346, regression losses: 0.1840616616150357, validation losses: 0.49693155201898076\n",
      "Epoch 9450, reconstruction losses: 0.022498467215559443, regression losses: 0.08692323681788293, validation losses: 0.4824752584983745\n",
      "Epoch 9451, reconstruction losses: 0.01840014629134336, regression losses: 0.08857587660022402, validation losses: 0.4606565523577799\n",
      "Epoch 9452, reconstruction losses: 0.020718184976059338, regression losses: 0.11167622792026968, validation losses: 0.4385908124109277\n",
      "Epoch 9453, reconstruction losses: 0.02328072055726373, regression losses: 0.11659868637570911, validation losses: 0.44544222693739816\n",
      "Epoch 9454, reconstruction losses: 0.020906431850784724, regression losses: 0.11946857318351865, validation losses: 0.43829686638763865\n",
      "Epoch 9455, reconstruction losses: 0.020891127412561744, regression losses: 0.11416481781853825, validation losses: 0.44516123042462463\n",
      "Epoch 9456, reconstruction losses: 0.021146227120802108, regression losses: 0.10906874095064378, validation losses: 0.4763746932610109\n",
      "Epoch 9457, reconstruction losses: 0.020423372792478498, regression losses: 0.12852194322698846, validation losses: 0.5189923502931879\n",
      "Epoch 9458, reconstruction losses: 0.020524896100284948, regression losses: 0.08991147687397982, validation losses: 0.4871403807436984\n",
      "Epoch 9459, reconstruction losses: 0.022588193941231398, regression losses: 0.1284747363166435, validation losses: 0.4489484266906797\n",
      "Epoch 9460, reconstruction losses: 0.021546116302997166, regression losses: 0.09173630990592839, validation losses: 0.4141337718415359\n",
      "Epoch 9461, reconstruction losses: 0.0212626389502167, regression losses: 0.1454599852833013, validation losses: 0.42823328086414436\n",
      "Epoch 9462, reconstruction losses: 0.022127822901465633, regression losses: 0.08759125790235564, validation losses: 0.516301758347046\n",
      "Epoch 9463, reconstruction losses: 0.019867187291171737, regression losses: 0.22319096758949522, validation losses: 0.49790466851168036\n",
      "Epoch 9464, reconstruction losses: 0.020681041452230875, regression losses: 0.09336793435301588, validation losses: 0.4807710078964596\n",
      "Epoch 9465, reconstruction losses: 0.02078666382365683, regression losses: 0.12358800091630555, validation losses: 0.5556663752863741\n",
      "Epoch 9466, reconstruction losses: 0.019153958375325773, regression losses: 0.1294186393065533, validation losses: 0.4640164148615499\n",
      "Epoch 9467, reconstruction losses: 0.019896919842350796, regression losses: 0.09105551713031354, validation losses: 0.5082022880027169\n",
      "Epoch 9468, reconstruction losses: 0.020885483125156472, regression losses: 0.12438305502980213, validation losses: 0.4668429695681624\n",
      "Epoch 9469, reconstruction losses: 0.02329666708425966, regression losses: 0.11521116287085961, validation losses: 0.4540709879967925\n",
      "Epoch 9470, reconstruction losses: 0.02019755883732374, regression losses: 0.08535510636059371, validation losses: 0.4305880521956165\n",
      "Epoch 9471, reconstruction losses: 0.02053165932805243, regression losses: 0.1267004783629857, validation losses: 0.4332541165033512\n",
      "Epoch 9472, reconstruction losses: 0.021317520441656947, regression losses: 0.11696207614226233, validation losses: 0.4324870967901388\n",
      "Epoch 9473, reconstruction losses: 0.021827294030683748, regression losses: 0.1101012812597433, validation losses: 0.4646188066952693\n",
      "Epoch 9474, reconstruction losses: 0.020098270430069204, regression losses: 0.10187334432984677, validation losses: 0.502125828682253\n",
      "Epoch 9475, reconstruction losses: 0.019420566240693223, regression losses: 0.09160211045105784, validation losses: 0.47858289635346557\n",
      "Epoch 9476, reconstruction losses: 0.02045602565702231, regression losses: 0.12444595586586764, validation losses: 0.46249560358488895\n",
      "Epoch 9477, reconstruction losses: 0.020670540252730792, regression losses: 0.09615616738763907, validation losses: 0.4875861611877828\n",
      "Epoch 9478, reconstruction losses: 0.022375561069743883, regression losses: 0.13247963715311004, validation losses: 0.5336037773752933\n",
      "Epoch 9479, reconstruction losses: 0.01977921735200883, regression losses: 0.11919657368161685, validation losses: 0.4444096435849707\n",
      "Epoch 9480, reconstruction losses: 0.02133928698177109, regression losses: 0.12203964887640895, validation losses: 0.42285910874314336\n",
      "Epoch 9481, reconstruction losses: 0.023283084486646254, regression losses: 0.10874433947080914, validation losses: 0.4412940920808651\n",
      "Epoch 9482, reconstruction losses: 0.02329996681672311, regression losses: 0.13879078978838522, validation losses: 0.49003601594621393\n",
      "Epoch 9483, reconstruction losses: 0.022317118925677566, regression losses: 0.11059001837009301, validation losses: 0.4670978235298122\n",
      "Epoch 9484, reconstruction losses: 0.024369270285558808, regression losses: 0.13703255826667196, validation losses: 0.4353863539836036\n",
      "Epoch 9485, reconstruction losses: 0.02024356958805161, regression losses: 0.11515448711112075, validation losses: 0.43030203479139256\n",
      "Epoch 9486, reconstruction losses: 0.022674956300296704, regression losses: 0.11724524161217183, validation losses: 0.47713622503361025\n",
      "Epoch 9487, reconstruction losses: 0.021230506433723945, regression losses: 0.20968869190407874, validation losses: 0.5681490476623607\n",
      "Epoch 9488, reconstruction losses: 0.02138995551724089, regression losses: 0.14907541038524055, validation losses: 0.623049858403681\n",
      "Epoch 9489, reconstruction losses: 0.02220826694316229, regression losses: 0.1825287141322323, validation losses: 0.6576208011093239\n",
      "Epoch 9490, reconstruction losses: 0.022521041365964167, regression losses: 0.12540842662151327, validation losses: 0.5485330362636641\n",
      "Epoch 9491, reconstruction losses: 0.02019141253283961, regression losses: 0.14280803875457324, validation losses: 0.5113096762526292\n",
      "Epoch 9492, reconstruction losses: 0.022932195257968788, regression losses: 0.12319039636823556, validation losses: 0.44818404401019335\n",
      "Epoch 9493, reconstruction losses: 0.02294524080828168, regression losses: 0.12639362572407759, validation losses: 0.44161385104073375\n",
      "Epoch 9494, reconstruction losses: 0.01952861351451178, regression losses: 0.10165322889114407, validation losses: 0.5300441397719672\n",
      "Epoch 9495, reconstruction losses: 0.01908700483145594, regression losses: 0.10802086871599838, validation losses: 0.5004822983410494\n",
      "Epoch 9496, reconstruction losses: 0.019385224229908436, regression losses: 0.10843291830929656, validation losses: 0.45100110878822885\n",
      "Epoch 9497, reconstruction losses: 0.023233607465152923, regression losses: 0.11309757716974135, validation losses: 0.47470218835457734\n",
      "Epoch 9498, reconstruction losses: 0.023003689487001523, regression losses: 0.11674628966429018, validation losses: 0.46630103292847075\n",
      "Epoch 9499, reconstruction losses: 0.02112858134028832, regression losses: 0.1573245020251754, validation losses: 0.44122914061854585\n",
      "Epoch 9500, reconstruction losses: 0.019715109403264548, regression losses: 0.11720495992121834, validation losses: 0.5275338129889947\n",
      "Epoch 9501, reconstruction losses: 0.021347229386834376, regression losses: 0.129762218882078, validation losses: 0.4690146250008881\n",
      "Epoch 9502, reconstruction losses: 0.01842827537012966, regression losses: 0.09284439938163246, validation losses: 0.4315204888833295\n",
      "Epoch 9503, reconstruction losses: 0.01979378119509883, regression losses: 0.10061000760086243, validation losses: 0.44475728675934567\n",
      "Epoch 9504, reconstruction losses: 0.019494622023759248, regression losses: 0.08936465346139696, validation losses: 0.45346177801851956\n",
      "Epoch 9505, reconstruction losses: 0.018401750630353098, regression losses: 0.10117452527273083, validation losses: 0.48812502647570033\n",
      "Epoch 9506, reconstruction losses: 0.02252789957415113, regression losses: 0.11559281600939861, validation losses: 0.4641144564510574\n",
      "Epoch 9507, reconstruction losses: 0.020612821863375066, regression losses: 0.1269306281101299, validation losses: 0.444665908001352\n",
      "Epoch 9508, reconstruction losses: 0.021483180868553806, regression losses: 0.14630661650627907, validation losses: 0.404558972282447\n",
      "Epoch 9509, reconstruction losses: 0.019391806848710804, regression losses: 0.10516493745842691, validation losses: 0.4083252468128009\n",
      "Epoch 9510, reconstruction losses: 0.02083150239007519, regression losses: 0.12754484801554533, validation losses: 0.40470252210472846\n",
      "Epoch 9511, reconstruction losses: 0.022415792867079454, regression losses: 0.3766445285112594, validation losses: 0.4615967388708958\n",
      "Epoch 9512, reconstruction losses: 0.023184047544053416, regression losses: 0.22654235507228618, validation losses: 0.603237897661495\n",
      "Epoch 9513, reconstruction losses: 0.020411626568685535, regression losses: 0.13374188896172218, validation losses: 0.5627174691070047\n",
      "Epoch 9514, reconstruction losses: 0.02011917934417008, regression losses: 0.13813003112684397, validation losses: 0.5570922795051044\n",
      "Epoch 9515, reconstruction losses: 0.021612161904825778, regression losses: 0.1276778054368146, validation losses: 0.4951759363097493\n",
      "Epoch 9516, reconstruction losses: 0.018381242689562087, regression losses: 0.1187831422524169, validation losses: 0.4724664228499228\n",
      "Epoch 9517, reconstruction losses: 0.021406775998231917, regression losses: 0.08777659682510491, validation losses: 0.4593235360750181\n",
      "Epoch 9518, reconstruction losses: 0.01930866757045509, regression losses: 0.12687229158341787, validation losses: 0.4486021342488765\n",
      "Epoch 9519, reconstruction losses: 0.020114145151108744, regression losses: 0.11124323871006096, validation losses: 0.45652211432475975\n",
      "Epoch 9520, reconstruction losses: 0.0229327559610556, regression losses: 0.114926924109314, validation losses: 0.43486219317476627\n",
      "Epoch 9521, reconstruction losses: 0.02312803871308352, regression losses: 0.16264685716569366, validation losses: 0.45409914126674517\n",
      "Epoch 9522, reconstruction losses: 0.022491079702100996, regression losses: 0.12377330942789477, validation losses: 0.4217395469940377\n",
      "Epoch 9523, reconstruction losses: 0.02216716389145038, regression losses: 0.20940702475153616, validation losses: 0.5502066102288686\n",
      "Epoch 9524, reconstruction losses: 0.021128372545343055, regression losses: 0.11438618179294661, validation losses: 0.7352211196502983\n",
      "Epoch 9525, reconstruction losses: 0.022729233822601492, regression losses: 0.17001484155370436, validation losses: 0.6641600702504862\n",
      "Epoch 9526, reconstruction losses: 0.021792038220344034, regression losses: 0.1550366827459612, validation losses: 0.7086554671814608\n",
      "Epoch 9527, reconstruction losses: 0.023565308124928665, regression losses: 0.22683485839447387, validation losses: 0.5801308098526494\n",
      "Epoch 9528, reconstruction losses: 0.019166752090618355, regression losses: 0.10836332269561129, validation losses: 0.5659942254877955\n",
      "Epoch 9529, reconstruction losses: 0.025146738190702535, regression losses: 0.3018387485541495, validation losses: 0.4510027562092796\n",
      "Epoch 9530, reconstruction losses: 0.020139308885064256, regression losses: 0.12104102685046952, validation losses: 0.7657500218499095\n",
      "Epoch 9531, reconstruction losses: 0.020798898016082337, regression losses: 0.19745585954685602, validation losses: 0.749001359975874\n",
      "Epoch 9532, reconstruction losses: 0.020852451941203477, regression losses: 0.14923117374855532, validation losses: 0.5486540881372336\n",
      "Epoch 9533, reconstruction losses: 0.0200660744975913, regression losses: 0.11420564867747546, validation losses: 0.49039334663302075\n",
      "Epoch 9534, reconstruction losses: 0.019805429256413633, regression losses: 0.15436555250407602, validation losses: 0.42605718422894534\n",
      "Epoch 9535, reconstruction losses: 0.024915904991750348, regression losses: 0.12501788067915398, validation losses: 0.40079527020903105\n",
      "Epoch 9536, reconstruction losses: 0.02234066357557301, regression losses: 0.21143005999665138, validation losses: 0.41725394276469685\n",
      "Epoch 9537, reconstruction losses: 0.02146432631573547, regression losses: 0.08864516711318657, validation losses: 0.4742494855030366\n",
      "Epoch 9538, reconstruction losses: 0.02005012359176185, regression losses: 0.10897107142812779, validation losses: 0.48057467678447396\n",
      "Epoch 9539, reconstruction losses: 0.02001190494418996, regression losses: 0.11641152810626731, validation losses: 0.4677282125260805\n",
      "Epoch 9540, reconstruction losses: 0.022002662100662002, regression losses: 0.1825560334005661, validation losses: 0.4667716926914526\n",
      "Epoch 9541, reconstruction losses: 0.019490460052137882, regression losses: 0.10292760119974079, validation losses: 0.5148792015239733\n",
      "Epoch 9542, reconstruction losses: 0.022304626090438446, regression losses: 0.09601513343186394, validation losses: 0.4741070555522039\n",
      "Epoch 9543, reconstruction losses: 0.023306593591023102, regression losses: 0.3483434548984399, validation losses: 0.47273390083817723\n",
      "Epoch 9544, reconstruction losses: 0.01924181987424568, regression losses: 0.10507370562957949, validation losses: 0.6224420869619648\n",
      "Epoch 9545, reconstruction losses: 0.020593949166303135, regression losses: 0.1365170555005039, validation losses: 0.5249775114282947\n",
      "Epoch 9546, reconstruction losses: 0.02207101492857374, regression losses: 0.14594426188261092, validation losses: 0.48588726663500326\n",
      "Epoch 9547, reconstruction losses: 0.020341804210569674, regression losses: 0.11497212539598642, validation losses: 0.5544331499930952\n",
      "Epoch 9548, reconstruction losses: 0.021934382886500643, regression losses: 0.2857028179341591, validation losses: 0.6048211068549343\n",
      "Epoch 9549, reconstruction losses: 0.024916532407532197, regression losses: 0.15903511792853683, validation losses: 0.7549842384592593\n",
      "Epoch 9550, reconstruction losses: 0.023413073862735057, regression losses: 0.1510183125442423, validation losses: 0.6842455947788713\n",
      "Epoch 9551, reconstruction losses: 0.020882520023888552, regression losses: 0.1426083106085255, validation losses: 0.6406754387723671\n",
      "Epoch 9552, reconstruction losses: 0.02119729448144583, regression losses: 0.12711421531632247, validation losses: 0.5842746129627387\n",
      "Epoch 9553, reconstruction losses: 0.018401051192334428, regression losses: 0.12336195240967437, validation losses: 0.452750595231186\n",
      "Epoch 9554, reconstruction losses: 0.02224526578330157, regression losses: 0.08842985265084852, validation losses: 0.4147110135679403\n",
      "Epoch 9555, reconstruction losses: 0.020592474285069044, regression losses: 0.0867552905395608, validation losses: 0.42549782017635157\n",
      "Epoch 9556, reconstruction losses: 0.01938468042069957, regression losses: 0.11576601081992621, validation losses: 0.4220025559520696\n",
      "Epoch 9557, reconstruction losses: 0.021333891664921546, regression losses: 0.09661211636675596, validation losses: 0.42503217672867966\n",
      "Epoch 9558, reconstruction losses: 0.020095931065882512, regression losses: 0.10457694069836139, validation losses: 0.43641262821740645\n",
      "Epoch 9559, reconstruction losses: 0.030345327869694495, regression losses: 0.2537494185306865, validation losses: 0.43728838962655886\n",
      "Epoch 9560, reconstruction losses: 0.0198233594199533, regression losses: 0.09223298034894209, validation losses: 0.435017108800371\n",
      "Epoch 9561, reconstruction losses: 0.02088307406777383, regression losses: 0.12372743230146101, validation losses: 0.45093532994961805\n",
      "Epoch 9562, reconstruction losses: 0.01877126258399876, regression losses: 0.09705322021301947, validation losses: 0.44598711336686586\n",
      "Epoch 9563, reconstruction losses: 0.02135158561035815, regression losses: 0.10733969459166141, validation losses: 0.46930214267218406\n",
      "Epoch 9564, reconstruction losses: 0.02117288738812222, regression losses: 0.0965204247452065, validation losses: 0.49405549906514123\n",
      "Epoch 9565, reconstruction losses: 0.019321425520852035, regression losses: 0.09719128009436839, validation losses: 0.5116015458670353\n",
      "Epoch 9566, reconstruction losses: 0.019652288669713035, regression losses: 0.10766783286182531, validation losses: 0.5219532443593896\n",
      "Epoch 9567, reconstruction losses: 0.02066369055377197, regression losses: 0.1014428260409899, validation losses: 0.5274399198528347\n",
      "Epoch 9568, reconstruction losses: 0.021274119185481166, regression losses: 0.12024366132659918, validation losses: 0.4909453632247934\n",
      "Epoch 9569, reconstruction losses: 0.02157521253618129, regression losses: 0.0741446364042467, validation losses: 0.48345897573726065\n",
      "Epoch 9570, reconstruction losses: 0.023073513005126254, regression losses: 0.2712748823682255, validation losses: 0.46614329925237236\n",
      "Epoch 9571, reconstruction losses: 0.019172540119804328, regression losses: 0.11735106294271802, validation losses: 0.5222003302355029\n",
      "Epoch 9572, reconstruction losses: 0.021616416897152532, regression losses: 0.15404834435775316, validation losses: 0.45896111138647205\n",
      "Epoch 9573, reconstruction losses: 0.02284965563453877, regression losses: 0.12205109381731294, validation losses: 0.474718390710436\n",
      "Epoch 9574, reconstruction losses: 0.02486149434973732, regression losses: 0.3484451887211616, validation losses: 0.4616806519898526\n",
      "Epoch 9575, reconstruction losses: 0.019165360601235578, regression losses: 0.1265272314887826, validation losses: 0.7048261773156782\n",
      "Epoch 9576, reconstruction losses: 0.020231180297113377, regression losses: 0.15921394980163245, validation losses: 0.5747342973321221\n",
      "Epoch 9577, reconstruction losses: 0.021914406013733543, regression losses: 0.23746305751828384, validation losses: 0.5210160210780639\n",
      "Epoch 9578, reconstruction losses: 0.023220586481727156, regression losses: 0.1727162620403394, validation losses: 0.7132661181446601\n",
      "Epoch 9579, reconstruction losses: 0.019253521705555735, regression losses: 0.13047468837882584, validation losses: 0.53506198465772\n",
      "Epoch 9580, reconstruction losses: 0.020892743556080774, regression losses: 0.10967679444731855, validation losses: 0.4692949266814957\n",
      "Epoch 9581, reconstruction losses: 0.020017087603887092, regression losses: 0.09550936737716931, validation losses: 0.4849611228060204\n",
      "Epoch 9582, reconstruction losses: 0.019315389559409722, regression losses: 0.09492266188859065, validation losses: 0.480752345762417\n",
      "Epoch 9583, reconstruction losses: 0.023696467713713552, regression losses: 0.12813456884431737, validation losses: 0.4622861972873316\n",
      "Epoch 9584, reconstruction losses: 0.019907256579154348, regression losses: 0.10112164927774779, validation losses: 0.4574717492598631\n",
      "Epoch 9585, reconstruction losses: 0.02690727365869182, regression losses: 0.2032171109614091, validation losses: 0.4761042859516569\n",
      "Epoch 9586, reconstruction losses: 0.021676740956663113, regression losses: 0.1023961224151733, validation losses: 0.6069024139252954\n",
      "Epoch 9587, reconstruction losses: 0.02007068949650075, regression losses: 0.10971163296751266, validation losses: 0.5806995984466632\n",
      "Epoch 9588, reconstruction losses: 0.02042148943960246, regression losses: 0.15637729668646597, validation losses: 0.4629303859303238\n",
      "Epoch 9589, reconstruction losses: 0.020252427097886595, regression losses: 0.10728928054564114, validation losses: 0.44127590646596837\n",
      "Epoch 9590, reconstruction losses: 0.02288575933109016, regression losses: 0.16019133223140844, validation losses: 0.43886725843258056\n",
      "Epoch 9591, reconstruction losses: 0.0201358791498928, regression losses: 0.10461434965440831, validation losses: 0.45640052851041374\n",
      "Epoch 9592, reconstruction losses: 0.023905968567448064, regression losses: 0.13869676341118106, validation losses: 0.44716994802604726\n",
      "Epoch 9593, reconstruction losses: 0.020891570840658583, regression losses: 0.09248365595013483, validation losses: 0.45503995713509915\n",
      "Epoch 9594, reconstruction losses: 0.01919000595399209, regression losses: 0.0784110360222005, validation losses: 0.4427899933648112\n",
      "Epoch 9595, reconstruction losses: 0.01898871925513947, regression losses: 0.1293417915204545, validation losses: 0.4469031246570483\n",
      "Epoch 9596, reconstruction losses: 0.022995953494340964, regression losses: 0.1713093083603305, validation losses: 0.46594188329881914\n",
      "Epoch 9597, reconstruction losses: 0.021577961865502898, regression losses: 0.09895812346668892, validation losses: 0.5954525391193132\n",
      "Epoch 9598, reconstruction losses: 0.021894051605158896, regression losses: 0.11657162463249915, validation losses: 0.5667310039667062\n",
      "Epoch 9599, reconstruction losses: 0.025161390375477447, regression losses: 0.08068126907530501, validation losses: 0.43628258948762916\n",
      "Epoch 9600, reconstruction losses: 0.024685782652424715, regression losses: 0.18639276414466038, validation losses: 0.43368253961932746\n",
      "Epoch 9601, reconstruction losses: 0.01968100815618487, regression losses: 0.10620178006009669, validation losses: 0.43686420877759236\n",
      "Epoch 9602, reconstruction losses: 0.022850088717830376, regression losses: 0.1442677889123535, validation losses: 0.4478370817324144\n",
      "Epoch 9603, reconstruction losses: 0.02037134335531363, regression losses: 0.09121207998139305, validation losses: 0.49265345307053726\n",
      "Epoch 9604, reconstruction losses: 0.018784649429931737, regression losses: 0.07984755028335254, validation losses: 0.5025897102018201\n",
      "Epoch 9605, reconstruction losses: 0.022499478936138698, regression losses: 0.13543936140877935, validation losses: 0.4900140517243427\n",
      "Epoch 9606, reconstruction losses: 0.021279093819263677, regression losses: 0.0907265260226258, validation losses: 0.47653362467325205\n",
      "Epoch 9607, reconstruction losses: 0.021151124216465582, regression losses: 0.11448928438728949, validation losses: 0.4620292234944798\n",
      "Epoch 9608, reconstruction losses: 0.021410357101187896, regression losses: 0.10025768964130895, validation losses: 0.47171888262795986\n",
      "Epoch 9609, reconstruction losses: 0.01805170074536402, regression losses: 0.1117985692204219, validation losses: 0.5084571801103089\n",
      "Epoch 9610, reconstruction losses: 0.02224636123280687, regression losses: 0.0755039522887894, validation losses: 0.45502181671649844\n",
      "Epoch 9611, reconstruction losses: 0.0249523853562836, regression losses: 0.19035665836473087, validation losses: 0.42461586889295394\n",
      "Epoch 9612, reconstruction losses: 0.02004048370456235, regression losses: 0.13535773515472205, validation losses: 0.5048517223780385\n",
      "Epoch 9613, reconstruction losses: 0.02253420663331568, regression losses: 0.11551019978427715, validation losses: 0.5344591534174665\n",
      "Epoch 9614, reconstruction losses: 0.01851844685962154, regression losses: 0.10176912833919141, validation losses: 0.551196987504514\n",
      "Epoch 9615, reconstruction losses: 0.023033479309269685, regression losses: 0.13741795554524766, validation losses: 0.4747853240069627\n",
      "Epoch 9616, reconstruction losses: 0.02264925214332443, regression losses: 0.19150755883844814, validation losses: 0.4327389068461909\n",
      "Epoch 9617, reconstruction losses: 0.018941386068911853, regression losses: 0.10444025539130107, validation losses: 0.4428804219664087\n",
      "Epoch 9618, reconstruction losses: 0.018828303590597804, regression losses: 0.10530545984534768, validation losses: 0.44804026217940013\n",
      "Epoch 9619, reconstruction losses: 0.021327181918072403, regression losses: 0.08836264200625388, validation losses: 0.4598247030093103\n",
      "Epoch 9620, reconstruction losses: 0.020670948126185584, regression losses: 0.11176319752323728, validation losses: 0.4496621272449974\n",
      "Epoch 9621, reconstruction losses: 0.02046617221811884, regression losses: 0.11698657253777425, validation losses: 0.42485786689524524\n",
      "Epoch 9622, reconstruction losses: 0.02353917814234426, regression losses: 0.11095277215005458, validation losses: 0.4124893008295481\n",
      "Epoch 9623, reconstruction losses: 0.019179443192234524, regression losses: 0.11661973436246102, validation losses: 0.43218421255897377\n",
      "Epoch 9624, reconstruction losses: 0.01951921349451755, regression losses: 0.09824369575567518, validation losses: 0.4311599225321339\n",
      "Epoch 9625, reconstruction losses: 0.022590441780882247, regression losses: 0.13232009054636476, validation losses: 0.448053929267448\n",
      "Epoch 9626, reconstruction losses: 0.021045814593044925, regression losses: 0.11169818721391313, validation losses: 0.46102158899395584\n",
      "Epoch 9627, reconstruction losses: 0.01999999918479676, regression losses: 0.12225245808347499, validation losses: 0.44024452966401123\n",
      "Epoch 9628, reconstruction losses: 0.019803880456742275, regression losses: 0.0985325273465479, validation losses: 0.43975614098645294\n",
      "Epoch 9629, reconstruction losses: 0.020818228162783985, regression losses: 0.1228193769218104, validation losses: 0.4493602910143854\n",
      "Epoch 9630, reconstruction losses: 0.019571984892172562, regression losses: 0.1056979265240998, validation losses: 0.4636832170489166\n",
      "Epoch 9631, reconstruction losses: 0.01989432702825555, regression losses: 0.08417365081176036, validation losses: 0.4709761581463979\n",
      "Epoch 9632, reconstruction losses: 0.02316976676705128, regression losses: 0.1568879396267847, validation losses: 0.44399176529549744\n",
      "Epoch 9633, reconstruction losses: 0.019401704236598278, regression losses: 0.11917018338459771, validation losses: 0.4643446945555787\n",
      "Epoch 9634, reconstruction losses: 0.025063947456473973, regression losses: 0.13832611424301844, validation losses: 0.4702559847609086\n",
      "Epoch 9635, reconstruction losses: 0.020322975613900576, regression losses: 0.12367812200216143, validation losses: 0.553587317790684\n",
      "Epoch 9636, reconstruction losses: 0.020636810098938415, regression losses: 0.10876413407485186, validation losses: 0.5337994410809829\n",
      "Epoch 9637, reconstruction losses: 0.022195883560968133, regression losses: 0.14373284043117562, validation losses: 0.49490230323857537\n",
      "Epoch 9638, reconstruction losses: 0.02400119661144821, regression losses: 0.17032683536243692, validation losses: 0.46862889705717964\n",
      "Epoch 9639, reconstruction losses: 0.02577679612611383, regression losses: 0.1123054912112085, validation losses: 0.5044227151863006\n",
      "Epoch 9640, reconstruction losses: 0.02141220609609225, regression losses: 0.1348559355158359, validation losses: 0.48512173146810866\n",
      "Epoch 9641, reconstruction losses: 0.022704194490203413, regression losses: 0.13212828818741396, validation losses: 0.4860582963810075\n",
      "Epoch 9642, reconstruction losses: 0.025293156824845474, regression losses: 0.1306569102756121, validation losses: 0.4903178665686217\n",
      "Epoch 9643, reconstruction losses: 0.019759114737468744, regression losses: 0.14038228267131778, validation losses: 0.4288543132767652\n",
      "Epoch 9644, reconstruction losses: 0.019702816229031382, regression losses: 0.09848537917696207, validation losses: 0.4476752562002693\n",
      "Epoch 9645, reconstruction losses: 0.021012333094435932, regression losses: 0.10833694219174184, validation losses: 0.4483166374801066\n",
      "Epoch 9646, reconstruction losses: 0.020237066914336584, regression losses: 0.1132269752294511, validation losses: 0.4199110796170361\n",
      "Epoch 9647, reconstruction losses: 0.020657208190700712, regression losses: 0.12252151900496129, validation losses: 0.45455520509771846\n",
      "Epoch 9648, reconstruction losses: 0.021793435662641445, regression losses: 0.09998295524594653, validation losses: 0.5102600349354869\n",
      "Epoch 9649, reconstruction losses: 0.020505464796488185, regression losses: 0.08996230656004806, validation losses: 0.46755381745920205\n",
      "Epoch 9650, reconstruction losses: 0.020284290213317582, regression losses: 0.0931982463118892, validation losses: 0.4784281811633864\n",
      "Epoch 9651, reconstruction losses: 0.022016731066437076, regression losses: 0.08301247347106966, validation losses: 0.47207099656804563\n",
      "Epoch 9652, reconstruction losses: 0.022380015443344493, regression losses: 0.11816209254067146, validation losses: 0.45594631106012956\n",
      "Epoch 9653, reconstruction losses: 0.02164031768899817, regression losses: 0.11781160533123566, validation losses: 0.4640612134374018\n",
      "Epoch 9654, reconstruction losses: 0.020733508446422747, regression losses: 0.12427447192634185, validation losses: 0.4486067923802126\n",
      "Epoch 9655, reconstruction losses: 0.02217710274783127, regression losses: 0.12246017663178344, validation losses: 0.4318848947663621\n",
      "Epoch 9656, reconstruction losses: 0.022951486809266928, regression losses: 0.12069938022007315, validation losses: 0.44773236251061216\n",
      "Epoch 9657, reconstruction losses: 0.023434959793372238, regression losses: 0.14618117835178288, validation losses: 0.5455838416412464\n",
      "Epoch 9658, reconstruction losses: 0.022288723880630926, regression losses: 0.17994851093624137, validation losses: 0.5337768886540948\n",
      "Epoch 9659, reconstruction losses: 0.021581146052309416, regression losses: 0.08821578010054584, validation losses: 0.488376879851022\n",
      "Epoch 9660, reconstruction losses: 0.0222015595858656, regression losses: 0.11525165994113513, validation losses: 0.4504850116989474\n",
      "Epoch 9661, reconstruction losses: 0.020578674214379124, regression losses: 0.09296247351894858, validation losses: 0.44544332696794187\n",
      "Epoch 9662, reconstruction losses: 0.02243567239020597, regression losses: 0.11989616917418103, validation losses: 0.4537392357780007\n",
      "Epoch 9663, reconstruction losses: 0.022248291143214312, regression losses: 0.33571974952912376, validation losses: 0.5301041586423278\n",
      "Epoch 9664, reconstruction losses: 0.019165764783289813, regression losses: 0.1323026175701388, validation losses: 0.7324904309914885\n",
      "Epoch 9665, reconstruction losses: 0.019220527971189387, regression losses: 0.16391740487687276, validation losses: 0.6084128790731849\n",
      "Epoch 9666, reconstruction losses: 0.028300881247637216, regression losses: 0.29790812288518587, validation losses: 0.5110941296367927\n",
      "Epoch 9667, reconstruction losses: 0.0201169399029629, regression losses: 0.1468056837659058, validation losses: 0.606073567372152\n",
      "Epoch 9668, reconstruction losses: 0.02249525188361574, regression losses: 0.20546196611651582, validation losses: 0.6420025903848084\n",
      "Epoch 9669, reconstruction losses: 0.01913764919598749, regression losses: 0.12165358125699023, validation losses: 0.7423046681533252\n",
      "Epoch 9670, reconstruction losses: 0.02089067798686052, regression losses: 0.11807211735307556, validation losses: 0.7099635722649891\n",
      "Epoch 9671, reconstruction losses: 0.019206247268319456, regression losses: 0.13519303560057247, validation losses: 0.5078403679886034\n",
      "Epoch 9672, reconstruction losses: 0.022240809635363217, regression losses: 0.14606392574660743, validation losses: 0.4179676508190933\n",
      "Epoch 9673, reconstruction losses: 0.023724732490909506, regression losses: 0.10884688395265157, validation losses: 0.4766873450417004\n",
      "Epoch 9674, reconstruction losses: 0.01954376345964089, regression losses: 0.1405415426644949, validation losses: 0.4588941045450617\n",
      "Epoch 9675, reconstruction losses: 0.019968963699612857, regression losses: 0.09211069596254783, validation losses: 0.4800231526797802\n",
      "Epoch 9676, reconstruction losses: 0.02123929687869249, regression losses: 0.10541321033710192, validation losses: 0.4818032916499662\n",
      "Epoch 9677, reconstruction losses: 0.0199807768732837, regression losses: 0.09833975695330191, validation losses: 0.43888379489630286\n",
      "Epoch 9678, reconstruction losses: 0.019940251221753906, regression losses: 0.10226879782205296, validation losses: 0.41255604096974663\n",
      "Epoch 9679, reconstruction losses: 0.022631044912594073, regression losses: 0.13868768295002326, validation losses: 0.4465931950169963\n",
      "Epoch 9680, reconstruction losses: 0.024706834777088963, regression losses: 0.14417227402553437, validation losses: 0.5104687841354153\n",
      "Epoch 9681, reconstruction losses: 0.020649071673402176, regression losses: 0.1021965486443307, validation losses: 0.5961638671576344\n",
      "Epoch 9682, reconstruction losses: 0.0229703326634809, regression losses: 0.11110471495201751, validation losses: 0.5579468593814785\n",
      "Epoch 9683, reconstruction losses: 0.0213598281774407, regression losses: 0.10946391717517841, validation losses: 0.44604097936848863\n",
      "Epoch 9684, reconstruction losses: 0.02433210637958149, regression losses: 0.17900985536749306, validation losses: 0.42436037532686177\n",
      "Epoch 9685, reconstruction losses: 0.021143412040812954, regression losses: 0.11437391563255395, validation losses: 0.4956203372762761\n",
      "Epoch 9686, reconstruction losses: 0.020971189362891798, regression losses: 0.12043446521671998, validation losses: 0.4588967287138922\n",
      "Epoch 9687, reconstruction losses: 0.022810157703005377, regression losses: 0.2389086270528179, validation losses: 0.4787796414497487\n",
      "Epoch 9688, reconstruction losses: 0.022910122447388367, regression losses: 0.1759503560185229, validation losses: 0.5899570916778549\n",
      "Epoch 9689, reconstruction losses: 0.022146124571160587, regression losses: 0.12076163403331275, validation losses: 0.6851260803933114\n",
      "Epoch 9690, reconstruction losses: 0.01834969125947641, regression losses: 0.11735977878062724, validation losses: 0.5591304957154661\n",
      "Epoch 9691, reconstruction losses: 0.020970864675957494, regression losses: 0.13415873107546486, validation losses: 0.44726502632098397\n",
      "Epoch 9692, reconstruction losses: 0.021683771102552003, regression losses: 0.13004060273417894, validation losses: 0.44877761182464404\n",
      "Epoch 9693, reconstruction losses: 0.022707316214110172, regression losses: 0.1656757359738749, validation losses: 0.508721736452735\n",
      "Epoch 9694, reconstruction losses: 0.02125699171120999, regression losses: 0.11077974216423606, validation losses: 0.5283680100307739\n",
      "Epoch 9695, reconstruction losses: 0.0194090899698965, regression losses: 0.08870627377300963, validation losses: 0.49210654697210426\n",
      "Epoch 9696, reconstruction losses: 0.021901768752263247, regression losses: 0.1439698483148399, validation losses: 0.49002315886169684\n",
      "Epoch 9697, reconstruction losses: 0.022693292244021963, regression losses: 0.16428253947151142, validation losses: 0.515028697208282\n",
      "Epoch 9698, reconstruction losses: 0.021958549720925497, regression losses: 0.11131505200023274, validation losses: 0.4448386007441536\n",
      "Epoch 9699, reconstruction losses: 0.022451218299394407, regression losses: 0.10808891642854664, validation losses: 0.45191554202377304\n",
      "Epoch 9700, reconstruction losses: 0.020869057716238856, regression losses: 0.08323837299112961, validation losses: 0.46786968325485695\n",
      "Epoch 9701, reconstruction losses: 0.025677650953354548, regression losses: 0.11901239873768105, validation losses: 0.4772436370003313\n",
      "Epoch 9702, reconstruction losses: 0.02015265667968006, regression losses: 0.0938544563235093, validation losses: 0.47283748053588676\n",
      "Epoch 9703, reconstruction losses: 0.02152560970246497, regression losses: 0.1341259373948907, validation losses: 0.4968077669050602\n",
      "Epoch 9704, reconstruction losses: 0.020331823972210082, regression losses: 0.1419689856027461, validation losses: 0.5441026844723682\n",
      "Epoch 9705, reconstruction losses: 0.0225941148147846, regression losses: 0.13493567296190992, validation losses: 0.5082434713115694\n",
      "Epoch 9706, reconstruction losses: 0.020491467038727597, regression losses: 0.10335359392329323, validation losses: 0.4876102621469558\n",
      "Epoch 9707, reconstruction losses: 0.02134302502814113, regression losses: 0.12453172838495527, validation losses: 0.44903512807865986\n",
      "Epoch 9708, reconstruction losses: 0.020899069141785045, regression losses: 0.10803300074919542, validation losses: 0.46777824384624206\n",
      "Epoch 9709, reconstruction losses: 0.021523197007083696, regression losses: 0.1080339293413228, validation losses: 0.509301072444441\n",
      "Epoch 9710, reconstruction losses: 0.021383806218591407, regression losses: 0.12217359868429481, validation losses: 0.4775077910148247\n",
      "Epoch 9711, reconstruction losses: 0.019156443477117147, regression losses: 0.09507426019218237, validation losses: 0.46752975503952543\n",
      "Epoch 9712, reconstruction losses: 0.02043289449948573, regression losses: 0.11882690193405743, validation losses: 0.45367726549016263\n",
      "Epoch 9713, reconstruction losses: 0.01878799008834799, regression losses: 0.10026912134040206, validation losses: 0.46745090848934623\n",
      "Epoch 9714, reconstruction losses: 0.020659456111946067, regression losses: 0.11446694996767993, validation losses: 0.447831289755383\n",
      "Epoch 9715, reconstruction losses: 0.020725838139467878, regression losses: 0.12464958673610035, validation losses: 0.4341748651992602\n",
      "Epoch 9716, reconstruction losses: 0.02162059451643413, regression losses: 0.11882063056453801, validation losses: 0.47041725002589097\n",
      "Epoch 9717, reconstruction losses: 0.021806630293818637, regression losses: 0.08959802318142289, validation losses: 0.4638591133978532\n",
      "Epoch 9718, reconstruction losses: 0.020320383364401933, regression losses: 0.17731001462976603, validation losses: 0.42575136120149637\n",
      "Epoch 9719, reconstruction losses: 0.019689527335752872, regression losses: 0.0959972533099088, validation losses: 0.4917156413366971\n",
      "Epoch 9720, reconstruction losses: 0.021397258631684152, regression losses: 0.10920531600328262, validation losses: 0.4526499258891755\n",
      "Epoch 9721, reconstruction losses: 0.01829142599284464, regression losses: 0.1157980760793599, validation losses: 0.45054507580146097\n",
      "Epoch 9722, reconstruction losses: 0.020913838834648802, regression losses: 0.18648298867170593, validation losses: 0.5263357163273689\n",
      "Epoch 9723, reconstruction losses: 0.020858021849629777, regression losses: 0.26566506231573717, validation losses: 0.4870762078436002\n",
      "Epoch 9724, reconstruction losses: 0.01880028591532872, regression losses: 0.08308488759191027, validation losses: 0.5323365228994943\n",
      "Epoch 9725, reconstruction losses: 0.019297673823771788, regression losses: 0.09200411435581124, validation losses: 0.503854595153447\n",
      "Epoch 9726, reconstruction losses: 0.02158388148126123, regression losses: 0.15261893736934568, validation losses: 0.4911369098379216\n",
      "Epoch 9727, reconstruction losses: 0.02058053040603428, regression losses: 0.09933511382287254, validation losses: 0.5453556717375808\n",
      "Epoch 9728, reconstruction losses: 0.02155318038774251, regression losses: 0.11141889334652438, validation losses: 0.47611820070545324\n",
      "Epoch 9729, reconstruction losses: 0.021370871333865456, regression losses: 0.11751162470037907, validation losses: 0.42662236880895527\n",
      "Epoch 9730, reconstruction losses: 0.019323098460321608, regression losses: 0.09982634335614438, validation losses: 0.4623622738457551\n",
      "Epoch 9731, reconstruction losses: 0.020485534965733538, regression losses: 0.08949696194975108, validation losses: 0.4898503864315552\n",
      "Epoch 9732, reconstruction losses: 0.017558280556244588, regression losses: 0.08918826458292568, validation losses: 0.48557976578187917\n",
      "Epoch 9733, reconstruction losses: 0.020121467810067097, regression losses: 0.10174855359702982, validation losses: 0.48246957393983037\n",
      "Epoch 9734, reconstruction losses: 0.01910592462461055, regression losses: 0.10226204789789153, validation losses: 0.4699127990587342\n",
      "Epoch 9735, reconstruction losses: 0.01925459115715233, regression losses: 0.07268576995400795, validation losses: 0.4711678527577375\n",
      "Epoch 9736, reconstruction losses: 0.02488839200579007, regression losses: 0.14411764011782358, validation losses: 0.46404842104227695\n",
      "Epoch 9737, reconstruction losses: 0.019569845120436156, regression losses: 0.14647415888368873, validation losses: 0.4748683457178368\n",
      "Epoch 9738, reconstruction losses: 0.021769593038780177, regression losses: 0.13488201478645861, validation losses: 0.46713332139048636\n",
      "Epoch 9739, reconstruction losses: 0.024372813820765622, regression losses: 0.13905409982002864, validation losses: 0.49684049809103203\n",
      "Epoch 9740, reconstruction losses: 0.019860280148947567, regression losses: 0.09952156693316037, validation losses: 0.45722241630396754\n",
      "Epoch 9741, reconstruction losses: 0.021680710055504312, regression losses: 0.14674777461007346, validation losses: 0.4323466128504672\n",
      "Epoch 9742, reconstruction losses: 0.02130796483709635, regression losses: 0.10289483646137486, validation losses: 0.4236718060529826\n",
      "Epoch 9743, reconstruction losses: 0.018462425477135294, regression losses: 0.07355577447906966, validation losses: 0.4049149400364582\n",
      "Epoch 9744, reconstruction losses: 0.024911504474963857, regression losses: 0.15160583603088668, validation losses: 0.4310501918290083\n",
      "Epoch 9745, reconstruction losses: 0.020298069288062673, regression losses: 0.12298323026031932, validation losses: 0.6165412600418239\n",
      "Epoch 9746, reconstruction losses: 0.019585944347819226, regression losses: 0.119966433318656, validation losses: 0.5250395162723697\n",
      "Epoch 9747, reconstruction losses: 0.020503837962112383, regression losses: 0.11311256363949522, validation losses: 0.4570175407439993\n",
      "Epoch 9748, reconstruction losses: 0.02017977131371127, regression losses: 0.10046625133813655, validation losses: 0.452868374076034\n",
      "Epoch 9749, reconstruction losses: 0.019473056979012145, regression losses: 0.08666896663342583, validation losses: 0.46822372625498887\n",
      "Epoch 9750, reconstruction losses: 0.02171464177221116, regression losses: 0.08416164684959956, validation losses: 0.46249030811364056\n",
      "Epoch 9751, reconstruction losses: 0.018702394406834202, regression losses: 0.08831707247422829, validation losses: 0.43991934631015284\n",
      "Epoch 9752, reconstruction losses: 0.02213059599239653, regression losses: 0.15737490170224422, validation losses: 0.4334995079352025\n",
      "Epoch 9753, reconstruction losses: 0.018557311851049873, regression losses: 0.1139764898760751, validation losses: 0.46251475280096904\n",
      "Epoch 9754, reconstruction losses: 0.020529669724901205, regression losses: 0.09849273181314075, validation losses: 0.43931112817568874\n",
      "Epoch 9755, reconstruction losses: 0.019968058470931773, regression losses: 0.13709507691136247, validation losses: 0.4561874212878711\n",
      "Epoch 9756, reconstruction losses: 0.022510578106466762, regression losses: 0.1268321919730962, validation losses: 0.4320420020509806\n",
      "Epoch 9757, reconstruction losses: 0.021318503308940903, regression losses: 0.10495112598366449, validation losses: 0.47912871438624866\n",
      "Epoch 9758, reconstruction losses: 0.01994047435357537, regression losses: 0.11346067872491981, validation losses: 0.4759281988496751\n",
      "Epoch 9759, reconstruction losses: 0.025781269823939766, regression losses: 0.3023208462508526, validation losses: 0.4522540573509174\n",
      "Epoch 9760, reconstruction losses: 0.020626561168421473, regression losses: 0.10954395990464343, validation losses: 0.6218524648202906\n",
      "Epoch 9761, reconstruction losses: 0.023980948358732625, regression losses: 0.15725876981796366, validation losses: 0.6090845369528521\n",
      "Epoch 9762, reconstruction losses: 0.019221296098594354, regression losses: 0.13902469994559696, validation losses: 0.5930039703410319\n",
      "Epoch 9763, reconstruction losses: 0.019266432234310023, regression losses: 0.11411786386006406, validation losses: 0.4565095966707357\n",
      "Epoch 9764, reconstruction losses: 0.02141508949149508, regression losses: 0.12725274012886506, validation losses: 0.4232982937102546\n",
      "Epoch 9765, reconstruction losses: 0.021048504004771387, regression losses: 0.10601889149363887, validation losses: 0.42748577156016965\n",
      "Epoch 9766, reconstruction losses: 0.023115676628561503, regression losses: 0.1327006178124858, validation losses: 0.45374942476060676\n",
      "Epoch 9767, reconstruction losses: 0.02355236270192072, regression losses: 0.14502094430579815, validation losses: 0.49764995812812696\n",
      "Epoch 9768, reconstruction losses: 0.023348511550276823, regression losses: 0.09499142734519866, validation losses: 0.5358917327333816\n",
      "Epoch 9769, reconstruction losses: 0.02143244298356619, regression losses: 0.1290439609362737, validation losses: 0.48158862589078844\n",
      "Epoch 9770, reconstruction losses: 0.02098952637471362, regression losses: 0.10834237211342165, validation losses: 0.44070868822759457\n",
      "Epoch 9771, reconstruction losses: 0.020663143456529184, regression losses: 0.11808678774528164, validation losses: 0.4426248615220614\n",
      "Epoch 9772, reconstruction losses: 0.02199343798782614, regression losses: 0.13141485431416, validation losses: 0.4463255698249166\n",
      "Epoch 9773, reconstruction losses: 0.020594587203367043, regression losses: 0.10955689726746451, validation losses: 0.45501896248885004\n",
      "Epoch 9774, reconstruction losses: 0.018801103241621715, regression losses: 0.10360092667620728, validation losses: 0.4680209293061059\n",
      "Epoch 9775, reconstruction losses: 0.020477827967136618, regression losses: 0.13039013579865752, validation losses: 0.4933875297537349\n",
      "Epoch 9776, reconstruction losses: 0.018384142237527646, regression losses: 0.08685914548678217, validation losses: 0.5035251655977037\n",
      "Epoch 9777, reconstruction losses: 0.018341456189349757, regression losses: 0.14911236177917775, validation losses: 0.48400573592762813\n",
      "Epoch 9778, reconstruction losses: 0.017896710797355296, regression losses: 0.10401286354082333, validation losses: 0.43998047371828025\n",
      "Epoch 9779, reconstruction losses: 0.021321175245385765, regression losses: 0.10383336094939741, validation losses: 0.4450518540288599\n",
      "Epoch 9780, reconstruction losses: 0.020797959655349328, regression losses: 0.10736089274250453, validation losses: 0.4221881213032271\n",
      "Epoch 9781, reconstruction losses: 0.021133360074618367, regression losses: 0.1009360020715242, validation losses: 0.4155539692177849\n",
      "Epoch 9782, reconstruction losses: 0.0195004602233262, regression losses: 0.08313453738988227, validation losses: 0.4637987278242556\n",
      "Epoch 9783, reconstruction losses: 0.019640436431593387, regression losses: 0.0968492040431302, validation losses: 0.4966325578005029\n",
      "Epoch 9784, reconstruction losses: 0.02385753575145908, regression losses: 0.19549729511795103, validation losses: 0.5089468799682604\n",
      "Epoch 9785, reconstruction losses: 0.021903784073029217, regression losses: 0.11524229091487635, validation losses: 0.6236701081381413\n",
      "Epoch 9786, reconstruction losses: 0.02116453258409809, regression losses: 0.1346357754104511, validation losses: 0.5777367544047987\n",
      "Epoch 9787, reconstruction losses: 0.020233338644905487, regression losses: 0.11142281210143475, validation losses: 0.5292964298648614\n",
      "Epoch 9788, reconstruction losses: 0.01965444568756535, regression losses: 0.0967773386259801, validation losses: 0.4891646162866223\n",
      "Epoch 9789, reconstruction losses: 0.019198013831697815, regression losses: 0.08744307001739371, validation losses: 0.4264327617871408\n",
      "Epoch 9790, reconstruction losses: 0.020578415413160196, regression losses: 0.12569612821463721, validation losses: 0.4062278154033168\n",
      "Epoch 9791, reconstruction losses: 0.022208845491566653, regression losses: 0.10138282844761996, validation losses: 0.4133102940015012\n",
      "Epoch 9792, reconstruction losses: 0.021866171861119423, regression losses: 0.4383835886677767, validation losses: 0.4319080018299414\n",
      "Epoch 9793, reconstruction losses: 0.019498406801329374, regression losses: 0.09312727282965293, validation losses: 0.5791729856007285\n",
      "Epoch 9794, reconstruction losses: 0.019741749018892068, regression losses: 0.1119177168138402, validation losses: 0.5905895749442557\n",
      "Epoch 9795, reconstruction losses: 0.020723691765829562, regression losses: 0.12751923411016935, validation losses: 0.5313931332365729\n",
      "Epoch 9796, reconstruction losses: 0.019935048771610564, regression losses: 0.10889106254190097, validation losses: 0.5591470148514417\n",
      "Epoch 9797, reconstruction losses: 0.01860967880505461, regression losses: 0.19714474005092342, validation losses: 0.5316743397180114\n",
      "Epoch 9798, reconstruction losses: 0.018020383041660627, regression losses: 0.0862023989535349, validation losses: 0.44816081159491644\n",
      "Epoch 9799, reconstruction losses: 0.020241156354919618, regression losses: 0.10540451383826711, validation losses: 0.4314659736696434\n",
      "Epoch 9800, reconstruction losses: 0.019723471934995792, regression losses: 0.09615551307248407, validation losses: 0.4295139985985156\n",
      "Epoch 9801, reconstruction losses: 0.019696086845829745, regression losses: 0.10551078838763585, validation losses: 0.4538571308242418\n",
      "Epoch 9802, reconstruction losses: 0.020827676965799905, regression losses: 0.09387887316268329, validation losses: 0.45915333328710883\n",
      "Epoch 9803, reconstruction losses: 0.021146662302096417, regression losses: 0.14843671148520296, validation losses: 0.45508306289592043\n",
      "Epoch 9804, reconstruction losses: 0.020000453325082466, regression losses: 0.13371847604497417, validation losses: 0.5354900187745052\n",
      "Epoch 9805, reconstruction losses: 0.021686634995452172, regression losses: 0.07369007255066376, validation losses: 0.5033429723249875\n",
      "Epoch 9806, reconstruction losses: 0.02057796099187541, regression losses: 0.11662762304156472, validation losses: 0.49082492736914973\n",
      "Epoch 9807, reconstruction losses: 0.02173270643192246, regression losses: 0.09379788024312977, validation losses: 0.4685524877583651\n",
      "Epoch 9808, reconstruction losses: 0.021184464108262115, regression losses: 0.1188122677668404, validation losses: 0.4635185495591698\n",
      "Epoch 9809, reconstruction losses: 0.020369554892271925, regression losses: 0.10546982418424718, validation losses: 0.45853191533895793\n",
      "Epoch 9810, reconstruction losses: 0.02177465753604203, regression losses: 0.10105258263618254, validation losses: 0.43785682860888553\n",
      "Epoch 9811, reconstruction losses: 0.021724662320071125, regression losses: 0.13003577163284846, validation losses: 0.4097321549160344\n",
      "Epoch 9812, reconstruction losses: 0.021975567799700085, regression losses: 0.12263225503624965, validation losses: 0.4092088853251458\n",
      "Epoch 9813, reconstruction losses: 0.01998424205932196, regression losses: 0.08978397719550965, validation losses: 0.4543556529268904\n",
      "Epoch 9814, reconstruction losses: 0.021437738813534557, regression losses: 0.10044426971257807, validation losses: 0.5047333605749482\n",
      "Epoch 9815, reconstruction losses: 0.019958118789303186, regression losses: 0.10926450753209382, validation losses: 0.43120556856000364\n",
      "Epoch 9816, reconstruction losses: 0.022933796501337096, regression losses: 0.0975372933652162, validation losses: 0.4116184933020225\n",
      "Epoch 9817, reconstruction losses: 0.021409937067742937, regression losses: 0.09938795677563926, validation losses: 0.4140714079491058\n",
      "Epoch 9818, reconstruction losses: 0.019613273755431676, regression losses: 0.1437554989391396, validation losses: 0.4248058567156513\n",
      "Epoch 9819, reconstruction losses: 0.023010471167035224, regression losses: 0.09025691992643296, validation losses: 0.45286064753562194\n",
      "Epoch 9820, reconstruction losses: 0.020056781575405334, regression losses: 0.1184999086599421, validation losses: 0.47997397927842755\n",
      "Epoch 9821, reconstruction losses: 0.02087585772833938, regression losses: 0.16033911717168275, validation losses: 0.4595033210139231\n",
      "Epoch 9822, reconstruction losses: 0.021293725796436395, regression losses: 0.121195231622125, validation losses: 0.45817672708209606\n",
      "Epoch 9823, reconstruction losses: 0.024152832669103043, regression losses: 0.13566890009618757, validation losses: 0.4346119221939049\n",
      "Epoch 9824, reconstruction losses: 0.023203497140515436, regression losses: 0.11263584113226854, validation losses: 0.4465997143146294\n",
      "Epoch 9825, reconstruction losses: 0.02802764011891346, regression losses: 0.22337487858497446, validation losses: 0.45441128876156023\n",
      "Epoch 9826, reconstruction losses: 0.022608061503713417, regression losses: 0.17755213267953374, validation losses: 0.6506405947212601\n",
      "Epoch 9827, reconstruction losses: 0.02263023633278528, regression losses: 0.1493962820155722, validation losses: 0.6650658874967309\n",
      "Epoch 9828, reconstruction losses: 0.02112940625328684, regression losses: 0.14857149704998396, validation losses: 0.5446938853957575\n",
      "Epoch 9829, reconstruction losses: 0.022718802183264893, regression losses: 0.12327210076090905, validation losses: 0.5298728550642359\n",
      "Epoch 9830, reconstruction losses: 0.021803350442720776, regression losses: 0.11366981951259877, validation losses: 0.5052376096858882\n",
      "Epoch 9831, reconstruction losses: 0.020237610879351376, regression losses: 0.10722097920441782, validation losses: 0.455596595839123\n",
      "Epoch 9832, reconstruction losses: 0.019872082773953456, regression losses: 0.13754219769402673, validation losses: 0.48569742750964096\n",
      "Epoch 9833, reconstruction losses: 0.020457821823303784, regression losses: 0.11687791242095316, validation losses: 0.5517054249103682\n",
      "Epoch 9834, reconstruction losses: 0.022474249644372862, regression losses: 0.1424685761918968, validation losses: 0.5255473005686168\n",
      "Epoch 9835, reconstruction losses: 0.02039650712402495, regression losses: 0.1298086344705589, validation losses: 0.46180875544997224\n",
      "Epoch 9836, reconstruction losses: 0.019046317443332666, regression losses: 0.14480079418814257, validation losses: 0.4610462096986803\n",
      "Epoch 9837, reconstruction losses: 0.0243246583420745, regression losses: 0.12463009049997492, validation losses: 0.5185138572108225\n",
      "Epoch 9838, reconstruction losses: 0.01959356488176144, regression losses: 0.1134292392838438, validation losses: 0.45048350633974377\n",
      "Epoch 9839, reconstruction losses: 0.019072317337152672, regression losses: 0.1289723915399443, validation losses: 0.43973808657059976\n",
      "Epoch 9840, reconstruction losses: 0.02051625714938688, regression losses: 0.09824805606972667, validation losses: 0.48296933254931373\n",
      "Epoch 9841, reconstruction losses: 0.022006153405467483, regression losses: 0.12962185195920034, validation losses: 0.50099743108559\n",
      "Epoch 9842, reconstruction losses: 0.020316769750560258, regression losses: 0.11091344535735434, validation losses: 0.4623406348000937\n",
      "Epoch 9843, reconstruction losses: 0.02037539137707523, regression losses: 0.1378188262351522, validation losses: 0.4507819052830073\n",
      "Epoch 9844, reconstruction losses: 0.0202173802740695, regression losses: 0.08674171960028207, validation losses: 0.4338914367533829\n",
      "Epoch 9845, reconstruction losses: 0.02075810378787231, regression losses: 0.147298733168917, validation losses: 0.4239037888174602\n",
      "Epoch 9846, reconstruction losses: 0.019832734431061247, regression losses: 0.11246421430806301, validation losses: 0.4712693838049829\n",
      "Epoch 9847, reconstruction losses: 0.019751819525455776, regression losses: 0.10734560886723978, validation losses: 0.46284404872267354\n",
      "Epoch 9848, reconstruction losses: 0.02063698184804783, regression losses: 0.1187523907433851, validation losses: 0.4618743240391842\n",
      "Epoch 9849, reconstruction losses: 0.019801750834731294, regression losses: 0.10200259276783566, validation losses: 0.48856906280456286\n",
      "Epoch 9850, reconstruction losses: 0.022805064086172236, regression losses: 0.17072663666108037, validation losses: 0.48619834076134943\n",
      "Epoch 9851, reconstruction losses: 0.02690634009683089, regression losses: 0.16751199259872063, validation losses: 0.6646425434441919\n",
      "Epoch 9852, reconstruction losses: 0.02444260892198682, regression losses: 0.1654194525837795, validation losses: 0.7022384805819555\n",
      "Epoch 9853, reconstruction losses: 0.021407342272100227, regression losses: 0.11146687786613176, validation losses: 0.4647542930979917\n",
      "Epoch 9854, reconstruction losses: 0.022291401014950515, regression losses: 0.09954920777160504, validation losses: 0.4466937815760436\n",
      "Epoch 9855, reconstruction losses: 0.02111333356172528, regression losses: 0.13799547684080074, validation losses: 0.4404732734027881\n",
      "Epoch 9856, reconstruction losses: 0.024890836249447306, regression losses: 0.15539880879253498, validation losses: 0.4504640441626137\n",
      "Epoch 9857, reconstruction losses: 0.019736006924450707, regression losses: 0.0851930485300818, validation losses: 0.46093215394730064\n",
      "Epoch 9858, reconstruction losses: 0.020111200700093385, regression losses: 0.10393195559349518, validation losses: 0.45327007378525863\n",
      "Epoch 9859, reconstruction losses: 0.022713721869019654, regression losses: 0.17010795924485544, validation losses: 0.4428912910736594\n",
      "Epoch 9860, reconstruction losses: 0.021094005326771477, regression losses: 0.11688399945298747, validation losses: 0.5095068491359905\n",
      "Epoch 9861, reconstruction losses: 0.01984424729577195, regression losses: 0.09131138931943139, validation losses: 0.5670273892140452\n",
      "Epoch 9862, reconstruction losses: 0.023201043170826028, regression losses: 0.09601421836485469, validation losses: 0.48581988877842736\n",
      "Epoch 9863, reconstruction losses: 0.01986919170312374, regression losses: 0.08321698232570109, validation losses: 0.4676094016291185\n",
      "Epoch 9864, reconstruction losses: 0.018989526862479723, regression losses: 0.08156299234408046, validation losses: 0.48732103999551807\n",
      "Epoch 9865, reconstruction losses: 0.023284566589401506, regression losses: 0.13846998980587236, validation losses: 0.5379541097602182\n",
      "Epoch 9866, reconstruction losses: 0.024750504455330426, regression losses: 0.1649200743441831, validation losses: 0.5684239960400165\n",
      "Epoch 9867, reconstruction losses: 0.022456263803062627, regression losses: 0.11910893754819285, validation losses: 0.5342550217254812\n",
      "Epoch 9868, reconstruction losses: 0.019766004650359947, regression losses: 0.10240264754420465, validation losses: 0.4559968845688014\n",
      "Epoch 9869, reconstruction losses: 0.021516993836034063, regression losses: 0.09560787932504793, validation losses: 0.44331901411722957\n",
      "Epoch 9870, reconstruction losses: 0.01893832572359409, regression losses: 0.11256226675063899, validation losses: 0.44390668274898104\n",
      "Epoch 9871, reconstruction losses: 0.02364821236724517, regression losses: 0.11467443858502539, validation losses: 0.5050440040489612\n",
      "Epoch 9872, reconstruction losses: 0.022433519755815194, regression losses: 0.13497518107260698, validation losses: 0.4587263488688391\n",
      "Epoch 9873, reconstruction losses: 0.021707762560711587, regression losses: 0.121679787003091, validation losses: 0.431877893448406\n",
      "Epoch 9874, reconstruction losses: 0.020133197910516418, regression losses: 0.12826124162809016, validation losses: 0.44960780052376426\n",
      "Epoch 9875, reconstruction losses: 0.022923566146064268, regression losses: 0.12567757636758126, validation losses: 0.48431518783603167\n",
      "Epoch 9876, reconstruction losses: 0.021598200908591495, regression losses: 0.11296441336881927, validation losses: 0.5045218806332534\n",
      "Epoch 9877, reconstruction losses: 0.0195737765344284, regression losses: 0.10642121826917249, validation losses: 0.4852950415716206\n",
      "Epoch 9878, reconstruction losses: 0.01905520945104474, regression losses: 0.12005821115578616, validation losses: 0.46409909082784784\n",
      "Epoch 9879, reconstruction losses: 0.019840769984213472, regression losses: 0.23997810791246219, validation losses: 0.4502040657405771\n",
      "Epoch 9880, reconstruction losses: 0.021440524102728363, regression losses: 0.12133506068892967, validation losses: 0.47861224826461923\n",
      "Epoch 9881, reconstruction losses: 0.022144929765503994, regression losses: 0.09716325947610822, validation losses: 0.4748994634371895\n",
      "Epoch 9882, reconstruction losses: 0.01995113695683683, regression losses: 0.13324968315953015, validation losses: 0.46862519527904856\n",
      "Epoch 9883, reconstruction losses: 0.02145842028166538, regression losses: 0.1171007863112977, validation losses: 0.4642146303692462\n",
      "Epoch 9884, reconstruction losses: 0.020629130007278906, regression losses: 0.0989489256369738, validation losses: 0.4963491531718274\n",
      "Epoch 9885, reconstruction losses: 0.01915878220147032, regression losses: 0.11812819596308775, validation losses: 0.4860309859170278\n",
      "Epoch 9886, reconstruction losses: 0.018768179733521396, regression losses: 0.09762300986714292, validation losses: 0.5404333511788595\n",
      "Epoch 9887, reconstruction losses: 0.020037854341547298, regression losses: 0.10392569700001375, validation losses: 0.5126201726067834\n",
      "Epoch 9888, reconstruction losses: 0.01998010424775461, regression losses: 0.08136338491032721, validation losses: 0.4563522399589865\n",
      "Epoch 9889, reconstruction losses: 0.02092999559717893, regression losses: 0.07875750535501169, validation losses: 0.46277611334818636\n",
      "Epoch 9890, reconstruction losses: 0.022226086795731227, regression losses: 0.07455580454081603, validation losses: 0.48596778989107137\n",
      "Epoch 9891, reconstruction losses: 0.02105451275500791, regression losses: 0.12043858005856513, validation losses: 0.4732546988447687\n",
      "Epoch 9892, reconstruction losses: 0.022547786863499855, regression losses: 0.1140835701311545, validation losses: 0.5058429641909112\n",
      "Epoch 9893, reconstruction losses: 0.020552140351219095, regression losses: 0.15270800459279946, validation losses: 0.47170450596401964\n",
      "Epoch 9894, reconstruction losses: 0.02388856120074364, regression losses: 0.14181691327854, validation losses: 0.4762325308191825\n",
      "Epoch 9895, reconstruction losses: 0.020945365996808487, regression losses: 0.08695280100241144, validation losses: 0.5973727320354942\n",
      "Epoch 9896, reconstruction losses: 0.020993706889296533, regression losses: 0.12611446041569754, validation losses: 0.4592805138078014\n",
      "Epoch 9897, reconstruction losses: 0.02165849763628452, regression losses: 0.1310199693232265, validation losses: 0.44334773871480115\n",
      "Epoch 9898, reconstruction losses: 0.02110629227685515, regression losses: 0.13162111469380333, validation losses: 0.4708894917284031\n",
      "Epoch 9899, reconstruction losses: 0.02162664885006057, regression losses: 0.13076383862044322, validation losses: 0.49542717912201434\n",
      "Epoch 9900, reconstruction losses: 0.02067875882185265, regression losses: 0.10029257676949715, validation losses: 0.47896798158538784\n",
      "Epoch 9901, reconstruction losses: 0.02144898431809312, regression losses: 0.13220064271292076, validation losses: 0.48354714959421247\n",
      "Epoch 9902, reconstruction losses: 0.020537979466441283, regression losses: 0.12157860374346087, validation losses: 0.4864853531388492\n",
      "Epoch 9903, reconstruction losses: 0.021329471476405393, regression losses: 0.13302953247891208, validation losses: 0.46080411290669937\n",
      "Epoch 9904, reconstruction losses: 0.019998950637403867, regression losses: 0.10053013638572698, validation losses: 0.4599491215861826\n",
      "Epoch 9905, reconstruction losses: 0.022213640402506632, regression losses: 0.11595225058892944, validation losses: 0.45310349742385\n",
      "Epoch 9906, reconstruction losses: 0.020518879072762893, regression losses: 0.10761081786712723, validation losses: 0.4609212979956146\n",
      "Epoch 9907, reconstruction losses: 0.027198759718801757, regression losses: 0.3646775938646696, validation losses: 0.4945518553061292\n",
      "Epoch 9908, reconstruction losses: 0.021196646882071353, regression losses: 0.12928815920080228, validation losses: 0.6011606826941273\n",
      "Epoch 9909, reconstruction losses: 0.019941164729735412, regression losses: 0.11476256110409506, validation losses: 0.5434568111753891\n",
      "Epoch 9910, reconstruction losses: 0.02182194075861052, regression losses: 0.10175985409812482, validation losses: 0.4338855958468782\n",
      "Epoch 9911, reconstruction losses: 0.025218110634440502, regression losses: 0.18942216720121716, validation losses: 0.47319029649668215\n",
      "Epoch 9912, reconstruction losses: 0.020356347309849462, regression losses: 0.12434491920508173, validation losses: 0.4539704609495133\n",
      "Epoch 9913, reconstruction losses: 0.021286466610283227, regression losses: 0.11484775520993123, validation losses: 0.46034449660083626\n",
      "Epoch 9914, reconstruction losses: 0.019477369313462597, regression losses: 0.10975612078157088, validation losses: 0.4579493809568693\n",
      "Epoch 9915, reconstruction losses: 0.0190533800828157, regression losses: 0.09057338255610448, validation losses: 0.45449597055913854\n",
      "Epoch 9916, reconstruction losses: 0.01955986879349709, regression losses: 0.10414004656327623, validation losses: 0.4714579294828035\n",
      "Epoch 9917, reconstruction losses: 0.02415221332740101, regression losses: 0.11377238780943062, validation losses: 0.4660818725126417\n",
      "Epoch 9918, reconstruction losses: 0.021470090538433167, regression losses: 0.16434717229164564, validation losses: 0.4985302591731552\n",
      "Epoch 9919, reconstruction losses: 0.02130012376818409, regression losses: 0.0908922788085451, validation losses: 0.5947079375477025\n",
      "Epoch 9920, reconstruction losses: 0.020512760762406063, regression losses: 0.1683285144120604, validation losses: 0.5219804311516756\n",
      "Epoch 9921, reconstruction losses: 0.019633936975766795, regression losses: 0.12638331058602803, validation losses: 0.4580791313040036\n",
      "Epoch 9922, reconstruction losses: 0.02312128628708543, regression losses: 0.12201118343442746, validation losses: 0.45451935908308516\n",
      "Epoch 9923, reconstruction losses: 0.019021188324882244, regression losses: 0.0977179850695239, validation losses: 0.43890991083953634\n",
      "Epoch 9924, reconstruction losses: 0.022098313375239632, regression losses: 0.10593067206952492, validation losses: 0.45145573137811107\n",
      "Epoch 9925, reconstruction losses: 0.019253637684205932, regression losses: 0.09636974503226094, validation losses: 0.46791785713978806\n",
      "Epoch 9926, reconstruction losses: 0.019665267890672408, regression losses: 0.0953868493477148, validation losses: 0.4209760070251095\n",
      "Epoch 9927, reconstruction losses: 0.0226526282204752, regression losses: 0.09798350629184113, validation losses: 0.43320829181519527\n",
      "Epoch 9928, reconstruction losses: 0.02563206106156217, regression losses: 0.1778484141477066, validation losses: 0.49756315382642624\n",
      "Epoch 9929, reconstruction losses: 0.021793969902125024, regression losses: 0.1251750788948421, validation losses: 0.5460989837487862\n",
      "Epoch 9930, reconstruction losses: 0.02279337767672528, regression losses: 0.30310796470320506, validation losses: 0.468512704979296\n",
      "Epoch 9931, reconstruction losses: 0.020477730151335232, regression losses: 0.1057022809733648, validation losses: 0.5246886188555702\n",
      "Epoch 9932, reconstruction losses: 0.022087164919654904, regression losses: 0.129973234991561, validation losses: 0.4837092299799595\n",
      "Epoch 9933, reconstruction losses: 0.01969627779310314, regression losses: 0.16316790801706302, validation losses: 0.4528885316624066\n",
      "Epoch 9934, reconstruction losses: 0.020384299077886095, regression losses: 0.11034713886001757, validation losses: 0.508435885022512\n",
      "Epoch 9935, reconstruction losses: 0.02011615167816292, regression losses: 0.10235140809605318, validation losses: 0.4805852136420088\n",
      "Epoch 9936, reconstruction losses: 0.02049052216418222, regression losses: 0.10262132200561712, validation losses: 0.4414060825334132\n",
      "Epoch 9937, reconstruction losses: 0.022610709832587443, regression losses: 0.11371668201670293, validation losses: 0.4377138037728168\n",
      "Epoch 9938, reconstruction losses: 0.018521178783482577, regression losses: 0.08759966953757146, validation losses: 0.4528773827954999\n",
      "Epoch 9939, reconstruction losses: 0.023011189221161913, regression losses: 0.15571047767983892, validation losses: 0.473160975903135\n",
      "Epoch 9940, reconstruction losses: 0.022650449772901007, regression losses: 0.3860186533496749, validation losses: 0.5277544762301914\n",
      "Epoch 9941, reconstruction losses: 0.018945608471991768, regression losses: 0.10908261957205807, validation losses: 0.545225895167809\n",
      "Epoch 9942, reconstruction losses: 0.020920740184771414, regression losses: 0.11552467480071234, validation losses: 0.5945655834778493\n",
      "Epoch 9943, reconstruction losses: 0.022670627484188747, regression losses: 0.1339161000919863, validation losses: 0.48255123509807285\n",
      "Epoch 9944, reconstruction losses: 0.0198488997518436, regression losses: 0.10601266022320241, validation losses: 0.4960671297735059\n",
      "Epoch 9945, reconstruction losses: 0.01890753076951519, regression losses: 0.12567165316581458, validation losses: 0.4877032555132922\n",
      "Epoch 9946, reconstruction losses: 0.01956431569461557, regression losses: 0.09669391522842463, validation losses: 0.43179926732267365\n",
      "Epoch 9947, reconstruction losses: 0.023026030200820526, regression losses: 0.18810090112563196, validation losses: 0.4415552677467699\n",
      "Epoch 9948, reconstruction losses: 0.02297675403711759, regression losses: 0.11600316871030703, validation losses: 0.513643696956759\n",
      "Epoch 9949, reconstruction losses: 0.019101256327538275, regression losses: 0.10198066962461584, validation losses: 0.4950821712247634\n",
      "Epoch 9950, reconstruction losses: 0.018959693774225867, regression losses: 0.0962963977507495, validation losses: 0.4636470709840871\n",
      "Epoch 9951, reconstruction losses: 0.02093599639540889, regression losses: 0.11103867664608952, validation losses: 0.4657158129018515\n",
      "Epoch 9952, reconstruction losses: 0.02130811020246006, regression losses: 0.09117566562659292, validation losses: 0.4457964582467133\n",
      "Epoch 9953, reconstruction losses: 0.020898335530441944, regression losses: 0.13324279260269986, validation losses: 0.44678417913380053\n",
      "Epoch 9954, reconstruction losses: 0.023085956571472232, regression losses: 0.09713362302369657, validation losses: 0.4661695333950659\n",
      "Epoch 9955, reconstruction losses: 0.02685045912309126, regression losses: 0.15191240741548015, validation losses: 0.5142381169832817\n",
      "Epoch 9956, reconstruction losses: 0.02242493148956361, regression losses: 0.1719973032206084, validation losses: 0.5542220719481923\n",
      "Epoch 9957, reconstruction losses: 0.024611253894975732, regression losses: 0.13928090802073434, validation losses: 0.5865937784673583\n",
      "Epoch 9958, reconstruction losses: 0.02221150232827139, regression losses: 0.17646190259335154, validation losses: 0.6393957759901818\n",
      "Epoch 9959, reconstruction losses: 0.025263429774388262, regression losses: 0.15578384396774553, validation losses: 0.657954764660764\n",
      "Epoch 9960, reconstruction losses: 0.02754223896831291, regression losses: 0.1339691381867124, validation losses: 0.5445290346601034\n",
      "Epoch 9961, reconstruction losses: 0.01969992265697701, regression losses: 0.14030647593122786, validation losses: 0.5194348888351057\n",
      "Epoch 9962, reconstruction losses: 0.020344975765063392, regression losses: 0.118462219312334, validation losses: 0.502599811021897\n",
      "Epoch 9963, reconstruction losses: 0.022449607555812403, regression losses: 0.15714649645058454, validation losses: 0.5584041916699843\n",
      "Epoch 9964, reconstruction losses: 0.028285881751148455, regression losses: 0.29145513537259105, validation losses: 0.5665446583548717\n",
      "Epoch 9965, reconstruction losses: 0.01784262373241591, regression losses: 0.10789531672707024, validation losses: 0.6369170077761456\n",
      "Epoch 9966, reconstruction losses: 0.020431065204059067, regression losses: 0.11597725036170693, validation losses: 0.56949252607521\n",
      "Epoch 9967, reconstruction losses: 0.02012437379278496, regression losses: 0.12320186005003457, validation losses: 0.5130414763914632\n",
      "Epoch 9968, reconstruction losses: 0.01770194457836323, regression losses: 0.13250823971029363, validation losses: 0.5421683772598469\n",
      "Epoch 9969, reconstruction losses: 0.021160407091030068, regression losses: 0.09414383413228035, validation losses: 0.5018081423942994\n",
      "Epoch 9970, reconstruction losses: 0.02583880107528453, regression losses: 0.21475114445050147, validation losses: 0.4977718652437699\n",
      "Epoch 9971, reconstruction losses: 0.021384688292137147, regression losses: 0.11698578176526955, validation losses: 0.6359337321568881\n",
      "Epoch 9972, reconstruction losses: 0.02210306814400303, regression losses: 0.1291457991911794, validation losses: 0.5293865538166123\n",
      "Epoch 9973, reconstruction losses: 0.019777610947089668, regression losses: 0.09521948073378395, validation losses: 0.4978209045951636\n",
      "Epoch 9974, reconstruction losses: 0.01658613028218995, regression losses: 0.14516427267445778, validation losses: 0.5277043901718533\n",
      "Epoch 9975, reconstruction losses: 0.019677995127917715, regression losses: 0.1732199170072364, validation losses: 0.49207647084653616\n",
      "Epoch 9976, reconstruction losses: 0.02318739369980336, regression losses: 0.1838240974161379, validation losses: 0.5227398827065426\n",
      "Epoch 9977, reconstruction losses: 0.018740609501952225, regression losses: 0.13919980979606314, validation losses: 0.5230316290284607\n",
      "Epoch 9978, reconstruction losses: 0.022528460807739504, regression losses: 0.11479375749120962, validation losses: 0.4803938800958967\n",
      "Epoch 9979, reconstruction losses: 0.020068566599463315, regression losses: 0.1135297235807411, validation losses: 0.46831439444160217\n",
      "Epoch 9980, reconstruction losses: 0.01980342556094358, regression losses: 0.09923227163882885, validation losses: 0.47012545816576545\n",
      "Epoch 9981, reconstruction losses: 0.02029422345918531, regression losses: 0.12317466378756987, validation losses: 0.4756260222365216\n",
      "Epoch 9982, reconstruction losses: 0.019982037567355875, regression losses: 0.09551339471094858, validation losses: 0.48023177065346384\n",
      "Epoch 9983, reconstruction losses: 0.02064659390098974, regression losses: 0.11292202911480356, validation losses: 0.5021010763866048\n",
      "Epoch 9984, reconstruction losses: 0.020116310110110985, regression losses: 0.10374528846869407, validation losses: 0.5667416551467599\n",
      "Epoch 9985, reconstruction losses: 0.020308242056963712, regression losses: 0.1596331225278836, validation losses: 0.5108832639047873\n",
      "Epoch 9986, reconstruction losses: 0.022054118906482886, regression losses: 0.09830398418967858, validation losses: 0.4542884393670665\n",
      "Epoch 9987, reconstruction losses: 0.022209048801329775, regression losses: 0.1356291717179218, validation losses: 0.45201177937668163\n",
      "Epoch 9988, reconstruction losses: 0.019178972555133622, regression losses: 0.11672659451703539, validation losses: 0.44314489536616314\n",
      "Epoch 9989, reconstruction losses: 0.02361743818377647, regression losses: 0.11568553618621284, validation losses: 0.49136728956396664\n",
      "Epoch 9990, reconstruction losses: 0.020968536117142368, regression losses: 0.11650961479424596, validation losses: 0.5308810998874548\n",
      "Epoch 9991, reconstruction losses: 0.020021262055151187, regression losses: 0.1192338714984243, validation losses: 0.4745233760926284\n",
      "Epoch 9992, reconstruction losses: 0.019676522110445783, regression losses: 0.1286744212563385, validation losses: 0.44480289153361174\n",
      "Epoch 9993, reconstruction losses: 0.02209000419964555, regression losses: 0.14467472639664822, validation losses: 0.42627863264686944\n",
      "Epoch 9994, reconstruction losses: 0.020321892529072454, regression losses: 0.10632885206115199, validation losses: 0.4327694940223667\n",
      "Epoch 9995, reconstruction losses: 0.023788677692887363, regression losses: 0.16078956578181364, validation losses: 0.4499482171876908\n",
      "Epoch 9996, reconstruction losses: 0.02028215494886859, regression losses: 0.1324509671001144, validation losses: 0.5214950830422707\n",
      "Epoch 9997, reconstruction losses: 0.02316327672194142, regression losses: 0.08920746631511879, validation losses: 0.4545959644275316\n",
      "Epoch 9998, reconstruction losses: 0.02183261869235213, regression losses: 0.14293453947358492, validation losses: 0.43706929954168866\n",
      "Epoch 9999, reconstruction losses: 0.02002914480742619, regression losses: 0.10484010153997084, validation losses: 0.5328342751532888\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_format()\n",
    "\n",
    "dataset, method = config.values()\n",
    "\n",
    "training_wifi_pos, testing_wifi_pos = load(dataset)\n",
    "\n",
    "boundary = get_boundary(training_wifi_pos[:, -2:], testing_wifi_pos[:, -2:])\n",
    "\n",
    "DSAR_training(dataset, training_wifi_pos, boundary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_pos, testing_err, rssi_reconst = DSAR_testing(testing_wifi_pos, dataset, boundary)\n",
    "avg_test_err= sum(testing_err) / len(testing_err)\n",
    "plot_wifi_pos(dataset, method, training_wifi_pos[:,-2:], testing_wifi_pos[:,-2:], testing_pos, testing_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label = [-1. 14.] -> predicted label = [-2.16374601 13.71739015], err = (1.1975696685907962+0j)\n",
      "original label = [-1. 20.] -> predicted label = [-1.51270375 20.04159081], err = (0.5143879150035002+0j)\n",
      "original label = [-10.  14.] -> predicted label = [-13.97418685  14.08899312], err = (3.9751831240276023+0j)\n",
      "original label = [-10.  16.] -> predicted label = [-10.10748015  18.55067257], err = (2.5529360626373045+0j)\n",
      "original label = [-10.  18.] -> predicted label = [-9.03956714 19.884969  ], err = (2.1155470722987086+0j)\n",
      "original label = [-10.  20.] -> predicted label = [-9.30997741 20.38098716], err = (0.7882146883206939+0j)\n",
      "original label = [-10.  22.] -> predicted label = [-9.23688763 20.53966033], err = (1.6477052009285018+0j)\n",
      "original label = [-11.  14.] -> predicted label = [-13.57521238  14.50817085], err = (2.624872644456429+0j)\n",
      "original label = [-11.  20.] -> predicted label = [-9.60780583 20.49811838], err = (1.4786231859713752+0j)\n",
      "original label = [-13.  14.] -> predicted label = [-14.95062319  14.55630152], err = (2.0283989291847075+0j)\n",
      "original label = [-13.  20.] -> predicted label = [-12.64855573  20.35084768], err = (0.496595580524451+0j)\n",
      "original label = [-14.  14.] -> predicted label = [-14.35687647  14.70771037], err = (0.7926000145912803+0j)\n",
      "original label = [-14.  16.] -> predicted label = [-15.7301142  14.6232615], err = (2.2110413943747282+0j)\n",
      "original label = [-14.  18.] -> predicted label = [-13.75848644  20.03924296], err = (2.053494740456778+0j)\n",
      "original label = [-14.  20.] -> predicted label = [-13.86337475  20.39879862], err = (0.4215528444503591+0j)\n",
      "original label = [-14.  22.] -> predicted label = [-13.7372773   20.37962546], err = (1.6415349117648304+0j)\n",
      "original label = [-15.  14.] -> predicted label = [-16.3147029   14.21969935], err = (1.3329334253038103+0j)\n",
      "original label = [-17.  14.] -> predicted label = [-16.66083092  14.63096385], err = (0.7163456225423638+0j)\n",
      "original label = [-19.  14.] -> predicted label = [-16.70899055  14.59762918], err = (2.36767500518868+0j)\n",
      "original label = [-3. 14.] -> predicted label = [-3.66737619 13.77905975], err = (0.7029975597995971+0j)\n",
      "original label = [-3. 20.] -> predicted label = [-4.4899526  20.18820141], err = (1.5017917717057347+0j)\n",
      "original label = [-5. 14.] -> predicted label = [-6.00958648 13.81280145], err = (1.0267950894647746+0j)\n",
      "original label = [-5. 20.] -> predicted label = [-6.34777944 20.27960231], err = (1.376476246262512+0j)\n",
      "original label = [-7. 14.] -> predicted label = [-7.34094118 13.70671482], err = (0.4497300132761392+0j)\n",
      "original label = [-7. 20.] -> predicted label = [-7.41946972 20.36524673], err = (0.5562014157880422+0j)\n",
      "original label = [-9. 14.] -> predicted label = [-7.41965882 13.96894478], err = (1.5806462824806595+0j)\n",
      "original label = [-9. 20.] -> predicted label = [-9.05498664 20.31903604], err = (0.3237399083168407+0j)\n",
      "testing avg error = 1.4250218636189333\n"
     ]
    }
   ],
   "source": [
    "#listing the difference of original label and predicted label\n",
    "import cmath\n",
    "testing_labels = testing_wifi_pos[:, -2:]\n",
    "for i, label in enumerate(testing_labels):\n",
    "    err = (label - testing_pos[i])\n",
    "    err = cmath.sqrt(err[0]**2 + err[-1]**2)\n",
    "    print(f\"original label = {label} -> predicted label = {testing_pos[i]}, err = {err}\")\n",
    "print(f\"testing avg error = {avg_test_err}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6ddf36f5b06b2d1dffbdce440328aa987a3baf133dab91692508e7a923335d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = {\n",
    "    #'dataset': 'IPIN2020_Track3_5F', #['NTU_CSIE_5F', 'DSI', 'IPIN2016_Tutorial', 'IPIN2020_Track3_2F', 'IPIN2020_Track3_3F', 'IPIN2020_Track3_5F']\n",
    "    'dataset':'NTUH_2F',\n",
    "    'method': 'DSAR',#['WKNN', 'RandomForest', 'WiDeep', 'DSAR']\n",
    "}\n",
    "\n",
    "def check_format():\n",
    "    assert config['method'] in ['WKNN', 'RandomForest', 'WiDeep', 'DSAR'], \\\n",
    "        'config method should be [WKNN, RandomForest, WiDeep, DSAR]'\n",
    "    assert config['dataset'] in ['NTUH_2F','NTU_CSIE_5F', 'DSI', 'IPIN2016_Tutorial', 'IPIN2020_Track3_2F', 'IPIN2020_Track3_3F', 'IPIN2020_Track3_5F'], \\\n",
    "        'config dataset should be [NTU_CSIE_5F, DSI, IPIN2016_Tutorial, IPIN2020_Track3_2F, IPIN2020_Track3_3F, IPIN2020_Track3_5F]'\n",
    "\n",
    "\n",
    "\n",
    "def load(dataset):\n",
    "    dir_path = osp.join(os.getcwd(), 'Dataset', dataset)\n",
    "\n",
    "    training_wifi_pos = np.load(osp.join(dir_path, 'training_wifi_pos.npy'))\n",
    "    testing_wifi_pos = np.load(osp.join(dir_path, 'testing_wifi_pos.npy'))\n",
    "\n",
    "    return training_wifi_pos, testing_wifi_pos\n",
    "\n",
    "\n",
    "\n",
    "def normalize_rssi(rssi):\n",
    "    return (rssi + 100) / 100\n",
    "\n",
    "\n",
    "\n",
    "def normalize_pos(pos, boundary):\n",
    "    max_x, min_x, max_y, min_y = boundary\n",
    "    norm_pos = np.zeros_like(pos)\n",
    "    norm_pos[:,0] = (pos[:,0] - min_x) / (max_x - min_x)\n",
    "    norm_pos[:,1] = (pos[:,1] - min_y) / (max_y - min_y)\n",
    "    return norm_pos\n",
    "\n",
    "\n",
    "\n",
    "def restore_pos(norm_pos, boundary):\n",
    "    max_x, min_x, max_y, min_y = boundary\n",
    "    pos = np.zeros_like(norm_pos)\n",
    "    pos[:,0] = norm_pos[:,0] * (max_x - min_x) + min_x\n",
    "    pos[:,1] = norm_pos[:,1] * (max_y - min_y) + min_y\n",
    "    return pos\n",
    "\n",
    "\n",
    "\n",
    "def get_rps(training_wifi_pos):\n",
    "\n",
    "    rps = {}\n",
    "    for i in range(training_wifi_pos.shape[0]):\n",
    "        pos = tuple(training_wifi_pos[i,-2:])\n",
    "        if pos not in rps:\n",
    "            rps[pos] = training_wifi_pos[None,i,:-2]\n",
    "        else:\n",
    "            rps[pos] = np.r_[rps[pos], training_wifi_pos[None,i,:-2]]\n",
    "    return rps\n",
    "        \n",
    "\n",
    "\n",
    "def add_noise(rssi):\n",
    "    noisy_rssi = rssi + torch.normal(0, 0.1, rssi.shape)\n",
    "    noisy_rssi = torch.clip(noisy_rssi, 0, 1)\n",
    "    mask = torch.rand(rssi.shape) < 0.1\n",
    "    noisy_rssi[mask] = 0\n",
    "    return noisy_rssi\n",
    "    \n",
    "\n",
    "\n",
    "def get_boundary(training_pos, testing_pos):\n",
    "    max_x = max(training_pos[:,0].max(), testing_pos[:,0].max())\n",
    "    min_x = min(training_pos[:,0].min(), testing_pos[:,0].min())\n",
    "    max_y = max(training_pos[:,1].max(), testing_pos[:,1].max())\n",
    "    min_y = min(training_pos[:,1].min(), testing_pos[:,1].min())\n",
    "    \n",
    "    return (max_x, min_x, max_y, min_y)\n",
    "\n",
    "\n",
    "\n",
    "def RBF(origin, reconstruction, gamma=16, axis=None):\n",
    "    return np.e**(-gamma * np.linalg.norm(origin - reconstruction, axis=axis)**2)\n",
    "\n",
    "\n",
    "\n",
    "def plot_wifi_pos(dataset, method, training_pos, testing_pos, pred_pos, pred_err):\n",
    "\n",
    "    dir_path = osp.join(os.getcwd(), 'Result', dataset, method)\n",
    "\n",
    "    fig, (axs0, axs1, axs2) = plt.subplots(1, 3, figsize=(20, 5), sharex=True, sharey=True)\n",
    "\n",
    "    axs0.plot(training_pos[:,0], training_pos[:,1], 'ob')\n",
    "    axs0.set_title('Training Points')\n",
    "    axs0.grid()\n",
    "\n",
    "    axs1.plot(testing_pos[:,0], testing_pos[:,1], 'og')\n",
    "    axs1.set_title('Testing Points')\n",
    "    axs1.grid()\n",
    "\n",
    "    axs2.plot(pred_pos[:,0], pred_pos[:,1], 'or')\n",
    "    axs2.set_title('Prediction Points')\n",
    "    axs2.grid()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(osp.join(dir_path, dataset), bbox_inches='tight')\n",
    "    np.save(osp.join(dir_path, 'loc_err.npy'), pred_err)\n",
    "    np.save(osp.join(dir_path, 'pred_pos.npy'), pred_pos)\n",
    "    \n",
    "    \n",
    "def plot_loss(r_losses, reg_losses, v_losses):\n",
    "    x = [i for i in range(len(r_losses))]\n",
    "    \n",
    "    plt.plot(x, r_losses , label = \"rec loss\")\n",
    "    plt.plot(x, reg_losses, label = \"reg loss\")\n",
    "    plt.plot(x, v_losses, label = \"val loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def DSAR_testing(query_wifi_pos, dataset, boundary):\n",
    "\n",
    "    dir_path = osp.join(os.getcwd(), 'Result', dataset, 'DSAR')\n",
    "    inputs = normalize_rssi(query_wifi_pos[:,:-2])\n",
    "    labels = query_wifi_pos[:,-2:]\n",
    "\n",
    "    path = osp.join(dir_path, 'dsar.pth') \n",
    "    network = torch.load(path).to(device) # if u don't have gpu, add map_location='cpu' in load's parameter\n",
    "    network.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.from_numpy(inputs).to(device)\n",
    "        rssi_reconst, pos = network(inputs)\n",
    "        rssi_reconst = rssi_reconst.cpu().numpy()\n",
    "        pred_pos = restore_pos(pos.cpu().numpy(), boundary)\n",
    "        loc_err = np.linalg.norm(pred_pos - labels, axis=1)\n",
    "\n",
    "    return pred_pos, loc_err, rssi_reconst\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DenoisingAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DenoisingAutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, input_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('sigmoid')) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AutoRegression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AutoRegression, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2),\n",
    "        )\n",
    "\n",
    "\n",
    "        for m in self.encoder.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('sigmoid'))\n",
    "        for m in self.decoder.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('sigmoid'))\n",
    "\n",
    "        for m in self.regression.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu')) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        o1 = self.decoder(x)\n",
    "        o2 = self.regression(x)\n",
    "        return (o1, o2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RadioMap(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = torch.from_numpy(inputs)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.inputs[index], self.labels[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def DSAR_training(dataset, training_wifi_pos, boundary):\n",
    "    dir_path = osp.join(os.getcwd(), 'Result', dataset, 'DSAR')\n",
    "    rps = get_rps(training_wifi_pos)\n",
    "\n",
    "    inputs = normalize_rssi(training_wifi_pos[:,:-2])\n",
    "    labels = normalize_pos(training_wifi_pos[:,-2:], boundary)\n",
    "    radio_map = RadioMap(inputs, labels)\n",
    "    loader = DataLoader(dataset=radio_map, shuffle=True, batch_size=16)\n",
    "    \n",
    "    r_losses = []\n",
    "    reg_losses = []\n",
    "    V_losses = []\n",
    "\n",
    "    val_inputs = []\n",
    "    val_labels = []\n",
    "    for rp_pos in rps:\n",
    "        val_inputs.append(np.average(rps[rp_pos], axis=0))\n",
    "        val_labels.append(np.array(rp_pos, dtype=np.float64))\n",
    "\n",
    "    val_inputs = normalize_rssi(np.array(val_inputs, dtype=np.float64))\n",
    "    val_labels = normalize_pos(np.array(val_labels, dtype=np.float64), boundary)\n",
    "    val_radio_map = RadioMap(val_inputs, val_labels)\n",
    "    val_loader = DataLoader(dataset=val_radio_map, shuffle=True, batch_size=8)\n",
    "\n",
    "    epochs = 5000\n",
    "    input_size = training_wifi_pos.shape[1] - 2\n",
    "    hidden_size = len(rps)\n",
    "\n",
    "    network = AutoRegression(input_size, hidden_size).to(device)        \n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    losses = np.zeros((epochs,3), dtype=np.float64)\n",
    "\n",
    "    network.train()\n",
    "    for epoch in range(epochs):\n",
    "        reconst_losses = 0.0\n",
    "        regression_losses = 0.0\n",
    "\n",
    "        for inputs, labels in loader:\n",
    "\n",
    "            noisy_inputs = add_noise(inputs).to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            reconst_rssi, pos = network(noisy_inputs)\n",
    "\n",
    "            reconst_loss = criterion(inputs, reconst_rssi)\n",
    "            regression_loss = criterion(labels, pos)\n",
    "\n",
    "            loss = reconst_loss + regression_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            reconst_losses += reconst_loss.item()\n",
    "            regression_losses += regression_loss.item()\n",
    "        \n",
    "        losses[epoch,0] = reconst_losses\n",
    "        losses[epoch,1] = regression_losses\n",
    "\n",
    "        network.eval()\n",
    "        val_losses = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                reconst, pos = network(inputs)\n",
    "                val_losses += (labels - pos).pow(2).sum()\n",
    "        \n",
    "        losses[epoch,2] = val_losses\n",
    "\n",
    "        if val_losses < best_val_loss:\n",
    "            best_val_loss = val_losses\n",
    "            torch.save(network, osp.join(dir_path, 'dsar.pth'))\n",
    "        \n",
    "        r_losses.append(reconst_losses)\n",
    "        reg_losses.append(regression_losses)\n",
    "        V_losses.append(val_losses.item())\n",
    "       \n",
    "        print(f'Epoch {epoch}, reconstruction losses: {reconst_losses}, regression losses: {regression_losses}, validation losses: {val_losses}')\n",
    "\n",
    "    np.save(osp.join(dir_path, 'losses.npy'), losses)\n",
    "    \n",
    "    plot_loss(r_losses, reg_losses, V_losses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, reconstruction losses: 0.9477538807687018, regression losses: 1.1508722406969627, validation losses: 6.347909588551528\n",
      "Epoch 1, reconstruction losses: 0.2507860024340247, regression losses: 0.7258469797800299, validation losses: 5.6589360762581435\n",
      "Epoch 2, reconstruction losses: 0.08384497729130905, regression losses: 0.6414799434337606, validation losses: 5.991634855186013\n",
      "Epoch 3, reconstruction losses: 0.05997190392673346, regression losses: 0.789053103002384, validation losses: 5.932682746216062\n",
      "Epoch 4, reconstruction losses: 0.05839559410630722, regression losses: 0.6576198410733657, validation losses: 5.754509096321535\n",
      "Epoch 5, reconstruction losses: 0.05727001716192889, regression losses: 0.6621727961997653, validation losses: 6.2473921573235325\n",
      "Epoch 6, reconstruction losses: 0.05696817215418586, regression losses: 0.8133088935288684, validation losses: 5.615992575894057\n",
      "Epoch 7, reconstruction losses: 0.0553318606057574, regression losses: 0.6518153119684573, validation losses: 5.748928568877899\n",
      "Epoch 8, reconstruction losses: 0.05074204342962596, regression losses: 0.7180782072159637, validation losses: 5.787235325283665\n",
      "Epoch 9, reconstruction losses: 0.055359766593313514, regression losses: 0.7896152445036279, validation losses: 6.2973707920984925\n",
      "Epoch 10, reconstruction losses: 0.04918425582975852, regression losses: 0.8222209193445029, validation losses: 5.690656476089231\n",
      "Epoch 11, reconstruction losses: 0.04871199173346055, regression losses: 0.5250006822971649, validation losses: 5.627905664408422\n",
      "Epoch 12, reconstruction losses: 0.04954252343066714, regression losses: 0.6389389746933333, validation losses: 5.594989297196982\n",
      "Epoch 13, reconstruction losses: 0.0461673040640279, regression losses: 0.5648077303627923, validation losses: 5.614417131621334\n",
      "Epoch 14, reconstruction losses: 0.05072064410626802, regression losses: 0.6215703210757174, validation losses: 5.519014679124431\n",
      "Epoch 15, reconstruction losses: 0.05060007800239938, regression losses: 0.600410234688705, validation losses: 5.531637000011929\n",
      "Epoch 16, reconstruction losses: 0.047640821232339176, regression losses: 0.5727224068784541, validation losses: 5.85982218022782\n",
      "Epoch 17, reconstruction losses: 0.04994763189797325, regression losses: 0.6469950129530873, validation losses: 5.499613010162422\n",
      "Epoch 18, reconstruction losses: 0.050252014383034435, regression losses: 0.6983939229698083, validation losses: 5.850326002581436\n",
      "Epoch 19, reconstruction losses: 0.05288706314267143, regression losses: 0.6630007671374497, validation losses: 5.698012890087909\n",
      "Epoch 20, reconstruction losses: 0.048670762114284054, regression losses: 0.5638399480110365, validation losses: 5.453683520987165\n",
      "Epoch 21, reconstruction losses: 0.049851272144721445, regression losses: 0.5806359768160431, validation losses: 5.597335387885546\n",
      "Epoch 22, reconstruction losses: 0.04941148228154539, regression losses: 0.5772069531657993, validation losses: 5.555254269242133\n",
      "Epoch 23, reconstruction losses: 0.0502231683690604, regression losses: 0.5865184625198573, validation losses: 5.446169366218532\n",
      "Epoch 24, reconstruction losses: 0.055188327933531074, regression losses: 0.6685840147484527, validation losses: 5.429745386602801\n",
      "Epoch 25, reconstruction losses: 0.055988640600277, regression losses: 0.6497262141209745, validation losses: 5.645504409548568\n",
      "Epoch 26, reconstruction losses: 0.05856470497555831, regression losses: 0.682305614802306, validation losses: 5.459433552446016\n",
      "Epoch 27, reconstruction losses: 0.052121037722812714, regression losses: 0.6632499878630134, validation losses: 5.493348721638359\n",
      "Epoch 28, reconstruction losses: 0.04856343904897127, regression losses: 0.6086539144251052, validation losses: 5.49513238718405\n",
      "Epoch 29, reconstruction losses: 0.04719820182124241, regression losses: 0.5652557867166568, validation losses: 5.402966617239341\n",
      "Epoch 30, reconstruction losses: 0.05120685317602109, regression losses: 0.5539727762967066, validation losses: 5.52532090568064\n",
      "Epoch 31, reconstruction losses: 0.04887854059352814, regression losses: 0.586593152019353, validation losses: 5.652377009634752\n",
      "Epoch 32, reconstruction losses: 0.05160257899027218, regression losses: 0.6016995314172976, validation losses: 5.329016337419947\n",
      "Epoch 33, reconstruction losses: 0.048462873253198785, regression losses: 0.6753194485215633, validation losses: 5.5180888535720065\n",
      "Epoch 34, reconstruction losses: 0.0490839347514872, regression losses: 0.5775622165892794, validation losses: 5.715859966835073\n",
      "Epoch 35, reconstruction losses: 0.04943864370444613, regression losses: 0.579006148468423, validation losses: 5.405351233619293\n",
      "Epoch 36, reconstruction losses: 0.04864701697175919, regression losses: 0.676010407481155, validation losses: 5.230249400478558\n",
      "Epoch 37, reconstruction losses: 0.04968037576208387, regression losses: 0.597571282356345, validation losses: 5.218817528786242\n",
      "Epoch 38, reconstruction losses: 0.046609696158181016, regression losses: 0.5745050925101669, validation losses: 5.539407706809576\n",
      "Epoch 39, reconstruction losses: 0.05248285015399799, regression losses: 0.6565669044171362, validation losses: 5.132006921293381\n",
      "Epoch 40, reconstruction losses: 0.04750400452812205, regression losses: 0.5792898311483795, validation losses: 5.122169112417834\n",
      "Epoch 41, reconstruction losses: 0.053533806066640766, regression losses: 0.5605269505017508, validation losses: 5.1079139905033575\n",
      "Epoch 42, reconstruction losses: 0.04780283780268024, regression losses: 0.5516252560944731, validation losses: 5.230488404295731\n",
      "Epoch 43, reconstruction losses: 0.047118811779198445, regression losses: 0.5530270028131647, validation losses: 5.082829429993782\n",
      "Epoch 44, reconstruction losses: 0.05232675675965236, regression losses: 0.5898394197674361, validation losses: 5.3537129766592955\n",
      "Epoch 45, reconstruction losses: 0.04730696693086195, regression losses: 0.562394231159979, validation losses: 4.900593600515705\n",
      "Epoch 46, reconstruction losses: 0.04596122228866165, regression losses: 0.543146720125482, validation losses: 4.856407459060546\n",
      "Epoch 47, reconstruction losses: 0.051363785671089554, regression losses: 0.568593170176306, validation losses: 4.860133870973954\n",
      "Epoch 48, reconstruction losses: 0.05042471433057777, regression losses: 0.5329786107884641, validation losses: 4.82081225796576\n",
      "Epoch 49, reconstruction losses: 0.052896497335142026, regression losses: 0.6464741522672135, validation losses: 4.701098409067322\n",
      "Epoch 50, reconstruction losses: 0.05354495716067445, regression losses: 0.6070248122248859, validation losses: 4.93129961309994\n",
      "Epoch 51, reconstruction losses: 0.04901377715134719, regression losses: 0.5264032134233972, validation losses: 4.551860287045571\n",
      "Epoch 52, reconstruction losses: 0.049952942749311495, regression losses: 0.5466914039299493, validation losses: 4.438701910690641\n",
      "Epoch 53, reconstruction losses: 0.049114455305613404, regression losses: 0.44502521225871833, validation losses: 4.306122715987847\n",
      "Epoch 54, reconstruction losses: 0.05946005187677296, regression losses: 0.6213571322641489, validation losses: 4.204526204182892\n",
      "Epoch 55, reconstruction losses: 0.04737133639249611, regression losses: 0.5081930581309103, validation losses: 4.303030520987198\n",
      "Epoch 56, reconstruction losses: 0.054676962997957455, regression losses: 0.5505174958162851, validation losses: 4.184336038100391\n",
      "Epoch 57, reconstruction losses: 0.05178376629008618, regression losses: 0.4356075013998045, validation losses: 3.9100904677611688\n",
      "Epoch 58, reconstruction losses: 0.04808716774335877, regression losses: 0.40566514863106284, validation losses: 3.669826368055892\n",
      "Epoch 59, reconstruction losses: 0.05945065803489206, regression losses: 0.5599612841548545, validation losses: 3.6439702790451123\n",
      "Epoch 60, reconstruction losses: 0.05009038437002824, regression losses: 0.44594844217276497, validation losses: 3.7917461564036983\n",
      "Epoch 61, reconstruction losses: 0.048934607863502205, regression losses: 0.4180347231917174, validation losses: 3.4274039594102232\n",
      "Epoch 62, reconstruction losses: 0.053488832592008484, regression losses: 0.42385248884610616, validation losses: 3.3278005536219197\n",
      "Epoch 63, reconstruction losses: 0.04732983456480716, regression losses: 0.4329863201408535, validation losses: 3.2496982482864096\n",
      "Epoch 64, reconstruction losses: 0.04937793366490502, regression losses: 0.3985141491786171, validation losses: 3.240109417139191\n",
      "Epoch 65, reconstruction losses: 0.052854770478015206, regression losses: 0.5595844088030555, validation losses: 3.201084488782413\n",
      "Epoch 66, reconstruction losses: 0.04766371286418947, regression losses: 0.35971228253989534, validation losses: 3.198615016054012\n",
      "Epoch 67, reconstruction losses: 0.04584609516036241, regression losses: 0.3981573699235669, validation losses: 3.2301608626214415\n",
      "Epoch 68, reconstruction losses: 0.049156434620356584, regression losses: 0.405782396360313, validation losses: 3.1544657886705862\n",
      "Epoch 69, reconstruction losses: 0.04891524002398174, regression losses: 0.36126669004763945, validation losses: 2.89313689556978\n",
      "Epoch 70, reconstruction losses: 0.05466111240053009, regression losses: 0.32445543872487276, validation losses: 2.9103240555457957\n",
      "Epoch 71, reconstruction losses: 0.048256066942818004, regression losses: 0.4165161786948216, validation losses: 2.934060032764421\n",
      "Epoch 72, reconstruction losses: 0.052017003315639125, regression losses: 0.3366866793999259, validation losses: 2.7851602928166814\n",
      "Epoch 73, reconstruction losses: 0.053043542420549594, regression losses: 0.3460859673569742, validation losses: 2.792551390722261\n",
      "Epoch 74, reconstruction losses: 0.0517606916028911, regression losses: 0.4658611118564143, validation losses: 3.1008501584291426\n",
      "Epoch 75, reconstruction losses: 0.05236920097207813, regression losses: 0.3833523111340492, validation losses: 3.367236779243128\n",
      "Epoch 76, reconstruction losses: 0.05038047250013322, regression losses: 0.46126058604779757, validation losses: 2.8128391915598865\n",
      "Epoch 77, reconstruction losses: 0.046255177168649124, regression losses: 0.3527454077364379, validation losses: 3.254301444428982\n",
      "Epoch 78, reconstruction losses: 0.04815597311342539, regression losses: 0.4232254480622644, validation losses: 2.864571312718871\n",
      "Epoch 79, reconstruction losses: 0.047089039523927366, regression losses: 0.3618638597506028, validation losses: 2.7381315650523255\n",
      "Epoch 80, reconstruction losses: 0.050959353146754024, regression losses: 0.3834229467072143, validation losses: 2.7599120799981827\n",
      "Epoch 81, reconstruction losses: 0.05504490198391469, regression losses: 0.41843596624570567, validation losses: 2.8289655084133507\n",
      "Epoch 82, reconstruction losses: 0.05144396682088824, regression losses: 0.32210251692628816, validation losses: 2.724976800136935\n",
      "Epoch 83, reconstruction losses: 0.04852573792268598, regression losses: 0.3484505861735736, validation losses: 2.6426125691772944\n",
      "Epoch 84, reconstruction losses: 0.05557925036039339, regression losses: 0.38428104310622746, validation losses: 2.585294189540001\n",
      "Epoch 85, reconstruction losses: 0.04976336593277654, regression losses: 0.34000069508893804, validation losses: 2.5975550488971195\n",
      "Epoch 86, reconstruction losses: 0.05409831228979047, regression losses: 0.3797616876817055, validation losses: 2.624299324176053\n",
      "Epoch 87, reconstruction losses: 0.05225798266055172, regression losses: 0.33627242649608136, validation losses: 2.653664295971926\n",
      "Epoch 88, reconstruction losses: 0.05092494008006714, regression losses: 0.34937396079388466, validation losses: 2.772044894518753\n",
      "Epoch 89, reconstruction losses: 0.048778474101705646, regression losses: 0.32061146094735427, validation losses: 2.9790359122477517\n",
      "Epoch 90, reconstruction losses: 0.05350264318208674, regression losses: 0.4138230163173149, validation losses: 2.6172291332158113\n",
      "Epoch 91, reconstruction losses: 0.053875789788253275, regression losses: 0.45228645441029114, validation losses: 2.649248114142133\n",
      "Epoch 92, reconstruction losses: 0.052750297683628995, regression losses: 0.36988683762566577, validation losses: 2.742146708004341\n",
      "Epoch 93, reconstruction losses: 0.053071629027210014, regression losses: 0.29819286450763255, validation losses: 2.594876224748844\n",
      "Epoch 94, reconstruction losses: 0.049774702336594256, regression losses: 0.3094991857883458, validation losses: 2.589813396134348\n",
      "Epoch 95, reconstruction losses: 0.0510029167954413, regression losses: 0.3674229179822685, validation losses: 2.483271670958136\n",
      "Epoch 96, reconstruction losses: 0.04816882307532805, regression losses: 0.3264495723765096, validation losses: 2.449613128938829\n",
      "Epoch 97, reconstruction losses: 0.04951096992366923, regression losses: 0.330512244809995, validation losses: 2.6228402196456653\n",
      "Epoch 98, reconstruction losses: 0.05228639157891105, regression losses: 0.3458141320079481, validation losses: 2.4815105700258977\n",
      "Epoch 99, reconstruction losses: 0.05197202274998481, regression losses: 0.386186235963438, validation losses: 2.463023136056948\n",
      "Epoch 100, reconstruction losses: 0.04730733802781173, regression losses: 0.3069570516851673, validation losses: 2.435200236391326\n",
      "Epoch 101, reconstruction losses: 0.04635648901402788, regression losses: 0.30955821783929954, validation losses: 2.426666947466267\n",
      "Epoch 102, reconstruction losses: 0.053610404187972985, regression losses: 0.34003007250711703, validation losses: 2.349009853279071\n",
      "Epoch 103, reconstruction losses: 0.056864167704410926, regression losses: 0.3847648310159542, validation losses: 2.349531575867583\n",
      "Epoch 104, reconstruction losses: 0.046818231731281926, regression losses: 0.3212017274273594, validation losses: 2.471494454280725\n",
      "Epoch 105, reconstruction losses: 0.05328286724319568, regression losses: 0.4819037860487704, validation losses: 2.3903406665600446\n",
      "Epoch 106, reconstruction losses: 0.04886582816732707, regression losses: 0.36824979308574285, validation losses: 2.427944989838164\n",
      "Epoch 107, reconstruction losses: 0.05332112710366895, regression losses: 0.4127855982263594, validation losses: 2.5234946885579816\n",
      "Epoch 108, reconstruction losses: 0.047784044348807925, regression losses: 0.29590011668408506, validation losses: 2.5029884898424726\n",
      "Epoch 109, reconstruction losses: 0.05084967463174757, regression losses: 0.2934818979979863, validation losses: 2.4748470530374402\n",
      "Epoch 110, reconstruction losses: 0.05010520222681613, regression losses: 0.34677097232138154, validation losses: 2.299625937024361\n",
      "Epoch 111, reconstruction losses: 0.05018091872216775, regression losses: 0.35490564722409973, validation losses: 2.1487382601110188\n",
      "Epoch 112, reconstruction losses: 0.0608263502042018, regression losses: 0.43657975926523906, validation losses: 2.295353587950354\n",
      "Epoch 113, reconstruction losses: 0.04614432399716726, regression losses: 0.28822545791935233, validation losses: 2.2367794346322762\n",
      "Epoch 114, reconstruction losses: 0.0478853160787266, regression losses: 0.2762369098110576, validation losses: 2.1146517752647207\n",
      "Epoch 115, reconstruction losses: 0.045861206401477554, regression losses: 0.25691601037651635, validation losses: 2.0730354723480255\n",
      "Epoch 116, reconstruction losses: 0.049088858266856265, regression losses: 0.2894830885638143, validation losses: 2.1104792997242616\n",
      "Epoch 117, reconstruction losses: 0.04724635442684425, regression losses: 0.2466693414027056, validation losses: 2.077385359439531\n",
      "Epoch 118, reconstruction losses: 0.049220923715232824, regression losses: 0.2600396984498971, validation losses: 2.0492898398902417\n",
      "Epoch 119, reconstruction losses: 0.05324931037847608, regression losses: 0.25384639606868253, validation losses: 2.0937581446591524\n",
      "Epoch 120, reconstruction losses: 0.04716872105798611, regression losses: 0.2859108311391975, validation losses: 2.0098285871518264\n",
      "Epoch 121, reconstruction losses: 0.052125733676159414, regression losses: 0.30387229081962835, validation losses: 2.002564046562182\n",
      "Epoch 122, reconstruction losses: 0.05263570286565796, regression losses: 0.27239377287461536, validation losses: 2.161488885032968\n",
      "Epoch 123, reconstruction losses: 0.05211931940375761, regression losses: 0.28088026560131296, validation losses: 1.9154202577732549\n",
      "Epoch 124, reconstruction losses: 0.049191311035080884, regression losses: 0.27320960531973376, validation losses: 1.9030208961007258\n",
      "Epoch 125, reconstruction losses: 0.04619563472052741, regression losses: 0.2506327654648317, validation losses: 1.8869429289865902\n",
      "Epoch 126, reconstruction losses: 0.056890881715564716, regression losses: 0.29966991572644347, validation losses: 1.821435947672769\n",
      "Epoch 127, reconstruction losses: 0.04702001573013873, regression losses: 0.37060274711633606, validation losses: 1.9794093358896245\n",
      "Epoch 128, reconstruction losses: 0.05014772299718459, regression losses: 0.2974694744398059, validation losses: 1.8490449917888963\n",
      "Epoch 129, reconstruction losses: 0.04905073049753113, regression losses: 0.41227045542342133, validation losses: 2.1433951698975453\n",
      "Epoch 130, reconstruction losses: 0.05374587738883055, regression losses: 0.2689244265106444, validation losses: 2.219975486374708\n",
      "Epoch 131, reconstruction losses: 0.048032610925520886, regression losses: 0.26226187001585904, validation losses: 1.750175228422184\n",
      "Epoch 132, reconstruction losses: 0.04629717411122672, regression losses: 0.2704487302872699, validation losses: 1.6866890766456728\n",
      "Epoch 133, reconstruction losses: 0.04966065235576521, regression losses: 0.2702341600806994, validation losses: 1.8456516930055014\n",
      "Epoch 134, reconstruction losses: 0.053298360361417024, regression losses: 0.32365273251161286, validation losses: 1.693980990318874\n",
      "Epoch 135, reconstruction losses: 0.05853918618119945, regression losses: 0.33523090943438594, validation losses: 2.0407250963978028\n",
      "Epoch 136, reconstruction losses: 0.04614914081747426, regression losses: 0.2578232123919177, validation losses: 1.8822427094043277\n",
      "Epoch 137, reconstruction losses: 0.04908788090214448, regression losses: 0.21666767119348554, validation losses: 2.0110267064818874\n",
      "Epoch 138, reconstruction losses: 0.04558781562811873, regression losses: 0.2629474511237624, validation losses: 1.7634398517908463\n",
      "Epoch 139, reconstruction losses: 0.047840162010479734, regression losses: 0.22303746224047155, validation losses: 1.522010299004858\n",
      "Epoch 140, reconstruction losses: 0.047675902765008, regression losses: 0.23569742616834038, validation losses: 1.5518769406445034\n",
      "Epoch 141, reconstruction losses: 0.05453520558346704, regression losses: 0.2567911952926926, validation losses: 1.5635977913422638\n",
      "Epoch 142, reconstruction losses: 0.04729300105156604, regression losses: 0.2816835574455327, validation losses: 1.3995420469498245\n",
      "Epoch 143, reconstruction losses: 0.05496284454107815, regression losses: 0.2787217584825799, validation losses: 1.71739291239771\n",
      "Epoch 144, reconstruction losses: 0.04530702754863791, regression losses: 0.22947663921342717, validation losses: 1.344700918320535\n",
      "Epoch 145, reconstruction losses: 0.047527105042997606, regression losses: 0.19399558543693618, validation losses: 1.5322270754681795\n",
      "Epoch 146, reconstruction losses: 0.04614074461283873, regression losses: 0.19493542482900098, validation losses: 1.3634790536708459\n",
      "Epoch 147, reconstruction losses: 0.05154794883049016, regression losses: 0.2169962700682313, validation losses: 1.326555963033706\n",
      "Epoch 148, reconstruction losses: 0.048997413871086436, regression losses: 0.2594151059937306, validation losses: 1.251580541218381\n",
      "Epoch 149, reconstruction losses: 0.04473702500743073, regression losses: 0.23612775279271037, validation losses: 1.5235163543119552\n",
      "Epoch 150, reconstruction losses: 0.049316704064735, regression losses: 0.18120309616534547, validation losses: 1.3510669685324244\n",
      "Epoch 151, reconstruction losses: 0.04481978061343681, regression losses: 0.2066479945984486, validation losses: 1.1573370791869197\n",
      "Epoch 152, reconstruction losses: 0.04876855862087139, regression losses: 0.20981697905181074, validation losses: 1.1526868011101188\n",
      "Epoch 153, reconstruction losses: 0.04521791830653292, regression losses: 0.2016540609848959, validation losses: 1.2285197398513223\n",
      "Epoch 154, reconstruction losses: 0.048320256496025095, regression losses: 0.16902173891827152, validation losses: 1.3341903673659894\n",
      "Epoch 155, reconstruction losses: 0.04400512965863464, regression losses: 0.1987084719286779, validation losses: 1.0555411958410361\n",
      "Epoch 156, reconstruction losses: 0.046119422550845536, regression losses: 0.20347406626550482, validation losses: 1.3575933925791017\n",
      "Epoch 157, reconstruction losses: 0.044810510475402035, regression losses: 0.21573595525499575, validation losses: 1.0923442329807176\n",
      "Epoch 158, reconstruction losses: 0.04353067639354007, regression losses: 0.20470344010968902, validation losses: 1.0566512173936475\n",
      "Epoch 159, reconstruction losses: 0.04264331044990551, regression losses: 0.16494705814826216, validation losses: 1.198702187025125\n",
      "Epoch 160, reconstruction losses: 0.04777303531576725, regression losses: 0.21116677929514951, validation losses: 1.0586401906771803\n",
      "Epoch 161, reconstruction losses: 0.04238569337109008, regression losses: 0.2232649468391491, validation losses: 0.9375931253701655\n",
      "Epoch 162, reconstruction losses: 0.04343435468406035, regression losses: 0.18097613980232244, validation losses: 1.3295007037733115\n",
      "Epoch 163, reconstruction losses: 0.054379120193376124, regression losses: 0.20601935016078168, validation losses: 0.8989539581614331\n",
      "Epoch 164, reconstruction losses: 0.04417788092736039, regression losses: 0.2246681779072605, validation losses: 0.9072251355446104\n",
      "Epoch 165, reconstruction losses: 0.04357527679763677, regression losses: 0.1988715301054077, validation losses: 1.1793944453665957\n",
      "Epoch 166, reconstruction losses: 0.04839170631889085, regression losses: 0.17281745869640416, validation losses: 0.8591556086984322\n",
      "Epoch 167, reconstruction losses: 0.04209620586547417, regression losses: 0.16912334202536264, validation losses: 0.8764961451653366\n",
      "Epoch 168, reconstruction losses: 0.04317200805005151, regression losses: 0.1667244670496713, validation losses: 0.9295897008905217\n",
      "Epoch 169, reconstruction losses: 0.0456358258140199, regression losses: 0.14783132931008847, validation losses: 0.9206558731278048\n",
      "Epoch 170, reconstruction losses: 0.04300003237146199, regression losses: 0.16467854431577708, validation losses: 1.0242048497558298\n",
      "Epoch 171, reconstruction losses: 0.042207682509558926, regression losses: 0.17905806984094902, validation losses: 0.8605139326443357\n",
      "Epoch 172, reconstruction losses: 0.0502429422713607, regression losses: 0.19358655723159737, validation losses: 0.8506319191510914\n",
      "Epoch 173, reconstruction losses: 0.044988259663642324, regression losses: 0.18761783470182153, validation losses: 0.926796224516523\n",
      "Epoch 174, reconstruction losses: 0.04132000023560945, regression losses: 0.19075978027285556, validation losses: 1.3075057850974499\n",
      "Epoch 175, reconstruction losses: 0.040636004078976815, regression losses: 0.2231091479279321, validation losses: 0.9775717619342648\n",
      "Epoch 176, reconstruction losses: 0.04016157568464967, regression losses: 0.1676363600272632, validation losses: 1.2501718590685758\n",
      "Epoch 177, reconstruction losses: 0.03896848883934408, regression losses: 0.17726389935742562, validation losses: 1.100000753255159\n",
      "Epoch 178, reconstruction losses: 0.04894619171384153, regression losses: 0.1996186069333904, validation losses: 0.9914539802735043\n",
      "Epoch 179, reconstruction losses: 0.041619406324609295, regression losses: 0.1664608903978575, validation losses: 0.9518780007806596\n",
      "Epoch 180, reconstruction losses: 0.039922539901924195, regression losses: 0.1600505139339798, validation losses: 0.9618108575536819\n",
      "Epoch 181, reconstruction losses: 0.04868928725073534, regression losses: 0.17626927583672528, validation losses: 0.7814195221437129\n",
      "Epoch 182, reconstruction losses: 0.04096059232632377, regression losses: 0.13329937443034212, validation losses: 0.8524638358764668\n",
      "Epoch 183, reconstruction losses: 0.03743962060636573, regression losses: 0.12403124586372133, validation losses: 0.8387325887128667\n",
      "Epoch 184, reconstruction losses: 0.03754859118478571, regression losses: 0.1452267698590286, validation losses: 0.8340374302145203\n",
      "Epoch 185, reconstruction losses: 0.037618563357375394, regression losses: 0.16577542602655254, validation losses: 0.7458545477996236\n",
      "Epoch 186, reconstruction losses: 0.03997772252163726, regression losses: 0.1783407098504387, validation losses: 0.8006707987511645\n",
      "Epoch 187, reconstruction losses: 0.038154187018551104, regression losses: 0.22294558467971304, validation losses: 0.8588666667194618\n",
      "Epoch 188, reconstruction losses: 0.041292912980561126, regression losses: 0.19425138944017378, validation losses: 1.2050602265735046\n",
      "Epoch 189, reconstruction losses: 0.03783994795509665, regression losses: 0.17991276552412616, validation losses: 1.1353921737831405\n",
      "Epoch 190, reconstruction losses: 0.04352955733730178, regression losses: 0.20212639815493902, validation losses: 0.8537444519856315\n",
      "Epoch 191, reconstruction losses: 0.04581630727936267, regression losses: 0.25320850148739493, validation losses: 1.2075777576779938\n",
      "Epoch 192, reconstruction losses: 0.04246022626986784, regression losses: 0.25013557656582197, validation losses: 1.1914535387112797\n",
      "Epoch 193, reconstruction losses: 0.04071440138559681, regression losses: 0.19886613891746602, validation losses: 1.159052568278835\n",
      "Epoch 194, reconstruction losses: 0.04539885289491329, regression losses: 0.20808414006850792, validation losses: 0.8289413399644516\n",
      "Epoch 195, reconstruction losses: 0.037318753166818076, regression losses: 0.15504898754887972, validation losses: 1.028638450564341\n",
      "Epoch 196, reconstruction losses: 0.050168296564354176, regression losses: 0.22984661857501304, validation losses: 0.7880111823492237\n",
      "Epoch 197, reconstruction losses: 0.03760184746628028, regression losses: 0.17173350513874883, validation losses: 0.8149766828512974\n",
      "Epoch 198, reconstruction losses: 0.040221101574901885, regression losses: 0.19453183029467036, validation losses: 1.3096867237983312\n",
      "Epoch 199, reconstruction losses: 0.041113285001184954, regression losses: 0.23627948560001472, validation losses: 0.8905867907109781\n",
      "Epoch 200, reconstruction losses: 0.03505276163911498, regression losses: 0.1432456736167932, validation losses: 0.7584912161200112\n",
      "Epoch 201, reconstruction losses: 0.04193305392402111, regression losses: 0.14520395091598676, validation losses: 0.8472455481888593\n",
      "Epoch 202, reconstruction losses: 0.03515624214233742, regression losses: 0.1260116649859674, validation losses: 0.8889771166831173\n",
      "Epoch 203, reconstruction losses: 0.03539058184761578, regression losses: 0.1285606022256251, validation losses: 0.7242583498894826\n",
      "Epoch 204, reconstruction losses: 0.034811649103255855, regression losses: 0.14134130501873599, validation losses: 0.896763138999725\n",
      "Epoch 205, reconstruction losses: 0.03939433189770488, regression losses: 0.18346670737716356, validation losses: 1.1239377625005593\n",
      "Epoch 206, reconstruction losses: 0.03683558380671437, regression losses: 0.15033894991008373, validation losses: 0.7442469486954636\n",
      "Epoch 207, reconstruction losses: 0.03685716333799666, regression losses: 0.12462930550950896, validation losses: 0.7542012465318708\n",
      "Epoch 208, reconstruction losses: 0.034650761257752745, regression losses: 0.14776867998012072, validation losses: 0.826638025349239\n",
      "Epoch 209, reconstruction losses: 0.035616606940459594, regression losses: 0.1521006500192488, validation losses: 0.7763752219669365\n",
      "Epoch 210, reconstruction losses: 0.043583355285407605, regression losses: 0.1481412762165279, validation losses: 0.7668464353594422\n",
      "Epoch 211, reconstruction losses: 0.037474866094194745, regression losses: 0.20071081191166085, validation losses: 0.7822431044008021\n",
      "Epoch 212, reconstruction losses: 0.03754835369875118, regression losses: 0.15305930931203535, validation losses: 1.1433914114233912\n",
      "Epoch 213, reconstruction losses: 0.038087968577971004, regression losses: 0.1529241951865831, validation losses: 0.7188673642704171\n",
      "Epoch 214, reconstruction losses: 0.04113879708610269, regression losses: 0.2232569157862973, validation losses: 0.7214417966044688\n",
      "Epoch 215, reconstruction losses: 0.035503702904249985, regression losses: 0.18351519041586678, validation losses: 1.3929813139966534\n",
      "Epoch 216, reconstruction losses: 0.039367431220092494, regression losses: 0.16488158491426147, validation losses: 0.7511579916710074\n",
      "Epoch 217, reconstruction losses: 0.04430633211636298, regression losses: 0.13673620144714996, validation losses: 0.6738476109641619\n",
      "Epoch 218, reconstruction losses: 0.03896590425554573, regression losses: 0.18180645118995112, validation losses: 0.8394485765616634\n",
      "Epoch 219, reconstruction losses: 0.04201780335270648, regression losses: 0.1586935393846709, validation losses: 0.8614701532402841\n",
      "Epoch 220, reconstruction losses: 0.03541333939360983, regression losses: 0.14119733035009682, validation losses: 0.7151161638676752\n",
      "Epoch 221, reconstruction losses: 0.0332223241940519, regression losses: 0.16549524701751817, validation losses: 0.7852758873939653\n",
      "Epoch 222, reconstruction losses: 0.036824303610380915, regression losses: 0.13659463411625639, validation losses: 0.8013949542106915\n",
      "Epoch 223, reconstruction losses: 0.034460874292468816, regression losses: 0.10086940988546636, validation losses: 0.6789443995214308\n",
      "Epoch 224, reconstruction losses: 0.03520964815079333, regression losses: 0.13306902077926422, validation losses: 0.6214328601006965\n",
      "Epoch 225, reconstruction losses: 0.03493832709444953, regression losses: 0.11945686250443596, validation losses: 0.7188621305001606\n",
      "Epoch 226, reconstruction losses: 0.03800275835653629, regression losses: 0.3604368808927569, validation losses: 0.8246292184991231\n",
      "Epoch 227, reconstruction losses: 0.044266271801324863, regression losses: 0.2077949547558313, validation losses: 0.9099039058515748\n",
      "Epoch 228, reconstruction losses: 0.033669033593883214, regression losses: 0.15436705896784325, validation losses: 1.0177873917553846\n",
      "Epoch 229, reconstruction losses: 0.042464643029552274, regression losses: 0.18002223501937673, validation losses: 0.8519043662093804\n",
      "Epoch 230, reconstruction losses: 0.04238491151028893, regression losses: 0.19364199692846557, validation losses: 1.0031961101170626\n",
      "Epoch 231, reconstruction losses: 0.04046986425140356, regression losses: 0.16173706750640965, validation losses: 0.720846968524057\n",
      "Epoch 232, reconstruction losses: 0.032923703150957925, regression losses: 0.13462576797420683, validation losses: 0.7179680842988108\n",
      "Epoch 233, reconstruction losses: 0.037044383096850805, regression losses: 0.11296832457365727, validation losses: 0.9454875053644982\n",
      "Epoch 234, reconstruction losses: 0.036347419152620256, regression losses: 0.47941346926687733, validation losses: 0.7856093444074317\n",
      "Epoch 235, reconstruction losses: 0.033536376971497965, regression losses: 0.2125873675457923, validation losses: 1.418174174606309\n",
      "Epoch 236, reconstruction losses: 0.03442513484319858, regression losses: 0.20586262911008352, validation losses: 1.2248347753173812\n",
      "Epoch 237, reconstruction losses: 0.03551718232863906, regression losses: 0.19846331297607647, validation losses: 0.8618031089593653\n",
      "Epoch 238, reconstruction losses: 0.0392734983478184, regression losses: 0.16186850061007008, validation losses: 0.8703317719276961\n",
      "Epoch 239, reconstruction losses: 0.034612397213902094, regression losses: 0.14157844176954199, validation losses: 0.7304698320907063\n",
      "Epoch 240, reconstruction losses: 0.03384461208889361, regression losses: 0.14530748448702063, validation losses: 0.9292435936571125\n",
      "Epoch 241, reconstruction losses: 0.03353485721155104, regression losses: 0.17101376365848353, validation losses: 0.9556051111971763\n",
      "Epoch 242, reconstruction losses: 0.03886568471165251, regression losses: 0.17044053656608812, validation losses: 0.8508154503987964\n",
      "Epoch 243, reconstruction losses: 0.03518262294419768, regression losses: 0.2071191517439179, validation losses: 0.8370813313306871\n",
      "Epoch 244, reconstruction losses: 0.03795950652942796, regression losses: 0.14928823554751097, validation losses: 0.8208247489739089\n",
      "Epoch 245, reconstruction losses: 0.03220957234478827, regression losses: 0.13946699794001638, validation losses: 0.6582706820809685\n",
      "Epoch 246, reconstruction losses: 0.03321641489709537, regression losses: 0.13235992100604685, validation losses: 0.7880814149139349\n",
      "Epoch 247, reconstruction losses: 0.03148819003838848, regression losses: 0.14231390274302785, validation losses: 0.6559598744731527\n",
      "Epoch 248, reconstruction losses: 0.03197374316271099, regression losses: 0.12325111782428347, validation losses: 0.6169796613291746\n",
      "Epoch 249, reconstruction losses: 0.04100348204454647, regression losses: 0.1086763885755107, validation losses: 0.7540207167010434\n",
      "Epoch 250, reconstruction losses: 0.03156395582265014, regression losses: 0.14658090148787273, validation losses: 0.6779326458486186\n",
      "Epoch 251, reconstruction losses: 0.03951743482516487, regression losses: 0.1283075065884303, validation losses: 0.6209288083494133\n",
      "Epoch 252, reconstruction losses: 0.03445858632558719, regression losses: 0.13810835106248753, validation losses: 0.5814540423574287\n",
      "Epoch 253, reconstruction losses: 0.03451351615282565, regression losses: 0.125470101122939, validation losses: 0.6779320766180108\n",
      "Epoch 254, reconstruction losses: 0.03375528560741557, regression losses: 0.12956773377595066, validation losses: 0.7737365955937399\n",
      "Epoch 255, reconstruction losses: 0.033181116129452126, regression losses: 0.19570191735585452, validation losses: 0.6607726461382759\n",
      "Epoch 256, reconstruction losses: 0.032219927737846994, regression losses: 0.09336376249996807, validation losses: 0.5752387613768404\n",
      "Epoch 257, reconstruction losses: 0.03728529165494424, regression losses: 0.11542025128205038, validation losses: 0.648434594472366\n",
      "Epoch 258, reconstruction losses: 0.035918138051255294, regression losses: 0.15051516512412522, validation losses: 0.7887157103285887\n",
      "Epoch 259, reconstruction losses: 0.033695887789849915, regression losses: 0.15422269596893393, validation losses: 0.7390445761080053\n",
      "Epoch 260, reconstruction losses: 0.03677707892650528, regression losses: 0.1657088816496626, validation losses: 0.6106429381022962\n",
      "Epoch 261, reconstruction losses: 0.031996026887123705, regression losses: 0.12994363757675806, validation losses: 0.7368735597976562\n",
      "Epoch 262, reconstruction losses: 0.03297913223794388, regression losses: 0.1567718275981705, validation losses: 0.8884440467803734\n",
      "Epoch 263, reconstruction losses: 0.03225351421701478, regression losses: 0.18091527227100787, validation losses: 0.6273920352745803\n",
      "Epoch 264, reconstruction losses: 0.0325596636352439, regression losses: 0.1200010711608365, validation losses: 0.5635953256748212\n",
      "Epoch 265, reconstruction losses: 0.036618290161338815, regression losses: 0.46867237674118006, validation losses: 0.7265063586422358\n",
      "Epoch 266, reconstruction losses: 0.03507501014868349, regression losses: 0.1741369592422191, validation losses: 0.967904375838466\n",
      "Epoch 267, reconstruction losses: 0.03253803059772516, regression losses: 0.15220980751329447, validation losses: 0.8564904304534611\n",
      "Epoch 268, reconstruction losses: 0.03275633457841576, regression losses: 0.23101704000631806, validation losses: 0.7938518350666872\n",
      "Epoch 269, reconstruction losses: 0.03508082794488438, regression losses: 0.17438823356250632, validation losses: 1.491309145053902\n",
      "Epoch 270, reconstruction losses: 0.035248287063038376, regression losses: 0.2447947918284344, validation losses: 0.8057718890371461\n",
      "Epoch 271, reconstruction losses: 0.04115830894467182, regression losses: 0.16962610842605055, validation losses: 1.1965973012534867\n",
      "Epoch 272, reconstruction losses: 0.0314759137433306, regression losses: 0.15853037201282172, validation losses: 0.7547383103164181\n",
      "Epoch 273, reconstruction losses: 0.03310376985111917, regression losses: 0.17449143661541652, validation losses: 0.927104208174191\n",
      "Epoch 274, reconstruction losses: 0.034514896318774024, regression losses: 0.26730697621345745, validation losses: 0.7709613805683754\n",
      "Epoch 275, reconstruction losses: 0.03424162361050989, regression losses: 0.205316015553268, validation losses: 1.2022447524253963\n",
      "Epoch 276, reconstruction losses: 0.036154366226854084, regression losses: 0.24771979522273863, validation losses: 0.6202063169266943\n",
      "Epoch 277, reconstruction losses: 0.03333828128134245, regression losses: 0.2158993359831408, validation losses: 1.5002724234940983\n",
      "Epoch 278, reconstruction losses: 0.034677087373407606, regression losses: 0.3751882395755957, validation losses: 0.8076293319226457\n",
      "Epoch 279, reconstruction losses: 0.03297869499085005, regression losses: 0.1389357569415179, validation losses: 0.7599252881024152\n",
      "Epoch 280, reconstruction losses: 0.03416423610738932, regression losses: 0.21161313300217893, validation losses: 0.7153503138587506\n",
      "Epoch 281, reconstruction losses: 0.030233711255653346, regression losses: 0.14523922691779376, validation losses: 0.7998179339820418\n",
      "Epoch 282, reconstruction losses: 0.030805402846436732, regression losses: 0.1300564806540101, validation losses: 0.7293041646679614\n",
      "Epoch 283, reconstruction losses: 0.03316566015770691, regression losses: 0.19944831141460634, validation losses: 0.7261593292754243\n",
      "Epoch 284, reconstruction losses: 0.03078734140762, regression losses: 0.14942201784860354, validation losses: 0.8178430998278413\n",
      "Epoch 285, reconstruction losses: 0.032739258931663476, regression losses: 0.18433419450957528, validation losses: 0.6800625405863082\n",
      "Epoch 286, reconstruction losses: 0.027680960645101386, regression losses: 0.09712867913923787, validation losses: 0.7921646087960523\n",
      "Epoch 287, reconstruction losses: 0.029939716231916616, regression losses: 0.19539074744890705, validation losses: 0.7324763216262261\n",
      "Epoch 288, reconstruction losses: 0.03186545685050157, regression losses: 0.13598755639724214, validation losses: 1.001686616289033\n",
      "Epoch 289, reconstruction losses: 0.029834939463602647, regression losses: 0.17204299834443001, validation losses: 0.8533554676102478\n",
      "Epoch 290, reconstruction losses: 0.028042022897539525, regression losses: 0.1331419387080115, validation losses: 0.7815688631635332\n",
      "Epoch 291, reconstruction losses: 0.029646651647681013, regression losses: 0.16858876008374896, validation losses: 0.7142062980997841\n",
      "Epoch 292, reconstruction losses: 0.02862377206299407, regression losses: 0.18107819686684642, validation losses: 0.7342835754226924\n",
      "Epoch 293, reconstruction losses: 0.029031757133427642, regression losses: 0.16345081453770074, validation losses: 0.6993946554279428\n",
      "Epoch 294, reconstruction losses: 0.030529938270935014, regression losses: 0.14447006174792623, validation losses: 0.6975234282177153\n",
      "Epoch 295, reconstruction losses: 0.02694579225368977, regression losses: 0.13628940475810025, validation losses: 0.6190968432607388\n",
      "Epoch 296, reconstruction losses: 0.02900372522246114, regression losses: 0.15738695134124264, validation losses: 0.8765267488916794\n",
      "Epoch 297, reconstruction losses: 0.03128159761856365, regression losses: 0.17162011744270783, validation losses: 0.677408142232512\n",
      "Epoch 298, reconstruction losses: 0.029408361259963538, regression losses: 0.17920083759685365, validation losses: 0.6483737357528045\n",
      "Epoch 299, reconstruction losses: 0.03061184046887955, regression losses: 0.12756230723576562, validation losses: 0.8615617639005148\n",
      "Epoch 300, reconstruction losses: 0.02799767269039619, regression losses: 0.14390347040555426, validation losses: 0.5842547595379708\n",
      "Epoch 301, reconstruction losses: 0.025348921060537682, regression losses: 0.0945602381956979, validation losses: 0.7241641038534665\n",
      "Epoch 302, reconstruction losses: 0.026671793360630896, regression losses: 0.1378214811696226, validation losses: 0.7712608663299936\n",
      "Epoch 303, reconstruction losses: 0.029698255781453232, regression losses: 0.14010983941666785, validation losses: 0.634887972950596\n",
      "Epoch 304, reconstruction losses: 0.024409990790987077, regression losses: 0.11722285250511506, validation losses: 0.6180858133414807\n",
      "Epoch 305, reconstruction losses: 0.026609093602087828, regression losses: 0.15255663828314558, validation losses: 0.7771613174963614\n",
      "Epoch 306, reconstruction losses: 0.026218240081008516, regression losses: 0.15903797659500427, validation losses: 0.6111623325846045\n",
      "Epoch 307, reconstruction losses: 0.027032468619081672, regression losses: 0.1121613386628188, validation losses: 0.6863041339966496\n",
      "Epoch 308, reconstruction losses: 0.02763372681149439, regression losses: 0.11710930140301341, validation losses: 0.7107609716574605\n",
      "Epoch 309, reconstruction losses: 0.029155898196259983, regression losses: 0.16008237886439539, validation losses: 0.5856918242577327\n",
      "Epoch 310, reconstruction losses: 0.02523513964987665, regression losses: 0.1835297210739932, validation losses: 0.6415178524394738\n",
      "Epoch 311, reconstruction losses: 0.024724255270836847, regression losses: 0.10360628412275005, validation losses: 0.7287792309577655\n",
      "Epoch 312, reconstruction losses: 0.025159371260986742, regression losses: 0.13791341091439488, validation losses: 0.6724509197347694\n",
      "Epoch 313, reconstruction losses: 0.02552026046868767, regression losses: 0.15200108049374983, validation losses: 0.6784323113273522\n",
      "Epoch 314, reconstruction losses: 0.03015331119401579, regression losses: 0.19590448262414836, validation losses: 0.7764305551349777\n",
      "Epoch 315, reconstruction losses: 0.03320691516477645, regression losses: 0.2808610569112825, validation losses: 0.7072040195018424\n",
      "Epoch 316, reconstruction losses: 0.028081055223029346, regression losses: 0.180672556335237, validation losses: 1.176491429105732\n",
      "Epoch 317, reconstruction losses: 0.02715576456278823, regression losses: 0.17397255407594647, validation losses: 0.5844400779901302\n",
      "Epoch 318, reconstruction losses: 0.022603055467060443, regression losses: 0.1339461747526556, validation losses: 0.699213047522008\n",
      "Epoch 319, reconstruction losses: 0.027375162699217175, regression losses: 0.12936290377695367, validation losses: 0.677343909467468\n",
      "Epoch 320, reconstruction losses: 0.027754177092518983, regression losses: 0.12610802038338143, validation losses: 0.5587009855275005\n",
      "Epoch 321, reconstruction losses: 0.024015924678089298, regression losses: 0.1698949220768714, validation losses: 0.5835570761547118\n",
      "Epoch 322, reconstruction losses: 0.028947357509781654, regression losses: 0.13255160285522222, validation losses: 0.6251264731362508\n",
      "Epoch 323, reconstruction losses: 0.02862046262181964, regression losses: 0.1286103973940093, validation losses: 0.5533339533180854\n",
      "Epoch 324, reconstruction losses: 0.02705805071231125, regression losses: 0.21496618723478705, validation losses: 0.6105259967909472\n",
      "Epoch 325, reconstruction losses: 0.02560738182705383, regression losses: 0.16752184588623642, validation losses: 0.5606329380883199\n",
      "Epoch 326, reconstruction losses: 0.026016966558187287, regression losses: 0.14359948179005766, validation losses: 0.829206126662619\n",
      "Epoch 327, reconstruction losses: 0.027726469685589346, regression losses: 0.13621061108241372, validation losses: 0.803344742562182\n",
      "Epoch 328, reconstruction losses: 0.026423925528273506, regression losses: 0.1268689268160647, validation losses: 0.6561369989684065\n",
      "Epoch 329, reconstruction losses: 0.027702455883860395, regression losses: 0.14410137042037938, validation losses: 0.5486457833907212\n",
      "Epoch 330, reconstruction losses: 0.02517520920320516, regression losses: 0.13772983974217745, validation losses: 0.6881279151186169\n",
      "Epoch 331, reconstruction losses: 0.02142233283760157, regression losses: 0.10503478882881254, validation losses: 0.7689025669479529\n",
      "Epoch 332, reconstruction losses: 0.022463059671354677, regression losses: 0.11305754324034945, validation losses: 0.5815013419138367\n",
      "Epoch 333, reconstruction losses: 0.02484018118683433, regression losses: 0.17371190950042692, validation losses: 0.5621364482433435\n",
      "Epoch 334, reconstruction losses: 0.020379539586721177, regression losses: 0.12728448240277426, validation losses: 0.9320546367164025\n",
      "Epoch 335, reconstruction losses: 0.024271107387572214, regression losses: 0.14782303074742964, validation losses: 0.6467715164057621\n",
      "Epoch 336, reconstruction losses: 0.023108673436942832, regression losses: 0.12133038924571224, validation losses: 0.5603062955395899\n",
      "Epoch 337, reconstruction losses: 0.02260208345393334, regression losses: 0.16675932965805979, validation losses: 0.6018617631930848\n",
      "Epoch 338, reconstruction losses: 0.02243071597412339, regression losses: 0.13395354476234456, validation losses: 0.6553988299712064\n",
      "Epoch 339, reconstruction losses: 0.024587793411713788, regression losses: 0.14192334148216657, validation losses: 0.6451919460923956\n",
      "Epoch 340, reconstruction losses: 0.026024600052268546, regression losses: 0.17065876656174425, validation losses: 0.7157692750547039\n",
      "Epoch 341, reconstruction losses: 0.022940888370072056, regression losses: 0.14806352847739876, validation losses: 0.5453479398496773\n",
      "Epoch 342, reconstruction losses: 0.026158580390806218, regression losses: 0.12206681912886153, validation losses: 0.5728911463606441\n",
      "Epoch 343, reconstruction losses: 0.023316128264561274, regression losses: 0.18544814952779104, validation losses: 0.6534332221974397\n",
      "Epoch 344, reconstruction losses: 0.022246999445748133, regression losses: 0.11315624075036188, validation losses: 0.5493052183227565\n",
      "Epoch 345, reconstruction losses: 0.021825134062619184, regression losses: 0.09812939882543577, validation losses: 0.5415237928544486\n",
      "Epoch 346, reconstruction losses: 0.02336277943948627, regression losses: 0.13094059195609048, validation losses: 0.549542008586487\n",
      "Epoch 347, reconstruction losses: 0.025448657705316458, regression losses: 0.11529326193832111, validation losses: 0.48717236040732365\n",
      "Epoch 348, reconstruction losses: 0.021069047374839785, regression losses: 0.1920484615642395, validation losses: 0.5613866775925453\n",
      "Epoch 349, reconstruction losses: 0.02269587898725621, regression losses: 0.12560773235718406, validation losses: 0.7661920603841774\n",
      "Epoch 350, reconstruction losses: 0.024261557200625044, regression losses: 0.19468902776401845, validation losses: 0.5055906945046562\n",
      "Epoch 351, reconstruction losses: 0.026288623584729456, regression losses: 0.21669050054207378, validation losses: 0.5182679750248551\n",
      "Epoch 352, reconstruction losses: 0.023809325087571817, regression losses: 0.19130447694098032, validation losses: 1.0019183331340598\n",
      "Epoch 353, reconstruction losses: 0.03124231084512853, regression losses: 0.3812278861180257, validation losses: 0.8575245903555847\n",
      "Epoch 354, reconstruction losses: 0.026990737573162317, regression losses: 0.15223075382898624, validation losses: 0.7153573937643282\n",
      "Epoch 355, reconstruction losses: 0.022049521827125756, regression losses: 0.12103961588565845, validation losses: 0.5918613595124896\n",
      "Epoch 356, reconstruction losses: 0.026585801658537557, regression losses: 0.14253218861402356, validation losses: 0.5413030090558493\n",
      "Epoch 357, reconstruction losses: 0.025286567032590697, regression losses: 0.17270508249413957, validation losses: 0.5824078367476302\n",
      "Epoch 358, reconstruction losses: 0.021797355051494136, regression losses: 0.14736272094715058, validation losses: 0.5354195785204625\n",
      "Epoch 359, reconstruction losses: 0.02469691875518158, regression losses: 0.13365451640661502, validation losses: 0.668198800123765\n",
      "Epoch 360, reconstruction losses: 0.02084619707913569, regression losses: 0.1536156211449731, validation losses: 0.6882210753977746\n",
      "Epoch 361, reconstruction losses: 0.025030471417039422, regression losses: 0.17354156212085906, validation losses: 0.7114417418167416\n",
      "Epoch 362, reconstruction losses: 0.023115863011181594, regression losses: 0.12873720495501972, validation losses: 0.7196860946684285\n",
      "Epoch 363, reconstruction losses: 0.02333865259354091, regression losses: 0.11717830229276521, validation losses: 0.5912713528632713\n",
      "Epoch 364, reconstruction losses: 0.025759806911396232, regression losses: 0.18334828236544548, validation losses: 0.5705006827400487\n",
      "Epoch 365, reconstruction losses: 0.02406735834394335, regression losses: 0.14268810199257148, validation losses: 0.6688650223706084\n",
      "Epoch 366, reconstruction losses: 0.020820317825567574, regression losses: 0.12481697382184151, validation losses: 0.7356825391065471\n",
      "Epoch 367, reconstruction losses: 0.022457290989820584, regression losses: 0.20762816507721665, validation losses: 0.8600524702912224\n",
      "Epoch 368, reconstruction losses: 0.02179019610732452, regression losses: 0.15792190851726692, validation losses: 0.7785471152725145\n",
      "Epoch 369, reconstruction losses: 0.022361088972283612, regression losses: 0.1378699261975898, validation losses: 0.5875409005863924\n",
      "Epoch 370, reconstruction losses: 0.02849805379942605, regression losses: 0.21162048598137828, validation losses: 0.5819700908814673\n",
      "Epoch 371, reconstruction losses: 0.023591204131064195, regression losses: 0.10952125938736504, validation losses: 0.8846756081434627\n",
      "Epoch 372, reconstruction losses: 0.024232214579431956, regression losses: 0.14333645915339832, validation losses: 0.6251647541236286\n",
      "Epoch 373, reconstruction losses: 0.022360343707687587, regression losses: 0.11704460854632666, validation losses: 0.6158537588182811\n",
      "Epoch 374, reconstruction losses: 0.021752695263810712, regression losses: 0.09933492099451438, validation losses: 0.6316641732334974\n",
      "Epoch 375, reconstruction losses: 0.02060775511105107, regression losses: 0.09592893774032187, validation losses: 0.5681313248758432\n",
      "Epoch 376, reconstruction losses: 0.019127631094537825, regression losses: 0.14231544096526133, validation losses: 0.5505781028229988\n",
      "Epoch 377, reconstruction losses: 0.02005854590510537, regression losses: 0.12145273096173965, validation losses: 0.5552928096579666\n",
      "Epoch 378, reconstruction losses: 0.01814637703465815, regression losses: 0.09365086743283463, validation losses: 0.5524203938357903\n",
      "Epoch 379, reconstruction losses: 0.026736886359441596, regression losses: 0.13932484462398664, validation losses: 0.5396229537820484\n",
      "Epoch 380, reconstruction losses: 0.023213666141738417, regression losses: 0.15476960900822362, validation losses: 0.537027240817571\n",
      "Epoch 381, reconstruction losses: 0.020554821883368025, regression losses: 0.10465691615583664, validation losses: 0.786085004307699\n",
      "Epoch 382, reconstruction losses: 0.021025920651244458, regression losses: 0.11324240961422562, validation losses: 0.5794651970501398\n",
      "Epoch 383, reconstruction losses: 0.02144327798344936, regression losses: 0.13418815924488173, validation losses: 0.5389108511066139\n",
      "Epoch 384, reconstruction losses: 0.02205570919909214, regression losses: 0.13303301223010883, validation losses: 0.689559697706851\n",
      "Epoch 385, reconstruction losses: 0.023164857506454615, regression losses: 0.14711049913659907, validation losses: 0.5692216651781962\n",
      "Epoch 386, reconstruction losses: 0.01832833971016977, regression losses: 0.09703454051718405, validation losses: 0.6579078347748485\n",
      "Epoch 387, reconstruction losses: 0.018663686768757716, regression losses: 0.12635487146524493, validation losses: 0.6708831424297728\n",
      "Epoch 388, reconstruction losses: 0.027115511827523704, regression losses: 0.17667179128600047, validation losses: 0.5161172501430028\n",
      "Epoch 389, reconstruction losses: 0.02915310277139112, regression losses: 0.1383875261818787, validation losses: 0.7046764276031318\n",
      "Epoch 390, reconstruction losses: 0.0248876482691838, regression losses: 0.19202935339565927, validation losses: 0.5388204796362943\n",
      "Epoch 391, reconstruction losses: 0.028647242477534883, regression losses: 0.13372506744512866, validation losses: 0.7527375340889624\n",
      "Epoch 392, reconstruction losses: 0.025264923417939632, regression losses: 0.12831328741086068, validation losses: 0.6577083535422004\n",
      "Epoch 393, reconstruction losses: 0.022144846995306184, regression losses: 0.1123488539010705, validation losses: 0.5696751090605978\n",
      "Epoch 394, reconstruction losses: 0.021770384535589694, regression losses: 0.13172458423190622, validation losses: 0.573620271472224\n",
      "Epoch 395, reconstruction losses: 0.019268437579436654, regression losses: 0.10593868310554774, validation losses: 0.5681621732069708\n",
      "Epoch 396, reconstruction losses: 0.02021695709207359, regression losses: 0.1264107242991628, validation losses: 0.5137308770154962\n",
      "Epoch 397, reconstruction losses: 0.02017194681639352, regression losses: 0.1470549607353898, validation losses: 0.5256202130471256\n",
      "Epoch 398, reconstruction losses: 0.019479763737582794, regression losses: 0.12588650818295583, validation losses: 0.528067861955312\n",
      "Epoch 399, reconstruction losses: 0.02312216669196529, regression losses: 0.2129680887644088, validation losses: 0.5321193408266169\n",
      "Epoch 400, reconstruction losses: 0.02219027577045851, regression losses: 0.13176359521516579, validation losses: 0.7773780773767993\n",
      "Epoch 401, reconstruction losses: 0.019647450911861295, regression losses: 0.1367877619799226, validation losses: 0.511046189610688\n",
      "Epoch 402, reconstruction losses: 0.020656400280482552, regression losses: 0.1684917148617357, validation losses: 0.7401385108854264\n",
      "Epoch 403, reconstruction losses: 0.018260312871959828, regression losses: 0.14669335649725757, validation losses: 0.6367743905931464\n",
      "Epoch 404, reconstruction losses: 0.018754097117733886, regression losses: 0.09894710097682757, validation losses: 0.5100247171122534\n",
      "Epoch 405, reconstruction losses: 0.020947652891475127, regression losses: 0.1303435078525672, validation losses: 0.48482601569205286\n",
      "Epoch 406, reconstruction losses: 0.019938913204113, regression losses: 0.14313144379436207, validation losses: 0.5703625244210774\n",
      "Epoch 407, reconstruction losses: 0.01976328926171505, regression losses: 0.11721333957560505, validation losses: 0.5325608798890346\n",
      "Epoch 408, reconstruction losses: 0.021475396079881724, regression losses: 0.0840844623332058, validation losses: 0.5263271774972017\n",
      "Epoch 409, reconstruction losses: 0.02749109529605361, regression losses: 0.1359233132680396, validation losses: 0.5025022231742414\n",
      "Epoch 410, reconstruction losses: 0.023939682532246775, regression losses: 0.309925576406224, validation losses: 0.5449325758864251\n",
      "Epoch 411, reconstruction losses: 0.01916820026474343, regression losses: 0.10692954011632637, validation losses: 1.1333857054855427\n",
      "Epoch 412, reconstruction losses: 0.022545316001068398, regression losses: 0.18808855875791594, validation losses: 0.9654252596757915\n",
      "Epoch 413, reconstruction losses: 0.020383266056756666, regression losses: 0.14116366980549433, validation losses: 0.4873315711139746\n",
      "Epoch 414, reconstruction losses: 0.023721992912787003, regression losses: 0.12072718317541122, validation losses: 0.7408714308486365\n",
      "Epoch 415, reconstruction losses: 0.02251818446449725, regression losses: 0.14639195983151687, validation losses: 0.5945477831737095\n",
      "Epoch 416, reconstruction losses: 0.020034216631602535, regression losses: 0.11956904842697799, validation losses: 0.7673659171696555\n",
      "Epoch 417, reconstruction losses: 0.020928801829624463, regression losses: 0.11732417277538557, validation losses: 0.5432159261633462\n",
      "Epoch 418, reconstruction losses: 0.02174571358725161, regression losses: 0.16000225540803834, validation losses: 0.5161020011794238\n",
      "Epoch 419, reconstruction losses: 0.01921747349110753, regression losses: 0.10970687474685988, validation losses: 0.7036336638073254\n",
      "Epoch 420, reconstruction losses: 0.019297355415390988, regression losses: 0.15272590126402383, validation losses: 0.7323637066465636\n",
      "Epoch 421, reconstruction losses: 0.019351437728902812, regression losses: 0.15458865974078315, validation losses: 0.7242392445317263\n",
      "Epoch 422, reconstruction losses: 0.018551224828788643, regression losses: 0.1488133045531003, validation losses: 0.6784109725125221\n",
      "Epoch 423, reconstruction losses: 0.02023819382165115, regression losses: 0.13062492805573533, validation losses: 0.590574868979049\n",
      "Epoch 424, reconstruction losses: 0.02041270295959037, regression losses: 0.13891104820148642, validation losses: 0.6290764198057596\n",
      "Epoch 425, reconstruction losses: 0.017696636505767485, regression losses: 0.11310983039522379, validation losses: 0.6597694414075008\n",
      "Epoch 426, reconstruction losses: 0.019528896587516192, regression losses: 0.1183430643612673, validation losses: 0.5904301600248254\n",
      "Epoch 427, reconstruction losses: 0.021988592197641366, regression losses: 0.09852932734892628, validation losses: 0.5706223477478894\n",
      "Epoch 428, reconstruction losses: 0.01788849844171381, regression losses: 0.08708246331510151, validation losses: 0.6590345535080278\n",
      "Epoch 429, reconstruction losses: 0.019100930371838052, regression losses: 0.12242475785242316, validation losses: 0.5456353158086529\n",
      "Epoch 430, reconstruction losses: 0.01948841908031365, regression losses: 0.1033720345662597, validation losses: 0.747960316787665\n",
      "Epoch 431, reconstruction losses: 0.0211733162246902, regression losses: 0.1431834051708163, validation losses: 0.5403787776104101\n",
      "Epoch 432, reconstruction losses: 0.01901277956028321, regression losses: 0.1383475427961725, validation losses: 0.5086254374242253\n",
      "Epoch 433, reconstruction losses: 0.019450197104564686, regression losses: 0.12482499013888747, validation losses: 0.5668034125817473\n",
      "Epoch 434, reconstruction losses: 0.020537654538877567, regression losses: 0.12199056473633145, validation losses: 0.6047595475999268\n",
      "Epoch 435, reconstruction losses: 0.02015796900282279, regression losses: 0.12019946564017131, validation losses: 0.6526806731872574\n",
      "Epoch 436, reconstruction losses: 0.020062597005616113, regression losses: 0.10579800653059318, validation losses: 0.5167989886361062\n",
      "Epoch 437, reconstruction losses: 0.021654142005629706, regression losses: 0.1353136915667401, validation losses: 0.581718850213098\n",
      "Epoch 438, reconstruction losses: 0.017196221936264293, regression losses: 0.11109711743287501, validation losses: 0.6305979102059507\n",
      "Epoch 439, reconstruction losses: 0.018926857880346308, regression losses: 0.1238273168972009, validation losses: 0.6689009842140904\n",
      "Epoch 440, reconstruction losses: 0.022740344542948085, regression losses: 0.14456381216219327, validation losses: 0.5019810144669241\n",
      "Epoch 441, reconstruction losses: 0.017742740711676683, regression losses: 0.18662076306672715, validation losses: 0.5688243530956175\n",
      "Epoch 442, reconstruction losses: 0.023568161961836098, regression losses: 0.22269253728246635, validation losses: 0.5297449234628785\n",
      "Epoch 443, reconstruction losses: 0.020022060872090745, regression losses: 0.13289626020431392, validation losses: 0.5143552459230265\n",
      "Epoch 444, reconstruction losses: 0.021083525429599338, regression losses: 0.14475893599872786, validation losses: 0.5098989597525108\n",
      "Epoch 445, reconstruction losses: 0.01837331117643175, regression losses: 0.11167118256872731, validation losses: 0.6099124781609138\n",
      "Epoch 446, reconstruction losses: 0.02040725871333544, regression losses: 0.12959330484773543, validation losses: 0.6116177796815621\n",
      "Epoch 447, reconstruction losses: 0.01727192858815019, regression losses: 0.10646360934817933, validation losses: 0.47802929372563246\n",
      "Epoch 448, reconstruction losses: 0.018678170689265045, regression losses: 0.1480550659827466, validation losses: 0.5078361665790908\n",
      "Epoch 449, reconstruction losses: 0.023538922083013135, regression losses: 0.14624691897687797, validation losses: 0.5761122197503397\n",
      "Epoch 450, reconstruction losses: 0.019374173339059865, regression losses: 0.11674626622487, validation losses: 0.7343371734594373\n",
      "Epoch 451, reconstruction losses: 0.02072829564514839, regression losses: 0.17583000382396796, validation losses: 0.6458030084103558\n",
      "Epoch 452, reconstruction losses: 0.02209087431078393, regression losses: 0.13757378858249217, validation losses: 0.7976404684188834\n",
      "Epoch 453, reconstruction losses: 0.023391684439532538, regression losses: 0.24618435262600677, validation losses: 0.6412117169996479\n",
      "Epoch 454, reconstruction losses: 0.018748120943937015, regression losses: 0.1067447813376344, validation losses: 0.744210969702733\n",
      "Epoch 455, reconstruction losses: 0.02189842096189238, regression losses: 0.16051391134808662, validation losses: 0.5639668660254469\n",
      "Epoch 456, reconstruction losses: 0.02306175920346155, regression losses: 0.14716716712610792, validation losses: 0.8343741984262077\n",
      "Epoch 457, reconstruction losses: 0.021438742327845713, regression losses: 0.15778167871216817, validation losses: 0.8175306709078551\n",
      "Epoch 458, reconstruction losses: 0.01999412133997462, regression losses: 0.13993135657364875, validation losses: 0.6810392884968838\n",
      "Epoch 459, reconstruction losses: 0.0202260621629597, regression losses: 0.1305653737835347, validation losses: 0.645331654000753\n",
      "Epoch 460, reconstruction losses: 0.020190315248374606, regression losses: 0.08959152466195383, validation losses: 0.5127549741294088\n",
      "Epoch 461, reconstruction losses: 0.02174419762596425, regression losses: 0.10402128035921991, validation losses: 0.5183523413899934\n",
      "Epoch 462, reconstruction losses: 0.022900825430322198, regression losses: 0.1438854904736144, validation losses: 0.47493257473960965\n",
      "Epoch 463, reconstruction losses: 0.01965181131750976, regression losses: 0.10396110242648236, validation losses: 0.575417005545389\n",
      "Epoch 464, reconstruction losses: 0.021868279608417487, regression losses: 0.16974457354892933, validation losses: 0.7143520039279414\n",
      "Epoch 465, reconstruction losses: 0.018688926083773198, regression losses: 0.15057381469328862, validation losses: 0.6469055095951091\n",
      "Epoch 466, reconstruction losses: 0.020564763846567635, regression losses: 0.11449579376403363, validation losses: 0.6693850393290683\n",
      "Epoch 467, reconstruction losses: 0.019179386889413126, regression losses: 0.11068064446234217, validation losses: 0.5883426173145405\n",
      "Epoch 468, reconstruction losses: 0.01822701312817571, regression losses: 0.1169731205072394, validation losses: 0.4939246487685624\n",
      "Epoch 469, reconstruction losses: 0.019924818152264115, regression losses: 0.09769471607539947, validation losses: 0.5777357714386824\n",
      "Epoch 470, reconstruction losses: 0.02008393633424135, regression losses: 0.11558075009245691, validation losses: 0.6016332826762198\n",
      "Epoch 471, reconstruction losses: 0.018547099173376606, regression losses: 0.09366251272339891, validation losses: 0.7764289651067716\n",
      "Epoch 472, reconstruction losses: 0.018904730846385994, regression losses: 0.12928351214318806, validation losses: 0.6777634931824748\n",
      "Epoch 473, reconstruction losses: 0.027512790929004105, regression losses: 0.16631530465190097, validation losses: 0.5790577480811033\n",
      "Epoch 474, reconstruction losses: 0.017969438729354047, regression losses: 0.10431733714059639, validation losses: 0.8550647465777779\n",
      "Epoch 475, reconstruction losses: 0.019818626039270638, regression losses: 0.11219558480386845, validation losses: 0.5609926449607037\n",
      "Epoch 476, reconstruction losses: 0.019571179247925796, regression losses: 0.12885452661145586, validation losses: 0.6550474065241768\n",
      "Epoch 477, reconstruction losses: 0.01971811000570391, regression losses: 0.13836914485250834, validation losses: 0.665067824584251\n",
      "Epoch 478, reconstruction losses: 0.019256385648845065, regression losses: 0.11110296134247682, validation losses: 0.4958576236513715\n",
      "Epoch 479, reconstruction losses: 0.017784823090245972, regression losses: 0.11535480872866827, validation losses: 0.5295798508805849\n",
      "Epoch 480, reconstruction losses: 0.02104972913925617, regression losses: 0.1129368544109363, validation losses: 0.6621362904322902\n",
      "Epoch 481, reconstruction losses: 0.0196270714782828, regression losses: 0.10150179862600976, validation losses: 0.6169832974242567\n",
      "Epoch 482, reconstruction losses: 0.017295294707903176, regression losses: 0.13707144033506896, validation losses: 0.6118929842228077\n",
      "Epoch 483, reconstruction losses: 0.017613978487164603, regression losses: 0.12380273182080774, validation losses: 0.5588476918595457\n",
      "Epoch 484, reconstruction losses: 0.018531268452757547, regression losses: 0.12447901707912908, validation losses: 0.5035274867830224\n",
      "Epoch 485, reconstruction losses: 0.015788419618568462, regression losses: 0.12054648700319595, validation losses: 0.5149840193956492\n",
      "Epoch 486, reconstruction losses: 0.016145484661696418, regression losses: 0.09709935878066839, validation losses: 0.600090926875885\n",
      "Epoch 487, reconstruction losses: 0.020007964692409997, regression losses: 0.11069019329639318, validation losses: 0.5441727841682478\n",
      "Epoch 488, reconstruction losses: 0.017406114676973315, regression losses: 0.09783516423691453, validation losses: 0.5058174487103113\n",
      "Epoch 489, reconstruction losses: 0.01887978394833902, regression losses: 0.11891203604128743, validation losses: 0.6250580380614552\n",
      "Epoch 490, reconstruction losses: 0.01683159706741136, regression losses: 0.10484088656087781, validation losses: 0.6473164673936309\n",
      "Epoch 491, reconstruction losses: 0.017353877599965588, regression losses: 0.09815062777536537, validation losses: 0.4660650812656009\n",
      "Epoch 492, reconstruction losses: 0.01638633672754998, regression losses: 0.16327843606893935, validation losses: 0.6365250667083918\n",
      "Epoch 493, reconstruction losses: 0.017914297230702866, regression losses: 0.152079642407081, validation losses: 0.6118664700017612\n",
      "Epoch 494, reconstruction losses: 0.022419181362443287, regression losses: 0.1355103504402719, validation losses: 0.672092066976914\n",
      "Epoch 495, reconstruction losses: 0.019087208502691647, regression losses: 0.14795895519802937, validation losses: 0.5190927460981309\n",
      "Epoch 496, reconstruction losses: 0.018603933972405104, regression losses: 0.12833651812700106, validation losses: 0.6128815104604406\n",
      "Epoch 497, reconstruction losses: 0.020181186601727134, regression losses: 0.13477990610493404, validation losses: 0.5205680349277105\n",
      "Epoch 498, reconstruction losses: 0.018586246163921228, regression losses: 0.16225305789278216, validation losses: 0.5321752194848357\n",
      "Epoch 499, reconstruction losses: 0.021746358713319994, regression losses: 0.13881738501701957, validation losses: 0.6365665332288402\n",
      "Epoch 500, reconstruction losses: 0.024028563457268084, regression losses: 0.2776371371758965, validation losses: 0.5210525495768817\n",
      "Epoch 501, reconstruction losses: 0.022059243702711288, regression losses: 0.13706390653538214, validation losses: 0.8170840811552832\n",
      "Epoch 502, reconstruction losses: 0.020200346123705415, regression losses: 0.1922308423904106, validation losses: 0.8180770905938007\n",
      "Epoch 503, reconstruction losses: 0.023398918649859074, regression losses: 0.1491035369641126, validation losses: 0.6245419509698106\n",
      "Epoch 504, reconstruction losses: 0.026540707167888863, regression losses: 0.18369109610362327, validation losses: 0.5740680474996916\n",
      "Epoch 505, reconstruction losses: 0.020806201716861525, regression losses: 0.14580106407711546, validation losses: 0.9318949836869221\n",
      "Epoch 506, reconstruction losses: 0.025453693888880795, regression losses: 0.17976569557776925, validation losses: 0.5145439131948654\n",
      "Epoch 507, reconstruction losses: 0.02240993159308833, regression losses: 0.15708913607143218, validation losses: 0.7628425059565423\n",
      "Epoch 508, reconstruction losses: 0.0212977868957226, regression losses: 0.15342367733941098, validation losses: 0.7148301759131014\n",
      "Epoch 509, reconstruction losses: 0.01892303699328936, regression losses: 0.1186161272942977, validation losses: 0.78910453758846\n",
      "Epoch 510, reconstruction losses: 0.01782821630558075, regression losses: 0.09198747459206506, validation losses: 0.5565110849289588\n",
      "Epoch 511, reconstruction losses: 0.027691222346192687, regression losses: 0.22331690542015353, validation losses: 0.6040440827912111\n",
      "Epoch 512, reconstruction losses: 0.023586751970468913, regression losses: 0.18435430858901503, validation losses: 1.1494750383489565\n",
      "Epoch 513, reconstruction losses: 0.022630187829566297, regression losses: 0.18574396023038545, validation losses: 0.6550348169485785\n",
      "Epoch 514, reconstruction losses: 0.020931289382488512, regression losses: 0.14375071678750576, validation losses: 0.673098776591182\n",
      "Epoch 515, reconstruction losses: 0.017036416556966198, regression losses: 0.10673182378564854, validation losses: 0.5917230901441062\n",
      "Epoch 516, reconstruction losses: 0.021167753179384026, regression losses: 0.14552650022991795, validation losses: 0.6844320775167411\n",
      "Epoch 517, reconstruction losses: 0.018375080967649338, regression losses: 0.12389207997247367, validation losses: 0.5584178909947692\n",
      "Epoch 518, reconstruction losses: 0.018113119455625253, regression losses: 0.1214272560773423, validation losses: 0.7014384583775999\n",
      "Epoch 519, reconstruction losses: 0.019812570787155807, regression losses: 0.1808003642569343, validation losses: 0.6450311303106557\n",
      "Epoch 520, reconstruction losses: 0.0168655866384469, regression losses: 0.11052600271921278, validation losses: 0.5864585891410982\n",
      "Epoch 521, reconstruction losses: 0.018233316310032017, regression losses: 0.16451086596525843, validation losses: 0.4769437875256444\n",
      "Epoch 522, reconstruction losses: 0.018907017683895817, regression losses: 0.10721203242885187, validation losses: 0.5204766226927791\n",
      "Epoch 523, reconstruction losses: 0.016300745908217208, regression losses: 0.1177708441026763, validation losses: 0.5545161368930165\n",
      "Epoch 524, reconstruction losses: 0.01705833845374337, regression losses: 0.11301977880447595, validation losses: 0.6619398785256057\n",
      "Epoch 525, reconstruction losses: 0.017154645329123395, regression losses: 0.1349701282043795, validation losses: 0.6067411077285236\n",
      "Epoch 526, reconstruction losses: 0.01934080003508849, regression losses: 0.11181212402012859, validation losses: 0.4783257690932497\n",
      "Epoch 527, reconstruction losses: 0.019208685571796405, regression losses: 0.12496347101550037, validation losses: 0.6014511861727881\n",
      "Epoch 528, reconstruction losses: 0.019112836584632135, regression losses: 0.1469818802818564, validation losses: 0.5688404205414987\n",
      "Epoch 529, reconstruction losses: 0.019392216909628945, regression losses: 0.09693193644485561, validation losses: 0.4740106963871535\n",
      "Epoch 530, reconstruction losses: 0.023917429777239516, regression losses: 0.2135407178361585, validation losses: 0.5154437606026997\n",
      "Epoch 531, reconstruction losses: 0.01828523493031251, regression losses: 0.11482992271346311, validation losses: 0.7053349504170244\n",
      "Epoch 532, reconstruction losses: 0.020155688751457092, regression losses: 0.12327519717553422, validation losses: 0.5629278107175928\n",
      "Epoch 533, reconstruction losses: 0.017988737158606403, regression losses: 0.10604647447296882, validation losses: 0.5882893671459564\n",
      "Epoch 534, reconstruction losses: 0.01760061014469002, regression losses: 0.11878536157435057, validation losses: 0.5401866691269289\n",
      "Epoch 535, reconstruction losses: 0.01653943368192848, regression losses: 0.14959444476612185, validation losses: 0.5011267034928472\n",
      "Epoch 536, reconstruction losses: 0.01881245488851303, regression losses: 0.18592898555281417, validation losses: 0.5730262853491084\n",
      "Epoch 537, reconstruction losses: 0.01802325939760682, regression losses: 0.133936367827949, validation losses: 0.8004817858624629\n",
      "Epoch 538, reconstruction losses: 0.016774714707121507, regression losses: 0.11249741249006251, validation losses: 0.6992573077978401\n",
      "Epoch 539, reconstruction losses: 0.018846289431976193, regression losses: 0.1417496059115738, validation losses: 0.5558343567221077\n",
      "Epoch 540, reconstruction losses: 0.018733252857923974, regression losses: 0.13162782605241596, validation losses: 0.633287740542756\n",
      "Epoch 541, reconstruction losses: 0.0185308526045997, regression losses: 0.14790985974364304, validation losses: 0.5541155126899207\n",
      "Epoch 542, reconstruction losses: 0.020597796563594468, regression losses: 0.14883813928883904, validation losses: 0.6180143813243806\n",
      "Epoch 543, reconstruction losses: 0.019658782558981118, regression losses: 0.14040313081649694, validation losses: 0.7326890271546149\n",
      "Epoch 544, reconstruction losses: 0.020945958421093237, regression losses: 0.1906923057692557, validation losses: 0.7527696402086133\n",
      "Epoch 545, reconstruction losses: 0.01732331588266343, regression losses: 0.12142899160533216, validation losses: 0.5763285926439461\n",
      "Epoch 546, reconstruction losses: 0.022205078558771088, regression losses: 0.1629976808300038, validation losses: 0.5858759707977609\n",
      "Epoch 547, reconstruction losses: 0.01788694980229625, regression losses: 0.1511112903161846, validation losses: 0.8208467629213869\n",
      "Epoch 548, reconstruction losses: 0.023105007353028575, regression losses: 0.12631311067394987, validation losses: 0.5387573962698521\n",
      "Epoch 549, reconstruction losses: 0.018005598237656618, regression losses: 0.12369293788279313, validation losses: 0.5376601562857559\n",
      "Epoch 550, reconstruction losses: 0.019841295578263515, regression losses: 0.22349574508514194, validation losses: 0.6899828520135534\n",
      "Epoch 551, reconstruction losses: 0.018741315119741846, regression losses: 0.15779269558925388, validation losses: 0.890525180269468\n",
      "Epoch 552, reconstruction losses: 0.017956844980469358, regression losses: 0.1271243704451635, validation losses: 0.7501997137873453\n",
      "Epoch 553, reconstruction losses: 0.018961068069038328, regression losses: 0.12690267841610622, validation losses: 0.4599852065495261\n",
      "Epoch 554, reconstruction losses: 0.017077165165377422, regression losses: 0.13386325593121742, validation losses: 0.6650372177009314\n",
      "Epoch 555, reconstruction losses: 0.019857414599396533, regression losses: 0.1261518217881168, validation losses: 0.5337706359112199\n",
      "Epoch 556, reconstruction losses: 0.015831489878224782, regression losses: 0.12227658104452002, validation losses: 0.4691485596205563\n",
      "Epoch 557, reconstruction losses: 0.01888260315025117, regression losses: 0.12851350441170176, validation losses: 0.5998925336417527\n",
      "Epoch 558, reconstruction losses: 0.018292285066930977, regression losses: 0.15740436253599058, validation losses: 0.7129813301549054\n",
      "Epoch 559, reconstruction losses: 0.0179953851914504, regression losses: 0.11481258490738826, validation losses: 0.4988259338726624\n",
      "Epoch 560, reconstruction losses: 0.019253302540413596, regression losses: 0.10106963592506515, validation losses: 0.4958339081600313\n",
      "Epoch 561, reconstruction losses: 0.017511468527270306, regression losses: 0.13519912100188436, validation losses: 0.5725126478049232\n",
      "Epoch 562, reconstruction losses: 0.01952060647488896, regression losses: 0.15274190477841218, validation losses: 0.48900669998402974\n",
      "Epoch 563, reconstruction losses: 0.017475678394143327, regression losses: 0.13840141415333343, validation losses: 0.4828392026027142\n",
      "Epoch 564, reconstruction losses: 0.018852466942315845, regression losses: 0.16465262555164384, validation losses: 0.5135509773598388\n",
      "Epoch 565, reconstruction losses: 0.016721352058328923, regression losses: 0.08663508189253888, validation losses: 0.5942627323314977\n",
      "Epoch 566, reconstruction losses: 0.018076504622491982, regression losses: 0.1300784670984764, validation losses: 0.5180170531712943\n",
      "Epoch 567, reconstruction losses: 0.018783934236970938, regression losses: 0.16866730119530726, validation losses: 0.7013312545184656\n",
      "Epoch 568, reconstruction losses: 0.01902288687388514, regression losses: 0.10453769308126992, validation losses: 0.6298754436494001\n",
      "Epoch 569, reconstruction losses: 0.016281379991511656, regression losses: 0.11081758582932466, validation losses: 0.5998353036414539\n",
      "Epoch 570, reconstruction losses: 0.020312447648148726, regression losses: 0.17286967097258854, validation losses: 0.48202464100096765\n",
      "Epoch 571, reconstruction losses: 0.018999639426563852, regression losses: 0.137406130359409, validation losses: 0.7489299794995983\n",
      "Epoch 572, reconstruction losses: 0.018678743548812243, regression losses: 0.16289294036447574, validation losses: 0.5513139568175545\n",
      "Epoch 573, reconstruction losses: 0.015413421243545864, regression losses: 0.10582943084475781, validation losses: 0.5677139024341861\n",
      "Epoch 574, reconstruction losses: 0.017107659729586996, regression losses: 0.136411529733253, validation losses: 0.5214011656260006\n",
      "Epoch 575, reconstruction losses: 0.01948270137086212, regression losses: 0.15836209636350126, validation losses: 0.5738665595258011\n",
      "Epoch 576, reconstruction losses: 0.02038214562542564, regression losses: 0.13761012996205066, validation losses: 0.5183228688678511\n",
      "Epoch 577, reconstruction losses: 0.01591077720245012, regression losses: 0.10718439902155345, validation losses: 0.6384879235644647\n",
      "Epoch 578, reconstruction losses: 0.01719372525089976, regression losses: 0.13693474598161004, validation losses: 0.7627061130511076\n",
      "Epoch 579, reconstruction losses: 0.016233189329990322, regression losses: 0.10085612437970429, validation losses: 0.5290347536785953\n",
      "Epoch 580, reconstruction losses: 0.020106757583008273, regression losses: 0.1314787640711816, validation losses: 0.5840246997504596\n",
      "Epoch 581, reconstruction losses: 0.017112666578556403, regression losses: 0.09284306405972706, validation losses: 0.6149625717651475\n",
      "Epoch 582, reconstruction losses: 0.01754065232281249, regression losses: 0.11624481327649104, validation losses: 0.6389351240251883\n",
      "Epoch 583, reconstruction losses: 0.01721031118540739, regression losses: 0.10762008825853203, validation losses: 0.4664613377080631\n",
      "Epoch 584, reconstruction losses: 0.017955285302856838, regression losses: 0.12883995893232558, validation losses: 0.5075743009743149\n",
      "Epoch 585, reconstruction losses: 0.017799765580114195, regression losses: 0.1714880994712521, validation losses: 0.6913443836595536\n",
      "Epoch 586, reconstruction losses: 0.019875280597610578, regression losses: 0.3157974159915169, validation losses: 0.7204733671007318\n",
      "Epoch 587, reconstruction losses: 0.017423208648548044, regression losses: 0.17749033725217106, validation losses: 0.9036681566128328\n",
      "Epoch 588, reconstruction losses: 0.01665676191412724, regression losses: 0.15994508572664873, validation losses: 0.7055597969213162\n",
      "Epoch 589, reconstruction losses: 0.015386674926858093, regression losses: 0.11693666166836246, validation losses: 0.5825609539526252\n",
      "Epoch 590, reconstruction losses: 0.017499409715988776, regression losses: 0.13157560525800732, validation losses: 0.5598243551398704\n",
      "Epoch 591, reconstruction losses: 0.019841880515090667, regression losses: 0.14254368259845396, validation losses: 0.6808288416041182\n",
      "Epoch 592, reconstruction losses: 0.017693804083513797, regression losses: 0.10118489782173141, validation losses: 0.4525172193487247\n",
      "Epoch 593, reconstruction losses: 0.017153559690836935, regression losses: 0.11647618865538317, validation losses: 0.5486133423360648\n",
      "Epoch 594, reconstruction losses: 0.019571230071824708, regression losses: 0.12060902056641838, validation losses: 0.6111718866568445\n",
      "Epoch 595, reconstruction losses: 0.018494899063615285, regression losses: 0.1114055010669358, validation losses: 0.5255107114448786\n",
      "Epoch 596, reconstruction losses: 0.017586176516686165, regression losses: 0.11444196521549847, validation losses: 0.5912660219137278\n",
      "Epoch 597, reconstruction losses: 0.016722085186240226, regression losses: 0.09265020593258244, validation losses: 0.6014542026013971\n",
      "Epoch 598, reconstruction losses: 0.016311762569087392, regression losses: 0.11488235884482172, validation losses: 0.5257948298712676\n",
      "Epoch 599, reconstruction losses: 0.019762033194869393, regression losses: 0.1612458429725753, validation losses: 0.5326755208368257\n",
      "Epoch 600, reconstruction losses: 0.019128872654179157, regression losses: 0.10419295858587165, validation losses: 0.6218950548989681\n",
      "Epoch 601, reconstruction losses: 0.018037013228213487, regression losses: 0.12585117128101553, validation losses: 0.5513781904758817\n",
      "Epoch 602, reconstruction losses: 0.018226967401586323, regression losses: 0.19075325937386917, validation losses: 0.8058553500118445\n",
      "Epoch 603, reconstruction losses: 0.018875083214407617, regression losses: 0.21331795479414656, validation losses: 0.7668113747154983\n",
      "Epoch 604, reconstruction losses: 0.023186232610519258, regression losses: 0.1554447202464673, validation losses: 0.5277616183784474\n",
      "Epoch 605, reconstruction losses: 0.018298025004825472, regression losses: 0.14543063517225224, validation losses: 0.5211286893913318\n",
      "Epoch 606, reconstruction losses: 0.021638037828222476, regression losses: 0.20067074504074722, validation losses: 0.7620370777051942\n",
      "Epoch 607, reconstruction losses: 0.019401466410883268, regression losses: 0.18365882734095013, validation losses: 1.6267236952835953\n",
      "Epoch 608, reconstruction losses: 0.017781360725183205, regression losses: 0.26452129851755946, validation losses: 0.7188237809645869\n",
      "Epoch 609, reconstruction losses: 0.02520718041704279, regression losses: 0.16047213992196668, validation losses: 0.7335278502814262\n",
      "Epoch 610, reconstruction losses: 0.023490084603542974, regression losses: 0.19483845654834706, validation losses: 0.6052281812830672\n",
      "Epoch 611, reconstruction losses: 0.019157571539057134, regression losses: 0.18409331981963556, validation losses: 0.7286923688045709\n",
      "Epoch 612, reconstruction losses: 0.022297302600557685, regression losses: 0.14575417173730398, validation losses: 1.206901132697746\n",
      "Epoch 613, reconstruction losses: 0.0187239276811033, regression losses: 0.17300654152696954, validation losses: 0.6303483840418598\n",
      "Epoch 614, reconstruction losses: 0.018899030468122646, regression losses: 0.11726530806981317, validation losses: 0.5509526684694237\n",
      "Epoch 615, reconstruction losses: 0.021579397972644215, regression losses: 0.14333573086365264, validation losses: 0.4862108805126353\n",
      "Epoch 616, reconstruction losses: 0.01889393950446833, regression losses: 0.12794877637480873, validation losses: 0.8170931766731566\n",
      "Epoch 617, reconstruction losses: 0.022721606841101943, regression losses: 0.1354914666256723, validation losses: 0.5942351974061226\n",
      "Epoch 618, reconstruction losses: 0.01782118639647929, regression losses: 0.12270872090603104, validation losses: 0.48176813954613656\n",
      "Epoch 619, reconstruction losses: 0.01876600848284696, regression losses: 0.13561185044241053, validation losses: 0.5341104301223105\n",
      "Epoch 620, reconstruction losses: 0.01659898958808404, regression losses: 0.12596660278378058, validation losses: 0.6123848023546724\n",
      "Epoch 621, reconstruction losses: 0.019973771766920535, regression losses: 0.14264923230445442, validation losses: 0.553596370855831\n",
      "Epoch 622, reconstruction losses: 0.017284228253981616, regression losses: 0.10470385747420996, validation losses: 0.5122073213342916\n",
      "Epoch 623, reconstruction losses: 0.017305082821154547, regression losses: 0.14133186645923324, validation losses: 0.5849077464911748\n",
      "Epoch 624, reconstruction losses: 0.020905200185244714, regression losses: 0.15404330137742356, validation losses: 0.6060679227852207\n",
      "Epoch 625, reconstruction losses: 0.018686482934496106, regression losses: 0.15188731278170772, validation losses: 0.6750636030304442\n",
      "Epoch 626, reconstruction losses: 0.018474884739758196, regression losses: 0.09131067696889562, validation losses: 0.545999959444655\n",
      "Epoch 627, reconstruction losses: 0.017137677606962286, regression losses: 0.13976130594223254, validation losses: 0.5264015265151766\n",
      "Epoch 628, reconstruction losses: 0.02299428079183949, regression losses: 0.1401602972563232, validation losses: 0.599383740075207\n",
      "Epoch 629, reconstruction losses: 0.016948922443685316, regression losses: 0.13423046073920583, validation losses: 0.7066145244520688\n",
      "Epoch 630, reconstruction losses: 0.018836459827720517, regression losses: 0.10451198245713132, validation losses: 0.5746622348712718\n",
      "Epoch 631, reconstruction losses: 0.020985048652617362, regression losses: 0.12160254148154476, validation losses: 0.609470705301888\n",
      "Epoch 632, reconstruction losses: 0.01619546237362874, regression losses: 0.11664943531001423, validation losses: 0.6797598444928964\n",
      "Epoch 633, reconstruction losses: 0.01793171467270574, regression losses: 0.10989349300879393, validation losses: 0.554860600561205\n",
      "Epoch 634, reconstruction losses: 0.015579986216589447, regression losses: 0.15430076223995007, validation losses: 0.5051067791537784\n",
      "Epoch 635, reconstruction losses: 0.02198169803954406, regression losses: 0.22038488242730056, validation losses: 0.6873848957342445\n",
      "Epoch 636, reconstruction losses: 0.019563712296627817, regression losses: 0.16278577626424948, validation losses: 0.6199309582062975\n",
      "Epoch 637, reconstruction losses: 0.018132549239129086, regression losses: 0.1353846479050678, validation losses: 0.6309764824101927\n",
      "Epoch 638, reconstruction losses: 0.019433760263522087, regression losses: 0.14518106577328366, validation losses: 0.72332077948834\n",
      "Epoch 639, reconstruction losses: 0.016262749302941675, regression losses: 0.10857266875850234, validation losses: 0.8576846175918842\n",
      "Epoch 640, reconstruction losses: 0.019898638838999966, regression losses: 0.161236048975201, validation losses: 0.6081024260136765\n",
      "Epoch 641, reconstruction losses: 0.01751183950716887, regression losses: 0.15272798598995488, validation losses: 0.5905782231907483\n",
      "Epoch 642, reconstruction losses: 0.01597041585942378, regression losses: 0.074794994527024, validation losses: 0.6427964414432278\n",
      "Epoch 643, reconstruction losses: 0.021046102759515784, regression losses: 0.13183052992829425, validation losses: 0.5670726433278444\n",
      "Epoch 644, reconstruction losses: 0.01699454048904014, regression losses: 0.11842211351871954, validation losses: 0.8449779511266006\n",
      "Epoch 645, reconstruction losses: 0.019578067178562083, regression losses: 0.15309716277629526, validation losses: 0.8347341718339072\n",
      "Epoch 646, reconstruction losses: 0.017480815595598442, regression losses: 0.15058183488204008, validation losses: 0.5857710366869162\n",
      "Epoch 647, reconstruction losses: 0.02575554258911962, regression losses: 0.23750758018361773, validation losses: 0.6595010028928837\n",
      "Epoch 648, reconstruction losses: 0.019160753418664123, regression losses: 0.26869820718639903, validation losses: 0.648958452700019\n",
      "Epoch 649, reconstruction losses: 0.027631504299117586, regression losses: 0.26530480888139474, validation losses: 1.0070844057713602\n",
      "Epoch 650, reconstruction losses: 0.01963175866891931, regression losses: 0.1438490243590155, validation losses: 0.5229926305538601\n",
      "Epoch 651, reconstruction losses: 0.019160052467474133, regression losses: 0.12728589362209602, validation losses: 0.5832468199824761\n",
      "Epoch 652, reconstruction losses: 0.018910441270728818, regression losses: 0.1357539295980397, validation losses: 0.49080328491566527\n",
      "Epoch 653, reconstruction losses: 0.018381014180819378, regression losses: 0.1178783428341365, validation losses: 0.6095472672124589\n",
      "Epoch 654, reconstruction losses: 0.02439857348812396, regression losses: 0.18045726012406296, validation losses: 0.7871434280099603\n",
      "Epoch 655, reconstruction losses: 0.01933046144533028, regression losses: 0.19660256262604478, validation losses: 0.8579095713658172\n",
      "Epoch 656, reconstruction losses: 0.019702694353834076, regression losses: 0.16062569965137616, validation losses: 0.5722316525102323\n",
      "Epoch 657, reconstruction losses: 0.01688693257998187, regression losses: 0.14310370426328592, validation losses: 0.8560523523278208\n",
      "Epoch 658, reconstruction losses: 0.018976439721205572, regression losses: 0.18724254617711275, validation losses: 0.6556115608690056\n",
      "Epoch 659, reconstruction losses: 0.019782606015251943, regression losses: 0.14995694755871172, validation losses: 0.6795517452270069\n",
      "Epoch 660, reconstruction losses: 0.014862793452018687, regression losses: 0.09729839813168331, validation losses: 0.8332871066821169\n",
      "Epoch 661, reconstruction losses: 0.019196127673196325, regression losses: 0.1704682350431362, validation losses: 0.6495137411461862\n",
      "Epoch 662, reconstruction losses: 0.016094924332824424, regression losses: 0.12257250227421447, validation losses: 0.5155075769505556\n",
      "Epoch 663, reconstruction losses: 0.018943038866924635, regression losses: 0.11088197953239474, validation losses: 0.5265724956970453\n",
      "Epoch 664, reconstruction losses: 0.0196570313818299, regression losses: 0.16329382731971076, validation losses: 0.6511819782916093\n",
      "Epoch 665, reconstruction losses: 0.01774930464982673, regression losses: 0.12722457694338796, validation losses: 0.5173612893729492\n",
      "Epoch 666, reconstruction losses: 0.015582668218856966, regression losses: 0.10802641437504341, validation losses: 0.5363135606922251\n",
      "Epoch 667, reconstruction losses: 0.016962461367921042, regression losses: 0.1575544298864071, validation losses: 0.6132764612019684\n",
      "Epoch 668, reconstruction losses: 0.017828064121389813, regression losses: 0.4756904240778603, validation losses: 0.5336885892930995\n",
      "Epoch 669, reconstruction losses: 0.018319398317174548, regression losses: 0.17097164670262452, validation losses: 0.6800173001217689\n",
      "Epoch 670, reconstruction losses: 0.01872967157761585, regression losses: 0.16224951595440248, validation losses: 0.673598015636113\n",
      "Epoch 671, reconstruction losses: 0.018216735195329167, regression losses: 0.13055119310337107, validation losses: 0.6203534590610691\n",
      "Epoch 672, reconstruction losses: 0.021465388240644617, regression losses: 0.15251344922801494, validation losses: 0.5836583874838397\n",
      "Epoch 673, reconstruction losses: 0.017789940388838462, regression losses: 0.12790251699102242, validation losses: 0.6382608421642121\n",
      "Epoch 674, reconstruction losses: 0.01799059551665397, regression losses: 0.11755531825066955, validation losses: 0.6337638117434572\n",
      "Epoch 675, reconstruction losses: 0.022503839418490316, regression losses: 0.14336976934322937, validation losses: 0.5591224462354524\n",
      "Epoch 676, reconstruction losses: 0.016039662017947716, regression losses: 0.15641920916137703, validation losses: 0.6034219448993107\n",
      "Epoch 677, reconstruction losses: 0.018653741398010345, regression losses: 0.12222282294624776, validation losses: 0.581571678292728\n",
      "Epoch 678, reconstruction losses: 0.014681701399887032, regression losses: 0.11761961004740976, validation losses: 0.5908307782159281\n",
      "Epoch 679, reconstruction losses: 0.014844687763373186, regression losses: 0.11897114222499985, validation losses: 0.5853831335874115\n",
      "Epoch 680, reconstruction losses: 0.02380018927940038, regression losses: 0.1409658981234774, validation losses: 0.626611197172548\n",
      "Epoch 681, reconstruction losses: 0.022058678187481726, regression losses: 0.14183133502955939, validation losses: 0.8098655335482945\n",
      "Epoch 682, reconstruction losses: 0.017056611856555423, regression losses: 0.1271816567528324, validation losses: 0.5538113427938971\n",
      "Epoch 683, reconstruction losses: 0.02277259450080944, regression losses: 0.138618114018969, validation losses: 0.5660383506107852\n",
      "Epoch 684, reconstruction losses: 0.01543695375723542, regression losses: 0.1007059930108676, validation losses: 0.7165650864451792\n",
      "Epoch 685, reconstruction losses: 0.017213834196046822, regression losses: 0.11539312712650218, validation losses: 0.5617317267321109\n",
      "Epoch 686, reconstruction losses: 0.01660386792385202, regression losses: 0.13153479058341716, validation losses: 0.5181317054295173\n",
      "Epoch 687, reconstruction losses: 0.01801520946920958, regression losses: 0.14731680121430485, validation losses: 0.5843638583264197\n",
      "Epoch 688, reconstruction losses: 0.014070995427029144, regression losses: 0.09776310981671656, validation losses: 0.5223998042666443\n",
      "Epoch 689, reconstruction losses: 0.014024647274575329, regression losses: 0.17362909956294992, validation losses: 0.5076715523892342\n",
      "Epoch 690, reconstruction losses: 0.016567773247449444, regression losses: 0.10315475913248195, validation losses: 0.5636296214559169\n",
      "Epoch 691, reconstruction losses: 0.018819898036322377, regression losses: 0.13608145018888257, validation losses: 0.5789368075320418\n",
      "Epoch 692, reconstruction losses: 0.01602588188780573, regression losses: 0.11652018579090924, validation losses: 0.5509816397968773\n",
      "Epoch 693, reconstruction losses: 0.021786044214400505, regression losses: 0.16576796453246626, validation losses: 0.6151020363709071\n",
      "Epoch 694, reconstruction losses: 0.018540152343494275, regression losses: 0.10808439289787826, validation losses: 0.7592708583039446\n",
      "Epoch 695, reconstruction losses: 0.01893264198550355, regression losses: 0.1106559037444894, validation losses: 0.5410885638372798\n",
      "Epoch 696, reconstruction losses: 0.01900549215347208, regression losses: 0.15050603626237363, validation losses: 0.5850258815249317\n",
      "Epoch 697, reconstruction losses: 0.021776167671682493, regression losses: 0.12111724243326327, validation losses: 0.8165053150988903\n",
      "Epoch 698, reconstruction losses: 0.018739531707155907, regression losses: 0.1415490408522226, validation losses: 0.6042042709420675\n",
      "Epoch 699, reconstruction losses: 0.01669094455524192, regression losses: 0.09814215946521412, validation losses: 0.5740647576860547\n",
      "Epoch 700, reconstruction losses: 0.017874523959547715, regression losses: 0.10219629783216597, validation losses: 0.5339733201123681\n",
      "Epoch 701, reconstruction losses: 0.02759374354470547, regression losses: 0.17042845718660077, validation losses: 0.5466827199658132\n",
      "Epoch 702, reconstruction losses: 0.016326062334990996, regression losses: 0.10492772852655768, validation losses: 0.5883326932451195\n",
      "Epoch 703, reconstruction losses: 0.01620957330985109, regression losses: 0.09337854357362982, validation losses: 0.6753485097306064\n",
      "Epoch 704, reconstruction losses: 0.01658443361642577, regression losses: 0.12702644704254637, validation losses: 0.5538050846400941\n",
      "Epoch 705, reconstruction losses: 0.016991199038351487, regression losses: 0.1483821734142587, validation losses: 0.5461437757860986\n",
      "Epoch 706, reconstruction losses: 0.018182389994133838, regression losses: 0.16742527763187773, validation losses: 0.5965802277712048\n",
      "Epoch 707, reconstruction losses: 0.019508379216634394, regression losses: 0.2154440360771536, validation losses: 0.7231732571160535\n",
      "Epoch 708, reconstruction losses: 0.01639330871511369, regression losses: 0.13616976087152677, validation losses: 0.8420743383873842\n",
      "Epoch 709, reconstruction losses: 0.020932758469240458, regression losses: 0.24395412188215337, validation losses: 0.6204980104520041\n",
      "Epoch 710, reconstruction losses: 0.015131242350252223, regression losses: 0.11917086859627328, validation losses: 0.6176326012634643\n",
      "Epoch 711, reconstruction losses: 0.017952454250008684, regression losses: 0.16730656687276557, validation losses: 0.4994746392449977\n",
      "Epoch 712, reconstruction losses: 0.01765174242790906, regression losses: 0.15820307395466893, validation losses: 0.5916125330437052\n",
      "Epoch 713, reconstruction losses: 0.015982701172871868, regression losses: 0.14568122875667228, validation losses: 0.7729434628296308\n",
      "Epoch 714, reconstruction losses: 0.020428743581560146, regression losses: 0.24615643763877032, validation losses: 0.5102936020252392\n",
      "Epoch 715, reconstruction losses: 0.01735452675287674, regression losses: 0.10689078481541955, validation losses: 0.5088038684941167\n",
      "Epoch 716, reconstruction losses: 0.017773756318829496, regression losses: 0.1517406768654453, validation losses: 0.5377871100163597\n",
      "Epoch 717, reconstruction losses: 0.01661727563308131, regression losses: 0.0978182049473288, validation losses: 0.7478446629720807\n",
      "Epoch 718, reconstruction losses: 0.01678094074163384, regression losses: 0.13063114621726582, validation losses: 0.5203810690414863\n",
      "Epoch 719, reconstruction losses: 0.018051009911051193, regression losses: 0.14137105679101683, validation losses: 0.5113251582675186\n",
      "Epoch 720, reconstruction losses: 0.016605615377099973, regression losses: 0.13568007246435032, validation losses: 0.5210481735337765\n",
      "Epoch 721, reconstruction losses: 0.01749367063024116, regression losses: 0.12226654237004986, validation losses: 0.5218586995249805\n",
      "Epoch 722, reconstruction losses: 0.015699781461414493, regression losses: 0.11094631978324007, validation losses: 0.5443787325189138\n",
      "Epoch 723, reconstruction losses: 0.017182452031452265, regression losses: 0.11445804795489183, validation losses: 0.5633886749228882\n",
      "Epoch 724, reconstruction losses: 0.01788160880176304, regression losses: 0.09835128700727234, validation losses: 0.5208079724175794\n",
      "Epoch 725, reconstruction losses: 0.017628856313003757, regression losses: 0.11868612626031842, validation losses: 0.5255371247748934\n",
      "Epoch 726, reconstruction losses: 0.022030536017695244, regression losses: 0.12230439352696415, validation losses: 0.546006093462858\n",
      "Epoch 727, reconstruction losses: 0.015698239684358413, regression losses: 0.10824138957684912, validation losses: 0.5232582978282043\n",
      "Epoch 728, reconstruction losses: 0.01779498873472609, regression losses: 0.09497283670552256, validation losses: 0.5478598785238498\n",
      "Epoch 729, reconstruction losses: 0.01996538573457901, regression losses: 0.1449811392441847, validation losses: 0.5940173950742906\n",
      "Epoch 730, reconstruction losses: 0.01611984358337279, regression losses: 0.1396039905293433, validation losses: 0.6744443883391074\n",
      "Epoch 731, reconstruction losses: 0.019868078157099706, regression losses: 0.09519711462975226, validation losses: 0.5139237429451109\n",
      "Epoch 732, reconstruction losses: 0.016905312623736988, regression losses: 0.12601275628784145, validation losses: 0.5135585179525364\n",
      "Epoch 733, reconstruction losses: 0.016662264889545076, regression losses: 0.12827141465064848, validation losses: 0.5568667755130206\n",
      "Epoch 734, reconstruction losses: 0.01972553149418846, regression losses: 0.15930117205523697, validation losses: 0.5343543643784333\n",
      "Epoch 735, reconstruction losses: 0.028793525620465672, regression losses: 0.4011131760373111, validation losses: 0.4985093088345655\n",
      "Epoch 736, reconstruction losses: 0.020415736957171658, regression losses: 0.19778754796059475, validation losses: 0.9787194187174557\n",
      "Epoch 737, reconstruction losses: 0.017773673505887076, regression losses: 0.20218954591687802, validation losses: 0.6806523433184919\n",
      "Epoch 738, reconstruction losses: 0.014290483285551145, regression losses: 0.14030821229790552, validation losses: 0.5369743793914757\n",
      "Epoch 739, reconstruction losses: 0.01756091000752255, regression losses: 0.14131453334613447, validation losses: 0.5479312916168837\n",
      "Epoch 740, reconstruction losses: 0.020249997929310024, regression losses: 0.14543967517072776, validation losses: 0.5043934316664347\n",
      "Epoch 741, reconstruction losses: 0.01576340715596647, regression losses: 0.10768310432963078, validation losses: 0.5820648323704953\n",
      "Epoch 742, reconstruction losses: 0.01816502675148639, regression losses: 0.1286546627136764, validation losses: 0.5214701202089952\n",
      "Epoch 743, reconstruction losses: 0.01648190944125201, regression losses: 0.1128420987982953, validation losses: 0.5388932655831593\n",
      "Epoch 744, reconstruction losses: 0.018705237889135914, regression losses: 0.14454900539679583, validation losses: 0.4761889356777689\n",
      "Epoch 745, reconstruction losses: 0.017079419473208936, regression losses: 0.145300224247093, validation losses: 0.5250391091995895\n",
      "Epoch 746, reconstruction losses: 0.017755969241328363, regression losses: 0.12972592439788266, validation losses: 0.6136672200512255\n",
      "Epoch 747, reconstruction losses: 0.016833852065601666, regression losses: 0.12107422160131193, validation losses: 0.5014728690245333\n",
      "Epoch 748, reconstruction losses: 0.018000026508162285, regression losses: 0.11010320235960702, validation losses: 0.6007198379661715\n",
      "Epoch 749, reconstruction losses: 0.015542337829139488, regression losses: 0.11035526143384213, validation losses: 0.8092621884789264\n",
      "Epoch 750, reconstruction losses: 0.019512924921227, regression losses: 0.11715067829019644, validation losses: 0.5931887704815709\n",
      "Epoch 751, reconstruction losses: 0.017138359827600706, regression losses: 0.11182389949396075, validation losses: 0.5412322797471093\n",
      "Epoch 752, reconstruction losses: 0.016001203159446427, regression losses: 0.12777031369467184, validation losses: 0.575556196084316\n",
      "Epoch 753, reconstruction losses: 0.014633706518176987, regression losses: 0.11351958645412687, validation losses: 0.592346511790568\n",
      "Epoch 754, reconstruction losses: 0.01631311718303341, regression losses: 0.11205220216022972, validation losses: 0.504407447651986\n",
      "Epoch 755, reconstruction losses: 0.014974850368530123, regression losses: 0.0950601105064668, validation losses: 0.49893528706839924\n",
      "Epoch 756, reconstruction losses: 0.0159981030372852, regression losses: 0.1218673645772649, validation losses: 0.5944425426056879\n",
      "Epoch 757, reconstruction losses: 0.01639599672934436, regression losses: 0.13684638599729537, validation losses: 0.545884353555995\n",
      "Epoch 758, reconstruction losses: 0.015347718019159812, regression losses: 0.1021680915573344, validation losses: 0.5955386240472664\n",
      "Epoch 759, reconstruction losses: 0.01732649553087709, regression losses: 0.12102591784100152, validation losses: 0.4916385760023644\n",
      "Epoch 760, reconstruction losses: 0.015337540360846454, regression losses: 0.10925795191066628, validation losses: 0.5072509309799191\n",
      "Epoch 761, reconstruction losses: 0.014978219253952547, regression losses: 0.12108734190825611, validation losses: 0.703423841749383\n",
      "Epoch 762, reconstruction losses: 0.019664071744434394, regression losses: 0.15135987518295596, validation losses: 0.6062918123339582\n",
      "Epoch 763, reconstruction losses: 0.016777300863125434, regression losses: 0.09999147324241074, validation losses: 0.5077022166320615\n",
      "Epoch 764, reconstruction losses: 0.02034326266351951, regression losses: 0.12001814215309069, validation losses: 0.5529336642523024\n",
      "Epoch 765, reconstruction losses: 0.015120548078910109, regression losses: 0.11621745613359986, validation losses: 0.7763593265674097\n",
      "Epoch 766, reconstruction losses: 0.018283929358279584, regression losses: 0.14554327422754001, validation losses: 0.5681023009909558\n",
      "Epoch 767, reconstruction losses: 0.018551809233366242, regression losses: 0.14971078761861462, validation losses: 0.47776378069164854\n",
      "Epoch 768, reconstruction losses: 0.02176632927180096, regression losses: 0.16272859590428673, validation losses: 0.5665796628903959\n",
      "Epoch 769, reconstruction losses: 0.01778757529802296, regression losses: 0.12897362752645333, validation losses: 0.5045528842746636\n",
      "Epoch 770, reconstruction losses: 0.016376010843684497, regression losses: 0.13532606427448685, validation losses: 0.7229084510711788\n",
      "Epoch 771, reconstruction losses: 0.01605944570442256, regression losses: 0.14089056617857376, validation losses: 0.794339514853361\n",
      "Epoch 772, reconstruction losses: 0.019662241710328383, regression losses: 0.22155780742654382, validation losses: 0.6076661450399762\n",
      "Epoch 773, reconstruction losses: 0.01965320262600361, regression losses: 0.1448977811626243, validation losses: 0.7537012297031284\n",
      "Epoch 774, reconstruction losses: 0.018157837903789078, regression losses: 0.17451299471882628, validation losses: 0.5182141645961077\n",
      "Epoch 775, reconstruction losses: 0.014938694940496487, regression losses: 0.13065896724549197, validation losses: 0.5695300128489087\n",
      "Epoch 776, reconstruction losses: 0.024995571103300508, regression losses: 0.21611127632335214, validation losses: 0.583992295602479\n",
      "Epoch 777, reconstruction losses: 0.02314684425512023, regression losses: 0.22145496290934746, validation losses: 0.4695072118284529\n",
      "Epoch 778, reconstruction losses: 0.016755447343950493, regression losses: 0.12470743780685262, validation losses: 0.739771769251591\n",
      "Epoch 779, reconstruction losses: 0.01765668175583249, regression losses: 0.1410426542872005, validation losses: 0.6052352059801933\n",
      "Epoch 780, reconstruction losses: 0.015905624495072195, regression losses: 0.13603898576132215, validation losses: 0.5351975356871943\n",
      "Epoch 781, reconstruction losses: 0.01934706248033605, regression losses: 0.12535425962964397, validation losses: 0.485708878242605\n",
      "Epoch 782, reconstruction losses: 0.014515141666908022, regression losses: 0.11369992252718003, validation losses: 0.5157953772316961\n",
      "Epoch 783, reconstruction losses: 0.015787813383279278, regression losses: 0.11291933057928243, validation losses: 0.5020554993398237\n",
      "Epoch 784, reconstruction losses: 0.01471184045804017, regression losses: 0.10005988725804228, validation losses: 0.5126042680442549\n",
      "Epoch 785, reconstruction losses: 0.016257306639364467, regression losses: 0.15067244468035274, validation losses: 0.5108357362735281\n",
      "Epoch 786, reconstruction losses: 0.017867832259590846, regression losses: 0.2194979816709985, validation losses: 0.5019906934602193\n",
      "Epoch 787, reconstruction losses: 0.014174424803985886, regression losses: 0.10739306292396926, validation losses: 0.6106731248295699\n",
      "Epoch 788, reconstruction losses: 0.01682194905280978, regression losses: 0.13154525542598364, validation losses: 0.529256631306425\n",
      "Epoch 789, reconstruction losses: 0.023632458039242, regression losses: 0.22550892016993646, validation losses: 0.7609728388841486\n",
      "Epoch 790, reconstruction losses: 0.020070691508852864, regression losses: 0.17102803073801104, validation losses: 0.9645966887688133\n",
      "Epoch 791, reconstruction losses: 0.020778463314641567, regression losses: 0.17827330938167582, validation losses: 0.6428376782351742\n",
      "Epoch 792, reconstruction losses: 0.017053180068097574, regression losses: 0.11731348404474863, validation losses: 0.8903414581873788\n",
      "Epoch 793, reconstruction losses: 0.024443044477402226, regression losses: 0.1991123737758512, validation losses: 0.5595848004277274\n",
      "Epoch 794, reconstruction losses: 0.01960974183694733, regression losses: 0.11305628360999395, validation losses: 0.5529049418894749\n",
      "Epoch 795, reconstruction losses: 0.022508762106789936, regression losses: 0.09864367422721346, validation losses: 0.6295811932544166\n",
      "Epoch 796, reconstruction losses: 0.019263324573614606, regression losses: 0.09892186412301109, validation losses: 0.6970446384945906\n",
      "Epoch 797, reconstruction losses: 0.018481862040004775, regression losses: 0.1316921554804361, validation losses: 0.5097920839979895\n",
      "Epoch 798, reconstruction losses: 0.01752098527767139, regression losses: 0.11400476697041331, validation losses: 0.5136362727771022\n",
      "Epoch 799, reconstruction losses: 0.01820851332083545, regression losses: 0.1850069484397206, validation losses: 0.6786059586799039\n",
      "Epoch 800, reconstruction losses: 0.019524372773281805, regression losses: 0.13859936062184963, validation losses: 0.7696574578439144\n",
      "Epoch 801, reconstruction losses: 0.01710118799629311, regression losses: 0.11489604358524805, validation losses: 0.6310860308505711\n",
      "Epoch 802, reconstruction losses: 0.015118521380382433, regression losses: 0.1734262947601674, validation losses: 0.5968583987425653\n",
      "Epoch 803, reconstruction losses: 0.014296327300595924, regression losses: 0.13268781280415437, validation losses: 0.6255656534396864\n",
      "Epoch 804, reconstruction losses: 0.01586915386927154, regression losses: 0.10825976056179851, validation losses: 0.5417627891508581\n",
      "Epoch 805, reconstruction losses: 0.01678903969964048, regression losses: 0.1275771466281876, validation losses: 0.5475744873551989\n",
      "Epoch 806, reconstruction losses: 0.016347495248327883, regression losses: 0.13097080844212566, validation losses: 0.6168339118034355\n",
      "Epoch 807, reconstruction losses: 0.016947717457169432, regression losses: 0.15008534516821673, validation losses: 0.5833471964231067\n",
      "Epoch 808, reconstruction losses: 0.01727064458244596, regression losses: 0.1333483036209964, validation losses: 0.5210109308669114\n",
      "Epoch 809, reconstruction losses: 0.01319218281682002, regression losses: 0.12220702077506562, validation losses: 0.5170126467516736\n",
      "Epoch 810, reconstruction losses: 0.014132092414728287, regression losses: 0.11206102771181663, validation losses: 0.6678367916223502\n",
      "Epoch 811, reconstruction losses: 0.019957991796016795, regression losses: 0.12627096993304995, validation losses: 0.5680948364903946\n",
      "Epoch 812, reconstruction losses: 0.02300050618612033, regression losses: 0.11030551604766148, validation losses: 0.7396971373195386\n",
      "Epoch 813, reconstruction losses: 0.014297638438002089, regression losses: 0.11926069266274754, validation losses: 0.5520444308244116\n",
      "Epoch 814, reconstruction losses: 0.014538875171147733, regression losses: 0.12432561592562233, validation losses: 0.615099881644746\n",
      "Epoch 815, reconstruction losses: 0.01589903258314381, regression losses: 0.13711685345993546, validation losses: 0.5491805354029607\n",
      "Epoch 816, reconstruction losses: 0.013782503825230044, regression losses: 0.1142425911490542, validation losses: 0.5512566544181333\n",
      "Epoch 817, reconstruction losses: 0.01829652885115872, regression losses: 0.385726831408696, validation losses: 0.539805039536119\n",
      "Epoch 818, reconstruction losses: 0.020772349527714336, regression losses: 0.16756170206519977, validation losses: 0.9864292031237407\n",
      "Epoch 819, reconstruction losses: 0.01885891650514118, regression losses: 0.23197012144798546, validation losses: 1.054433487101071\n",
      "Epoch 820, reconstruction losses: 0.018878435411581657, regression losses: 0.16156871626659766, validation losses: 0.5874543294752601\n",
      "Epoch 821, reconstruction losses: 0.015947137273579198, regression losses: 0.14641965633111675, validation losses: 0.5830703780762678\n",
      "Epoch 822, reconstruction losses: 0.015912160001074, regression losses: 0.11494897118076439, validation losses: 0.6253006899521648\n",
      "Epoch 823, reconstruction losses: 0.017938482650710543, regression losses: 0.12619962454383152, validation losses: 0.6249192776869911\n",
      "Epoch 824, reconstruction losses: 0.016698934268328858, regression losses: 0.1312182538809295, validation losses: 0.5169224092788457\n",
      "Epoch 825, reconstruction losses: 0.018462279127222536, regression losses: 0.14113576679877116, validation losses: 0.5564337946250515\n",
      "Epoch 826, reconstruction losses: 0.017546203843766792, regression losses: 0.12671154249611255, validation losses: 0.5960774414197902\n",
      "Epoch 827, reconstruction losses: 0.015962501446071316, regression losses: 0.07832249317245765, validation losses: 0.6178938416866696\n",
      "Epoch 828, reconstruction losses: 0.022900196098770045, regression losses: 0.14351208802481719, validation losses: 0.6879266961904249\n",
      "Epoch 829, reconstruction losses: 0.01715608022854105, regression losses: 0.1226053161224074, validation losses: 0.5649364496334298\n",
      "Epoch 830, reconstruction losses: 0.015888204951933972, regression losses: 0.1013222068243589, validation losses: 0.5569349330771427\n",
      "Epoch 831, reconstruction losses: 0.021976206510079775, regression losses: 0.1620575543099438, validation losses: 0.5737380204033635\n",
      "Epoch 832, reconstruction losses: 0.024639382632761584, regression losses: 0.14938244527717515, validation losses: 0.4990395929895677\n",
      "Epoch 833, reconstruction losses: 0.019799037087142285, regression losses: 0.09417601399519697, validation losses: 0.5830632457638637\n",
      "Epoch 834, reconstruction losses: 0.02536379111830992, regression losses: 0.170741542325705, validation losses: 0.5081515072189631\n",
      "Epoch 835, reconstruction losses: 0.017013265806282454, regression losses: 0.13515527185912796, validation losses: 0.5194200298977119\n",
      "Epoch 836, reconstruction losses: 0.016243817134307587, regression losses: 0.14254114827285513, validation losses: 0.6245309824084297\n",
      "Epoch 837, reconstruction losses: 0.01752263046611187, regression losses: 0.13141573212435398, validation losses: 0.61357810747368\n",
      "Epoch 838, reconstruction losses: 0.014923604322402481, regression losses: 0.11837360576244517, validation losses: 0.5160540779832439\n",
      "Epoch 839, reconstruction losses: 0.017554814436363288, regression losses: 0.1472478841880289, validation losses: 0.504466830535501\n",
      "Epoch 840, reconstruction losses: 0.017297433657520223, regression losses: 0.13585165323368648, validation losses: 0.6651062436784498\n",
      "Epoch 841, reconstruction losses: 0.01879958568178132, regression losses: 0.1331040091275332, validation losses: 0.5783614655354978\n",
      "Epoch 842, reconstruction losses: 0.01625884686849128, regression losses: 0.12492339398361953, validation losses: 0.5485401327545989\n",
      "Epoch 843, reconstruction losses: 0.020467613021014745, regression losses: 0.17780442118927278, validation losses: 0.49493230276772116\n",
      "Epoch 844, reconstruction losses: 0.015803472688729572, regression losses: 0.15047937027462976, validation losses: 0.4810879550315076\n",
      "Epoch 845, reconstruction losses: 0.01822090277466995, regression losses: 0.14293675292032548, validation losses: 0.48818044906511465\n",
      "Epoch 846, reconstruction losses: 0.027850462076108713, regression losses: 0.3622922005202155, validation losses: 0.5845714292827238\n",
      "Epoch 847, reconstruction losses: 0.016325918888994595, regression losses: 0.14884950466813437, validation losses: 0.5380508772638009\n",
      "Epoch 848, reconstruction losses: 0.01653586731346887, regression losses: 0.1469080354728693, validation losses: 0.5066218608016251\n",
      "Epoch 849, reconstruction losses: 0.01975094777094419, regression losses: 0.15917019138271038, validation losses: 0.5592893255470488\n",
      "Epoch 850, reconstruction losses: 0.014645514929934624, regression losses: 0.12231744522944404, validation losses: 0.6427542739208617\n",
      "Epoch 851, reconstruction losses: 0.02242982981495527, regression losses: 0.15377810450426865, validation losses: 0.5076091547624592\n",
      "Epoch 852, reconstruction losses: 0.014919291039271091, regression losses: 0.10641128324920063, validation losses: 0.5479186762524031\n",
      "Epoch 853, reconstruction losses: 0.014510727374198494, regression losses: 0.1234690118948165, validation losses: 0.5098303276040386\n",
      "Epoch 854, reconstruction losses: 0.01717989861202641, regression losses: 0.13952058316917643, validation losses: 0.5683851860935909\n",
      "Epoch 855, reconstruction losses: 0.020376502663056933, regression losses: 0.1386348658017843, validation losses: 0.5799450424154661\n",
      "Epoch 856, reconstruction losses: 0.015872385002376053, regression losses: 0.1444491267268131, validation losses: 0.5771247218476164\n",
      "Epoch 857, reconstruction losses: 0.017697876236036778, regression losses: 0.12473587172957815, validation losses: 0.5140738412567836\n",
      "Epoch 858, reconstruction losses: 0.01661296325237438, regression losses: 0.11267592207508492, validation losses: 0.49455372166795\n",
      "Epoch 859, reconstruction losses: 0.01442658506640131, regression losses: 0.08719059225596934, validation losses: 0.5071526290648897\n",
      "Epoch 860, reconstruction losses: 0.01661100753137742, regression losses: 0.19971704009078078, validation losses: 0.5641271416197181\n",
      "Epoch 861, reconstruction losses: 0.01744892472725477, regression losses: 0.15071395136159257, validation losses: 0.6267551535906244\n",
      "Epoch 862, reconstruction losses: 0.01627121111061076, regression losses: 0.11012773927441431, validation losses: 0.5497100177600969\n",
      "Epoch 863, reconstruction losses: 0.015063563228738336, regression losses: 0.1185338338791498, validation losses: 0.6781754247290526\n",
      "Epoch 864, reconstruction losses: 0.019917247456305277, regression losses: 0.12221899700073804, validation losses: 0.7216188592890543\n",
      "Epoch 865, reconstruction losses: 0.01734194330106346, regression losses: 0.10788154320572987, validation losses: 0.7107187841979739\n",
      "Epoch 866, reconstruction losses: 0.01709864618319823, regression losses: 0.11271360254974894, validation losses: 0.5406490313255004\n",
      "Epoch 867, reconstruction losses: 0.015996460552733485, regression losses: 0.12506966936916245, validation losses: 0.49493368805164656\n",
      "Epoch 868, reconstruction losses: 0.016896832345181703, regression losses: 0.13649385807765885, validation losses: 0.6075935965776562\n",
      "Epoch 869, reconstruction losses: 0.014025187330863075, regression losses: 0.10614079792102334, validation losses: 0.6379590699499129\n",
      "Epoch 870, reconstruction losses: 0.015087839553617793, regression losses: 0.13086941470227936, validation losses: 0.5167855205322024\n",
      "Epoch 871, reconstruction losses: 0.02082052679239487, regression losses: 0.15303217401173871, validation losses: 0.512403528408339\n",
      "Epoch 872, reconstruction losses: 0.016566181906089904, regression losses: 0.15636797394369004, validation losses: 0.5997139573304292\n",
      "Epoch 873, reconstruction losses: 0.018279253089827613, regression losses: 0.2034582877504802, validation losses: 0.5020664086196733\n",
      "Epoch 874, reconstruction losses: 0.015683525356186136, regression losses: 0.12748159361544467, validation losses: 0.5276937349907984\n",
      "Epoch 875, reconstruction losses: 0.02318827809826589, regression losses: 0.18981957491216372, validation losses: 0.554863038512266\n",
      "Epoch 876, reconstruction losses: 0.016573335780554442, regression losses: 0.14270961377209396, validation losses: 0.882076660817562\n",
      "Epoch 877, reconstruction losses: 0.02079588627909422, regression losses: 0.1807326989196476, validation losses: 0.6234011830838462\n",
      "Epoch 878, reconstruction losses: 0.014307654081843618, regression losses: 0.11667874436103644, validation losses: 0.719510819615152\n",
      "Epoch 879, reconstruction losses: 0.016695715988921646, regression losses: 0.11788429460596601, validation losses: 0.534706821732072\n",
      "Epoch 880, reconstruction losses: 0.015725747549846278, regression losses: 0.13939813233418386, validation losses: 0.4938183877544713\n",
      "Epoch 881, reconstruction losses: 0.01715708083949508, regression losses: 0.139334195283543, validation losses: 0.49895728828112684\n",
      "Epoch 882, reconstruction losses: 0.015397179281955171, regression losses: 0.10204386573649385, validation losses: 0.6184769936054028\n",
      "Epoch 883, reconstruction losses: 0.016116297879868617, regression losses: 0.14364413449107213, validation losses: 0.5900168350932364\n",
      "Epoch 884, reconstruction losses: 0.019995243396963375, regression losses: 0.12411595894068098, validation losses: 0.5758838976272732\n",
      "Epoch 885, reconstruction losses: 0.018537580863204388, regression losses: 0.1321108567608481, validation losses: 0.7639929220070775\n",
      "Epoch 886, reconstruction losses: 0.015402778604858587, regression losses: 0.16387416246514405, validation losses: 0.6780321717704992\n",
      "Epoch 887, reconstruction losses: 0.018333493780074487, regression losses: 0.13166433462281393, validation losses: 0.5798258808486934\n",
      "Epoch 888, reconstruction losses: 0.022607377836168802, regression losses: 0.17139881948078833, validation losses: 0.5270947419289801\n",
      "Epoch 889, reconstruction losses: 0.014590472841647002, regression losses: 0.13144081751463949, validation losses: 0.5941222458440334\n",
      "Epoch 890, reconstruction losses: 0.015477651981671331, regression losses: 0.11143784621544738, validation losses: 0.5541015315516897\n",
      "Epoch 891, reconstruction losses: 0.017069578619606014, regression losses: 0.15481878001780502, validation losses: 0.5092861294400365\n",
      "Epoch 892, reconstruction losses: 0.020316255367723895, regression losses: 0.12408327668162995, validation losses: 0.5287105741284419\n",
      "Epoch 893, reconstruction losses: 0.018178929038854274, regression losses: 0.14213626970731005, validation losses: 0.565846687356613\n",
      "Epoch 894, reconstruction losses: 0.022204997727013936, regression losses: 0.19928519661443791, validation losses: 0.628885657016284\n",
      "Epoch 895, reconstruction losses: 0.01607920669917335, regression losses: 0.1303909301646703, validation losses: 0.8877792984592404\n",
      "Epoch 896, reconstruction losses: 0.020390562691704188, regression losses: 0.1862712864912183, validation losses: 0.7058726420928516\n",
      "Epoch 897, reconstruction losses: 0.015202375551769136, regression losses: 0.11758237129635732, validation losses: 0.5618736973618624\n",
      "Epoch 898, reconstruction losses: 0.019274776137106004, regression losses: 0.23230251710039207, validation losses: 0.7743825841378863\n",
      "Epoch 899, reconstruction losses: 0.01820669260700254, regression losses: 0.16003655538792647, validation losses: 1.0312509168637658\n",
      "Epoch 900, reconstruction losses: 0.01809290416227103, regression losses: 0.19711762256690238, validation losses: 0.6199909366185471\n",
      "Epoch 901, reconstruction losses: 0.015218454856916676, regression losses: 0.14338611096558262, validation losses: 0.6321561035661083\n",
      "Epoch 902, reconstruction losses: 0.024219471450211034, regression losses: 0.2104161707802792, validation losses: 0.638731597553488\n",
      "Epoch 903, reconstruction losses: 0.016325213811287518, regression losses: 0.12274943345227023, validation losses: 0.6508508110810716\n",
      "Epoch 904, reconstruction losses: 0.01855491389018555, regression losses: 0.1521565996791271, validation losses: 0.5619893951655741\n",
      "Epoch 905, reconstruction losses: 0.014672708433952585, regression losses: 0.12480496941709793, validation losses: 0.5562924238007932\n",
      "Epoch 906, reconstruction losses: 0.01657698601065603, regression losses: 0.11268834799457124, validation losses: 0.6095851663063113\n",
      "Epoch 907, reconstruction losses: 0.016506681897170604, regression losses: 0.11971359762419721, validation losses: 0.6287308064099281\n",
      "Epoch 908, reconstruction losses: 0.014156280392398043, regression losses: 0.10981375378163928, validation losses: 0.5002290792502136\n",
      "Epoch 909, reconstruction losses: 0.020085218844029685, regression losses: 0.14797546573275222, validation losses: 0.4830133298484678\n",
      "Epoch 910, reconstruction losses: 0.01562378829763405, regression losses: 0.09631944750633532, validation losses: 0.4864480959458315\n",
      "Epoch 911, reconstruction losses: 0.01870043652450782, regression losses: 0.11902584652789383, validation losses: 0.5501290888924603\n",
      "Epoch 912, reconstruction losses: 0.01657368782445439, regression losses: 0.11572665377666984, validation losses: 0.5274750135371633\n",
      "Epoch 913, reconstruction losses: 0.016310017474558375, regression losses: 0.1195555634859302, validation losses: 0.5338411827767892\n",
      "Epoch 914, reconstruction losses: 0.0157609307528551, regression losses: 0.12007925006416369, validation losses: 0.5162642246940892\n",
      "Epoch 915, reconstruction losses: 0.014640654612058228, regression losses: 0.10493462152784615, validation losses: 0.5001043551542625\n",
      "Epoch 916, reconstruction losses: 0.01811099394028496, regression losses: 0.09662130296795643, validation losses: 0.46689928149883475\n",
      "Epoch 917, reconstruction losses: 0.016323431822784545, regression losses: 0.1348474797500359, validation losses: 0.48384530214060834\n",
      "Epoch 918, reconstruction losses: 0.024874541751087657, regression losses: 0.147963803514755, validation losses: 0.5112973262459269\n",
      "Epoch 919, reconstruction losses: 0.014652977765287912, regression losses: 0.09549679848521633, validation losses: 0.5116517639213038\n",
      "Epoch 920, reconstruction losses: 0.019905004772673696, regression losses: 0.17532510863488776, validation losses: 0.5361111379148552\n",
      "Epoch 921, reconstruction losses: 0.018127965108454023, regression losses: 0.16142651922074625, validation losses: 0.5060320936268949\n",
      "Epoch 922, reconstruction losses: 0.016527004071657955, regression losses: 0.17741070546283755, validation losses: 0.5269986402113988\n",
      "Epoch 923, reconstruction losses: 0.015777165635323182, regression losses: 0.13573615170803333, validation losses: 0.6454265537206141\n",
      "Epoch 924, reconstruction losses: 0.017465884502213244, regression losses: 0.10603713773209827, validation losses: 0.6647205237782574\n",
      "Epoch 925, reconstruction losses: 0.015958643603603523, regression losses: 0.12877432691722518, validation losses: 0.5776324708096185\n",
      "Epoch 926, reconstruction losses: 0.016766618218998313, regression losses: 0.12877247618544987, validation losses: 0.5260639427066173\n",
      "Epoch 927, reconstruction losses: 0.014912241079544801, regression losses: 0.10807253439932689, validation losses: 0.521316279935723\n",
      "Epoch 928, reconstruction losses: 0.014485582515901454, regression losses: 0.11922584270749609, validation losses: 0.47634677631027417\n",
      "Epoch 929, reconstruction losses: 0.016236931341151842, regression losses: 0.14780378867012223, validation losses: 0.5299733077532774\n",
      "Epoch 930, reconstruction losses: 0.014341157686279216, regression losses: 0.10324775526719188, validation losses: 0.5231726872652345\n",
      "Epoch 931, reconstruction losses: 0.020528706143582653, regression losses: 0.1189997119947744, validation losses: 0.46386807651391687\n",
      "Epoch 932, reconstruction losses: 0.017082085019319484, regression losses: 0.151314782097453, validation losses: 0.4672323267992231\n",
      "Epoch 933, reconstruction losses: 0.017521601474025733, regression losses: 0.11051404288467648, validation losses: 0.5401297757333181\n",
      "Epoch 934, reconstruction losses: 0.01403210610709078, regression losses: 0.10996141430913917, validation losses: 0.5436506229344812\n",
      "Epoch 935, reconstruction losses: 0.01578921765392683, regression losses: 0.10224921983545363, validation losses: 0.5102312886090964\n",
      "Epoch 936, reconstruction losses: 0.014229940062190789, regression losses: 0.12483521253395805, validation losses: 0.46771137164438537\n",
      "Epoch 937, reconstruction losses: 0.016472110391289506, regression losses: 0.09774146128029157, validation losses: 0.5358257270524636\n",
      "Epoch 938, reconstruction losses: 0.017570955496210242, regression losses: 0.13178554083717328, validation losses: 0.5861127467891296\n",
      "Epoch 939, reconstruction losses: 0.01592045662904171, regression losses: 0.10888747210567992, validation losses: 0.5313233536746955\n",
      "Epoch 940, reconstruction losses: 0.01619079520633387, regression losses: 0.12717845614566864, validation losses: 0.5726352798828072\n",
      "Epoch 941, reconstruction losses: 0.019078725159199346, regression losses: 0.1442112930063177, validation losses: 0.5318666735432157\n",
      "Epoch 942, reconstruction losses: 0.018210188181016846, regression losses: 0.1456647037164151, validation losses: 0.49008529597433587\n",
      "Epoch 943, reconstruction losses: 0.014439337970332762, regression losses: 0.11432765003810087, validation losses: 0.5053274234847838\n",
      "Epoch 944, reconstruction losses: 0.016595462951607215, regression losses: 0.13190712398461757, validation losses: 0.6789279372027757\n",
      "Epoch 945, reconstruction losses: 0.016544073634570215, regression losses: 0.15480105630880955, validation losses: 0.5922562805235405\n",
      "Epoch 946, reconstruction losses: 0.015892701171674548, regression losses: 0.13274966905996244, validation losses: 0.5800964637986947\n",
      "Epoch 947, reconstruction losses: 0.016896559014915366, regression losses: 0.11140113192252782, validation losses: 0.524165309920066\n",
      "Epoch 948, reconstruction losses: 0.017932297132843954, regression losses: 0.13454841241091542, validation losses: 0.4810542629939275\n",
      "Epoch 949, reconstruction losses: 0.01784682934392116, regression losses: 0.12498435030144635, validation losses: 0.536684102487601\n",
      "Epoch 950, reconstruction losses: 0.020088741132430754, regression losses: 0.13047673647227592, validation losses: 0.6057903856739987\n",
      "Epoch 951, reconstruction losses: 0.015645073216465556, regression losses: 0.1329885602950856, validation losses: 0.514363879812607\n",
      "Epoch 952, reconstruction losses: 0.014570403050812263, regression losses: 0.10401769281698278, validation losses: 0.5214351597171714\n",
      "Epoch 953, reconstruction losses: 0.018588135189666375, regression losses: 0.1483760088946445, validation losses: 0.6231596209200881\n",
      "Epoch 954, reconstruction losses: 0.013408807828948878, regression losses: 0.10267570514653006, validation losses: 0.46903426373257706\n",
      "Epoch 955, reconstruction losses: 0.016718615442286987, regression losses: 0.09978145397382843, validation losses: 0.5186698784563428\n",
      "Epoch 956, reconstruction losses: 0.015162476834276881, regression losses: 0.11296181024307006, validation losses: 0.6345237149599059\n",
      "Epoch 957, reconstruction losses: 0.016936444411061728, regression losses: 0.12292339947887804, validation losses: 0.6598886951710985\n",
      "Epoch 958, reconstruction losses: 0.015097981897185177, regression losses: 0.14642527578512993, validation losses: 0.4511569465842366\n",
      "Epoch 959, reconstruction losses: 0.018897383503889816, regression losses: 0.14256735688581101, validation losses: 0.5752605091355975\n",
      "Epoch 960, reconstruction losses: 0.015304953110723522, regression losses: 0.1372656614057588, validation losses: 0.5374787393869492\n",
      "Epoch 961, reconstruction losses: 0.014913422278743038, regression losses: 0.11662534003278328, validation losses: 0.8624081329006912\n",
      "Epoch 962, reconstruction losses: 0.02094964055446122, regression losses: 0.21175527578090997, validation losses: 0.5053025014694285\n",
      "Epoch 963, reconstruction losses: 0.016079275537463605, regression losses: 0.1397437464177533, validation losses: 0.6323584068128624\n",
      "Epoch 964, reconstruction losses: 0.018918068803674255, regression losses: 0.18117670627527294, validation losses: 0.4294732253432324\n",
      "Epoch 965, reconstruction losses: 0.015384654398516176, regression losses: 0.1303350728662201, validation losses: 0.6318453136520427\n",
      "Epoch 966, reconstruction losses: 0.016031680871393818, regression losses: 0.12567330121441345, validation losses: 0.6427346213878891\n",
      "Epoch 967, reconstruction losses: 0.014395685469250276, regression losses: 0.09732060013784478, validation losses: 0.5247320009952646\n",
      "Epoch 968, reconstruction losses: 0.02558961132009721, regression losses: 0.1729997892753882, validation losses: 0.5005303347798258\n",
      "Epoch 969, reconstruction losses: 0.023164311478375114, regression losses: 0.1338957330212968, validation losses: 0.6438556957845298\n",
      "Epoch 970, reconstruction losses: 0.017523927575422368, regression losses: 0.11181746437893292, validation losses: 0.50541600053933\n",
      "Epoch 971, reconstruction losses: 0.017785576755209618, regression losses: 0.1581000259767308, validation losses: 0.5633027400099272\n",
      "Epoch 972, reconstruction losses: 0.01721391083562688, regression losses: 0.12204780287153656, validation losses: 0.6819796181102666\n",
      "Epoch 973, reconstruction losses: 0.01573539764471596, regression losses: 0.1269682570201192, validation losses: 0.5684854311945792\n",
      "Epoch 974, reconstruction losses: 0.015737435941458027, regression losses: 0.12100913777426589, validation losses: 0.4497571292737742\n",
      "Epoch 975, reconstruction losses: 0.0232734455260935, regression losses: 0.12199994324428454, validation losses: 0.4339420908241175\n",
      "Epoch 976, reconstruction losses: 0.017719092526379335, regression losses: 0.12035383828234537, validation losses: 0.6393234774790715\n",
      "Epoch 977, reconstruction losses: 0.01960985697608796, regression losses: 0.17194411976981228, validation losses: 0.6595796196910497\n",
      "Epoch 978, reconstruction losses: 0.014634864791178797, regression losses: 0.11999156377538324, validation losses: 0.4962089738762704\n",
      "Epoch 979, reconstruction losses: 0.015703443205133925, regression losses: 0.08747089273265385, validation losses: 0.4728206167322844\n",
      "Epoch 980, reconstruction losses: 0.015308757978552533, regression losses: 0.11030563736724044, validation losses: 0.5315497888519983\n",
      "Epoch 981, reconstruction losses: 0.02085581038314984, regression losses: 0.15614261521849115, validation losses: 0.4816432285287833\n",
      "Epoch 982, reconstruction losses: 0.01531712458635098, regression losses: 0.09958340195053896, validation losses: 0.4207386269569714\n",
      "Epoch 983, reconstruction losses: 0.02337506424394556, regression losses: 0.12313177463550429, validation losses: 0.45360680292584626\n",
      "Epoch 984, reconstruction losses: 0.022825492963846443, regression losses: 0.16210358034314282, validation losses: 0.7064533527900491\n",
      "Epoch 985, reconstruction losses: 0.01642066104237722, regression losses: 0.11602650048506966, validation losses: 0.5934008181888397\n",
      "Epoch 986, reconstruction losses: 0.018814624986983688, regression losses: 0.13244032761084404, validation losses: 0.47791074664377275\n",
      "Epoch 987, reconstruction losses: 0.014883758833657893, regression losses: 0.11538440828414168, validation losses: 0.625549428770124\n",
      "Epoch 988, reconstruction losses: 0.0183798484313217, regression losses: 0.17061410155386755, validation losses: 0.5554066127472009\n",
      "Epoch 989, reconstruction losses: 0.014695501960012469, regression losses: 0.08592458399977991, validation losses: 0.6697900894935968\n",
      "Epoch 990, reconstruction losses: 0.014664649662222806, regression losses: 0.10625130583233526, validation losses: 0.5816839713568863\n",
      "Epoch 991, reconstruction losses: 0.015257940597032144, regression losses: 0.15357649863357295, validation losses: 0.4903274430042314\n",
      "Epoch 992, reconstruction losses: 0.01742733777697663, regression losses: 0.1316341624673815, validation losses: 0.5246348693487833\n",
      "Epoch 993, reconstruction losses: 0.01641565215779963, regression losses: 0.12531145519514134, validation losses: 0.553876103856836\n",
      "Epoch 994, reconstruction losses: 0.015207289179647629, regression losses: 0.1263338544031552, validation losses: 0.5616226274264423\n",
      "Epoch 995, reconstruction losses: 0.01405014107907393, regression losses: 0.11984506811789813, validation losses: 0.5863292466998128\n",
      "Epoch 996, reconstruction losses: 0.017424605785450666, regression losses: 0.11699913377297566, validation losses: 0.5864717956969799\n",
      "Epoch 997, reconstruction losses: 0.015280085288656103, regression losses: 0.1214497969482217, validation losses: 0.5425196689554631\n",
      "Epoch 998, reconstruction losses: 0.01787737532150462, regression losses: 0.15048523434390032, validation losses: 0.5415234091883855\n",
      "Epoch 999, reconstruction losses: 0.01778396099659285, regression losses: 0.13601721178192455, validation losses: 0.5595547429854886\n",
      "Epoch 1000, reconstruction losses: 0.013097569978712795, regression losses: 0.09026656268470207, validation losses: 0.5581658186088132\n",
      "Epoch 1001, reconstruction losses: 0.01505778420512496, regression losses: 0.12566051110560747, validation losses: 0.5085892874567903\n",
      "Epoch 1002, reconstruction losses: 0.019203662495115906, regression losses: 0.1829289764635181, validation losses: 0.4977547786477118\n",
      "Epoch 1003, reconstruction losses: 0.01741602775863045, regression losses: 0.20377359321968436, validation losses: 1.240422958680085\n",
      "Epoch 1004, reconstruction losses: 0.019293734866762512, regression losses: 0.2243847622943947, validation losses: 0.9861912150078914\n",
      "Epoch 1005, reconstruction losses: 0.017902315230190147, regression losses: 0.19756314037110972, validation losses: 1.2059874955602088\n",
      "Epoch 1006, reconstruction losses: 0.019603896222929164, regression losses: 0.17426941596932027, validation losses: 0.7700979753630771\n",
      "Epoch 1007, reconstruction losses: 0.01865763281955825, regression losses: 0.10761813146044026, validation losses: 0.49149998964112546\n",
      "Epoch 1008, reconstruction losses: 0.016531836849609342, regression losses: 0.1271857920961182, validation losses: 0.5086121881593267\n",
      "Epoch 1009, reconstruction losses: 0.015828361477604243, regression losses: 0.10952098549629083, validation losses: 0.5663525924029755\n",
      "Epoch 1010, reconstruction losses: 0.01606144997588171, regression losses: 0.12473754912846582, validation losses: 0.4268617747322968\n",
      "Epoch 1011, reconstruction losses: 0.01942138261572957, regression losses: 0.14204228788153325, validation losses: 0.47398085319008176\n",
      "Epoch 1012, reconstruction losses: 0.02080631983267962, regression losses: 0.15318701568945492, validation losses: 0.4736798036900837\n",
      "Epoch 1013, reconstruction losses: 0.01819736704918564, regression losses: 0.12114261747401986, validation losses: 0.6291308034513088\n",
      "Epoch 1014, reconstruction losses: 0.01623852567312801, regression losses: 0.0978565923151458, validation losses: 0.5302263166435032\n",
      "Epoch 1015, reconstruction losses: 0.014954908472143579, regression losses: 0.106965066213404, validation losses: 0.4730052102222838\n",
      "Epoch 1016, reconstruction losses: 0.019314668563241738, regression losses: 0.19547743457928127, validation losses: 0.48671848787302346\n",
      "Epoch 1017, reconstruction losses: 0.017545360246100445, regression losses: 0.17438376372024683, validation losses: 0.7637965271970062\n",
      "Epoch 1018, reconstruction losses: 0.01756786757191863, regression losses: 0.1579838071201471, validation losses: 0.5165383295132576\n",
      "Epoch 1019, reconstruction losses: 0.022728497158841666, regression losses: 0.28650555359429297, validation losses: 0.4626837031405607\n",
      "Epoch 1020, reconstruction losses: 0.014906428031812505, regression losses: 0.13866175594155217, validation losses: 0.5122460439335267\n",
      "Epoch 1021, reconstruction losses: 0.015012754672310539, regression losses: 0.11801656405364686, validation losses: 0.5012618411312977\n",
      "Epoch 1022, reconstruction losses: 0.02026700810098217, regression losses: 0.11129752181428361, validation losses: 0.4965773101623712\n",
      "Epoch 1023, reconstruction losses: 0.014719049814861157, regression losses: 0.10726397891168785, validation losses: 0.4417045767087783\n",
      "Epoch 1024, reconstruction losses: 0.01745041053613659, regression losses: 0.14275297689279673, validation losses: 0.5109489174775427\n",
      "Epoch 1025, reconstruction losses: 0.015922829535994658, regression losses: 0.11174426184701694, validation losses: 0.6186375660195962\n",
      "Epoch 1026, reconstruction losses: 0.023184536531892348, regression losses: 0.20283910063988123, validation losses: 0.5713769742041483\n",
      "Epoch 1027, reconstruction losses: 0.017592027915185635, regression losses: 0.1283195554344376, validation losses: 0.6616333108914482\n",
      "Epoch 1028, reconstruction losses: 0.01899982631563725, regression losses: 0.23678589084071994, validation losses: 0.6396456979103122\n",
      "Epoch 1029, reconstruction losses: 0.017954125169099427, regression losses: 0.1600487166378448, validation losses: 1.0070902523869303\n",
      "Epoch 1030, reconstruction losses: 0.015455808039350151, regression losses: 0.12270131312722475, validation losses: 0.5800537876890233\n",
      "Epoch 1031, reconstruction losses: 0.015138527665118145, regression losses: 0.12775528908730105, validation losses: 0.49982239420860486\n",
      "Epoch 1032, reconstruction losses: 0.016545204134032536, regression losses: 0.16988094184988844, validation losses: 0.5864218940040584\n",
      "Epoch 1033, reconstruction losses: 0.017052050510056715, regression losses: 0.1298559014495806, validation losses: 0.5357545814862701\n",
      "Epoch 1034, reconstruction losses: 0.015474581192647866, regression losses: 0.11948220082425219, validation losses: 0.5025925914888247\n",
      "Epoch 1035, reconstruction losses: 0.01877029979252737, regression losses: 0.16017177612125733, validation losses: 0.4776022751047576\n",
      "Epoch 1036, reconstruction losses: 0.0163304834698129, regression losses: 0.12203439680633525, validation losses: 0.48771265649403905\n",
      "Epoch 1037, reconstruction losses: 0.019035164532643065, regression losses: 0.1217023342814246, validation losses: 0.4898071636014273\n",
      "Epoch 1038, reconstruction losses: 0.018155289330847448, regression losses: 0.136068247817487, validation losses: 0.7453069330831176\n",
      "Epoch 1039, reconstruction losses: 0.016436049751291038, regression losses: 0.130878087819075, validation losses: 0.6965430262245952\n",
      "Epoch 1040, reconstruction losses: 0.015907779726386486, regression losses: 0.11174660477494908, validation losses: 0.5433292884272946\n",
      "Epoch 1041, reconstruction losses: 0.013617893000770327, regression losses: 0.09627662955926414, validation losses: 0.47883601777397045\n",
      "Epoch 1042, reconstruction losses: 0.016629186249115566, regression losses: 0.13399476565048773, validation losses: 0.468065974837233\n",
      "Epoch 1043, reconstruction losses: 0.015085525893019393, regression losses: 0.10669058292239438, validation losses: 0.5321846336908659\n",
      "Epoch 1044, reconstruction losses: 0.01481562543435704, regression losses: 0.12617713418745485, validation losses: 0.6389327757216366\n",
      "Epoch 1045, reconstruction losses: 0.017225702826739898, regression losses: 0.14155311097248305, validation losses: 0.5650503821412503\n",
      "Epoch 1046, reconstruction losses: 0.014481401401701977, regression losses: 0.11136232325224146, validation losses: 0.49656711025170686\n",
      "Epoch 1047, reconstruction losses: 0.013555857013913543, regression losses: 0.08755472358224803, validation losses: 0.5041579489711421\n",
      "Epoch 1048, reconstruction losses: 0.016503564395687342, regression losses: 0.10316686599121781, validation losses: 0.510503252513996\n",
      "Epoch 1049, reconstruction losses: 0.015876654268729477, regression losses: 0.14452420428456525, validation losses: 0.4741031258764171\n",
      "Epoch 1050, reconstruction losses: 0.01456961213297005, regression losses: 0.1128030742442976, validation losses: 0.5439984565922433\n",
      "Epoch 1051, reconstruction losses: 0.016806207648236544, regression losses: 0.1557049356050927, validation losses: 0.47237342998867554\n",
      "Epoch 1052, reconstruction losses: 0.01844427888046788, regression losses: 0.1845805828547022, validation losses: 0.5985654084744447\n",
      "Epoch 1053, reconstruction losses: 0.014560560559801924, regression losses: 0.1199617711102518, validation losses: 0.5321995117545055\n",
      "Epoch 1054, reconstruction losses: 0.012322455893513704, regression losses: 0.09687859793198184, validation losses: 0.4855694715120488\n",
      "Epoch 1055, reconstruction losses: 0.016585829519229486, regression losses: 0.12615193251437332, validation losses: 0.4576310822244165\n",
      "Epoch 1056, reconstruction losses: 0.016999873063270537, regression losses: 0.13520178316033943, validation losses: 0.4994114262230316\n",
      "Epoch 1057, reconstruction losses: 0.014588267909780898, regression losses: 0.182934914831832, validation losses: 0.5024040241923702\n",
      "Epoch 1058, reconstruction losses: 0.018739045949211212, regression losses: 0.22351358712893438, validation losses: 0.44049921440908757\n",
      "Epoch 1059, reconstruction losses: 0.01437939072229463, regression losses: 0.12630253491618332, validation losses: 0.6575231576825908\n",
      "Epoch 1060, reconstruction losses: 0.015936643670489054, regression losses: 0.17248715952302107, validation losses: 0.5955300096869711\n",
      "Epoch 1061, reconstruction losses: 0.01594357558928273, regression losses: 0.12966202059602172, validation losses: 0.47520744767933454\n",
      "Epoch 1062, reconstruction losses: 0.01457500129962841, regression losses: 0.11705848909497762, validation losses: 0.45621661067990077\n",
      "Epoch 1063, reconstruction losses: 0.015210195677649588, regression losses: 0.11849094528826724, validation losses: 0.44667318045094495\n",
      "Epoch 1064, reconstruction losses: 0.013753814711340427, regression losses: 0.10735520467147759, validation losses: 0.48962048052922424\n",
      "Epoch 1065, reconstruction losses: 0.014146518145419583, regression losses: 0.1052860857061037, validation losses: 0.507148119112697\n",
      "Epoch 1066, reconstruction losses: 0.014951452525009644, regression losses: 0.114335535606611, validation losses: 0.5026036416108437\n",
      "Epoch 1067, reconstruction losses: 0.01573885239430992, regression losses: 0.14048639542725838, validation losses: 0.4914590440262247\n",
      "Epoch 1068, reconstruction losses: 0.016847217679473687, regression losses: 0.14642332789347495, validation losses: 0.48286371800909667\n",
      "Epoch 1069, reconstruction losses: 0.014509902321436556, regression losses: 0.10880383472669466, validation losses: 0.46357922547056774\n",
      "Epoch 1070, reconstruction losses: 0.013697236424897398, regression losses: 0.10155348594291287, validation losses: 0.46792837052459374\n",
      "Epoch 1071, reconstruction losses: 0.016081258000836363, regression losses: 0.12001626270675657, validation losses: 0.45452450036557285\n",
      "Epoch 1072, reconstruction losses: 0.016816078902927054, regression losses: 0.2129103081950306, validation losses: 0.4934128922974863\n",
      "Epoch 1073, reconstruction losses: 0.01753121352816323, regression losses: 0.1524775004737585, validation losses: 0.6149090576905981\n",
      "Epoch 1074, reconstruction losses: 0.0144393733784572, regression losses: 0.1388570919229431, validation losses: 0.502183019044716\n",
      "Epoch 1075, reconstruction losses: 0.013720512029961157, regression losses: 0.136592295481923, validation losses: 0.51177418182247\n",
      "Epoch 1076, reconstruction losses: 0.014143142306768098, regression losses: 0.12397146773220433, validation losses: 0.5349391858814164\n",
      "Epoch 1077, reconstruction losses: 0.015127783484675842, regression losses: 0.10847343297485659, validation losses: 0.5154226293353472\n",
      "Epoch 1078, reconstruction losses: 0.016218937018685164, regression losses: 0.21262380843700956, validation losses: 0.4485603178115576\n",
      "Epoch 1079, reconstruction losses: 0.016453764360985463, regression losses: 0.1417244366385629, validation losses: 0.7747492218498263\n",
      "Epoch 1080, reconstruction losses: 0.014974636434994195, regression losses: 0.16912778261543485, validation losses: 0.5707662411310394\n",
      "Epoch 1081, reconstruction losses: 0.015358478697539143, regression losses: 0.13526495620905526, validation losses: 0.7570881314400434\n",
      "Epoch 1082, reconstruction losses: 0.017726381378313824, regression losses: 0.15017884445254276, validation losses: 0.6207382715946191\n",
      "Epoch 1083, reconstruction losses: 0.018266030539808915, regression losses: 0.10887511686606628, validation losses: 0.5857863904193625\n",
      "Epoch 1084, reconstruction losses: 0.017917804801190044, regression losses: 0.107650677372149, validation losses: 0.5022051705297548\n",
      "Epoch 1085, reconstruction losses: 0.019474581734075146, regression losses: 0.15577396568186413, validation losses: 0.512457321096847\n",
      "Epoch 1086, reconstruction losses: 0.015125348938463007, regression losses: 0.12591044034066354, validation losses: 0.4951379626059308\n",
      "Epoch 1087, reconstruction losses: 0.0158914468653665, regression losses: 0.1424399387964145, validation losses: 0.468790075082839\n",
      "Epoch 1088, reconstruction losses: 0.016748388809314896, regression losses: 0.14955161814779716, validation losses: 0.4774766168893434\n",
      "Epoch 1089, reconstruction losses: 0.01585704741071695, regression losses: 0.12945702054749925, validation losses: 0.48999152492168735\n",
      "Epoch 1090, reconstruction losses: 0.01488235435504106, regression losses: 0.12951397617552138, validation losses: 0.49708999471560167\n",
      "Epoch 1091, reconstruction losses: 0.01490438968833287, regression losses: 0.1430196965785124, validation losses: 0.5475578805487257\n",
      "Epoch 1092, reconstruction losses: 0.01568685346417789, regression losses: 0.11980028155466371, validation losses: 0.5043920120454397\n",
      "Epoch 1093, reconstruction losses: 0.015742996590204922, regression losses: 0.13757740164032814, validation losses: 0.4616241451143963\n",
      "Epoch 1094, reconstruction losses: 0.016208842664308484, regression losses: 0.13277816771640893, validation losses: 0.501323437225454\n",
      "Epoch 1095, reconstruction losses: 0.014089390200027339, regression losses: 0.128315036577688, validation losses: 0.5671229249787434\n",
      "Epoch 1096, reconstruction losses: 0.012542541194858878, regression losses: 0.11055605870435167, validation losses: 0.6588264162635726\n",
      "Epoch 1097, reconstruction losses: 0.016778400703285182, regression losses: 0.11311187381689813, validation losses: 0.601636668386129\n",
      "Epoch 1098, reconstruction losses: 0.012399763650958457, regression losses: 0.10864648143281498, validation losses: 0.4471019487213384\n",
      "Epoch 1099, reconstruction losses: 0.016300126187343632, regression losses: 0.09736615567935901, validation losses: 0.43142093536558024\n",
      "Epoch 1100, reconstruction losses: 0.01605638036873905, regression losses: 0.11815412974516915, validation losses: 0.4822093163903227\n",
      "Epoch 1101, reconstruction losses: 0.016261168988405506, regression losses: 0.14305667499986713, validation losses: 0.6535566656967162\n",
      "Epoch 1102, reconstruction losses: 0.015653770106602176, regression losses: 0.12225450792929492, validation losses: 0.4961309067715371\n",
      "Epoch 1103, reconstruction losses: 0.014637225722164204, regression losses: 0.10374606032413984, validation losses: 0.4495035831428496\n",
      "Epoch 1104, reconstruction losses: 0.014709905059293272, regression losses: 0.11460706753912273, validation losses: 0.4511884661448287\n",
      "Epoch 1105, reconstruction losses: 0.013668380624709079, regression losses: 0.09864386402455538, validation losses: 0.5412150068083608\n",
      "Epoch 1106, reconstruction losses: 0.019409133999239554, regression losses: 0.14364497797384118, validation losses: 0.44387648258594486\n",
      "Epoch 1107, reconstruction losses: 0.01777168943656276, regression losses: 0.14169892155385283, validation losses: 0.44122358641217896\n",
      "Epoch 1108, reconstruction losses: 0.01788375349008606, regression losses: 0.13193348164732738, validation losses: 0.5003826979420097\n",
      "Epoch 1109, reconstruction losses: 0.019282804980871725, regression losses: 0.4450972592077158, validation losses: 0.5397586488047372\n",
      "Epoch 1110, reconstruction losses: 0.018701071309406972, regression losses: 0.130025811637523, validation losses: 0.8465961338844213\n",
      "Epoch 1111, reconstruction losses: 0.014658462675079508, regression losses: 0.12152972849476087, validation losses: 0.7006086101088156\n",
      "Epoch 1112, reconstruction losses: 0.01617882496455142, regression losses: 0.12817936349625186, validation losses: 0.5647786529077533\n",
      "Epoch 1113, reconstruction losses: 0.015504265293889496, regression losses: 0.1528836533454191, validation losses: 0.5952722550314073\n",
      "Epoch 1114, reconstruction losses: 0.014557566072999083, regression losses: 0.1041799327817241, validation losses: 0.542817658718564\n",
      "Epoch 1115, reconstruction losses: 0.015288513462592664, regression losses: 0.1255903622036045, validation losses: 0.5309065327393963\n",
      "Epoch 1116, reconstruction losses: 0.01436295764134221, regression losses: 0.11212963508299408, validation losses: 0.5200619258957548\n",
      "Epoch 1117, reconstruction losses: 0.015093617737048893, regression losses: 0.1028339839240896, validation losses: 0.5698378773962913\n",
      "Epoch 1118, reconstruction losses: 0.014650379213449976, regression losses: 0.08937194792775731, validation losses: 0.5843544097276312\n",
      "Epoch 1119, reconstruction losses: 0.013104111920650707, regression losses: 0.11458683798644734, validation losses: 0.5372233063016045\n",
      "Epoch 1120, reconstruction losses: 0.01611046757725962, regression losses: 0.12873945181653423, validation losses: 0.5422977381811546\n",
      "Epoch 1121, reconstruction losses: 0.018479388461887753, regression losses: 0.11437537297677233, validation losses: 0.5447793276890617\n",
      "Epoch 1122, reconstruction losses: 0.017520139964891462, regression losses: 0.12962714552046428, validation losses: 0.5353998692344679\n",
      "Epoch 1123, reconstruction losses: 0.01649908117026289, regression losses: 0.13225343287711538, validation losses: 0.5720744797230384\n",
      "Epoch 1124, reconstruction losses: 0.016174332348141415, regression losses: 0.14179715738859197, validation losses: 0.580558133730916\n",
      "Epoch 1125, reconstruction losses: 0.018517079013737236, regression losses: 0.11919557544541964, validation losses: 0.5306123100562012\n",
      "Epoch 1126, reconstruction losses: 0.014776468611603435, regression losses: 0.10192779069739748, validation losses: 0.49910252506045155\n",
      "Epoch 1127, reconstruction losses: 0.014941243854781348, regression losses: 0.09734423013148502, validation losses: 0.5309314494700555\n",
      "Epoch 1128, reconstruction losses: 0.014206433817947358, regression losses: 0.09875959454990654, validation losses: 0.5722679376667731\n",
      "Epoch 1129, reconstruction losses: 0.014883142547225107, regression losses: 0.11363433177147168, validation losses: 0.5004027314439086\n",
      "Epoch 1130, reconstruction losses: 0.019836865708722184, regression losses: 0.14929285774150114, validation losses: 0.5189081912811961\n",
      "Epoch 1131, reconstruction losses: 0.016038977555964437, regression losses: 0.14195033419874284, validation losses: 0.7047255859788203\n",
      "Epoch 1132, reconstruction losses: 0.01859521072323827, regression losses: 0.13934339413635125, validation losses: 0.5797845094546659\n",
      "Epoch 1133, reconstruction losses: 0.016101087242665325, regression losses: 0.12130052740650847, validation losses: 0.5242308632051259\n",
      "Epoch 1134, reconstruction losses: 0.015524660135158665, regression losses: 0.1116628551651851, validation losses: 0.5081590626237538\n",
      "Epoch 1135, reconstruction losses: 0.015452763752996661, regression losses: 0.12624498427621172, validation losses: 0.5368137746569405\n",
      "Epoch 1136, reconstruction losses: 0.013137814030023913, regression losses: 0.09158839265940588, validation losses: 0.5450733787125221\n",
      "Epoch 1137, reconstruction losses: 0.01449470146881549, regression losses: 0.11707212791704939, validation losses: 0.6246709054545598\n",
      "Epoch 1138, reconstruction losses: 0.015057986704292373, regression losses: 0.10684786613578609, validation losses: 0.6069696345027983\n",
      "Epoch 1139, reconstruction losses: 0.018256322697331732, regression losses: 0.11024679942836499, validation losses: 0.46689171857142675\n",
      "Epoch 1140, reconstruction losses: 0.012995607416492373, regression losses: 0.08847256094369574, validation losses: 0.5344118481721891\n",
      "Epoch 1141, reconstruction losses: 0.014985569341623884, regression losses: 0.10920798445979588, validation losses: 0.5371024418551404\n",
      "Epoch 1142, reconstruction losses: 0.013145238482165401, regression losses: 0.10463471513792275, validation losses: 0.5974971571206098\n",
      "Epoch 1143, reconstruction losses: 0.01610818021614209, regression losses: 0.1314811743952226, validation losses: 0.5678591466615551\n",
      "Epoch 1144, reconstruction losses: 0.01717599341026777, regression losses: 0.14835105344180127, validation losses: 0.5093510017652486\n",
      "Epoch 1145, reconstruction losses: 0.014789392507267013, regression losses: 0.14543654559409752, validation losses: 0.5387864731719404\n",
      "Epoch 1146, reconstruction losses: 0.014889962606847365, regression losses: 0.09619763865579067, validation losses: 0.5637770004624462\n",
      "Epoch 1147, reconstruction losses: 0.019182658041119453, regression losses: 0.1240773263060987, validation losses: 0.5800830812220275\n",
      "Epoch 1148, reconstruction losses: 0.015206018043914265, regression losses: 0.1606408956572644, validation losses: 0.5658283869211564\n",
      "Epoch 1149, reconstruction losses: 0.01595627468447488, regression losses: 0.13408971465859137, validation losses: 0.5198910606475617\n",
      "Epoch 1150, reconstruction losses: 0.01617146335054983, regression losses: 0.1319601754236389, validation losses: 0.45721931332619964\n",
      "Epoch 1151, reconstruction losses: 0.0159409528448438, regression losses: 0.1224070308050927, validation losses: 0.5504107027196738\n",
      "Epoch 1152, reconstruction losses: 0.015084932202122928, regression losses: 0.12546981963629733, validation losses: 0.5688755988953688\n",
      "Epoch 1153, reconstruction losses: 0.017465109158741783, regression losses: 0.1547365459249729, validation losses: 0.49464033569655513\n",
      "Epoch 1154, reconstruction losses: 0.019032817519959302, regression losses: 0.11790691341345037, validation losses: 0.45984211015035714\n",
      "Epoch 1155, reconstruction losses: 0.01873412980154271, regression losses: 0.16980357964181494, validation losses: 0.466430268768775\n",
      "Epoch 1156, reconstruction losses: 0.014015575398966364, regression losses: 0.100622943582598, validation losses: 0.6301735563190991\n",
      "Epoch 1157, reconstruction losses: 0.015878739194698354, regression losses: 0.11482912470354587, validation losses: 0.5893596142533377\n",
      "Epoch 1158, reconstruction losses: 0.022723658017207347, regression losses: 0.14213169425065836, validation losses: 0.5312092274497254\n",
      "Epoch 1159, reconstruction losses: 0.01464287382592895, regression losses: 0.0984381271433591, validation losses: 0.5627904057003719\n",
      "Epoch 1160, reconstruction losses: 0.013769184780384563, regression losses: 0.10476504499630189, validation losses: 0.45412345337654086\n",
      "Epoch 1161, reconstruction losses: 0.014869988231710688, regression losses: 0.12113005947523375, validation losses: 0.4605770050956888\n",
      "Epoch 1162, reconstruction losses: 0.014471276610806133, regression losses: 0.10520331316164377, validation losses: 0.44883402763204105\n",
      "Epoch 1163, reconstruction losses: 0.014904190550635351, regression losses: 0.1039563001864172, validation losses: 0.45497534032999865\n",
      "Epoch 1164, reconstruction losses: 0.01627247208276695, regression losses: 0.1489933881371603, validation losses: 0.5098315549979261\n",
      "Epoch 1165, reconstruction losses: 0.01632944712418585, regression losses: 0.11575901548738914, validation losses: 0.5033410291438819\n",
      "Epoch 1166, reconstruction losses: 0.014899841853154235, regression losses: 0.08890970672355658, validation losses: 0.5147943547859449\n",
      "Epoch 1167, reconstruction losses: 0.01714773004269147, regression losses: 0.1091371739115973, validation losses: 0.4896307843084381\n",
      "Epoch 1168, reconstruction losses: 0.01590609091859531, regression losses: 0.13692267665752283, validation losses: 0.47829526811792555\n",
      "Epoch 1169, reconstruction losses: 0.01966935061159937, regression losses: 0.13865274255508936, validation losses: 0.5925541344353257\n",
      "Epoch 1170, reconstruction losses: 0.014645136300100144, regression losses: 0.11760337974524318, validation losses: 0.5021274391347663\n",
      "Epoch 1171, reconstruction losses: 0.016924311462689863, regression losses: 0.1241415773149352, validation losses: 0.5291850074206168\n",
      "Epoch 1172, reconstruction losses: 0.015086186023574963, regression losses: 0.10485423118448645, validation losses: 0.599370734196482\n",
      "Epoch 1173, reconstruction losses: 0.016913443371296338, regression losses: 0.10349807050830971, validation losses: 0.5794081693359\n",
      "Epoch 1174, reconstruction losses: 0.013460996319842471, regression losses: 0.1141994750885008, validation losses: 0.5148498386425426\n",
      "Epoch 1175, reconstruction losses: 0.015398556198650213, regression losses: 0.124366209328868, validation losses: 0.4573085417661028\n",
      "Epoch 1176, reconstruction losses: 0.015660478829269936, regression losses: 0.15080822966685542, validation losses: 0.5308743752774027\n",
      "Epoch 1177, reconstruction losses: 0.015436415620722128, regression losses: 0.13641031406753945, validation losses: 0.5231477477072074\n",
      "Epoch 1178, reconstruction losses: 0.01639511191037661, regression losses: 0.11441973804149065, validation losses: 0.6348749461318521\n",
      "Epoch 1179, reconstruction losses: 0.016444157989604573, regression losses: 0.1346242991354912, validation losses: 0.48245661821007424\n",
      "Epoch 1180, reconstruction losses: 0.014051462004589286, regression losses: 0.08419742118406207, validation losses: 0.5321904293498556\n",
      "Epoch 1181, reconstruction losses: 0.014218131588767665, regression losses: 0.11465087824992913, validation losses: 0.553239356520268\n",
      "Epoch 1182, reconstruction losses: 0.014375997250441377, regression losses: 0.10035265399888987, validation losses: 0.4687836999437557\n",
      "Epoch 1183, reconstruction losses: 0.01335432107771349, regression losses: 0.10599945889179907, validation losses: 0.5117446267444004\n",
      "Epoch 1184, reconstruction losses: 0.018204366083280264, regression losses: 0.15163741610861928, validation losses: 0.4975778115042584\n",
      "Epoch 1185, reconstruction losses: 0.01679549467467874, regression losses: 0.16659083642910633, validation losses: 0.5999699713448351\n",
      "Epoch 1186, reconstruction losses: 0.01272020663426275, regression losses: 0.0999328533049668, validation losses: 0.4545328800102196\n",
      "Epoch 1187, reconstruction losses: 0.022029710041694982, regression losses: 0.12149212226274528, validation losses: 0.479845854667279\n",
      "Epoch 1188, reconstruction losses: 0.013265894898204978, regression losses: 0.12203118339670811, validation losses: 0.5783210987061421\n",
      "Epoch 1189, reconstruction losses: 0.013649076007457302, regression losses: 0.14315148979968273, validation losses: 0.5673989558336201\n",
      "Epoch 1190, reconstruction losses: 0.017505893806788558, regression losses: 0.24260023408712922, validation losses: 0.4685126171622095\n",
      "Epoch 1191, reconstruction losses: 0.01563236599897945, regression losses: 0.12988834532486834, validation losses: 0.8840783061743895\n",
      "Epoch 1192, reconstruction losses: 0.02055439204032961, regression losses: 0.2701176559990281, validation losses: 0.6114626579409201\n",
      "Epoch 1193, reconstruction losses: 0.013161902088362149, regression losses: 0.13007952375102136, validation losses: 0.5999871101510298\n",
      "Epoch 1194, reconstruction losses: 0.017712505453545916, regression losses: 0.15942774696817244, validation losses: 0.498338467839941\n",
      "Epoch 1195, reconstruction losses: 0.015234358010148809, regression losses: 0.13179823920350986, validation losses: 0.5387317648933267\n",
      "Epoch 1196, reconstruction losses: 0.015570389899841766, regression losses: 0.12566652986740215, validation losses: 0.612450838129666\n",
      "Epoch 1197, reconstruction losses: 0.015439026117391367, regression losses: 0.1129466764988891, validation losses: 0.5187528083181775\n",
      "Epoch 1198, reconstruction losses: 0.018850892712019368, regression losses: 0.13620349353064318, validation losses: 0.5284285548289961\n",
      "Epoch 1199, reconstruction losses: 0.017274472025438397, regression losses: 0.11888148364419525, validation losses: 0.501499805194912\n",
      "Epoch 1200, reconstruction losses: 0.023059700695504958, regression losses: 0.15325398743253374, validation losses: 0.4895555358205579\n",
      "Epoch 1201, reconstruction losses: 0.01578243729905378, regression losses: 0.08952556675295141, validation losses: 0.559959956535338\n",
      "Epoch 1202, reconstruction losses: 0.017337336532195283, regression losses: 0.14267739730657106, validation losses: 0.4866378253282071\n",
      "Epoch 1203, reconstruction losses: 0.015684319201072418, regression losses: 0.12316088819105295, validation losses: 0.5318276926023772\n",
      "Epoch 1204, reconstruction losses: 0.020702239849260284, regression losses: 0.1471644413198274, validation losses: 0.5656819607622805\n",
      "Epoch 1205, reconstruction losses: 0.021691915487479625, regression losses: 0.15430606660813495, validation losses: 0.5714183034007764\n",
      "Epoch 1206, reconstruction losses: 0.01983779258966962, regression losses: 0.14007882247407186, validation losses: 0.7202301662192602\n",
      "Epoch 1207, reconstruction losses: 0.0171073456938279, regression losses: 0.14315259462213017, validation losses: 0.7056163556640116\n",
      "Epoch 1208, reconstruction losses: 0.020377872014495767, regression losses: 0.2101814911417933, validation losses: 0.5835206647106281\n",
      "Epoch 1209, reconstruction losses: 0.016919565641897307, regression losses: 0.11616259954833365, validation losses: 0.5921517380492467\n",
      "Epoch 1210, reconstruction losses: 0.017340773152870987, regression losses: 0.15908927575866888, validation losses: 0.4732907890179507\n",
      "Epoch 1211, reconstruction losses: 0.01568974754753497, regression losses: 0.1203379332325971, validation losses: 0.6427697784135742\n",
      "Epoch 1212, reconstruction losses: 0.01658991316370333, regression losses: 0.11107997119043646, validation losses: 0.5848375235986196\n",
      "Epoch 1213, reconstruction losses: 0.014607434383874324, regression losses: 0.137796268469273, validation losses: 0.514918421746181\n",
      "Epoch 1214, reconstruction losses: 0.0178539144921697, regression losses: 0.11406047661616828, validation losses: 0.4580344561784931\n",
      "Epoch 1215, reconstruction losses: 0.015185012298384782, regression losses: 0.10928510061856235, validation losses: 0.4986325292629095\n",
      "Epoch 1216, reconstruction losses: 0.01569245828905249, regression losses: 0.13115137879699051, validation losses: 0.48993186915824416\n",
      "Epoch 1217, reconstruction losses: 0.013733941798038884, regression losses: 0.08984334017166493, validation losses: 0.47401008566591923\n",
      "Epoch 1218, reconstruction losses: 0.015108370005186614, regression losses: 0.11136234755828968, validation losses: 0.5359260793940893\n",
      "Epoch 1219, reconstruction losses: 0.017352320334460308, regression losses: 0.2907943930101755, validation losses: 0.4571725042954563\n",
      "Epoch 1220, reconstruction losses: 0.013107994259484921, regression losses: 0.12243829468084427, validation losses: 0.8328526125450482\n",
      "Epoch 1221, reconstruction losses: 0.020154871319566125, regression losses: 0.18964570593581706, validation losses: 0.77385394285182\n",
      "Epoch 1222, reconstruction losses: 0.016876082377133433, regression losses: 0.16514646650704648, validation losses: 0.7225193248029129\n",
      "Epoch 1223, reconstruction losses: 0.018583474254203397, regression losses: 0.11332650197526545, validation losses: 0.8593565876290932\n",
      "Epoch 1224, reconstruction losses: 0.022197808268642087, regression losses: 0.15583890149267862, validation losses: 0.6797859502791732\n",
      "Epoch 1225, reconstruction losses: 0.014719120372947408, regression losses: 0.09669724550291764, validation losses: 0.504908395795243\n",
      "Epoch 1226, reconstruction losses: 0.022342670631239243, regression losses: 0.10506590414798074, validation losses: 0.47972874372408864\n",
      "Epoch 1227, reconstruction losses: 0.021041452366003285, regression losses: 0.1579816189956176, validation losses: 0.5157126775903424\n",
      "Epoch 1228, reconstruction losses: 0.018437276119891353, regression losses: 0.188376360789804, validation losses: 0.46115586143548376\n",
      "Epoch 1229, reconstruction losses: 0.017658464099271343, regression losses: 0.10972600221597041, validation losses: 0.6307178086804817\n",
      "Epoch 1230, reconstruction losses: 0.0165784495213585, regression losses: 0.1306868225684626, validation losses: 0.529887920252527\n",
      "Epoch 1231, reconstruction losses: 0.016194416148638053, regression losses: 0.11791538014496916, validation losses: 0.5237087183108176\n",
      "Epoch 1232, reconstruction losses: 0.014316705443599838, regression losses: 0.10291838205524821, validation losses: 0.48694379614133115\n",
      "Epoch 1233, reconstruction losses: 0.014037827345681448, regression losses: 0.17431418984209274, validation losses: 0.4922061214626401\n",
      "Epoch 1234, reconstruction losses: 0.013346537148841101, regression losses: 0.10983560034564499, validation losses: 0.47702357742489687\n",
      "Epoch 1235, reconstruction losses: 0.017627807875730366, regression losses: 0.13938315126677356, validation losses: 0.444335212573272\n",
      "Epoch 1236, reconstruction losses: 0.01870686423781307, regression losses: 0.3635920221333145, validation losses: 0.5316783011607947\n",
      "Epoch 1237, reconstruction losses: 0.014617867313940299, regression losses: 0.13593627820676285, validation losses: 0.8740148744892815\n",
      "Epoch 1238, reconstruction losses: 0.02092606922905021, regression losses: 0.1532709408774742, validation losses: 0.8169838849553719\n",
      "Epoch 1239, reconstruction losses: 0.014558480173324255, regression losses: 0.1360612801099095, validation losses: 0.5698828130393414\n",
      "Epoch 1240, reconstruction losses: 0.015920930826530184, regression losses: 0.1263958292324958, validation losses: 0.46163364844428817\n",
      "Epoch 1241, reconstruction losses: 0.014323063420116683, regression losses: 0.1178234392792368, validation losses: 0.48551658624567107\n",
      "Epoch 1242, reconstruction losses: 0.015345064795530154, regression losses: 0.11926180051429545, validation losses: 0.5356132375716011\n",
      "Epoch 1243, reconstruction losses: 0.01591354593834318, regression losses: 0.11548152654401794, validation losses: 0.5184023531829939\n",
      "Epoch 1244, reconstruction losses: 0.013641035792916908, regression losses: 0.08150004479979846, validation losses: 0.4771740221695067\n",
      "Epoch 1245, reconstruction losses: 0.014656642710085372, regression losses: 0.09362647344012283, validation losses: 0.49028904687906005\n",
      "Epoch 1246, reconstruction losses: 0.01531616666028086, regression losses: 0.0953721466399133, validation losses: 0.5657617381035078\n",
      "Epoch 1247, reconstruction losses: 0.019592599105500652, regression losses: 0.11251848349568587, validation losses: 0.5343326842359999\n",
      "Epoch 1248, reconstruction losses: 0.013589862784675721, regression losses: 0.08599071413359555, validation losses: 0.4858023875404833\n",
      "Epoch 1249, reconstruction losses: 0.014733547894234379, regression losses: 0.14806965435147848, validation losses: 0.5072331568887705\n",
      "Epoch 1250, reconstruction losses: 0.015380929761089696, regression losses: 0.11917870771826321, validation losses: 0.5286739670656496\n",
      "Epoch 1251, reconstruction losses: 0.013989725037000713, regression losses: 0.13008305743176507, validation losses: 0.45881661632363624\n",
      "Epoch 1252, reconstruction losses: 0.018350411112739533, regression losses: 0.2177424006130707, validation losses: 0.5770133801307422\n",
      "Epoch 1253, reconstruction losses: 0.016694315881971993, regression losses: 0.16366319600368692, validation losses: 0.813018364361611\n",
      "Epoch 1254, reconstruction losses: 0.0154337533646196, regression losses: 0.14486156866431057, validation losses: 0.7362808869788147\n",
      "Epoch 1255, reconstruction losses: 0.016723692015208094, regression losses: 0.125804950413028, validation losses: 0.5819326891780147\n",
      "Epoch 1256, reconstruction losses: 0.016260931712638222, regression losses: 0.17113125237795784, validation losses: 0.5377176295679477\n",
      "Epoch 1257, reconstruction losses: 0.01959863947820429, regression losses: 0.1217769364563561, validation losses: 0.6305004231655622\n",
      "Epoch 1258, reconstruction losses: 0.016592420829740655, regression losses: 0.12848579718347014, validation losses: 0.5128449333317415\n",
      "Epoch 1259, reconstruction losses: 0.013792737124021534, regression losses: 0.10140396831891842, validation losses: 0.46377032118912054\n",
      "Epoch 1260, reconstruction losses: 0.01679257915074422, regression losses: 0.1305656220307881, validation losses: 0.47385456387195757\n",
      "Epoch 1261, reconstruction losses: 0.01206203729743316, regression losses: 0.07926449826316002, validation losses: 0.49489289270269343\n",
      "Epoch 1262, reconstruction losses: 0.017190753827284567, regression losses: 0.12215520022026204, validation losses: 0.46856930605361985\n",
      "Epoch 1263, reconstruction losses: 0.021031496170559376, regression losses: 0.23789590731227478, validation losses: 0.546697320931381\n",
      "Epoch 1264, reconstruction losses: 0.01966963839780133, regression losses: 0.1252820004991262, validation losses: 0.7817795569242831\n",
      "Epoch 1265, reconstruction losses: 0.015950762385550994, regression losses: 0.13615644506875407, validation losses: 0.727763163776348\n",
      "Epoch 1266, reconstruction losses: 0.01695866155777349, regression losses: 0.12604162792705825, validation losses: 0.5305727185672996\n",
      "Epoch 1267, reconstruction losses: 0.01536032219878122, regression losses: 0.12464488827872067, validation losses: 0.4918170744019519\n",
      "Epoch 1268, reconstruction losses: 0.01693819543521292, regression losses: 0.16404313645946694, validation losses: 0.44781387922039645\n",
      "Epoch 1269, reconstruction losses: 0.014876356044576778, regression losses: 0.13994242975659127, validation losses: 0.5084699417032871\n",
      "Epoch 1270, reconstruction losses: 0.01729893364823282, regression losses: 0.12307216493496796, validation losses: 0.5249764389983504\n",
      "Epoch 1271, reconstruction losses: 0.014316965023977935, regression losses: 0.1029929303892514, validation losses: 0.43626277486672504\n",
      "Epoch 1272, reconstruction losses: 0.018070294968858272, regression losses: 0.18437258613253998, validation losses: 0.44075007168398994\n",
      "Epoch 1273, reconstruction losses: 0.017165263971502278, regression losses: 0.1353270408076628, validation losses: 0.46789222615666987\n",
      "Epoch 1274, reconstruction losses: 0.01835008298533884, regression losses: 0.10623668540832885, validation losses: 0.45797796061704793\n",
      "Epoch 1275, reconstruction losses: 0.014131400091914974, regression losses: 0.09415875051314387, validation losses: 0.4789323024241091\n",
      "Epoch 1276, reconstruction losses: 0.020360836964542973, regression losses: 0.13890175415790088, validation losses: 0.5559798973802564\n",
      "Epoch 1277, reconstruction losses: 0.01483145849065796, regression losses: 0.1092774966672599, validation losses: 0.6224596573873369\n",
      "Epoch 1278, reconstruction losses: 0.023278555983897747, regression losses: 0.12172767589197582, validation losses: 0.45105340488359286\n",
      "Epoch 1279, reconstruction losses: 0.017580478403155155, regression losses: 0.09708495996318263, validation losses: 0.4704796863729376\n",
      "Epoch 1280, reconstruction losses: 0.015288203243208646, regression losses: 0.12257651725446252, validation losses: 0.4729077025154821\n",
      "Epoch 1281, reconstruction losses: 0.01663256005477664, regression losses: 0.20900073856238868, validation losses: 0.4794671934387874\n",
      "Epoch 1282, reconstruction losses: 0.018891007439219006, regression losses: 0.12051962375791683, validation losses: 0.4561333609296088\n",
      "Epoch 1283, reconstruction losses: 0.01583855183732173, regression losses: 0.09933391800416953, validation losses: 0.4413099390634416\n",
      "Epoch 1284, reconstruction losses: 0.014551481088235667, regression losses: 0.10466912301575403, validation losses: 0.54457527522904\n",
      "Epoch 1285, reconstruction losses: 0.016432759572909756, regression losses: 0.14054138443509612, validation losses: 0.5905572409499293\n",
      "Epoch 1286, reconstruction losses: 0.017498431992668324, regression losses: 0.12994973868012244, validation losses: 0.6190796334858348\n",
      "Epoch 1287, reconstruction losses: 0.016583751546965245, regression losses: 0.11215988118360339, validation losses: 0.473133796718878\n",
      "Epoch 1288, reconstruction losses: 0.017008578659426284, regression losses: 0.1119649478893609, validation losses: 0.4753700839090955\n",
      "Epoch 1289, reconstruction losses: 0.0218459909208268, regression losses: 0.1461653882676254, validation losses: 0.5454785879184345\n",
      "Epoch 1290, reconstruction losses: 0.022698255475890654, regression losses: 0.4499127897782417, validation losses: 0.49500582992761877\n",
      "Epoch 1291, reconstruction losses: 0.016552902964672288, regression losses: 0.13099706228794017, validation losses: 0.808411977431682\n",
      "Epoch 1292, reconstruction losses: 0.01676553245494738, regression losses: 0.1547180442150045, validation losses: 0.5365199654147229\n",
      "Epoch 1293, reconstruction losses: 0.015083563689992696, regression losses: 0.11337445711725933, validation losses: 0.45615432077819457\n",
      "Epoch 1294, reconstruction losses: 0.015697461772574438, regression losses: 0.14997376592097672, validation losses: 0.5056008033625581\n",
      "Epoch 1295, reconstruction losses: 0.015429857393792216, regression losses: 0.10005206700634459, validation losses: 0.5301903843477977\n",
      "Epoch 1296, reconstruction losses: 0.01505715105494199, regression losses: 0.11109260560722671, validation losses: 0.4845085128476158\n",
      "Epoch 1297, reconstruction losses: 0.015868522029599097, regression losses: 0.10732659909056948, validation losses: 0.4494311893729749\n",
      "Epoch 1298, reconstruction losses: 0.016093601525322715, regression losses: 0.12368488673017108, validation losses: 0.43091660435899865\n",
      "Epoch 1299, reconstruction losses: 0.01329150418213541, regression losses: 0.09690243872893352, validation losses: 0.465499138100477\n",
      "Epoch 1300, reconstruction losses: 0.015878560693021113, regression losses: 0.08814063706125197, validation losses: 0.5470969372158689\n",
      "Epoch 1301, reconstruction losses: 0.014500155817924649, regression losses: 0.11796579216195649, validation losses: 0.5315171510593846\n",
      "Epoch 1302, reconstruction losses: 0.019670857795709693, regression losses: 0.12085000582091547, validation losses: 0.44616632197993195\n",
      "Epoch 1303, reconstruction losses: 0.01454387761522263, regression losses: 0.1714622394003731, validation losses: 0.518772780221351\n",
      "Epoch 1304, reconstruction losses: 0.014965729158446142, regression losses: 0.14567050901454695, validation losses: 0.47155902631428465\n",
      "Epoch 1305, reconstruction losses: 0.014715139085995642, regression losses: 0.11568706279234588, validation losses: 0.540328880090927\n",
      "Epoch 1306, reconstruction losses: 0.016659171707828255, regression losses: 0.1846565723732716, validation losses: 0.6374236707252452\n",
      "Epoch 1307, reconstruction losses: 0.014450984719789582, regression losses: 0.12148869472030233, validation losses: 0.7458222769575802\n",
      "Epoch 1308, reconstruction losses: 0.01671677743424895, regression losses: 0.15161913333522362, validation losses: 0.5306085514041078\n",
      "Epoch 1309, reconstruction losses: 0.021478351944659784, regression losses: 0.39715234598604554, validation losses: 0.44685603067132784\n",
      "Epoch 1310, reconstruction losses: 0.016635445320485446, regression losses: 0.1047967245124157, validation losses: 0.7111937270581381\n",
      "Epoch 1311, reconstruction losses: 0.01517180790200494, regression losses: 0.16308569262722164, validation losses: 0.7291675838504346\n",
      "Epoch 1312, reconstruction losses: 0.019372131000493727, regression losses: 0.30861911701244193, validation losses: 0.5494220039177204\n",
      "Epoch 1313, reconstruction losses: 0.014798323055368195, regression losses: 0.12971545213567134, validation losses: 0.6182742287888715\n",
      "Epoch 1314, reconstruction losses: 0.013714963522850664, regression losses: 0.12339624228296227, validation losses: 0.5366972607086739\n",
      "Epoch 1315, reconstruction losses: 0.017852957977309795, regression losses: 0.20600125761397348, validation losses: 0.5290417844709242\n",
      "Epoch 1316, reconstruction losses: 0.016485824500918414, regression losses: 0.11722736416809193, validation losses: 0.5469862969531376\n",
      "Epoch 1317, reconstruction losses: 0.01787013178949722, regression losses: 0.1519776832694628, validation losses: 0.4263434695534861\n",
      "Epoch 1318, reconstruction losses: 0.02394253136974147, regression losses: 0.14603559410155098, validation losses: 0.44253686200130476\n",
      "Epoch 1319, reconstruction losses: 0.016313301889378688, regression losses: 0.08106626697387863, validation losses: 0.6093981363228719\n",
      "Epoch 1320, reconstruction losses: 0.01792464070461157, regression losses: 0.12032196154708827, validation losses: 0.4831345233551891\n",
      "Epoch 1321, reconstruction losses: 0.01441843812130978, regression losses: 0.11178148606040728, validation losses: 0.431885341312974\n",
      "Epoch 1322, reconstruction losses: 0.014562879071118069, regression losses: 0.13519667448144357, validation losses: 0.4273945886455082\n",
      "Epoch 1323, reconstruction losses: 0.0183761278367872, regression losses: 0.10777100687253377, validation losses: 0.4454744142968823\n",
      "Epoch 1324, reconstruction losses: 0.015765707422794085, regression losses: 0.12830653226856384, validation losses: 0.4944990924666802\n",
      "Epoch 1325, reconstruction losses: 0.017430730709045918, regression losses: 0.11217570858927595, validation losses: 0.4979053847998195\n",
      "Epoch 1326, reconstruction losses: 0.017034393909145403, regression losses: 0.12932061739622366, validation losses: 0.49416172672829295\n",
      "Epoch 1327, reconstruction losses: 0.015693566188037716, regression losses: 0.11452097999999326, validation losses: 0.5283824904306798\n",
      "Epoch 1328, reconstruction losses: 0.015478261821856555, regression losses: 0.11934840489288592, validation losses: 0.527617073624082\n",
      "Epoch 1329, reconstruction losses: 0.016682711815494567, regression losses: 0.0965804625963916, validation losses: 0.4814717379571711\n",
      "Epoch 1330, reconstruction losses: 0.01728111340787753, regression losses: 0.10311346688815119, validation losses: 0.49018343720848506\n",
      "Epoch 1331, reconstruction losses: 0.01775402558829227, regression losses: 0.09939679888793983, validation losses: 0.5216392317837312\n",
      "Epoch 1332, reconstruction losses: 0.01836173983724926, regression losses: 0.2338388593848702, validation losses: 0.428872117973248\n",
      "Epoch 1333, reconstruction losses: 0.01453297485598738, regression losses: 0.14428180113145664, validation losses: 0.4737332947934473\n",
      "Epoch 1334, reconstruction losses: 0.01664118904028804, regression losses: 0.16064514680586006, validation losses: 0.5288250052724383\n",
      "Epoch 1335, reconstruction losses: 0.01685036736648581, regression losses: 0.11113972567270644, validation losses: 0.5300320695991814\n",
      "Epoch 1336, reconstruction losses: 0.015349090696233015, regression losses: 0.10712515647896644, validation losses: 0.5264261386771663\n",
      "Epoch 1337, reconstruction losses: 0.0156541287197526, regression losses: 0.09322973345315194, validation losses: 0.5228425856165706\n",
      "Epoch 1338, reconstruction losses: 0.014678430623316066, regression losses: 0.11500877699561035, validation losses: 0.5157156234474986\n",
      "Epoch 1339, reconstruction losses: 0.015872558836482538, regression losses: 0.2082624120138311, validation losses: 0.5753797131208903\n",
      "Epoch 1340, reconstruction losses: 0.021717834855248842, regression losses: 0.2145199803915148, validation losses: 0.7126638562966688\n",
      "Epoch 1341, reconstruction losses: 0.017017399251476256, regression losses: 0.2202891903706311, validation losses: 0.40668084816353656\n",
      "Epoch 1342, reconstruction losses: 0.015051688412036244, regression losses: 0.10255030829660901, validation losses: 0.5148145387250704\n",
      "Epoch 1343, reconstruction losses: 0.016762853813448726, regression losses: 0.1738896187032265, validation losses: 0.44827948794267014\n",
      "Epoch 1344, reconstruction losses: 0.014189920018016751, regression losses: 0.11090005482501356, validation losses: 0.5653726851998876\n",
      "Epoch 1345, reconstruction losses: 0.01445275204941827, regression losses: 0.1208040248315971, validation losses: 0.4298424261095968\n",
      "Epoch 1346, reconstruction losses: 0.015244152814690277, regression losses: 0.10642475880968368, validation losses: 0.46590027495050035\n",
      "Epoch 1347, reconstruction losses: 0.014411826145103461, regression losses: 0.11693046637842817, validation losses: 0.4228134492303647\n",
      "Epoch 1348, reconstruction losses: 0.01481281795169458, regression losses: 0.11334536450145315, validation losses: 0.4590078291776534\n",
      "Epoch 1349, reconstruction losses: 0.016231884531926706, regression losses: 0.1392670373985022, validation losses: 0.41035465713444813\n",
      "Epoch 1350, reconstruction losses: 0.016387202462015533, regression losses: 0.1403115929374267, validation losses: 0.5176138769414756\n",
      "Epoch 1351, reconstruction losses: 0.016363263105762096, regression losses: 0.12324423193159448, validation losses: 0.6922104448593308\n",
      "Epoch 1352, reconstruction losses: 0.014025686201052294, regression losses: 0.13238323835666477, validation losses: 0.6395320195485521\n",
      "Epoch 1353, reconstruction losses: 0.015128918427582983, regression losses: 0.11268576624871918, validation losses: 0.5133220179488256\n",
      "Epoch 1354, reconstruction losses: 0.01727166572834007, regression losses: 0.17810624929546653, validation losses: 0.5264309485163611\n",
      "Epoch 1355, reconstruction losses: 0.018300609254641487, regression losses: 0.26471535381387534, validation losses: 0.5576954550714793\n",
      "Epoch 1356, reconstruction losses: 0.016772237376637154, regression losses: 0.1264754645312833, validation losses: 0.4756305348055792\n",
      "Epoch 1357, reconstruction losses: 0.016628669732266458, regression losses: 0.1161602908739455, validation losses: 0.4543903196527405\n",
      "Epoch 1358, reconstruction losses: 0.015789273173609463, regression losses: 0.14006486554739564, validation losses: 0.5184108511123564\n",
      "Epoch 1359, reconstruction losses: 0.013726375052830146, regression losses: 0.08398574461110196, validation losses: 0.5363231072456487\n",
      "Epoch 1360, reconstruction losses: 0.014070312706282692, regression losses: 0.12102516599954188, validation losses: 0.491989101355365\n",
      "Epoch 1361, reconstruction losses: 0.016671966756270327, regression losses: 0.11209274503487394, validation losses: 0.4742142991336229\n",
      "Epoch 1362, reconstruction losses: 0.016169354269539603, regression losses: 0.10207441941360267, validation losses: 0.47165959468411955\n",
      "Epoch 1363, reconstruction losses: 0.014145631082311922, regression losses: 0.09917728491041396, validation losses: 0.4824530432682981\n",
      "Epoch 1364, reconstruction losses: 0.015026441778158416, regression losses: 0.11513609134268599, validation losses: 0.49343266461557783\n",
      "Epoch 1365, reconstruction losses: 0.017838888340516213, regression losses: 0.11557488159310403, validation losses: 0.5029303478929901\n",
      "Epoch 1366, reconstruction losses: 0.014220378060148546, regression losses: 0.11323511081565785, validation losses: 0.5123712563764523\n",
      "Epoch 1367, reconstruction losses: 0.016093560547529813, regression losses: 0.12394744040663154, validation losses: 0.4740866980276018\n",
      "Epoch 1368, reconstruction losses: 0.016138051604958643, regression losses: 0.11538931391540813, validation losses: 0.43286614540165175\n",
      "Epoch 1369, reconstruction losses: 0.01588146526585923, regression losses: 0.1291827154690998, validation losses: 0.5371174129511475\n",
      "Epoch 1370, reconstruction losses: 0.01699203033799118, regression losses: 0.13298573559853585, validation losses: 0.4666845018199606\n",
      "Epoch 1371, reconstruction losses: 0.014201374213732416, regression losses: 0.12696133584969516, validation losses: 0.5144964185703151\n",
      "Epoch 1372, reconstruction losses: 0.01611416617243134, regression losses: 0.15140544742705658, validation losses: 0.5214087852483996\n",
      "Epoch 1373, reconstruction losses: 0.016504000549274672, regression losses: 0.16081046377455982, validation losses: 0.5750773942153538\n",
      "Epoch 1374, reconstruction losses: 0.015479551557461346, regression losses: 0.1084995555617413, validation losses: 0.5617835776997675\n",
      "Epoch 1375, reconstruction losses: 0.01394109174241792, regression losses: 0.14025163914972602, validation losses: 0.43903151936101414\n",
      "Epoch 1376, reconstruction losses: 0.012616824470307028, regression losses: 0.09704404664644027, validation losses: 0.44295742249106906\n",
      "Epoch 1377, reconstruction losses: 0.014303098249650321, regression losses: 0.10723441526047511, validation losses: 0.4365367030184802\n",
      "Epoch 1378, reconstruction losses: 0.015480961795992334, regression losses: 0.11002163694770935, validation losses: 0.45046178861491387\n",
      "Epoch 1379, reconstruction losses: 0.014996872609873795, regression losses: 0.11846140726771255, validation losses: 0.5407795468752968\n",
      "Epoch 1380, reconstruction losses: 0.015957507106688383, regression losses: 0.13276258577977437, validation losses: 0.5722047522117347\n",
      "Epoch 1381, reconstruction losses: 0.018820238262655855, regression losses: 0.43898285634197565, validation losses: 0.4925729730942263\n",
      "Epoch 1382, reconstruction losses: 0.01351418804993888, regression losses: 0.08631239041406404, validation losses: 0.6419804624177858\n",
      "Epoch 1383, reconstruction losses: 0.014369852917689278, regression losses: 0.09746416863806426, validation losses: 0.6229456316667613\n",
      "Epoch 1384, reconstruction losses: 0.016794469942928957, regression losses: 0.11856680681034042, validation losses: 0.5952046929725017\n",
      "Epoch 1385, reconstruction losses: 0.01705569009324737, regression losses: 0.16247638300166323, validation losses: 0.5648459873807344\n",
      "Epoch 1386, reconstruction losses: 0.01618694381622397, regression losses: 0.13680559345322363, validation losses: 0.48194939997480774\n",
      "Epoch 1387, reconstruction losses: 0.01869642310369441, regression losses: 0.1434777255750854, validation losses: 0.4760142157195546\n",
      "Epoch 1388, reconstruction losses: 0.014026618584182577, regression losses: 0.12669988139409738, validation losses: 0.5889570458771674\n",
      "Epoch 1389, reconstruction losses: 0.018045160992310405, regression losses: 0.13441711234386375, validation losses: 0.6211195348833748\n",
      "Epoch 1390, reconstruction losses: 0.01593727143932675, regression losses: 0.1306667731126564, validation losses: 0.7250833094411305\n",
      "Epoch 1391, reconstruction losses: 0.0231861929970339, regression losses: 0.18323322476634207, validation losses: 0.584161176371418\n",
      "Epoch 1392, reconstruction losses: 0.016249993550616723, regression losses: 0.11423136698276203, validation losses: 0.5629016281393661\n",
      "Epoch 1393, reconstruction losses: 0.015495996426423707, regression losses: 0.1302917157973562, validation losses: 0.5739208280680783\n",
      "Epoch 1394, reconstruction losses: 0.016985924838929828, regression losses: 0.3741287767021839, validation losses: 0.6195618451048569\n",
      "Epoch 1395, reconstruction losses: 0.01779564609093681, regression losses: 0.13422779651631023, validation losses: 0.6526152722772788\n",
      "Epoch 1396, reconstruction losses: 0.016975809898073752, regression losses: 0.13509739066613596, validation losses: 0.603406861197263\n",
      "Epoch 1397, reconstruction losses: 0.017813613641203905, regression losses: 0.12391715534271903, validation losses: 0.5578180037089953\n",
      "Epoch 1398, reconstruction losses: 0.01632445003239364, regression losses: 0.10221731438628996, validation losses: 0.5117709578479777\n",
      "Epoch 1399, reconstruction losses: 0.01377709477130785, regression losses: 0.11037978815461354, validation losses: 0.483595237609034\n",
      "Epoch 1400, reconstruction losses: 0.016072679949044287, regression losses: 0.13192568802751828, validation losses: 0.6167229124240864\n",
      "Epoch 1401, reconstruction losses: 0.01575815997400196, regression losses: 0.10431846449284206, validation losses: 0.7071274104785583\n",
      "Epoch 1402, reconstruction losses: 0.01420215230915315, regression losses: 0.09775253742677772, validation losses: 0.5342670409548635\n",
      "Epoch 1403, reconstruction losses: 0.016913631338850058, regression losses: 0.10673426042366563, validation losses: 0.4476236933550654\n",
      "Epoch 1404, reconstruction losses: 0.01961990635038891, regression losses: 0.11176064673210473, validation losses: 0.4439464220426658\n",
      "Epoch 1405, reconstruction losses: 0.01807232567208359, regression losses: 0.10286244217677647, validation losses: 0.4634783759498868\n",
      "Epoch 1406, reconstruction losses: 0.014935540881680316, regression losses: 0.14319111588877376, validation losses: 0.49838175266011037\n",
      "Epoch 1407, reconstruction losses: 0.017839326955730823, regression losses: 0.10265577669462511, validation losses: 0.4638781246452081\n",
      "Epoch 1408, reconstruction losses: 0.014835018266247897, regression losses: 0.13442474844703983, validation losses: 0.46823281488202445\n",
      "Epoch 1409, reconstruction losses: 0.018408045317061465, regression losses: 0.13645366681093068, validation losses: 0.503381941308959\n",
      "Epoch 1410, reconstruction losses: 0.017584931243612444, regression losses: 0.13394405445621757, validation losses: 0.4744500248460103\n",
      "Epoch 1411, reconstruction losses: 0.016222406906879733, regression losses: 0.15921230682703963, validation losses: 0.48494830369078157\n",
      "Epoch 1412, reconstruction losses: 0.015207935636077708, regression losses: 0.11034749348099673, validation losses: 0.510069407411109\n",
      "Epoch 1413, reconstruction losses: 0.01676634502866849, regression losses: 0.12358877078136403, validation losses: 0.5912106107150558\n",
      "Epoch 1414, reconstruction losses: 0.019282439773299954, regression losses: 0.1025272064040467, validation losses: 0.6125114836305843\n",
      "Epoch 1415, reconstruction losses: 0.012649534853929228, regression losses: 0.09313721798497454, validation losses: 0.6030783348976514\n",
      "Epoch 1416, reconstruction losses: 0.021261816777280715, regression losses: 0.16170284928421635, validation losses: 0.48635781183354765\n",
      "Epoch 1417, reconstruction losses: 0.01455825408743842, regression losses: 0.1254450541922372, validation losses: 0.47079759963141626\n",
      "Epoch 1418, reconstruction losses: 0.02395133146302631, regression losses: 0.4239225402078956, validation losses: 0.5178530558632396\n",
      "Epoch 1419, reconstruction losses: 0.01668223230108836, regression losses: 0.13376730148853822, validation losses: 0.6998751397201735\n",
      "Epoch 1420, reconstruction losses: 0.01664435331819716, regression losses: 0.18051312388329044, validation losses: 0.5597906624361062\n",
      "Epoch 1421, reconstruction losses: 0.014947423212946783, regression losses: 0.1012841504404205, validation losses: 0.4662645519923993\n",
      "Epoch 1422, reconstruction losses: 0.01636537857253989, regression losses: 0.11968104900969238, validation losses: 0.5170904517585522\n",
      "Epoch 1423, reconstruction losses: 0.019281583734628016, regression losses: 0.2836260002371133, validation losses: 0.4611769415272009\n",
      "Epoch 1424, reconstruction losses: 0.02083435945587183, regression losses: 0.15632004685452022, validation losses: 0.4481192435167855\n",
      "Epoch 1425, reconstruction losses: 0.01460953149083393, regression losses: 0.12269384375478118, validation losses: 0.4558478765454069\n",
      "Epoch 1426, reconstruction losses: 0.017910655940293937, regression losses: 0.1318573614336203, validation losses: 0.5197425311505026\n",
      "Epoch 1427, reconstruction losses: 0.015372050112986, regression losses: 0.13869897515576968, validation losses: 0.7765862480916682\n",
      "Epoch 1428, reconstruction losses: 0.013957786275971273, regression losses: 0.12248850627079844, validation losses: 0.5443578560626171\n",
      "Epoch 1429, reconstruction losses: 0.016419439993006206, regression losses: 0.09432193114691442, validation losses: 0.4174842684725304\n",
      "Epoch 1430, reconstruction losses: 0.015160229514666512, regression losses: 0.12449814623192222, validation losses: 0.46361662609602045\n",
      "Epoch 1431, reconstruction losses: 0.018331839414200104, regression losses: 0.11706995982225733, validation losses: 0.4837223912678993\n",
      "Epoch 1432, reconstruction losses: 0.014697630133900755, regression losses: 0.09632230591462188, validation losses: 0.423428060037928\n",
      "Epoch 1433, reconstruction losses: 0.015345747420939615, regression losses: 0.13745307141488827, validation losses: 0.43649512836914606\n",
      "Epoch 1434, reconstruction losses: 0.01679408895019586, regression losses: 0.12810498791449068, validation losses: 0.46145008462137455\n",
      "Epoch 1435, reconstruction losses: 0.014624564617722824, regression losses: 0.09271721765129332, validation losses: 0.45569308896624733\n",
      "Epoch 1436, reconstruction losses: 0.014979011821087006, regression losses: 0.14768698122532045, validation losses: 0.46023332259002375\n",
      "Epoch 1437, reconstruction losses: 0.013333820950980608, regression losses: 0.07455072119901747, validation losses: 0.514316855692077\n",
      "Epoch 1438, reconstruction losses: 0.015083107178805748, regression losses: 0.0959893568508724, validation losses: 0.4791950677717129\n",
      "Epoch 1439, reconstruction losses: 0.01793991217957625, regression losses: 0.3126846917018097, validation losses: 0.4593527843939651\n",
      "Epoch 1440, reconstruction losses: 0.014400565592613438, regression losses: 0.14014835168507467, validation losses: 0.6609957889603866\n",
      "Epoch 1441, reconstruction losses: 0.01881197878158362, regression losses: 0.16032429606919454, validation losses: 0.5252247473712667\n",
      "Epoch 1442, reconstruction losses: 0.014707598914525548, regression losses: 0.11917253430194374, validation losses: 0.5977469248159877\n",
      "Epoch 1443, reconstruction losses: 0.016308988892234984, regression losses: 0.11619365639575416, validation losses: 0.47768608167179566\n",
      "Epoch 1444, reconstruction losses: 0.01492655839926096, regression losses: 0.09300997919116812, validation losses: 0.47105254632640803\n",
      "Epoch 1445, reconstruction losses: 0.014190784620944518, regression losses: 0.12093692935099248, validation losses: 0.4532129574709915\n",
      "Epoch 1446, reconstruction losses: 0.01603861941131223, regression losses: 0.12650837049387695, validation losses: 0.4730267920347227\n",
      "Epoch 1447, reconstruction losses: 0.01496477742375275, regression losses: 0.11273455387835321, validation losses: 0.5275815469962324\n",
      "Epoch 1448, reconstruction losses: 0.015172839847765674, regression losses: 0.15250212744800315, validation losses: 0.494289278564455\n",
      "Epoch 1449, reconstruction losses: 0.015437610775300203, regression losses: 0.14287748031036063, validation losses: 0.47842695203288355\n",
      "Epoch 1450, reconstruction losses: 0.01472375539211301, regression losses: 0.1309081536861571, validation losses: 0.5085530872981934\n",
      "Epoch 1451, reconstruction losses: 0.013772607145901079, regression losses: 0.12627645931530695, validation losses: 0.44503192948254183\n",
      "Epoch 1452, reconstruction losses: 0.018489581127296057, regression losses: 0.127510521255329, validation losses: 0.4598356486875646\n",
      "Epoch 1453, reconstruction losses: 0.016123866844672704, regression losses: 0.10437060582250286, validation losses: 0.5299201577973427\n",
      "Epoch 1454, reconstruction losses: 0.01553735631839681, regression losses: 0.14698217510236306, validation losses: 0.5436686967818167\n",
      "Epoch 1455, reconstruction losses: 0.015092519062420446, regression losses: 0.12668732389227544, validation losses: 0.7241156619099245\n",
      "Epoch 1456, reconstruction losses: 0.02083759620993244, regression losses: 0.14620062777909903, validation losses: 0.5988407092124285\n",
      "Epoch 1457, reconstruction losses: 0.015269758816229556, regression losses: 0.10214135252451226, validation losses: 0.5033311428004238\n",
      "Epoch 1458, reconstruction losses: 0.019371951411226773, regression losses: 0.12050568268607255, validation losses: 0.4829717243327427\n",
      "Epoch 1459, reconstruction losses: 0.016016579726117496, regression losses: 0.10068026641975836, validation losses: 0.5932050479557176\n",
      "Epoch 1460, reconstruction losses: 0.01712876880723729, regression losses: 0.1525990360123725, validation losses: 0.44896794705425697\n",
      "Epoch 1461, reconstruction losses: 0.014409196658376434, regression losses: 0.11511625991600027, validation losses: 0.43835393529623035\n",
      "Epoch 1462, reconstruction losses: 0.015995215048999936, regression losses: 0.10121756797170028, validation losses: 0.5361029639186587\n",
      "Epoch 1463, reconstruction losses: 0.014523755023231276, regression losses: 0.10285237947107298, validation losses: 0.5517435222766699\n",
      "Epoch 1464, reconstruction losses: 0.015368388856606269, regression losses: 0.12940376232560635, validation losses: 0.42664893075650345\n",
      "Epoch 1465, reconstruction losses: 0.016538938234643617, regression losses: 0.1125233578611806, validation losses: 0.43094111632154575\n",
      "Epoch 1466, reconstruction losses: 0.014426027393461167, regression losses: 0.13004308470250528, validation losses: 0.4814038782193913\n",
      "Epoch 1467, reconstruction losses: 0.013852966852065086, regression losses: 0.09026290697574424, validation losses: 0.42973606826712607\n",
      "Epoch 1468, reconstruction losses: 0.017946594683332165, regression losses: 0.11838478189046787, validation losses: 0.4581712949560539\n",
      "Epoch 1469, reconstruction losses: 0.015298006714889598, regression losses: 0.1408075238858541, validation losses: 0.4948892157081827\n",
      "Epoch 1470, reconstruction losses: 0.01732630733806379, regression losses: 0.1416613565720856, validation losses: 0.5103777348970838\n",
      "Epoch 1471, reconstruction losses: 0.015151169203879059, regression losses: 0.11216732644682104, validation losses: 0.4723555847345462\n",
      "Epoch 1472, reconstruction losses: 0.013596884067764381, regression losses: 0.10977828384882168, validation losses: 0.4896007129070181\n",
      "Epoch 1473, reconstruction losses: 0.013554856351745139, regression losses: 0.12102612846914432, validation losses: 0.49177485635807944\n",
      "Epoch 1474, reconstruction losses: 0.015231857528872562, regression losses: 0.12886674501717385, validation losses: 0.4387221100413664\n",
      "Epoch 1475, reconstruction losses: 0.013241442709607632, regression losses: 0.12806932081444647, validation losses: 0.4382699745259415\n",
      "Epoch 1476, reconstruction losses: 0.014167475864210213, regression losses: 0.12074269439541999, validation losses: 0.45043041939065037\n",
      "Epoch 1477, reconstruction losses: 0.015726151678109382, regression losses: 0.13799990612310112, validation losses: 0.4477541923106272\n",
      "Epoch 1478, reconstruction losses: 0.01826030167635026, regression losses: 0.09258736530415436, validation losses: 0.517708988033313\n",
      "Epoch 1479, reconstruction losses: 0.014954933218904239, regression losses: 0.14041359637353018, validation losses: 0.5043295048403763\n",
      "Epoch 1480, reconstruction losses: 0.01339988999708194, regression losses: 0.11459269597001313, validation losses: 0.48757117595249055\n",
      "Epoch 1481, reconstruction losses: 0.013576660359714832, regression losses: 0.08016100039298185, validation losses: 0.4817181064620539\n",
      "Epoch 1482, reconstruction losses: 0.019856164747667413, regression losses: 0.41044973426082765, validation losses: 0.5690918329576519\n",
      "Epoch 1483, reconstruction losses: 0.01442493402312977, regression losses: 0.09655259843354846, validation losses: 0.7658673565534109\n",
      "Epoch 1484, reconstruction losses: 0.013754429827889348, regression losses: 0.1549899931724114, validation losses: 0.5573454374380536\n",
      "Epoch 1485, reconstruction losses: 0.017772669214384567, regression losses: 0.17610866153878924, validation losses: 0.4860305346208973\n",
      "Epoch 1486, reconstruction losses: 0.014694050930641842, regression losses: 0.12443633111172553, validation losses: 0.5615617948151423\n",
      "Epoch 1487, reconstruction losses: 0.01456836485503633, regression losses: 0.10808731994415319, validation losses: 0.516882147382947\n",
      "Epoch 1488, reconstruction losses: 0.01687367709348446, regression losses: 0.12392219157742096, validation losses: 0.4910336445458511\n",
      "Epoch 1489, reconstruction losses: 0.01591280862793452, regression losses: 0.11707840223059333, validation losses: 0.577640480102737\n",
      "Epoch 1490, reconstruction losses: 0.014559041507906833, regression losses: 0.11560796313761729, validation losses: 0.5952109391597569\n",
      "Epoch 1491, reconstruction losses: 0.01248558627449023, regression losses: 0.0867091585061408, validation losses: 0.5479441759825036\n",
      "Epoch 1492, reconstruction losses: 0.020791868408083503, regression losses: 0.1631513111775057, validation losses: 0.57011319600337\n",
      "Epoch 1493, reconstruction losses: 0.02170410956253906, regression losses: 0.15223041378503382, validation losses: 0.7108569145483057\n",
      "Epoch 1494, reconstruction losses: 0.017659053493218987, regression losses: 0.1768421704629714, validation losses: 0.7077758325868664\n",
      "Epoch 1495, reconstruction losses: 0.018767381742967555, regression losses: 0.1319226130270877, validation losses: 0.6495310682604458\n",
      "Epoch 1496, reconstruction losses: 0.015454202399397826, regression losses: 0.1357532532623669, validation losses: 0.6422631614820136\n",
      "Epoch 1497, reconstruction losses: 0.022421172592841085, regression losses: 0.204235054775476, validation losses: 0.6057051168729405\n",
      "Epoch 1498, reconstruction losses: 0.015193162016848694, regression losses: 0.13007160227119346, validation losses: 0.7842604184378426\n",
      "Epoch 1499, reconstruction losses: 0.018553956719595456, regression losses: 0.13606119304823072, validation losses: 0.6598747198945909\n",
      "Epoch 1500, reconstruction losses: 0.016229311739415248, regression losses: 0.18374195993727158, validation losses: 0.5603941951713061\n",
      "Epoch 1501, reconstruction losses: 0.014804211798287635, regression losses: 0.1991050972489978, validation losses: 0.6406924356868077\n",
      "Epoch 1502, reconstruction losses: 0.015420244857973598, regression losses: 0.13325795263523452, validation losses: 0.5678740164434013\n",
      "Epoch 1503, reconstruction losses: 0.015234573788974802, regression losses: 0.12098361263993795, validation losses: 0.5536449989914919\n",
      "Epoch 1504, reconstruction losses: 0.012466997558743705, regression losses: 0.09602237652096293, validation losses: 0.5596135648184474\n",
      "Epoch 1505, reconstruction losses: 0.012379770962628836, regression losses: 0.09463057009647073, validation losses: 0.5765277708942794\n",
      "Epoch 1506, reconstruction losses: 0.014348972515707938, regression losses: 0.12083617530707971, validation losses: 0.5404422583948728\n",
      "Epoch 1507, reconstruction losses: 0.015840242531062188, regression losses: 0.11564668710185899, validation losses: 0.4835523713410184\n",
      "Epoch 1508, reconstruction losses: 0.0167008424622742, regression losses: 0.1258303602862263, validation losses: 0.5065515150529899\n",
      "Epoch 1509, reconstruction losses: 0.015604969313167204, regression losses: 0.09828907684386437, validation losses: 0.49847833766342453\n",
      "Epoch 1510, reconstruction losses: 0.01839024809184194, regression losses: 0.11957453137393168, validation losses: 0.49300338555328843\n",
      "Epoch 1511, reconstruction losses: 0.017266115668248323, regression losses: 0.14426068856656507, validation losses: 0.4961184752572521\n",
      "Epoch 1512, reconstruction losses: 0.012742495910777911, regression losses: 0.10436139611053653, validation losses: 0.5727916764272236\n",
      "Epoch 1513, reconstruction losses: 0.013758911805827476, regression losses: 0.12645266426088814, validation losses: 0.5322617048806455\n",
      "Epoch 1514, reconstruction losses: 0.015030484799751503, regression losses: 0.13281454914869983, validation losses: 0.47189478541047125\n",
      "Epoch 1515, reconstruction losses: 0.015604613856974432, regression losses: 0.12771494084964458, validation losses: 0.4412805180985383\n",
      "Epoch 1516, reconstruction losses: 0.013411002762458178, regression losses: 0.10279911461692606, validation losses: 0.560270097767397\n",
      "Epoch 1517, reconstruction losses: 0.01574470834191707, regression losses: 0.1158952710043661, validation losses: 0.5882073265541161\n",
      "Epoch 1518, reconstruction losses: 0.015360477220464597, regression losses: 0.11950073031618869, validation losses: 0.5327096093712445\n",
      "Epoch 1519, reconstruction losses: 0.018172194841944093, regression losses: 0.15580257950273205, validation losses: 0.558917067581444\n",
      "Epoch 1520, reconstruction losses: 0.015286944948477255, regression losses: 0.14719524995630223, validation losses: 0.5338004687016361\n",
      "Epoch 1521, reconstruction losses: 0.01825278296534956, regression losses: 0.1370424395305687, validation losses: 0.4571053199209467\n",
      "Epoch 1522, reconstruction losses: 0.016544039554460686, regression losses: 0.1246398309000938, validation losses: 0.533804846081466\n",
      "Epoch 1523, reconstruction losses: 0.014318099436143868, regression losses: 0.1298049389730092, validation losses: 0.5396521846667699\n",
      "Epoch 1524, reconstruction losses: 0.01534056276071353, regression losses: 0.09838261630636, validation losses: 0.47368328168394336\n",
      "Epoch 1525, reconstruction losses: 0.01642482577843343, regression losses: 0.12273501044007154, validation losses: 0.458523813187534\n",
      "Epoch 1526, reconstruction losses: 0.01471136394706908, regression losses: 0.11266510658355663, validation losses: 0.5039701818435609\n",
      "Epoch 1527, reconstruction losses: 0.012500062942264249, regression losses: 0.08568325356302467, validation losses: 0.5215403264117463\n",
      "Epoch 1528, reconstruction losses: 0.011378501801982237, regression losses: 0.09828907790623366, validation losses: 0.4849699516832524\n",
      "Epoch 1529, reconstruction losses: 0.012740747640758894, regression losses: 0.09494182079215135, validation losses: 0.5076612647102012\n",
      "Epoch 1530, reconstruction losses: 0.013488093013050338, regression losses: 0.11481789370619006, validation losses: 0.44748909343973425\n",
      "Epoch 1531, reconstruction losses: 0.015654671300832743, regression losses: 0.1182558558991034, validation losses: 0.5313118064541033\n",
      "Epoch 1532, reconstruction losses: 0.015041338034282389, regression losses: 0.12879232324690704, validation losses: 0.5116253394900603\n",
      "Epoch 1533, reconstruction losses: 0.01435913736873683, regression losses: 0.08921755018619937, validation losses: 0.4491043208301448\n",
      "Epoch 1534, reconstruction losses: 0.01642314019927251, regression losses: 0.09745882618226703, validation losses: 0.4465094691014737\n",
      "Epoch 1535, reconstruction losses: 0.01434731707651192, regression losses: 0.12576248514918964, validation losses: 0.5026410005887272\n",
      "Epoch 1536, reconstruction losses: 0.013209095893756649, regression losses: 0.11104788227695753, validation losses: 0.6020778185471571\n",
      "Epoch 1537, reconstruction losses: 0.01814909378274774, regression losses: 0.12609071859645088, validation losses: 0.638474815682932\n",
      "Epoch 1538, reconstruction losses: 0.01617816845644007, regression losses: 0.17402679972808588, validation losses: 0.5132434343617873\n",
      "Epoch 1539, reconstruction losses: 0.014476192561167636, regression losses: 0.10039330804749436, validation losses: 0.48237055444997\n",
      "Epoch 1540, reconstruction losses: 0.013221984544475013, regression losses: 0.08827675584055324, validation losses: 0.4357038708065513\n",
      "Epoch 1541, reconstruction losses: 0.01590459005135271, regression losses: 0.1101510818995542, validation losses: 0.49613342165418906\n",
      "Epoch 1542, reconstruction losses: 0.014485503726629437, regression losses: 0.13310215056872146, validation losses: 0.5911343449202793\n",
      "Epoch 1543, reconstruction losses: 0.0154878816302911, regression losses: 0.13623174801490945, validation losses: 0.4635840502965328\n",
      "Epoch 1544, reconstruction losses: 0.017025411891821843, regression losses: 0.1432535318581541, validation losses: 0.4156148582923739\n",
      "Epoch 1545, reconstruction losses: 0.016596985633415193, regression losses: 0.09168725168670429, validation losses: 0.41563657638524737\n",
      "Epoch 1546, reconstruction losses: 0.016019001467745243, regression losses: 0.11616606878351537, validation losses: 0.42277440107323055\n",
      "Epoch 1547, reconstruction losses: 0.014779450825241893, regression losses: 0.09799157694703348, validation losses: 0.4917578948787552\n",
      "Epoch 1548, reconstruction losses: 0.012614545093981048, regression losses: 0.10685557815882755, validation losses: 0.4513609656220251\n",
      "Epoch 1549, reconstruction losses: 0.018384431237609845, regression losses: 0.1409572549629533, validation losses: 0.5277501914174074\n",
      "Epoch 1550, reconstruction losses: 0.015021728201935702, regression losses: 0.10112692245990983, validation losses: 0.6608574670529832\n",
      "Epoch 1551, reconstruction losses: 0.016909989249454846, regression losses: 0.11354598183451244, validation losses: 0.5592146982787902\n",
      "Epoch 1552, reconstruction losses: 0.017939099625483658, regression losses: 0.12903446783804237, validation losses: 0.5045479348972566\n",
      "Epoch 1553, reconstruction losses: 0.018816196672650238, regression losses: 0.12400996141001924, validation losses: 0.4332264203563296\n",
      "Epoch 1554, reconstruction losses: 0.014538757147657322, regression losses: 0.10673984580515382, validation losses: 0.5034945463560313\n",
      "Epoch 1555, reconstruction losses: 0.01596633642289839, regression losses: 0.13984796480529688, validation losses: 0.6100417745859633\n",
      "Epoch 1556, reconstruction losses: 0.01689278009740989, regression losses: 0.17042014957206586, validation losses: 0.5989938059202495\n",
      "Epoch 1557, reconstruction losses: 0.01955740133603525, regression losses: 0.41060389229736366, validation losses: 0.687918766127243\n",
      "Epoch 1558, reconstruction losses: 0.02011705841297877, regression losses: 0.18350605153217442, validation losses: 0.6723399115881903\n",
      "Epoch 1559, reconstruction losses: 0.013346341450670741, regression losses: 0.11874178367553885, validation losses: 0.7175582206431779\n",
      "Epoch 1560, reconstruction losses: 0.026561577770540336, regression losses: 0.3138818676419821, validation losses: 0.5590259866797842\n",
      "Epoch 1561, reconstruction losses: 0.015005630683736731, regression losses: 0.1381381992842919, validation losses: 1.046636037410608\n",
      "Epoch 1562, reconstruction losses: 0.017514929326085577, regression losses: 0.14411891518934183, validation losses: 0.8467082203796692\n",
      "Epoch 1563, reconstruction losses: 0.016675156744128058, regression losses: 0.11708092103711236, validation losses: 0.5108722704185277\n",
      "Epoch 1564, reconstruction losses: 0.01990624809870028, regression losses: 0.10475967026723208, validation losses: 0.4846458317402563\n",
      "Epoch 1565, reconstruction losses: 0.012548959340234849, regression losses: 0.09348598555802878, validation losses: 0.4776926166798663\n",
      "Epoch 1566, reconstruction losses: 0.015873475353690467, regression losses: 0.11787856790379599, validation losses: 0.4825476032194142\n",
      "Epoch 1567, reconstruction losses: 0.01394222712061181, regression losses: 0.12023105661374622, validation losses: 0.44786012659292723\n",
      "Epoch 1568, reconstruction losses: 0.013407517759065018, regression losses: 0.11386550238964255, validation losses: 0.4720323225143764\n",
      "Epoch 1569, reconstruction losses: 0.025076507875674586, regression losses: 0.29671979249878727, validation losses: 0.5205773122646379\n",
      "Epoch 1570, reconstruction losses: 0.013324979001739698, regression losses: 0.09594695644694036, validation losses: 0.60552246682228\n",
      "Epoch 1571, reconstruction losses: 0.015374399161091472, regression losses: 0.11771064914065914, validation losses: 0.5322380260079429\n",
      "Epoch 1572, reconstruction losses: 0.016483987058301175, regression losses: 0.10080780508360168, validation losses: 0.5102048064327191\n",
      "Epoch 1573, reconstruction losses: 0.015321740109771142, regression losses: 0.2013459192857226, validation losses: 0.49909618939737715\n",
      "Epoch 1574, reconstruction losses: 0.015289075415195884, regression losses: 0.12042188841930558, validation losses: 0.6725148797965714\n",
      "Epoch 1575, reconstruction losses: 0.014213797680236083, regression losses: 0.11558400502648578, validation losses: 0.5623882366239539\n",
      "Epoch 1576, reconstruction losses: 0.014236909696749917, regression losses: 0.11317431318278524, validation losses: 0.5113271717534544\n",
      "Epoch 1577, reconstruction losses: 0.015439902707550938, regression losses: 0.10122308951846662, validation losses: 0.5847530311069793\n",
      "Epoch 1578, reconstruction losses: 0.016014679294602294, regression losses: 0.1311645801424559, validation losses: 0.669423810608263\n",
      "Epoch 1579, reconstruction losses: 0.01610839335626816, regression losses: 0.1351263407598726, validation losses: 0.736884127878402\n",
      "Epoch 1580, reconstruction losses: 0.013633237632002155, regression losses: 0.11646805495787059, validation losses: 0.5787879458528452\n",
      "Epoch 1581, reconstruction losses: 0.019196256764208434, regression losses: 0.16147512371115652, validation losses: 0.5074629273627423\n",
      "Epoch 1582, reconstruction losses: 0.012975896271416775, regression losses: 0.10810983177869454, validation losses: 0.6165353643218253\n",
      "Epoch 1583, reconstruction losses: 0.0126950654835711, regression losses: 0.105884867137729, validation losses: 0.5806649958406118\n",
      "Epoch 1584, reconstruction losses: 0.016168966736216393, regression losses: 0.13661902568436832, validation losses: 0.5948628526504051\n",
      "Epoch 1585, reconstruction losses: 0.01386981957548494, regression losses: 0.12406953471543213, validation losses: 0.6598095815691587\n",
      "Epoch 1586, reconstruction losses: 0.01644625818029452, regression losses: 0.133694250091413, validation losses: 0.6058927111756505\n",
      "Epoch 1587, reconstruction losses: 0.01479384291241015, regression losses: 0.11384493181301326, validation losses: 0.586710441265189\n",
      "Epoch 1588, reconstruction losses: 0.017112760223487167, regression losses: 0.10747676464023215, validation losses: 0.6256950706001065\n",
      "Epoch 1589, reconstruction losses: 0.013892304600045388, regression losses: 0.13305277742773294, validation losses: 0.5916584476708517\n",
      "Epoch 1590, reconstruction losses: 0.01641273423897467, regression losses: 0.12005053805162413, validation losses: 0.5972774600366824\n",
      "Epoch 1591, reconstruction losses: 0.0168089078976643, regression losses: 0.14546019194383558, validation losses: 0.49767203816560573\n",
      "Epoch 1592, reconstruction losses: 0.012803176923674482, regression losses: 0.10373284646231175, validation losses: 0.5653833546715786\n",
      "Epoch 1593, reconstruction losses: 0.016375488093029498, regression losses: 0.12325021445576242, validation losses: 0.5689091079432993\n",
      "Epoch 1594, reconstruction losses: 0.013354456841767243, regression losses: 0.0874964857124091, validation losses: 0.6116212431473887\n",
      "Epoch 1595, reconstruction losses: 0.016107021086690872, regression losses: 0.1298381273887254, validation losses: 0.5587816446878509\n",
      "Epoch 1596, reconstruction losses: 0.018399389686735244, regression losses: 0.12519078321104626, validation losses: 0.48229365757444165\n",
      "Epoch 1597, reconstruction losses: 0.017777415252307305, regression losses: 0.15579847262102664, validation losses: 0.48265329572891025\n",
      "Epoch 1598, reconstruction losses: 0.016722714265067547, regression losses: 0.11423609080047893, validation losses: 0.44097119267953616\n",
      "Epoch 1599, reconstruction losses: 0.015374182368145566, regression losses: 0.09517757077459091, validation losses: 0.54688508686982\n",
      "Epoch 1600, reconstruction losses: 0.015274297568841072, regression losses: 0.1180373658447934, validation losses: 0.5077712153225368\n",
      "Epoch 1601, reconstruction losses: 0.015047451498976086, regression losses: 0.09553066164378106, validation losses: 0.43006450960722475\n",
      "Epoch 1602, reconstruction losses: 0.014456022538186605, regression losses: 0.17281472708148501, validation losses: 0.4874925451582386\n",
      "Epoch 1603, reconstruction losses: 0.019627148274460132, regression losses: 0.14263159107902665, validation losses: 0.5368247974284159\n",
      "Epoch 1604, reconstruction losses: 0.014538811553070696, regression losses: 0.11216529067103952, validation losses: 0.46410525551464876\n",
      "Epoch 1605, reconstruction losses: 0.01658232298478652, regression losses: 0.16486314321553105, validation losses: 0.47232669463271104\n",
      "Epoch 1606, reconstruction losses: 0.016004997426533375, regression losses: 0.14145306048655648, validation losses: 0.47105999828924455\n",
      "Epoch 1607, reconstruction losses: 0.013672400257299547, regression losses: 0.11469811216954923, validation losses: 0.4770599549907581\n",
      "Epoch 1608, reconstruction losses: 0.012941252800496706, regression losses: 0.1255406864237665, validation losses: 0.45867104371737644\n",
      "Epoch 1609, reconstruction losses: 0.014146698954496528, regression losses: 0.12933956668122584, validation losses: 0.49967667328002624\n",
      "Epoch 1610, reconstruction losses: 0.015850064599810608, regression losses: 0.10701894588194723, validation losses: 0.5649545062704697\n",
      "Epoch 1611, reconstruction losses: 0.013838069900699359, regression losses: 0.17973211952439822, validation losses: 0.6166946781123319\n",
      "Epoch 1612, reconstruction losses: 0.015620951013376523, regression losses: 0.13077085663976462, validation losses: 0.6274259527431045\n",
      "Epoch 1613, reconstruction losses: 0.014772686658481676, regression losses: 0.15144026709783506, validation losses: 0.5301900698364004\n",
      "Epoch 1614, reconstruction losses: 0.014076761482140236, regression losses: 0.11591434965274526, validation losses: 0.49577960333212945\n",
      "Epoch 1615, reconstruction losses: 0.015397213404867029, regression losses: 0.14417891998985405, validation losses: 0.47704846156351954\n",
      "Epoch 1616, reconstruction losses: 0.0141512252474799, regression losses: 0.15974695585694365, validation losses: 0.5549860650685999\n",
      "Epoch 1617, reconstruction losses: 0.019982627313790954, regression losses: 0.12769840181667014, validation losses: 0.6556810250287771\n",
      "Epoch 1618, reconstruction losses: 0.018366818212591878, regression losses: 0.1114105852136614, validation losses: 0.6061646901181437\n",
      "Epoch 1619, reconstruction losses: 0.015303214361615627, regression losses: 0.11855608724224061, validation losses: 0.4852502802198575\n",
      "Epoch 1620, reconstruction losses: 0.01743191210263227, regression losses: 0.19230523284491594, validation losses: 0.4446374574768177\n",
      "Epoch 1621, reconstruction losses: 0.014799596679131465, regression losses: 0.12722685478983875, validation losses: 0.49245482815722497\n",
      "Epoch 1622, reconstruction losses: 0.018858299221489197, regression losses: 0.37481817084793073, validation losses: 0.497165542023035\n",
      "Epoch 1623, reconstruction losses: 0.01437207877400091, regression losses: 0.1398735314421593, validation losses: 1.0365874820391319\n",
      "Epoch 1624, reconstruction losses: 0.0132553318135002, regression losses: 0.16367313986408985, validation losses: 0.9690243046652965\n",
      "Epoch 1625, reconstruction losses: 0.015335569515890426, regression losses: 0.1401017385796742, validation losses: 0.6350655621383832\n",
      "Epoch 1626, reconstruction losses: 0.016646938619689685, regression losses: 0.09588508729651583, validation losses: 0.5589821506513444\n",
      "Epoch 1627, reconstruction losses: 0.018455869396835158, regression losses: 0.11649735806153443, validation losses: 0.561005815175103\n",
      "Epoch 1628, reconstruction losses: 0.012257149873991506, regression losses: 0.09427656093037753, validation losses: 0.6333048903456204\n",
      "Epoch 1629, reconstruction losses: 0.017480695695742787, regression losses: 0.12676566188983357, validation losses: 0.5943935122934415\n",
      "Epoch 1630, reconstruction losses: 0.016102570951387587, regression losses: 0.1747889883484704, validation losses: 0.5084739099553529\n",
      "Epoch 1631, reconstruction losses: 0.01451142380603984, regression losses: 0.13290995482391868, validation losses: 0.6073332576939623\n",
      "Epoch 1632, reconstruction losses: 0.014124334905822907, regression losses: 0.12498527630473763, validation losses: 0.5351992673228836\n",
      "Epoch 1633, reconstruction losses: 0.016454612630461038, regression losses: 0.15106576528240828, validation losses: 0.6413866654681931\n",
      "Epoch 1634, reconstruction losses: 0.01885246898541937, regression losses: 0.154332931598748, validation losses: 0.8556087536738323\n",
      "Epoch 1635, reconstruction losses: 0.01784823229431433, regression losses: 0.22489317567218114, validation losses: 0.5923527775898074\n",
      "Epoch 1636, reconstruction losses: 0.013116520121756485, regression losses: 0.11495256677409084, validation losses: 0.5853260502213233\n",
      "Epoch 1637, reconstruction losses: 0.016073724291915507, regression losses: 0.12835065059833814, validation losses: 0.5310609789673277\n",
      "Epoch 1638, reconstruction losses: 0.013705746011850876, regression losses: 0.10731324781089538, validation losses: 0.5741601311709715\n",
      "Epoch 1639, reconstruction losses: 0.014330074473378432, regression losses: 0.10393378308626222, validation losses: 0.4849684969583914\n",
      "Epoch 1640, reconstruction losses: 0.013581142121167327, regression losses: 0.1086598428098274, validation losses: 0.43800085804962247\n",
      "Epoch 1641, reconstruction losses: 0.016172377780922228, regression losses: 0.10397254436551703, validation losses: 0.47368764665752067\n",
      "Epoch 1642, reconstruction losses: 0.01684406791879605, regression losses: 0.15849156613977441, validation losses: 0.4667672543677002\n",
      "Epoch 1643, reconstruction losses: 0.015999106899749815, regression losses: 0.1086813775254849, validation losses: 0.45607449149595614\n",
      "Epoch 1644, reconstruction losses: 0.017377203670562474, regression losses: 0.20105630420992945, validation losses: 0.4959493129055413\n",
      "Epoch 1645, reconstruction losses: 0.014149853931718345, regression losses: 0.1237390856293859, validation losses: 0.5805309414044949\n",
      "Epoch 1646, reconstruction losses: 0.0176729201005695, regression losses: 0.13363778153351316, validation losses: 0.5972217397462872\n",
      "Epoch 1647, reconstruction losses: 0.013126742393082806, regression losses: 0.09116841500911493, validation losses: 0.5658639525984375\n",
      "Epoch 1648, reconstruction losses: 0.014318070181786224, regression losses: 0.09377923241630082, validation losses: 0.5622592723987195\n",
      "Epoch 1649, reconstruction losses: 0.016810195805685192, regression losses: 0.10320623479880874, validation losses: 0.5858599883944977\n",
      "Epoch 1650, reconstruction losses: 0.016231717482171438, regression losses: 0.17680931399853358, validation losses: 0.4740015428147587\n",
      "Epoch 1651, reconstruction losses: 0.013669113977633781, regression losses: 0.08467874109969144, validation losses: 0.43949504067325584\n",
      "Epoch 1652, reconstruction losses: 0.015460335629126874, regression losses: 0.08019401593292612, validation losses: 0.42906107951520245\n",
      "Epoch 1653, reconstruction losses: 0.013422769263535061, regression losses: 0.09916132811113054, validation losses: 0.4913562798978035\n",
      "Epoch 1654, reconstruction losses: 0.016461214857448243, regression losses: 0.10593301066713255, validation losses: 0.4586295132205175\n",
      "Epoch 1655, reconstruction losses: 0.017239693719077114, regression losses: 0.14696623542646386, validation losses: 0.4780784704681986\n",
      "Epoch 1656, reconstruction losses: 0.014575555019711008, regression losses: 0.11584632307804604, validation losses: 0.4817087376210112\n",
      "Epoch 1657, reconstruction losses: 0.01599861713999313, regression losses: 0.12309427461326654, validation losses: 0.4631832267620378\n",
      "Epoch 1658, reconstruction losses: 0.01722751306096963, regression losses: 0.13766765567575562, validation losses: 0.4714885731779703\n",
      "Epoch 1659, reconstruction losses: 0.01998158407535393, regression losses: 0.3146410830819426, validation losses: 0.5243274589192747\n",
      "Epoch 1660, reconstruction losses: 0.015978311000986692, regression losses: 0.12776401834081244, validation losses: 0.7371312605722553\n",
      "Epoch 1661, reconstruction losses: 0.017285950683260044, regression losses: 0.1729910052524611, validation losses: 0.5890653155354056\n",
      "Epoch 1662, reconstruction losses: 0.015673458735165856, regression losses: 0.1560780494257337, validation losses: 0.5697746152915248\n",
      "Epoch 1663, reconstruction losses: 0.015295317705136638, regression losses: 0.12705617872508784, validation losses: 0.5295505296264933\n",
      "Epoch 1664, reconstruction losses: 0.015636080938807986, regression losses: 0.12335192306237462, validation losses: 0.45442867231863376\n",
      "Epoch 1665, reconstruction losses: 0.016966285463557277, regression losses: 0.11640232721724679, validation losses: 0.5122728080439981\n",
      "Epoch 1666, reconstruction losses: 0.015826595979383254, regression losses: 0.0998320060165744, validation losses: 0.6044990785549808\n",
      "Epoch 1667, reconstruction losses: 0.019510244021396596, regression losses: 0.1593188291025048, validation losses: 0.5993603364482178\n",
      "Epoch 1668, reconstruction losses: 0.014819555708966974, regression losses: 0.12949990121672697, validation losses: 0.521707750983828\n",
      "Epoch 1669, reconstruction losses: 0.01286626509579459, regression losses: 0.09159041454252272, validation losses: 0.46542081617950043\n",
      "Epoch 1670, reconstruction losses: 0.013528767855214842, regression losses: 0.11077742251814383, validation losses: 0.4679386707526022\n",
      "Epoch 1671, reconstruction losses: 0.016151704315804594, regression losses: 0.1506862257113668, validation losses: 0.46471526769688065\n",
      "Epoch 1672, reconstruction losses: 0.014840392022055627, regression losses: 0.10804539754677296, validation losses: 0.49798032031639544\n",
      "Epoch 1673, reconstruction losses: 0.014859374448179799, regression losses: 0.09736076500813903, validation losses: 0.4488259235757078\n",
      "Epoch 1674, reconstruction losses: 0.013983359350693815, regression losses: 0.12076291858819042, validation losses: 0.4840455197414475\n",
      "Epoch 1675, reconstruction losses: 0.013906827229855676, regression losses: 0.11544702926370412, validation losses: 0.45972698846763066\n",
      "Epoch 1676, reconstruction losses: 0.014947209550632173, regression losses: 0.12803162748802074, validation losses: 0.5165839407295506\n",
      "Epoch 1677, reconstruction losses: 0.013124996418605426, regression losses: 0.1120576267424874, validation losses: 0.4834868582166685\n",
      "Epoch 1678, reconstruction losses: 0.022509824510761577, regression losses: 0.19357254851788488, validation losses: 0.45219742437038996\n",
      "Epoch 1679, reconstruction losses: 0.015786198105421326, regression losses: 0.13016044387476738, validation losses: 0.5163509872260708\n",
      "Epoch 1680, reconstruction losses: 0.021586393580912477, regression losses: 0.12086261744083107, validation losses: 0.4375279720907354\n",
      "Epoch 1681, reconstruction losses: 0.020679997050734523, regression losses: 0.26844294241648436, validation losses: 0.4703946030444873\n",
      "Epoch 1682, reconstruction losses: 0.021694715236607914, regression losses: 0.13618142858865193, validation losses: 0.502865558718032\n",
      "Epoch 1683, reconstruction losses: 0.014381913864709946, regression losses: 0.11422421170297775, validation losses: 0.550950942933747\n",
      "Epoch 1684, reconstruction losses: 0.015892162750440843, regression losses: 0.10593268675383563, validation losses: 0.5677241273538268\n",
      "Epoch 1685, reconstruction losses: 0.013606823155472236, regression losses: 0.11234710254081891, validation losses: 0.55561597716216\n",
      "Epoch 1686, reconstruction losses: 0.015083839920074829, regression losses: 0.1390277918462373, validation losses: 0.4713759500888813\n",
      "Epoch 1687, reconstruction losses: 0.016747808083000842, regression losses: 0.14895020353892893, validation losses: 0.45006393029637193\n",
      "Epoch 1688, reconstruction losses: 0.01756434797360739, regression losses: 0.14195868219571123, validation losses: 0.47988336489848105\n",
      "Epoch 1689, reconstruction losses: 0.017285339998956244, regression losses: 0.11691421787959656, validation losses: 0.45879103300507024\n",
      "Epoch 1690, reconstruction losses: 0.016004597175643252, regression losses: 0.10719128896156715, validation losses: 0.46406761682875347\n",
      "Epoch 1691, reconstruction losses: 0.01713801672597136, regression losses: 0.126848495791895, validation losses: 0.5269690025701034\n",
      "Epoch 1692, reconstruction losses: 0.016086391202865542, regression losses: 0.08856145745861164, validation losses: 0.5141004007526855\n",
      "Epoch 1693, reconstruction losses: 0.015852655797705728, regression losses: 0.2123581583691841, validation losses: 0.5013106134448728\n",
      "Epoch 1694, reconstruction losses: 0.016448342126226357, regression losses: 0.1344998569402279, validation losses: 0.5732462851566966\n",
      "Epoch 1695, reconstruction losses: 0.01701069833444157, regression losses: 0.11503358111622478, validation losses: 0.5826423181402598\n",
      "Epoch 1696, reconstruction losses: 0.019554564576530604, regression losses: 0.20373907018778714, validation losses: 0.487529438035712\n",
      "Epoch 1697, reconstruction losses: 0.0149570795801096, regression losses: 0.12772267446943625, validation losses: 0.5548291143609535\n",
      "Epoch 1698, reconstruction losses: 0.017109429386074203, regression losses: 0.15167954446608842, validation losses: 0.5051025609003442\n",
      "Epoch 1699, reconstruction losses: 0.01681126269095477, regression losses: 0.10832924100448839, validation losses: 0.451130606027518\n",
      "Epoch 1700, reconstruction losses: 0.012241666241260982, regression losses: 0.10115907067552891, validation losses: 0.5267930618912038\n",
      "Epoch 1701, reconstruction losses: 0.014041767172460393, regression losses: 0.13229801883802944, validation losses: 0.5234250312490782\n",
      "Epoch 1702, reconstruction losses: 0.017845250424966274, regression losses: 0.14216420172074345, validation losses: 0.5198418259122091\n",
      "Epoch 1703, reconstruction losses: 0.018852330149759386, regression losses: 0.17991956254895697, validation losses: 0.45525205990962225\n",
      "Epoch 1704, reconstruction losses: 0.012123550273247742, regression losses: 0.07866261701595167, validation losses: 0.7031282895451931\n",
      "Epoch 1705, reconstruction losses: 0.01786759880640429, regression losses: 0.13619216527713612, validation losses: 0.5830459680073893\n",
      "Epoch 1706, reconstruction losses: 0.01848646684866681, regression losses: 0.1516992780592742, validation losses: 0.5102147910985453\n",
      "Epoch 1707, reconstruction losses: 0.01611472768723381, regression losses: 0.1454283579169506, validation losses: 0.5276631090770117\n",
      "Epoch 1708, reconstruction losses: 0.020331164345735352, regression losses: 0.15352346965080815, validation losses: 0.5181031834532182\n",
      "Epoch 1709, reconstruction losses: 0.013930837363040422, regression losses: 0.10117970094322505, validation losses: 0.4944361555015755\n",
      "Epoch 1710, reconstruction losses: 0.013518195559822983, regression losses: 0.11833225074253877, validation losses: 0.4538920661659367\n",
      "Epoch 1711, reconstruction losses: 0.015365229505608655, regression losses: 0.1146028745733422, validation losses: 0.46721071684077886\n",
      "Epoch 1712, reconstruction losses: 0.013104122651963333, regression losses: 0.09275988213288361, validation losses: 0.5439079886237979\n",
      "Epoch 1713, reconstruction losses: 0.018027062100802006, regression losses: 0.12343682140995722, validation losses: 0.48517770738873894\n",
      "Epoch 1714, reconstruction losses: 0.01435228572473276, regression losses: 0.11272046835305216, validation losses: 0.4384624183033227\n",
      "Epoch 1715, reconstruction losses: 0.013561167820917333, regression losses: 0.1468763700983325, validation losses: 0.42942769040135775\n",
      "Epoch 1716, reconstruction losses: 0.013396453421166936, regression losses: 0.10965384277309498, validation losses: 0.4506274249486607\n",
      "Epoch 1717, reconstruction losses: 0.016083530679718155, regression losses: 0.1754811822413594, validation losses: 0.4482205575611026\n",
      "Epoch 1718, reconstruction losses: 0.014156979702231799, regression losses: 0.10502653169356449, validation losses: 0.5713971839141244\n",
      "Epoch 1719, reconstruction losses: 0.01953919291073486, regression losses: 0.1630510179253581, validation losses: 0.5421811555529569\n",
      "Epoch 1720, reconstruction losses: 0.015708938033483454, regression losses: 0.14399649353631783, validation losses: 0.6333888062994558\n",
      "Epoch 1721, reconstruction losses: 0.017933053163019994, regression losses: 0.10680597658907047, validation losses: 0.6231868963280832\n",
      "Epoch 1722, reconstruction losses: 0.014900264778979964, regression losses: 0.12988685373095757, validation losses: 0.47656387684599905\n",
      "Epoch 1723, reconstruction losses: 0.013102876739676602, regression losses: 0.1094679806003838, validation losses: 0.49759409293945045\n",
      "Epoch 1724, reconstruction losses: 0.015356432301392314, regression losses: 0.1075372300094204, validation losses: 0.4972313525126121\n",
      "Epoch 1725, reconstruction losses: 0.013802541046726052, regression losses: 0.11118447467046433, validation losses: 0.4666602125064855\n",
      "Epoch 1726, reconstruction losses: 0.015004437273555868, regression losses: 0.0978543341471812, validation losses: 0.48674822773708704\n",
      "Epoch 1727, reconstruction losses: 0.015436862563563605, regression losses: 0.11077215737155303, validation losses: 0.45906353064415434\n",
      "Epoch 1728, reconstruction losses: 0.014754840066354032, regression losses: 0.12218686172052973, validation losses: 0.4533144290058409\n",
      "Epoch 1729, reconstruction losses: 0.018491846346678636, regression losses: 0.3983726496561997, validation losses: 0.5271423373527664\n",
      "Epoch 1730, reconstruction losses: 0.013788171221170582, regression losses: 0.14048412329805093, validation losses: 0.9529033028440698\n",
      "Epoch 1731, reconstruction losses: 0.013336537821980236, regression losses: 0.1835272859952371, validation losses: 0.861118790257536\n",
      "Epoch 1732, reconstruction losses: 0.01286856222747434, regression losses: 0.1323283624599455, validation losses: 0.5451505701005955\n",
      "Epoch 1733, reconstruction losses: 0.014505469189651263, regression losses: 0.10220753980173226, validation losses: 0.46419256453838026\n",
      "Epoch 1734, reconstruction losses: 0.014164777786908427, regression losses: 0.13333326625131958, validation losses: 0.45304556302735655\n",
      "Epoch 1735, reconstruction losses: 0.01739443031780257, regression losses: 0.1928689796597731, validation losses: 0.448274668429469\n",
      "Epoch 1736, reconstruction losses: 0.014253557101829817, regression losses: 0.1291750133997032, validation losses: 0.45367274615720043\n",
      "Epoch 1737, reconstruction losses: 0.016762481284595718, regression losses: 0.16823836967183348, validation losses: 0.451446770848811\n",
      "Epoch 1738, reconstruction losses: 0.015379545296006302, regression losses: 0.15306792243955802, validation losses: 0.5574627394967309\n",
      "Epoch 1739, reconstruction losses: 0.014093832107485885, regression losses: 0.1661705408221281, validation losses: 0.704726566508032\n",
      "Epoch 1740, reconstruction losses: 0.02004354458606662, regression losses: 0.21939864237730788, validation losses: 0.6593003643040157\n",
      "Epoch 1741, reconstruction losses: 0.015482823526113514, regression losses: 0.12635657359670308, validation losses: 0.5495537811337724\n",
      "Epoch 1742, reconstruction losses: 0.015612888484303766, regression losses: 0.14216265981374102, validation losses: 0.5038177295250909\n",
      "Epoch 1743, reconstruction losses: 0.015015769545553725, regression losses: 0.1483180685012427, validation losses: 0.43341194461289656\n",
      "Epoch 1744, reconstruction losses: 0.013934711152718398, regression losses: 0.1378360048437578, validation losses: 0.4335312805099385\n",
      "Epoch 1745, reconstruction losses: 0.019581531737387012, regression losses: 0.1299173941478485, validation losses: 0.4921647228280525\n",
      "Epoch 1746, reconstruction losses: 0.01571488724558349, regression losses: 0.15289206537903266, validation losses: 0.49483487459222425\n",
      "Epoch 1747, reconstruction losses: 0.013846552416013578, regression losses: 0.11986936948886028, validation losses: 0.5521792295236182\n",
      "Epoch 1748, reconstruction losses: 0.018097536577245603, regression losses: 0.10311484081038558, validation losses: 0.5651801111491616\n",
      "Epoch 1749, reconstruction losses: 0.015962635866579786, regression losses: 0.11013603646067333, validation losses: 0.48413622805158063\n",
      "Epoch 1750, reconstruction losses: 0.015183284431265848, regression losses: 0.1328741314274784, validation losses: 0.4653879032770145\n",
      "Epoch 1751, reconstruction losses: 0.028191098136798824, regression losses: 0.3667570192938512, validation losses: 0.4574397063152511\n",
      "Epoch 1752, reconstruction losses: 0.014657222602219931, regression losses: 0.1162370437154393, validation losses: 0.6984431319105002\n",
      "Epoch 1753, reconstruction losses: 0.025120899866019702, regression losses: 0.17916044550631993, validation losses: 0.6816781552549612\n",
      "Epoch 1754, reconstruction losses: 0.014566884727802296, regression losses: 0.11377093773505989, validation losses: 0.4821823557726605\n",
      "Epoch 1755, reconstruction losses: 0.020089354467260293, regression losses: 0.12973064236609258, validation losses: 0.4901808573637515\n",
      "Epoch 1756, reconstruction losses: 0.015926982370289132, regression losses: 0.11817688532153547, validation losses: 0.5063885592232138\n",
      "Epoch 1757, reconstruction losses: 0.014765637838809575, regression losses: 0.16272244344763084, validation losses: 0.482387708105546\n",
      "Epoch 1758, reconstruction losses: 0.02132815044413145, regression losses: 0.2770858951504308, validation losses: 0.5196641950285259\n",
      "Epoch 1759, reconstruction losses: 0.013765859715575276, regression losses: 0.10821508175422227, validation losses: 0.507876439328603\n",
      "Epoch 1760, reconstruction losses: 0.013907295423086653, regression losses: 0.0983002097163088, validation losses: 0.5159457204828101\n",
      "Epoch 1761, reconstruction losses: 0.01226195405420555, regression losses: 0.10574045168945369, validation losses: 0.46713998566924736\n",
      "Epoch 1762, reconstruction losses: 0.014951752789566631, regression losses: 0.10309680718043646, validation losses: 0.4687359306633041\n",
      "Epoch 1763, reconstruction losses: 0.015795221071981475, regression losses: 0.1380310183978766, validation losses: 0.4842516568663576\n",
      "Epoch 1764, reconstruction losses: 0.012618088891733254, regression losses: 0.13812542642068731, validation losses: 0.42965746368239094\n",
      "Epoch 1765, reconstruction losses: 0.01998227197147109, regression losses: 0.1314447980441941, validation losses: 0.45298555346679553\n",
      "Epoch 1766, reconstruction losses: 0.016976373796048782, regression losses: 0.22918923155712997, validation losses: 0.5250742542645588\n",
      "Epoch 1767, reconstruction losses: 0.016248419115125347, regression losses: 0.1558981622947385, validation losses: 0.6055065887452349\n",
      "Epoch 1768, reconstruction losses: 0.016701515997741986, regression losses: 0.14730260859936917, validation losses: 0.5802760913635517\n",
      "Epoch 1769, reconstruction losses: 0.014159074945856031, regression losses: 0.10895976024370133, validation losses: 0.4695454823066971\n",
      "Epoch 1770, reconstruction losses: 0.01568637857853664, regression losses: 0.10853039724190619, validation losses: 0.4476049546004848\n",
      "Epoch 1771, reconstruction losses: 0.013706567063917667, regression losses: 0.11798058954392428, validation losses: 0.44114025003537705\n",
      "Epoch 1772, reconstruction losses: 0.014264668546625359, regression losses: 0.09799943378881143, validation losses: 0.4184730796745893\n",
      "Epoch 1773, reconstruction losses: 0.013929872417831436, regression losses: 0.10961418754142595, validation losses: 0.4159597155914226\n",
      "Epoch 1774, reconstruction losses: 0.02012928593136757, regression losses: 0.1613622368341944, validation losses: 0.4965823366924541\n",
      "Epoch 1775, reconstruction losses: 0.016027631657081952, regression losses: 0.13915270675122704, validation losses: 0.6686797310733138\n",
      "Epoch 1776, reconstruction losses: 0.013235322682624647, regression losses: 0.11498922669660469, validation losses: 0.5186757786877353\n",
      "Epoch 1777, reconstruction losses: 0.023621106266446267, regression losses: 0.20434785067588396, validation losses: 0.4795834059862388\n",
      "Epoch 1778, reconstruction losses: 0.016458716389349495, regression losses: 0.15175205809115339, validation losses: 0.5841164632953901\n",
      "Epoch 1779, reconstruction losses: 0.01628022191295166, regression losses: 0.14019651481105372, validation losses: 0.4947248143019053\n",
      "Epoch 1780, reconstruction losses: 0.014705253761062072, regression losses: 0.09089065003437082, validation losses: 0.4996653073182409\n",
      "Epoch 1781, reconstruction losses: 0.014050762020199465, regression losses: 0.10036580557807931, validation losses: 0.4874471277698246\n",
      "Epoch 1782, reconstruction losses: 0.015298960648929426, regression losses: 0.10673265918782238, validation losses: 0.4569864873956096\n",
      "Epoch 1783, reconstruction losses: 0.01511807689505391, regression losses: 0.370386060413301, validation losses: 0.4478695444042994\n",
      "Epoch 1784, reconstruction losses: 0.014838944475978845, regression losses: 0.08435032027269172, validation losses: 0.5831063544936902\n",
      "Epoch 1785, reconstruction losses: 0.013759986478093247, regression losses: 0.11126494663794562, validation losses: 0.583836468123726\n",
      "Epoch 1786, reconstruction losses: 0.01752138445443349, regression losses: 0.14588047353545142, validation losses: 0.5272302610246719\n",
      "Epoch 1787, reconstruction losses: 0.01762391862744025, regression losses: 0.09661450267980637, validation losses: 0.4357910887243058\n",
      "Epoch 1788, reconstruction losses: 0.01604431039021213, regression losses: 0.1353012728006341, validation losses: 0.4255812518244819\n",
      "Epoch 1789, reconstruction losses: 0.015760382238319007, regression losses: 0.13234717185181558, validation losses: 0.47604364069747174\n",
      "Epoch 1790, reconstruction losses: 0.014606404011256064, regression losses: 0.09468291711518184, validation losses: 0.4679387507258335\n",
      "Epoch 1791, reconstruction losses: 0.014178951184198983, regression losses: 0.09376881134917082, validation losses: 0.45680602061489417\n",
      "Epoch 1792, reconstruction losses: 0.012318860562854144, regression losses: 0.0949404112981347, validation losses: 0.4563666963972178\n",
      "Epoch 1793, reconstruction losses: 0.013729711567239372, regression losses: 0.11428767726417423, validation losses: 0.4502031519518985\n",
      "Epoch 1794, reconstruction losses: 0.0184880385895992, regression losses: 0.1128479849208887, validation losses: 0.4904989561228723\n",
      "Epoch 1795, reconstruction losses: 0.01645919187165078, regression losses: 0.1657946693646091, validation losses: 0.6094157133875139\n",
      "Epoch 1796, reconstruction losses: 0.017370375185555523, regression losses: 0.14917761723924094, validation losses: 0.5901356203333048\n",
      "Epoch 1797, reconstruction losses: 0.016137548218278897, regression losses: 0.108178322092938, validation losses: 0.5671007207073775\n",
      "Epoch 1798, reconstruction losses: 0.013360007445602855, regression losses: 0.10024187188768405, validation losses: 0.545337971271098\n",
      "Epoch 1799, reconstruction losses: 0.016465513122014157, regression losses: 0.11271171818874262, validation losses: 0.48944183663467633\n",
      "Epoch 1800, reconstruction losses: 0.015742530893487504, regression losses: 0.11148499225220511, validation losses: 0.43068875153323555\n",
      "Epoch 1801, reconstruction losses: 0.0136539414730498, regression losses: 0.0968169044354367, validation losses: 0.4376524955753903\n",
      "Epoch 1802, reconstruction losses: 0.019226444486424896, regression losses: 0.11209038010892092, validation losses: 0.4644605418885299\n",
      "Epoch 1803, reconstruction losses: 0.014822846232056357, regression losses: 0.14882025663149145, validation losses: 0.574208698763814\n",
      "Epoch 1804, reconstruction losses: 0.015765401914915125, regression losses: 0.13419422396768108, validation losses: 0.5308322078950163\n",
      "Epoch 1805, reconstruction losses: 0.016595034765563087, regression losses: 0.1690351397671746, validation losses: 0.48941686266704404\n",
      "Epoch 1806, reconstruction losses: 0.013772179522208322, regression losses: 0.11842260837318828, validation losses: 0.5908151450375392\n",
      "Epoch 1807, reconstruction losses: 0.016896209388353938, regression losses: 0.1396407803725492, validation losses: 0.5108116371820691\n",
      "Epoch 1808, reconstruction losses: 0.016678775690130997, regression losses: 0.18797822829904953, validation losses: 0.5771359834356053\n",
      "Epoch 1809, reconstruction losses: 0.011810955802263034, regression losses: 0.10850459460666659, validation losses: 0.726001858636255\n",
      "Epoch 1810, reconstruction losses: 0.01492990952242327, regression losses: 0.1295307486625792, validation losses: 0.5685698684575812\n",
      "Epoch 1811, reconstruction losses: 0.017167711408553235, regression losses: 0.15535562401358205, validation losses: 0.46390733961254677\n",
      "Epoch 1812, reconstruction losses: 0.015698095480023003, regression losses: 0.1206125211148942, validation losses: 0.48626615098808235\n",
      "Epoch 1813, reconstruction losses: 0.020158254234810713, regression losses: 0.31232664942147237, validation losses: 0.4781099023171052\n",
      "Epoch 1814, reconstruction losses: 0.015494679415210755, regression losses: 0.1320745978154832, validation losses: 0.7776682315220712\n",
      "Epoch 1815, reconstruction losses: 0.01940655893331557, regression losses: 0.23341321366388823, validation losses: 0.6923376775787938\n",
      "Epoch 1816, reconstruction losses: 0.014023391376784303, regression losses: 0.14606238528822693, validation losses: 0.5551408183652496\n",
      "Epoch 1817, reconstruction losses: 0.018280920346430037, regression losses: 0.16765633560793233, validation losses: 0.5429771993339216\n",
      "Epoch 1818, reconstruction losses: 0.014233341912244011, regression losses: 0.1148553427060866, validation losses: 0.5139114311074784\n",
      "Epoch 1819, reconstruction losses: 0.014190841559293116, regression losses: 0.12193484156871039, validation losses: 0.448830402967164\n",
      "Epoch 1820, reconstruction losses: 0.015481543151095985, regression losses: 0.15851306935359707, validation losses: 0.4693174630434679\n",
      "Epoch 1821, reconstruction losses: 0.019358483204053315, regression losses: 0.18479702315380747, validation losses: 0.49164071237502316\n",
      "Epoch 1822, reconstruction losses: 0.016615355977877104, regression losses: 0.10131267905338265, validation losses: 0.4307329477989577\n",
      "Epoch 1823, reconstruction losses: 0.014127176861645562, regression losses: 0.11462874939699683, validation losses: 0.4331650966607026\n",
      "Epoch 1824, reconstruction losses: 0.017999474275734024, regression losses: 0.12447251683416088, validation losses: 0.420014545771139\n",
      "Epoch 1825, reconstruction losses: 0.014005038891267495, regression losses: 0.10627102738242265, validation losses: 0.4234363785641392\n",
      "Epoch 1826, reconstruction losses: 0.014128019435335721, regression losses: 0.135979015444783, validation losses: 0.44277202117859366\n",
      "Epoch 1827, reconstruction losses: 0.015319437392381025, regression losses: 0.12383551092782155, validation losses: 0.4574149654947671\n",
      "Epoch 1828, reconstruction losses: 0.015540697864506722, regression losses: 0.11772681823648593, validation losses: 0.4546088924983507\n",
      "Epoch 1829, reconstruction losses: 0.012303711311233622, regression losses: 0.09965272297786308, validation losses: 0.43861044363804536\n",
      "Epoch 1830, reconstruction losses: 0.013895269038808307, regression losses: 0.1294771762232413, validation losses: 0.4244191550643232\n",
      "Epoch 1831, reconstruction losses: 0.012109522391660025, regression losses: 0.10703795327206952, validation losses: 0.42096077444916813\n",
      "Epoch 1832, reconstruction losses: 0.017062866060624158, regression losses: 0.15603623349351106, validation losses: 0.46730914190756834\n",
      "Epoch 1833, reconstruction losses: 0.014183757176418992, regression losses: 0.09945864658368682, validation losses: 0.566317094730964\n",
      "Epoch 1834, reconstruction losses: 0.01285695640051714, regression losses: 0.13662308531208428, validation losses: 0.5214882429025512\n",
      "Epoch 1835, reconstruction losses: 0.012265418561818528, regression losses: 0.08235231690157852, validation losses: 0.5032628766202438\n",
      "Epoch 1836, reconstruction losses: 0.01492690902309108, regression losses: 0.12035383697749978, validation losses: 0.4630124010331878\n",
      "Epoch 1837, reconstruction losses: 0.01346718079436163, regression losses: 0.09178373241008161, validation losses: 0.4334507682818888\n",
      "Epoch 1838, reconstruction losses: 0.015168525273200721, regression losses: 0.12905158528683539, validation losses: 0.45123411431958416\n",
      "Epoch 1839, reconstruction losses: 0.013462874087799632, regression losses: 0.10881163294717916, validation losses: 0.4426191611550025\n",
      "Epoch 1840, reconstruction losses: 0.020421322320594508, regression losses: 0.5113781152498422, validation losses: 0.4258987694917017\n",
      "Epoch 1841, reconstruction losses: 0.014738215044734835, regression losses: 0.14442814241974583, validation losses: 0.5498587579769862\n",
      "Epoch 1842, reconstruction losses: 0.016413191960791523, regression losses: 0.1351555923972352, validation losses: 0.5570464699207051\n",
      "Epoch 1843, reconstruction losses: 0.016189806421770696, regression losses: 0.1717039682568563, validation losses: 0.5267894406359488\n",
      "Epoch 1844, reconstruction losses: 0.014035185902347517, regression losses: 0.11354419620891196, validation losses: 0.5242272532042541\n",
      "Epoch 1845, reconstruction losses: 0.013642796134600938, regression losses: 0.1512194974622596, validation losses: 0.5349710898575976\n",
      "Epoch 1846, reconstruction losses: 0.016514275328606002, regression losses: 0.14839692616953132, validation losses: 0.49360082437413977\n",
      "Epoch 1847, reconstruction losses: 0.015243894271101137, regression losses: 0.1287046049829247, validation losses: 0.47274151916947504\n",
      "Epoch 1848, reconstruction losses: 0.013187541603037829, regression losses: 0.10319558263894896, validation losses: 0.4285530398963574\n",
      "Epoch 1849, reconstruction losses: 0.014422399850649687, regression losses: 0.11809234391457274, validation losses: 0.4256452287173702\n",
      "Epoch 1850, reconstruction losses: 0.01341743066793437, regression losses: 0.09620241422667532, validation losses: 0.49245841083194564\n",
      "Epoch 1851, reconstruction losses: 0.013462605958109108, regression losses: 0.11857633177548452, validation losses: 0.47584457856309426\n",
      "Epoch 1852, reconstruction losses: 0.015400774356612449, regression losses: 0.16181051950370626, validation losses: 0.4955003935008463\n",
      "Epoch 1853, reconstruction losses: 0.01571423454299294, regression losses: 0.13308114280962335, validation losses: 0.4497718827374084\n",
      "Epoch 1854, reconstruction losses: 0.014556857155825637, regression losses: 0.11399554969278122, validation losses: 0.42448829650854214\n",
      "Epoch 1855, reconstruction losses: 0.013204163600670598, regression losses: 0.12172134037870722, validation losses: 0.4370670617639825\n",
      "Epoch 1856, reconstruction losses: 0.013993614471841366, regression losses: 0.10999933308137874, validation losses: 0.43982178136758016\n",
      "Epoch 1857, reconstruction losses: 0.013720076142118912, regression losses: 0.112757302820036, validation losses: 0.5079815858538724\n",
      "Epoch 1858, reconstruction losses: 0.014585766273448101, regression losses: 0.11427196231475507, validation losses: 0.5401597223256916\n",
      "Epoch 1859, reconstruction losses: 0.016815695005109432, regression losses: 0.34986345329249047, validation losses: 0.5905247578470623\n",
      "Epoch 1860, reconstruction losses: 0.01598269310361744, regression losses: 0.12206667300417029, validation losses: 0.7648502853667991\n",
      "Epoch 1861, reconstruction losses: 0.016085753199098683, regression losses: 0.13418081439176688, validation losses: 0.6976861627295601\n",
      "Epoch 1862, reconstruction losses: 0.015191290673923889, regression losses: 0.1381600609299204, validation losses: 0.6055810749227281\n",
      "Epoch 1863, reconstruction losses: 0.016426315372800114, regression losses: 0.14315601946376197, validation losses: 0.5589044055737943\n",
      "Epoch 1864, reconstruction losses: 0.016666996913702194, regression losses: 0.10648032318216624, validation losses: 0.6237766058094807\n",
      "Epoch 1865, reconstruction losses: 0.017100621572857348, regression losses: 0.15147833675775096, validation losses: 0.536441777484702\n",
      "Epoch 1866, reconstruction losses: 0.01643486599968329, regression losses: 0.13221985477904713, validation losses: 0.48839394974397066\n",
      "Epoch 1867, reconstruction losses: 0.014273446218931883, regression losses: 0.1047899934184114, validation losses: 0.5978086389829\n",
      "Epoch 1868, reconstruction losses: 0.01388963454942169, regression losses: 0.14558351531184274, validation losses: 0.6582832944157472\n",
      "Epoch 1869, reconstruction losses: 0.017580155033688726, regression losses: 0.12951591521938055, validation losses: 0.523702863041402\n",
      "Epoch 1870, reconstruction losses: 0.013685778234317748, regression losses: 0.1412740929412311, validation losses: 0.48836853053972507\n",
      "Epoch 1871, reconstruction losses: 0.02201916296058179, regression losses: 0.18566620061532738, validation losses: 0.5254308171760823\n",
      "Epoch 1872, reconstruction losses: 0.019901944704563287, regression losses: 0.17433168739277238, validation losses: 0.6640816093160499\n",
      "Epoch 1873, reconstruction losses: 0.01434641944910557, regression losses: 0.12270990668185648, validation losses: 0.6920818747600345\n",
      "Epoch 1874, reconstruction losses: 0.018072358137931184, regression losses: 0.172256851688459, validation losses: 0.6097655648037603\n",
      "Epoch 1875, reconstruction losses: 0.015149711984233144, regression losses: 0.16450359018513955, validation losses: 0.5292091805857432\n",
      "Epoch 1876, reconstruction losses: 0.01828746531042279, regression losses: 0.15363167701824854, validation losses: 0.5268581370716675\n",
      "Epoch 1877, reconstruction losses: 0.016542226646229827, regression losses: 0.13978476875767953, validation losses: 0.5107386383191952\n",
      "Epoch 1878, reconstruction losses: 0.01648606055684564, regression losses: 0.16303650339491585, validation losses: 0.5743066770986583\n",
      "Epoch 1879, reconstruction losses: 0.017047451507620777, regression losses: 0.16332033388066272, validation losses: 0.6280772960250054\n",
      "Epoch 1880, reconstruction losses: 0.015573137231729194, regression losses: 0.12141905698944566, validation losses: 0.5019651772133635\n",
      "Epoch 1881, reconstruction losses: 0.014839980492009332, regression losses: 0.13980020182718345, validation losses: 0.49801566570563155\n",
      "Epoch 1882, reconstruction losses: 0.014647503373856431, regression losses: 0.14110641908417226, validation losses: 0.48270038354728256\n",
      "Epoch 1883, reconstruction losses: 0.014973171693233483, regression losses: 0.12467375634609748, validation losses: 0.555162693698074\n",
      "Epoch 1884, reconstruction losses: 0.016398443062891024, regression losses: 0.11654068727094374, validation losses: 0.5588801517777012\n",
      "Epoch 1885, reconstruction losses: 0.01396458935246316, regression losses: 0.10743677327750538, validation losses: 0.4728351435095809\n",
      "Epoch 1886, reconstruction losses: 0.012011209406286274, regression losses: 0.10664685474051962, validation losses: 0.45857155693572105\n",
      "Epoch 1887, reconstruction losses: 0.01582062881916825, regression losses: 0.12490459977096846, validation losses: 0.44623961441665\n",
      "Epoch 1888, reconstruction losses: 0.015810501532919366, regression losses: 0.1225323229406293, validation losses: 0.5053996972569941\n",
      "Epoch 1889, reconstruction losses: 0.014191150584229126, regression losses: 0.11166795924763474, validation losses: 0.5623662714880497\n",
      "Epoch 1890, reconstruction losses: 0.01592354352262062, regression losses: 0.19884562214658197, validation losses: 0.4457138810232856\n",
      "Epoch 1891, reconstruction losses: 0.013995944102058604, regression losses: 0.09552262760593755, validation losses: 0.4477439548121403\n",
      "Epoch 1892, reconstruction losses: 0.013237053659823916, regression losses: 0.10969427031427066, validation losses: 0.4615402460479394\n",
      "Epoch 1893, reconstruction losses: 0.017627285341364256, regression losses: 0.10943354554383826, validation losses: 0.4821680426067446\n",
      "Epoch 1894, reconstruction losses: 0.015137830129575102, regression losses: 0.11949290139382959, validation losses: 0.5027149864384781\n",
      "Epoch 1895, reconstruction losses: 0.014429148103304479, regression losses: 0.14644145778135972, validation losses: 0.5309948411987928\n",
      "Epoch 1896, reconstruction losses: 0.013969348573550573, regression losses: 0.10275987054119765, validation losses: 0.4866965421185092\n",
      "Epoch 1897, reconstruction losses: 0.012625180980692128, regression losses: 0.09928102313409141, validation losses: 0.49809707098128425\n",
      "Epoch 1898, reconstruction losses: 0.016181273759797766, regression losses: 0.10399371268768393, validation losses: 0.4467301523381165\n",
      "Epoch 1899, reconstruction losses: 0.015145769947753745, regression losses: 0.11142118733642185, validation losses: 0.4832128127067776\n",
      "Epoch 1900, reconstruction losses: 0.011805834785736548, regression losses: 0.09955888803577022, validation losses: 0.4533086862162783\n",
      "Epoch 1901, reconstruction losses: 0.015561140749945048, regression losses: 0.09832174827931528, validation losses: 0.4811370645299485\n",
      "Epoch 1902, reconstruction losses: 0.013476307276109715, regression losses: 0.09594946830782111, validation losses: 0.46076051630825327\n",
      "Epoch 1903, reconstruction losses: 0.011549861761681901, regression losses: 0.07729163898332941, validation losses: 0.4243493544921305\n",
      "Epoch 1904, reconstruction losses: 0.01653108592242905, regression losses: 0.10998614288879002, validation losses: 0.4301565324165486\n",
      "Epoch 1905, reconstruction losses: 0.01556753910371574, regression losses: 0.12885497890941108, validation losses: 0.5470327866372201\n",
      "Epoch 1906, reconstruction losses: 0.013507783434322592, regression losses: 0.09702221580937292, validation losses: 0.5203673504824298\n",
      "Epoch 1907, reconstruction losses: 0.01478607457164105, regression losses: 0.11456908893493736, validation losses: 0.48626359831011073\n",
      "Epoch 1908, reconstruction losses: 0.01398742343348198, regression losses: 0.1090006720501634, validation losses: 0.5175332149964434\n",
      "Epoch 1909, reconstruction losses: 0.013460955486760748, regression losses: 0.11983590836512722, validation losses: 0.4601692396707767\n",
      "Epoch 1910, reconstruction losses: 0.015759068245057996, regression losses: 0.10005591282096671, validation losses: 0.4850931518603835\n",
      "Epoch 1911, reconstruction losses: 0.017666541164584174, regression losses: 0.14162564095726865, validation losses: 0.4460540763266136\n",
      "Epoch 1912, reconstruction losses: 0.013867173126171804, regression losses: 0.10269254258089656, validation losses: 0.4264450071645488\n",
      "Epoch 1913, reconstruction losses: 0.015736595475202717, regression losses: 0.1357783430135367, validation losses: 0.4514049008966825\n",
      "Epoch 1914, reconstruction losses: 0.01532910694476347, regression losses: 0.13057749117065956, validation losses: 0.5110516667065816\n",
      "Epoch 1915, reconstruction losses: 0.015025440262357661, regression losses: 0.1240490862747412, validation losses: 0.5789055757299671\n",
      "Epoch 1916, reconstruction losses: 0.01414054841449658, regression losses: 0.1129123865999511, validation losses: 0.5447245003371749\n",
      "Epoch 1917, reconstruction losses: 0.01472571650311413, regression losses: 0.126358158390256, validation losses: 0.4946528155770918\n",
      "Epoch 1918, reconstruction losses: 0.01593938158078454, regression losses: 0.12433062726026697, validation losses: 0.4811393284746772\n",
      "Epoch 1919, reconstruction losses: 0.015454285943422564, regression losses: 0.11611541861734788, validation losses: 0.51347833654299\n",
      "Epoch 1920, reconstruction losses: 0.014581104904694598, regression losses: 0.12224669275624059, validation losses: 0.5488895099234616\n",
      "Epoch 1921, reconstruction losses: 0.012634279810095938, regression losses: 0.09758092712855558, validation losses: 0.5228754919141243\n",
      "Epoch 1922, reconstruction losses: 0.014152193810531167, regression losses: 0.09023354499872495, validation losses: 0.48424012080955786\n",
      "Epoch 1923, reconstruction losses: 0.012453562066402534, regression losses: 0.10522688134409146, validation losses: 0.4778753905994563\n",
      "Epoch 1924, reconstruction losses: 0.013897406462440849, regression losses: 0.10264107353518373, validation losses: 0.4966118380328194\n",
      "Epoch 1925, reconstruction losses: 0.015992222501009352, regression losses: 0.11409585683594307, validation losses: 0.4844975881134651\n",
      "Epoch 1926, reconstruction losses: 0.014465625324337272, regression losses: 0.19143126741168348, validation losses: 0.45687478691406586\n",
      "Epoch 1927, reconstruction losses: 0.015045062820762055, regression losses: 0.10651986106871959, validation losses: 0.44976036173534234\n",
      "Epoch 1928, reconstruction losses: 0.01637284458665962, regression losses: 0.18044822857589804, validation losses: 0.4811502615377923\n",
      "Epoch 1929, reconstruction losses: 0.014239541279554211, regression losses: 0.11525944279650197, validation losses: 0.541098653575078\n",
      "Epoch 1930, reconstruction losses: 0.019940300551777874, regression losses: 0.2603335943634929, validation losses: 0.5983567773513209\n",
      "Epoch 1931, reconstruction losses: 0.01499126115106063, regression losses: 0.13680576969461045, validation losses: 0.6942227414928657\n",
      "Epoch 1932, reconstruction losses: 0.0178617392232033, regression losses: 0.15935949676751626, validation losses: 0.5167843413535941\n",
      "Epoch 1933, reconstruction losses: 0.019336332001016938, regression losses: 0.16781184643786184, validation losses: 0.4636051302124385\n",
      "Epoch 1934, reconstruction losses: 0.018398888055856814, regression losses: 0.11616612803770644, validation losses: 0.551582009683094\n",
      "Epoch 1935, reconstruction losses: 0.01653396535020462, regression losses: 0.10274521046586779, validation losses: 0.5058499481256914\n",
      "Epoch 1936, reconstruction losses: 0.016644523871867913, regression losses: 0.13442839105598398, validation losses: 0.4393816613045934\n",
      "Epoch 1937, reconstruction losses: 0.015397755921338612, regression losses: 0.09624739820142753, validation losses: 0.529912588744006\n",
      "Epoch 1938, reconstruction losses: 0.015599947306792981, regression losses: 0.14142156723991808, validation losses: 0.5449447465236997\n",
      "Epoch 1939, reconstruction losses: 0.01654888141403672, regression losses: 0.1324734204889953, validation losses: 0.42728289634323546\n",
      "Epoch 1940, reconstruction losses: 0.013588131998275023, regression losses: 0.09779838676111921, validation losses: 0.4003988587362094\n",
      "Epoch 1941, reconstruction losses: 0.013056469111861077, regression losses: 0.11370929573517374, validation losses: 0.42283467257442325\n",
      "Epoch 1942, reconstruction losses: 0.013719987193577884, regression losses: 0.10011224877083552, validation losses: 0.5115617023123948\n",
      "Epoch 1943, reconstruction losses: 0.02064994134494235, regression losses: 0.12080693484074148, validation losses: 0.592966299329928\n",
      "Epoch 1944, reconstruction losses: 0.016149898234819472, regression losses: 0.10826234754929098, validation losses: 0.5112779627388286\n",
      "Epoch 1945, reconstruction losses: 0.014788326732654481, regression losses: 0.14644326375084982, validation losses: 0.5326477999136453\n",
      "Epoch 1946, reconstruction losses: 0.01119605546507468, regression losses: 0.10295494172695963, validation losses: 0.5066657148051489\n",
      "Epoch 1947, reconstruction losses: 0.016811712751604126, regression losses: 0.10006049522083942, validation losses: 0.4367786729990426\n",
      "Epoch 1948, reconstruction losses: 0.014012386404051296, regression losses: 0.11356889782848253, validation losses: 0.44974340543119806\n",
      "Epoch 1949, reconstruction losses: 0.0144298118991403, regression losses: 0.13007163544366573, validation losses: 0.4411838851799113\n",
      "Epoch 1950, reconstruction losses: 0.015555300376050095, regression losses: 0.14789284650572465, validation losses: 0.4359516981150233\n",
      "Epoch 1951, reconstruction losses: 0.020625167163247495, regression losses: 0.19116372983022656, validation losses: 0.44349314234486015\n",
      "Epoch 1952, reconstruction losses: 0.019308555260398534, regression losses: 0.13589876179226384, validation losses: 0.46306773651201116\n",
      "Epoch 1953, reconstruction losses: 0.01656527539338473, regression losses: 0.09670766202530183, validation losses: 0.5139842795016629\n",
      "Epoch 1954, reconstruction losses: 0.01702668946674318, regression losses: 0.17430967732871422, validation losses: 0.5254283977639901\n",
      "Epoch 1955, reconstruction losses: 0.015261796074944316, regression losses: 0.11993558650095328, validation losses: 0.5013119007749587\n",
      "Epoch 1956, reconstruction losses: 0.017541801380602316, regression losses: 0.11463958928877958, validation losses: 0.48175131377575997\n",
      "Epoch 1957, reconstruction losses: 0.013366266484812808, regression losses: 0.1384512994991519, validation losses: 0.532482585841233\n",
      "Epoch 1958, reconstruction losses: 0.013003263968038813, regression losses: 0.0878822978317644, validation losses: 0.48054403381374977\n",
      "Epoch 1959, reconstruction losses: 0.014277021785213114, regression losses: 0.12175552563411234, validation losses: 0.4186626644585864\n",
      "Epoch 1960, reconstruction losses: 0.012507423607682982, regression losses: 0.09418951628009192, validation losses: 0.4219297024092938\n",
      "Epoch 1961, reconstruction losses: 0.01373100629196856, regression losses: 0.12531621642368812, validation losses: 0.4299889856871923\n",
      "Epoch 1962, reconstruction losses: 0.013815662283890404, regression losses: 0.10725421267398826, validation losses: 0.4342339164841607\n",
      "Epoch 1963, reconstruction losses: 0.015357813042750646, regression losses: 0.15521482084039914, validation losses: 0.48387319839136994\n",
      "Epoch 1964, reconstruction losses: 0.014880617230684649, regression losses: 0.12753126532915202, validation losses: 0.4829589473476\n",
      "Epoch 1965, reconstruction losses: 0.014377040163800705, regression losses: 0.14904361254173587, validation losses: 0.5158325343003589\n",
      "Epoch 1966, reconstruction losses: 0.017541598939543473, regression losses: 0.12447857525473884, validation losses: 0.5574530848650422\n",
      "Epoch 1967, reconstruction losses: 0.013762978023184932, regression losses: 0.13768810426790873, validation losses: 0.5268796053586173\n",
      "Epoch 1968, reconstruction losses: 0.012216788945266396, regression losses: 0.1348687753714245, validation losses: 0.45985277518532064\n",
      "Epoch 1969, reconstruction losses: 0.014183070934799074, regression losses: 0.10417265524227176, validation losses: 0.44738628854243695\n",
      "Epoch 1970, reconstruction losses: 0.01335933473782648, regression losses: 0.1186411785858669, validation losses: 0.5217625625183755\n",
      "Epoch 1971, reconstruction losses: 0.013843688396250307, regression losses: 0.09400965047292514, validation losses: 0.464512443821755\n",
      "Epoch 1972, reconstruction losses: 0.016868410266677177, regression losses: 0.13572848858126804, validation losses: 0.47860050686576056\n",
      "Epoch 1973, reconstruction losses: 0.01529100361726147, regression losses: 0.14108535451213106, validation losses: 0.5897352712006015\n",
      "Epoch 1974, reconstruction losses: 0.014849713391797085, regression losses: 0.11562645997929721, validation losses: 0.4816959124390456\n",
      "Epoch 1975, reconstruction losses: 0.012518180103708554, regression losses: 0.09798762597117565, validation losses: 0.46072439071991367\n",
      "Epoch 1976, reconstruction losses: 0.014902571035687116, regression losses: 0.10209837722518167, validation losses: 0.4834930847024377\n",
      "Epoch 1977, reconstruction losses: 0.014773424820207923, regression losses: 0.11639673981676707, validation losses: 0.5366077925829272\n",
      "Epoch 1978, reconstruction losses: 0.01520569829452183, regression losses: 0.10838585404599071, validation losses: 0.5356618600954807\n",
      "Epoch 1979, reconstruction losses: 0.013454861823961465, regression losses: 0.10477141058419455, validation losses: 0.4390451249000519\n",
      "Epoch 1980, reconstruction losses: 0.01757036087591713, regression losses: 0.12187971285121574, validation losses: 0.42222617584946254\n",
      "Epoch 1981, reconstruction losses: 0.014885185516719097, regression losses: 0.10288202043241704, validation losses: 0.43895812380093935\n",
      "Epoch 1982, reconstruction losses: 0.013081294510250422, regression losses: 0.18201415869941678, validation losses: 0.5018771715352592\n",
      "Epoch 1983, reconstruction losses: 0.014852190848886827, regression losses: 0.11516068732507868, validation losses: 0.5952680095813372\n",
      "Epoch 1984, reconstruction losses: 0.015170904274650156, regression losses: 0.1126511957440198, validation losses: 0.46922911847738924\n",
      "Epoch 1985, reconstruction losses: 0.014006364433502958, regression losses: 0.12496220933094684, validation losses: 0.46345623317002127\n",
      "Epoch 1986, reconstruction losses: 0.012071861703362212, regression losses: 0.08942074413131391, validation losses: 0.47544411165320466\n",
      "Epoch 1987, reconstruction losses: 0.012602121405960304, regression losses: 0.11376097118171885, validation losses: 0.48734109903126444\n",
      "Epoch 1988, reconstruction losses: 0.012767996984178291, regression losses: 0.09740588523979382, validation losses: 0.5605873663385497\n",
      "Epoch 1989, reconstruction losses: 0.01354878743474293, regression losses: 0.10910571286968516, validation losses: 0.5158669755361436\n",
      "Epoch 1990, reconstruction losses: 0.015308538384606146, regression losses: 0.10034108057329844, validation losses: 0.4820636255583966\n",
      "Epoch 1991, reconstruction losses: 0.014020288347419578, regression losses: 0.1007177581982194, validation losses: 0.4470156256908962\n",
      "Epoch 1992, reconstruction losses: 0.014133860012209074, regression losses: 0.11457460193706245, validation losses: 0.4139386567805813\n",
      "Epoch 1993, reconstruction losses: 0.017383810180969038, regression losses: 0.11591029867347868, validation losses: 0.41371166308271984\n",
      "Epoch 1994, reconstruction losses: 0.014683798853044782, regression losses: 0.11819433435302477, validation losses: 0.4279110109244096\n",
      "Epoch 1995, reconstruction losses: 0.013532370234987037, regression losses: 0.09447871201024079, validation losses: 0.5226811429660033\n",
      "Epoch 1996, reconstruction losses: 0.01779996017256229, regression losses: 0.19109886915314586, validation losses: 0.4893149510016486\n",
      "Epoch 1997, reconstruction losses: 0.01461088488019974, regression losses: 0.109691683244139, validation losses: 0.5288240784218139\n",
      "Epoch 1998, reconstruction losses: 0.013709878983049656, regression losses: 0.09222281144674598, validation losses: 0.48234075891506056\n",
      "Epoch 1999, reconstruction losses: 0.013912287920179834, regression losses: 0.09972837632220856, validation losses: 0.4279367548737722\n",
      "Epoch 2000, reconstruction losses: 0.014132233426244405, regression losses: 0.1147633692962086, validation losses: 0.4179330513888561\n",
      "Epoch 2001, reconstruction losses: 0.016210115713395104, regression losses: 0.16566195784083915, validation losses: 0.42071083436845647\n",
      "Epoch 2002, reconstruction losses: 0.01584321190662094, regression losses: 0.14483396275547522, validation losses: 0.4616791038211573\n",
      "Epoch 2003, reconstruction losses: 0.017727297632791447, regression losses: 0.13048743313262742, validation losses: 0.44334259967542194\n",
      "Epoch 2004, reconstruction losses: 0.01284082731689948, regression losses: 0.08990800179058482, validation losses: 0.47131402757901825\n",
      "Epoch 2005, reconstruction losses: 0.012750024072307593, regression losses: 0.09235629984907757, validation losses: 0.4647998677877468\n",
      "Epoch 2006, reconstruction losses: 0.016317105625080312, regression losses: 0.11009034911281353, validation losses: 0.43424725694074523\n",
      "Epoch 2007, reconstruction losses: 0.016547491060939796, regression losses: 0.1181627889858971, validation losses: 0.42317058325654155\n",
      "Epoch 2008, reconstruction losses: 0.018432460552141726, regression losses: 0.22301281748131732, validation losses: 0.4389435102694363\n",
      "Epoch 2009, reconstruction losses: 0.015862840852952184, regression losses: 0.08794068435659504, validation losses: 0.6756124518538279\n",
      "Epoch 2010, reconstruction losses: 0.01494504608165216, regression losses: 0.12816942316578425, validation losses: 0.5854572364315405\n",
      "Epoch 2011, reconstruction losses: 0.01300234670069228, regression losses: 0.12503958128852677, validation losses: 0.5353503111767769\n",
      "Epoch 2012, reconstruction losses: 0.013161044355829718, regression losses: 0.1155657360477274, validation losses: 0.49916799779457777\n",
      "Epoch 2013, reconstruction losses: 0.012803803422091482, regression losses: 0.10986036935803409, validation losses: 0.44254891789784356\n",
      "Epoch 2014, reconstruction losses: 0.01382781239645381, regression losses: 0.12951140904562736, validation losses: 0.4700210368917733\n",
      "Epoch 2015, reconstruction losses: 0.0172655546266033, regression losses: 0.2357495194392654, validation losses: 0.4775357762925514\n",
      "Epoch 2016, reconstruction losses: 0.015057861721954878, regression losses: 0.2029224648076828, validation losses: 0.6432882112107097\n",
      "Epoch 2017, reconstruction losses: 0.014854480234663785, regression losses: 0.12532499132779093, validation losses: 0.5272410360559243\n",
      "Epoch 2018, reconstruction losses: 0.01270017553483314, regression losses: 0.101172731804172, validation losses: 0.5387193938850857\n",
      "Epoch 2019, reconstruction losses: 0.011299943099520683, regression losses: 0.08996367606256568, validation losses: 0.48177747946106647\n",
      "Epoch 2020, reconstruction losses: 0.01770046515906817, regression losses: 0.14048089332456337, validation losses: 0.5332178999684876\n",
      "Epoch 2021, reconstruction losses: 0.01480830692924949, regression losses: 0.1123865827815304, validation losses: 0.7253606015130045\n",
      "Epoch 2022, reconstruction losses: 0.013450883191005512, regression losses: 0.1084819009218779, validation losses: 0.5354799102711048\n",
      "Epoch 2023, reconstruction losses: 0.014869912821435334, regression losses: 0.11229008301156285, validation losses: 0.44226291165614257\n",
      "Epoch 2024, reconstruction losses: 0.016319649433845305, regression losses: 0.16248217208317783, validation losses: 0.43186812916739203\n",
      "Epoch 2025, reconstruction losses: 0.015061070704079674, regression losses: 0.12326077270254447, validation losses: 0.4942905889834797\n",
      "Epoch 2026, reconstruction losses: 0.01352571690335702, regression losses: 0.12614280980446102, validation losses: 0.4964143992245593\n",
      "Epoch 2027, reconstruction losses: 0.015106744960124966, regression losses: 0.09887856882686857, validation losses: 0.45129319916091887\n",
      "Epoch 2028, reconstruction losses: 0.014474469295116674, regression losses: 0.14904876069625922, validation losses: 0.44999830764455867\n",
      "Epoch 2029, reconstruction losses: 0.013781455366055524, regression losses: 0.11811683423133759, validation losses: 0.5370789305101265\n",
      "Epoch 2030, reconstruction losses: 0.014135320152227264, regression losses: 0.12865681640902757, validation losses: 0.5623180619729525\n",
      "Epoch 2031, reconstruction losses: 0.0146436626803849, regression losses: 0.15067491518524476, validation losses: 0.5000618547569683\n",
      "Epoch 2032, reconstruction losses: 0.01613536619883075, regression losses: 0.1334123773211992, validation losses: 0.4316081408203949\n",
      "Epoch 2033, reconstruction losses: 0.013695259508455196, regression losses: 0.11702014344027083, validation losses: 0.44085994959073077\n",
      "Epoch 2034, reconstruction losses: 0.012051048565276947, regression losses: 0.09126438219667493, validation losses: 0.44798706114830855\n",
      "Epoch 2035, reconstruction losses: 0.014432044722741191, regression losses: 0.135373842879071, validation losses: 0.47568913129364293\n",
      "Epoch 2036, reconstruction losses: 0.013887601358265696, regression losses: 0.09702510139195632, validation losses: 0.5177015829916999\n",
      "Epoch 2037, reconstruction losses: 0.013517876047423279, regression losses: 0.07635535451098627, validation losses: 0.4749696435378388\n",
      "Epoch 2038, reconstruction losses: 0.01337459573780337, regression losses: 0.09567690973278602, validation losses: 0.43408473522316954\n",
      "Epoch 2039, reconstruction losses: 0.014896369227965488, regression losses: 0.37968991938510377, validation losses: 0.46346826247386286\n",
      "Epoch 2040, reconstruction losses: 0.012891873727857928, regression losses: 0.09981469428112089, validation losses: 0.7961450119681974\n",
      "Epoch 2041, reconstruction losses: 0.014208446700864994, regression losses: 0.13408666619514836, validation losses: 0.7279767219974194\n",
      "Epoch 2042, reconstruction losses: 0.01702048881939606, regression losses: 0.19049888787544458, validation losses: 0.5817073111817546\n",
      "Epoch 2043, reconstruction losses: 0.012024824479210446, regression losses: 0.08740280323070498, validation losses: 0.49223046654092495\n",
      "Epoch 2044, reconstruction losses: 0.011757400706805107, regression losses: 0.10924322816967624, validation losses: 0.4651988534060565\n",
      "Epoch 2045, reconstruction losses: 0.013534537490259454, regression losses: 0.08942659018290655, validation losses: 0.47153398784874984\n",
      "Epoch 2046, reconstruction losses: 0.011436980272059031, regression losses: 0.11190366116059929, validation losses: 0.4546102077489169\n",
      "Epoch 2047, reconstruction losses: 0.013948167212702041, regression losses: 0.1239000340010708, validation losses: 0.48685791020091823\n",
      "Epoch 2048, reconstruction losses: 0.01544811621049411, regression losses: 0.13020624641677234, validation losses: 0.5559839603376432\n",
      "Epoch 2049, reconstruction losses: 0.015066354249905182, regression losses: 0.1543337357772876, validation losses: 0.5266196144901074\n",
      "Epoch 2050, reconstruction losses: 0.01327888612067874, regression losses: 0.14553630661911554, validation losses: 0.5408928912985276\n",
      "Epoch 2051, reconstruction losses: 0.012859020499153878, regression losses: 0.09916946374308304, validation losses: 0.5425453888148503\n",
      "Epoch 2052, reconstruction losses: 0.011571983475213795, regression losses: 0.08148588731120344, validation losses: 0.5478850355370091\n",
      "Epoch 2053, reconstruction losses: 0.013332811527249896, regression losses: 0.14364749020824744, validation losses: 0.5053578546580546\n",
      "Epoch 2054, reconstruction losses: 0.013148310889567909, regression losses: 0.10231808698513173, validation losses: 0.4893171921208996\n",
      "Epoch 2055, reconstruction losses: 0.013793386973608778, regression losses: 0.08858555207637603, validation losses: 0.44702962195004337\n",
      "Epoch 2056, reconstruction losses: 0.01319716108367833, regression losses: 0.12569740295204646, validation losses: 0.4471275425496184\n",
      "Epoch 2057, reconstruction losses: 0.015369901422349902, regression losses: 0.17055482217605045, validation losses: 0.5710120529830216\n",
      "Epoch 2058, reconstruction losses: 0.016131804654601387, regression losses: 0.09617780533642357, validation losses: 0.5143977625269174\n",
      "Epoch 2059, reconstruction losses: 0.01590931105161962, regression losses: 0.10861138516759684, validation losses: 0.44162679630466967\n",
      "Epoch 2060, reconstruction losses: 0.015356650500615222, regression losses: 0.12066686196894857, validation losses: 0.43327656205681503\n",
      "Epoch 2061, reconstruction losses: 0.013261186715378837, regression losses: 0.1054145125267847, validation losses: 0.4052176099160355\n",
      "Epoch 2062, reconstruction losses: 0.012499984889961636, regression losses: 0.09064107974058143, validation losses: 0.4351358747269457\n",
      "Epoch 2063, reconstruction losses: 0.013046442023207306, regression losses: 0.11124379450017505, validation losses: 0.5028676394903125\n",
      "Epoch 2064, reconstruction losses: 0.012113383550536408, regression losses: 0.1052835186606432, validation losses: 0.5952275186808724\n",
      "Epoch 2065, reconstruction losses: 0.014118692078565111, regression losses: 0.11885606242045509, validation losses: 0.5215815861123578\n",
      "Epoch 2066, reconstruction losses: 0.014480054378874672, regression losses: 0.07313408377320663, validation losses: 0.47665959835852884\n",
      "Epoch 2067, reconstruction losses: 0.018601530360273823, regression losses: 0.3762329365483862, validation losses: 0.47488198845802315\n",
      "Epoch 2068, reconstruction losses: 0.013689240846225779, regression losses: 0.09664420756560003, validation losses: 0.6524984280190221\n",
      "Epoch 2069, reconstruction losses: 0.011809839957764722, regression losses: 0.10369764180242506, validation losses: 0.6698191087455229\n",
      "Epoch 2070, reconstruction losses: 0.013166379018373314, regression losses: 0.13196695762667884, validation losses: 0.5484469864205372\n",
      "Epoch 2071, reconstruction losses: 0.013404581669872483, regression losses: 0.09158118187776454, validation losses: 0.46647087584417407\n",
      "Epoch 2072, reconstruction losses: 0.015973216799992994, regression losses: 0.15823496993167807, validation losses: 0.45847142544820757\n",
      "Epoch 2073, reconstruction losses: 0.010304132578014182, regression losses: 0.09368230900343523, validation losses: 0.5142001587187276\n",
      "Epoch 2074, reconstruction losses: 0.01230340362407734, regression losses: 0.08315891770403554, validation losses: 0.4536506772117065\n",
      "Epoch 2075, reconstruction losses: 0.015970348600957678, regression losses: 0.1181258923427209, validation losses: 0.45288690457440134\n",
      "Epoch 2076, reconstruction losses: 0.01897785303242459, regression losses: 0.16017441478157932, validation losses: 0.4352334212825144\n",
      "Epoch 2077, reconstruction losses: 0.017473233296214235, regression losses: 0.11870046144657832, validation losses: 0.740136401038734\n",
      "Epoch 2078, reconstruction losses: 0.017869458481521355, regression losses: 0.15584616435562065, validation losses: 0.5952093414232306\n",
      "Epoch 2079, reconstruction losses: 0.014413358141923049, regression losses: 0.11137296940055953, validation losses: 0.6178116391125067\n",
      "Epoch 2080, reconstruction losses: 0.013946320497239293, regression losses: 0.11496128922253773, validation losses: 0.47878754476316593\n",
      "Epoch 2081, reconstruction losses: 0.013055492567508223, regression losses: 0.12998457189063428, validation losses: 0.5123017613468295\n",
      "Epoch 2082, reconstruction losses: 0.01634626660084408, regression losses: 0.09041933088988444, validation losses: 0.4392792186487915\n",
      "Epoch 2083, reconstruction losses: 0.018982032413947445, regression losses: 0.190932677943061, validation losses: 0.4263998785093451\n",
      "Epoch 2084, reconstruction losses: 0.013539538251865444, regression losses: 0.09729219541287404, validation losses: 0.4422114494798051\n",
      "Epoch 2085, reconstruction losses: 0.015182748570817254, regression losses: 0.11759049983520622, validation losses: 0.43899067703521455\n",
      "Epoch 2086, reconstruction losses: 0.015504498322084462, regression losses: 0.12245309067660151, validation losses: 0.45482030440030685\n",
      "Epoch 2087, reconstruction losses: 0.012456197208890123, regression losses: 0.09639550192253166, validation losses: 0.4661422087114071\n",
      "Epoch 2088, reconstruction losses: 0.013854755266036007, regression losses: 0.11807404823452516, validation losses: 0.45192633486355793\n",
      "Epoch 2089, reconstruction losses: 0.013617039270293564, regression losses: 0.09652813424662238, validation losses: 0.41333847299251447\n",
      "Epoch 2090, reconstruction losses: 0.015183896177447467, regression losses: 0.34605840549133843, validation losses: 0.441129277611012\n",
      "Epoch 2091, reconstruction losses: 0.013599951114574215, regression losses: 0.09627700805703088, validation losses: 0.7331253165801587\n",
      "Epoch 2092, reconstruction losses: 0.018020830741013846, regression losses: 0.21196394799692117, validation losses: 0.6551061159083419\n",
      "Epoch 2093, reconstruction losses: 0.015845667776990348, regression losses: 0.13051229344919013, validation losses: 0.5530884797665043\n",
      "Epoch 2094, reconstruction losses: 0.018163639962549435, regression losses: 0.12320340971485663, validation losses: 0.5093683772327287\n",
      "Epoch 2095, reconstruction losses: 0.018828444242203625, regression losses: 0.15031276152710618, validation losses: 0.5725996206844406\n",
      "Epoch 2096, reconstruction losses: 0.01733151270213109, regression losses: 0.11836244658530747, validation losses: 0.5870137295744737\n",
      "Epoch 2097, reconstruction losses: 0.0139693651130667, regression losses: 0.10895278538961588, validation losses: 0.6045085099667565\n",
      "Epoch 2098, reconstruction losses: 0.01584513228825451, regression losses: 0.12041620916499476, validation losses: 0.4784598200996681\n",
      "Epoch 2099, reconstruction losses: 0.018367200318127944, regression losses: 0.21477772165782535, validation losses: 0.501515219919504\n",
      "Epoch 2100, reconstruction losses: 0.016211773607880158, regression losses: 0.18258779242133488, validation losses: 0.6815178071916624\n",
      "Epoch 2101, reconstruction losses: 0.016437126467055897, regression losses: 0.1318194289277724, validation losses: 0.5573591362957032\n",
      "Epoch 2102, reconstruction losses: 0.014753808126977613, regression losses: 0.11175556731277367, validation losses: 0.5322174876570519\n",
      "Epoch 2103, reconstruction losses: 0.015284831237802901, regression losses: 0.1387095239516983, validation losses: 0.5052115043018577\n",
      "Epoch 2104, reconstruction losses: 0.015474808099625256, regression losses: 0.11031502111732691, validation losses: 0.4510062806542103\n",
      "Epoch 2105, reconstruction losses: 0.012414216114777585, regression losses: 0.08669625793162139, validation losses: 0.4714169993846449\n",
      "Epoch 2106, reconstruction losses: 0.013770581633893553, regression losses: 0.1261676402605417, validation losses: 0.5132159975279317\n",
      "Epoch 2107, reconstruction losses: 0.016025565848863003, regression losses: 0.1675092405684727, validation losses: 0.5474329932772164\n",
      "Epoch 2108, reconstruction losses: 0.013929969310838845, regression losses: 0.1236281281607775, validation losses: 0.5401274634020583\n",
      "Epoch 2109, reconstruction losses: 0.013575218148933067, regression losses: 0.10379496826297901, validation losses: 0.5351722027295995\n",
      "Epoch 2110, reconstruction losses: 0.012763130249966816, regression losses: 0.13899435823668158, validation losses: 0.49645018068179625\n",
      "Epoch 2111, reconstruction losses: 0.012299912909888277, regression losses: 0.0971708060360612, validation losses: 0.4803387502199458\n",
      "Epoch 2112, reconstruction losses: 0.018599542111784405, regression losses: 0.11335065678896482, validation losses: 0.46500172543423024\n",
      "Epoch 2113, reconstruction losses: 0.017996539108104205, regression losses: 0.10868082815451309, validation losses: 0.54772246400154\n",
      "Epoch 2114, reconstruction losses: 0.015509506660644221, regression losses: 0.1371446577655453, validation losses: 0.5543670388067463\n",
      "Epoch 2115, reconstruction losses: 0.014150526539829017, regression losses: 0.1154943386739708, validation losses: 0.5436170681372336\n",
      "Epoch 2116, reconstruction losses: 0.014170289214433602, regression losses: 0.10608871671119272, validation losses: 0.49585267501170693\n",
      "Epoch 2117, reconstruction losses: 0.013751192043427394, regression losses: 0.13699279292792166, validation losses: 0.4311964888055738\n",
      "Epoch 2118, reconstruction losses: 0.021992113181564868, regression losses: 0.32994689667281707, validation losses: 0.517013416412263\n",
      "Epoch 2119, reconstruction losses: 0.014427437910200687, regression losses: 0.11331318187614862, validation losses: 0.8734950843723256\n",
      "Epoch 2120, reconstruction losses: 0.019731721063690585, regression losses: 0.22265267344579034, validation losses: 0.7089114990762719\n",
      "Epoch 2121, reconstruction losses: 0.013786102117396667, regression losses: 0.12274903539876682, validation losses: 0.5379328329962226\n",
      "Epoch 2122, reconstruction losses: 0.014853464262753078, regression losses: 0.15633421151209725, validation losses: 0.49793253051821057\n",
      "Epoch 2123, reconstruction losses: 0.013900651670693848, regression losses: 0.10740143095490634, validation losses: 0.46795897574919953\n",
      "Epoch 2124, reconstruction losses: 0.012791612033496765, regression losses: 0.10714226163432458, validation losses: 0.4446132303675209\n",
      "Epoch 2125, reconstruction losses: 0.014449049798884032, regression losses: 0.12880970082116916, validation losses: 0.4527715865967403\n",
      "Epoch 2126, reconstruction losses: 0.016963314747696336, regression losses: 0.185602379246687, validation losses: 0.5154769169079493\n",
      "Epoch 2127, reconstruction losses: 0.013157107428785359, regression losses: 0.09597280131300788, validation losses: 0.5532004121571172\n",
      "Epoch 2128, reconstruction losses: 0.013458621986227555, regression losses: 0.12656430988659254, validation losses: 0.4796678913615738\n",
      "Epoch 2129, reconstruction losses: 0.014579748506533529, regression losses: 0.13700299651660905, validation losses: 0.45817703904956264\n",
      "Epoch 2130, reconstruction losses: 0.011974391780402119, regression losses: 0.12360260358545958, validation losses: 0.4448527164895649\n",
      "Epoch 2131, reconstruction losses: 0.014304073944269295, regression losses: 0.12594883159641218, validation losses: 0.4255302518671438\n",
      "Epoch 2132, reconstruction losses: 0.012729789694807522, regression losses: 0.11056773253470693, validation losses: 0.5458130510419869\n",
      "Epoch 2133, reconstruction losses: 0.013968138421318423, regression losses: 0.1059926064382572, validation losses: 0.4028825614003377\n",
      "Epoch 2134, reconstruction losses: 0.014240197308753215, regression losses: 0.10917307317796326, validation losses: 0.4516349893561395\n",
      "Epoch 2135, reconstruction losses: 0.014006172145998147, regression losses: 0.12301347319481223, validation losses: 0.5218554072552051\n",
      "Epoch 2136, reconstruction losses: 0.013531809144824228, regression losses: 0.13232224050417063, validation losses: 0.5249173199417251\n",
      "Epoch 2137, reconstruction losses: 0.013870342012435567, regression losses: 0.1244589727857501, validation losses: 0.5134060801540646\n",
      "Epoch 2138, reconstruction losses: 0.01409508933468361, regression losses: 0.12334241815574443, validation losses: 0.5310606388481901\n",
      "Epoch 2139, reconstruction losses: 0.012812836173245488, regression losses: 0.11330703509900626, validation losses: 0.4593663073772179\n",
      "Epoch 2140, reconstruction losses: 0.012247759697123073, regression losses: 0.12463328882136288, validation losses: 0.4730077869343437\n",
      "Epoch 2141, reconstruction losses: 0.012493689043695966, regression losses: 0.10338512428010636, validation losses: 0.49599798350651736\n",
      "Epoch 2142, reconstruction losses: 0.017823433999333352, regression losses: 0.16474289474344553, validation losses: 0.42556225704275075\n",
      "Epoch 2143, reconstruction losses: 0.01563202471456353, regression losses: 0.11637314157000087, validation losses: 0.41301769075362943\n",
      "Epoch 2144, reconstruction losses: 0.016796329468456137, regression losses: 0.11632297572606279, validation losses: 0.45421899001344274\n",
      "Epoch 2145, reconstruction losses: 0.014526357252987022, regression losses: 0.08134809594525663, validation losses: 0.5246235716371045\n",
      "Epoch 2146, reconstruction losses: 0.016086955419373983, regression losses: 0.08824696359500583, validation losses: 0.45490077263949613\n",
      "Epoch 2147, reconstruction losses: 0.012888346497104608, regression losses: 0.09558435348379735, validation losses: 0.45043658193440256\n",
      "Epoch 2148, reconstruction losses: 0.012752232982029885, regression losses: 0.10609025981032058, validation losses: 0.4479494048020697\n",
      "Epoch 2149, reconstruction losses: 0.013991699599372544, regression losses: 0.13022809278235872, validation losses: 0.44430613881112585\n",
      "Epoch 2150, reconstruction losses: 0.012714463112570445, regression losses: 0.08851334026953397, validation losses: 0.47345981056872766\n",
      "Epoch 2151, reconstruction losses: 0.015157314316194895, regression losses: 0.1386134253304746, validation losses: 0.4297276619707838\n",
      "Epoch 2152, reconstruction losses: 0.011955844588863241, regression losses: 0.1365678741877786, validation losses: 0.4521335476012618\n",
      "Epoch 2153, reconstruction losses: 0.01379918651063652, regression losses: 0.12301108483074506, validation losses: 0.45991121850514155\n",
      "Epoch 2154, reconstruction losses: 0.014195450450664192, regression losses: 0.13986618378746313, validation losses: 0.47167939074158227\n",
      "Epoch 2155, reconstruction losses: 0.012709885770210934, regression losses: 0.09776916522459765, validation losses: 0.44407899983925075\n",
      "Epoch 2156, reconstruction losses: 0.01410371519212983, regression losses: 0.10791109718934064, validation losses: 0.4191014856673255\n",
      "Epoch 2157, reconstruction losses: 0.014022551295332877, regression losses: 0.09569875341372411, validation losses: 0.42825537625305987\n",
      "Epoch 2158, reconstruction losses: 0.015039462649794179, regression losses: 0.36319668181526543, validation losses: 0.48738330323918083\n",
      "Epoch 2159, reconstruction losses: 0.014085698831626716, regression losses: 0.11992777329195208, validation losses: 0.6835585920265917\n",
      "Epoch 2160, reconstruction losses: 0.014678076632929804, regression losses: 0.11834354944212999, validation losses: 0.6074857378662519\n",
      "Epoch 2161, reconstruction losses: 0.013817697256138878, regression losses: 0.14109816885359133, validation losses: 0.5534644766878899\n",
      "Epoch 2162, reconstruction losses: 0.016561364930325204, regression losses: 0.14613988661096544, validation losses: 0.6009755177892304\n",
      "Epoch 2163, reconstruction losses: 0.015622211339515834, regression losses: 0.12398331120274123, validation losses: 0.5071963519615841\n",
      "Epoch 2164, reconstruction losses: 0.015522479546757992, regression losses: 0.11699828569825618, validation losses: 0.559551990549083\n",
      "Epoch 2165, reconstruction losses: 0.016092792678140375, regression losses: 0.1252716160872342, validation losses: 0.5530741659144429\n",
      "Epoch 2166, reconstruction losses: 0.011953996923790136, regression losses: 0.10032599461046607, validation losses: 0.4408759378996549\n",
      "Epoch 2167, reconstruction losses: 0.015331961558349313, regression losses: 0.08841144563776714, validation losses: 0.4802913690605533\n",
      "Epoch 2168, reconstruction losses: 0.01576573051399259, regression losses: 0.12995280546674978, validation losses: 0.47612570779943475\n",
      "Epoch 2169, reconstruction losses: 0.012951632642148863, regression losses: 0.09186858395828745, validation losses: 0.46205057049845377\n",
      "Epoch 2170, reconstruction losses: 0.013216981379114113, regression losses: 0.11806084915322117, validation losses: 0.4978164290225094\n",
      "Epoch 2171, reconstruction losses: 0.013622639166245065, regression losses: 0.11678761450715704, validation losses: 0.47255205384093346\n",
      "Epoch 2172, reconstruction losses: 0.014507875566629483, regression losses: 0.13205347495180106, validation losses: 0.44660925989874156\n",
      "Epoch 2173, reconstruction losses: 0.0133162980572319, regression losses: 0.08521085298360671, validation losses: 0.44986434055398916\n",
      "Epoch 2174, reconstruction losses: 0.01695270999924555, regression losses: 0.14209441201275935, validation losses: 0.4647149007190991\n",
      "Epoch 2175, reconstruction losses: 0.012260378692809229, regression losses: 0.08781711333431254, validation losses: 0.5476052803547514\n",
      "Epoch 2176, reconstruction losses: 0.012330382197635843, regression losses: 0.11712766737678518, validation losses: 0.5474204190163217\n",
      "Epoch 2177, reconstruction losses: 0.01408036009263476, regression losses: 0.12448129078361515, validation losses: 0.4665912327162038\n",
      "Epoch 2178, reconstruction losses: 0.013712359378784329, regression losses: 0.11782323694098763, validation losses: 0.4525782124470835\n",
      "Epoch 2179, reconstruction losses: 0.011853135630536953, regression losses: 0.11408756635516895, validation losses: 0.45190875439587347\n",
      "Epoch 2180, reconstruction losses: 0.018472787341193564, regression losses: 0.3951230581966053, validation losses: 0.4665914224982348\n",
      "Epoch 2181, reconstruction losses: 0.01367944527586181, regression losses: 0.13119899027376736, validation losses: 0.6537454336475179\n",
      "Epoch 2182, reconstruction losses: 0.01709146573471958, regression losses: 0.14400054249458774, validation losses: 0.6298057707546626\n",
      "Epoch 2183, reconstruction losses: 0.014042979137395224, regression losses: 0.1566506520170794, validation losses: 0.5725139327513484\n",
      "Epoch 2184, reconstruction losses: 0.012909712964003303, regression losses: 0.09011710902854098, validation losses: 0.5722484312647761\n",
      "Epoch 2185, reconstruction losses: 0.011887619641126078, regression losses: 0.09103030821426239, validation losses: 0.5067859404732572\n",
      "Epoch 2186, reconstruction losses: 0.014483047349516002, regression losses: 0.12578715763883497, validation losses: 0.4944355787346323\n",
      "Epoch 2187, reconstruction losses: 0.01251762561756853, regression losses: 0.10443912210846915, validation losses: 0.5245301077627068\n",
      "Epoch 2188, reconstruction losses: 0.015061868652781706, regression losses: 0.10738245289052964, validation losses: 0.5336168703468109\n",
      "Epoch 2189, reconstruction losses: 0.017144317722657808, regression losses: 0.11824569397580593, validation losses: 0.5282117182992889\n",
      "Epoch 2190, reconstruction losses: 0.013295182765342483, regression losses: 0.11052038815330545, validation losses: 0.5450586549527869\n",
      "Epoch 2191, reconstruction losses: 0.013340670502604787, regression losses: 0.12254888899273826, validation losses: 0.5009906859834966\n",
      "Epoch 2192, reconstruction losses: 0.017012396425377656, regression losses: 0.09071615807581529, validation losses: 0.4574651060292147\n",
      "Epoch 2193, reconstruction losses: 0.014893591013356801, regression losses: 0.14359698351861525, validation losses: 0.4316831212863825\n",
      "Epoch 2194, reconstruction losses: 0.02007326758254525, regression losses: 0.3791243306807791, validation losses: 0.40759172929241083\n",
      "Epoch 2195, reconstruction losses: 0.020345296671201912, regression losses: 0.1421601601740408, validation losses: 0.5039417079840095\n",
      "Epoch 2196, reconstruction losses: 0.0170259481016723, regression losses: 0.11882146622954941, validation losses: 0.4651145329126655\n",
      "Epoch 2197, reconstruction losses: 0.019249834516546126, regression losses: 0.13775955850485247, validation losses: 0.49925364148221735\n",
      "Epoch 2198, reconstruction losses: 0.013689309988515598, regression losses: 0.09980459006947964, validation losses: 0.7252407117266624\n",
      "Epoch 2199, reconstruction losses: 0.015336956427214304, regression losses: 0.10768464919860535, validation losses: 0.54161697033354\n",
      "Epoch 2200, reconstruction losses: 0.012449106517053513, regression losses: 0.11308565190260246, validation losses: 0.46555636012500723\n",
      "Epoch 2201, reconstruction losses: 0.015752180657014128, regression losses: 0.11518007998047275, validation losses: 0.43486827907682885\n",
      "Epoch 2202, reconstruction losses: 0.013259841963532096, regression losses: 0.13444426104751372, validation losses: 0.4761633497030646\n",
      "Epoch 2203, reconstruction losses: 0.015155208102419685, regression losses: 0.10911227671371661, validation losses: 0.42241897613459084\n",
      "Epoch 2204, reconstruction losses: 0.01422845579353044, regression losses: 0.12530217446499378, validation losses: 0.4117978079282279\n",
      "Epoch 2205, reconstruction losses: 0.013556953048371569, regression losses: 0.22533563896384684, validation losses: 0.42686790702726546\n",
      "Epoch 2206, reconstruction losses: 0.010687701829907633, regression losses: 0.10597304895858246, validation losses: 0.53033306829936\n",
      "Epoch 2207, reconstruction losses: 0.014781135291197407, regression losses: 0.13283878750587894, validation losses: 0.46029757866635634\n",
      "Epoch 2208, reconstruction losses: 0.013043480215689525, regression losses: 0.10840136101156285, validation losses: 0.4271861180684002\n",
      "Epoch 2209, reconstruction losses: 0.012909227702433681, regression losses: 0.1294425351919521, validation losses: 0.44149392665694737\n",
      "Epoch 2210, reconstruction losses: 0.014456956159468997, regression losses: 0.1683580070088076, validation losses: 0.43113321555769035\n",
      "Epoch 2211, reconstruction losses: 0.011911692837301112, regression losses: 0.08987489789417885, validation losses: 0.4333906789174911\n",
      "Epoch 2212, reconstruction losses: 0.014764059396661033, regression losses: 0.0858948123427203, validation losses: 0.5060897190490837\n",
      "Epoch 2213, reconstruction losses: 0.013610252092030376, regression losses: 0.1458009869344923, validation losses: 0.48282739216114\n",
      "Epoch 2214, reconstruction losses: 0.01348630720317045, regression losses: 0.11743587648634461, validation losses: 0.44642117759009836\n",
      "Epoch 2215, reconstruction losses: 0.01895316092081474, regression losses: 0.221934990354008, validation losses: 0.4904469793442659\n",
      "Epoch 2216, reconstruction losses: 0.014335350961699852, regression losses: 0.10706671665026586, validation losses: 0.4725855422190084\n",
      "Epoch 2217, reconstruction losses: 0.014759459933024157, regression losses: 0.09794318909051754, validation losses: 0.4398796611412309\n",
      "Epoch 2218, reconstruction losses: 0.017085798118163322, regression losses: 0.13055047756466584, validation losses: 0.4561868440810702\n",
      "Epoch 2219, reconstruction losses: 0.014940715788936227, regression losses: 0.11651261916509349, validation losses: 0.5235465914625008\n",
      "Epoch 2220, reconstruction losses: 0.015016952014943087, regression losses: 0.11353868075421664, validation losses: 0.5157004385752477\n",
      "Epoch 2221, reconstruction losses: 0.015425349591825854, regression losses: 0.11162122780736303, validation losses: 0.41937291224026996\n",
      "Epoch 2222, reconstruction losses: 0.012688870934971596, regression losses: 0.10637078822219956, validation losses: 0.4090863753230397\n",
      "Epoch 2223, reconstruction losses: 0.019747264714815096, regression losses: 0.12693019082338727, validation losses: 0.4121584692054863\n",
      "Epoch 2224, reconstruction losses: 0.014668301594388507, regression losses: 0.10328693047246648, validation losses: 0.44201066956440616\n",
      "Epoch 2225, reconstruction losses: 0.015426495591446654, regression losses: 0.1301602738756983, validation losses: 0.4594304803939099\n",
      "Epoch 2226, reconstruction losses: 0.013074470634053995, regression losses: 0.09163731938142537, validation losses: 0.43121927544424854\n",
      "Epoch 2227, reconstruction losses: 0.015470988987321068, regression losses: 0.1063300014744795, validation losses: 0.4228353527960509\n",
      "Epoch 2228, reconstruction losses: 0.013364511346794304, regression losses: 0.09091826623345899, validation losses: 0.40326388492454807\n",
      "Epoch 2229, reconstruction losses: 0.012608262498427841, regression losses: 0.11198250399075123, validation losses: 0.4017304612242578\n",
      "Epoch 2230, reconstruction losses: 0.013718157468010627, regression losses: 0.10238460177873729, validation losses: 0.4197513184656982\n",
      "Epoch 2231, reconstruction losses: 0.01144445483936964, regression losses: 0.1097482428269054, validation losses: 0.4308911714827505\n",
      "Epoch 2232, reconstruction losses: 0.012865877407576528, regression losses: 0.10134811532057877, validation losses: 0.3684122778919388\n",
      "Epoch 2233, reconstruction losses: 0.013386742540540671, regression losses: 0.09512576927095165, validation losses: 0.373065394574852\n",
      "Epoch 2234, reconstruction losses: 0.015353538810282591, regression losses: 0.10148964133961626, validation losses: 0.41598898820849384\n",
      "Epoch 2235, reconstruction losses: 0.012401275945723687, regression losses: 0.10605300578520213, validation losses: 0.39711089545791856\n",
      "Epoch 2236, reconstruction losses: 0.011892864103642839, regression losses: 0.07599799075772011, validation losses: 0.4085855933236946\n",
      "Epoch 2237, reconstruction losses: 0.012133287768411941, regression losses: 0.08103748473557837, validation losses: 0.4049607322307165\n",
      "Epoch 2238, reconstruction losses: 0.014312678483892631, regression losses: 0.14819584621754553, validation losses: 0.4588258410694428\n",
      "Epoch 2239, reconstruction losses: 0.013430118360567938, regression losses: 0.12629575256982503, validation losses: 0.5087695388479222\n",
      "Epoch 2240, reconstruction losses: 0.012161884874063191, regression losses: 0.11242342022667859, validation losses: 0.44311339927261484\n",
      "Epoch 2241, reconstruction losses: 0.014486546883300047, regression losses: 0.12488186266548153, validation losses: 0.4175974108006448\n",
      "Epoch 2242, reconstruction losses: 0.013418169900683653, regression losses: 0.132543328010248, validation losses: 0.43532088057250057\n",
      "Epoch 2243, reconstruction losses: 0.011791237826943256, regression losses: 0.07522475109966931, validation losses: 0.44725741133971514\n",
      "Epoch 2244, reconstruction losses: 0.01351451020058926, regression losses: 0.08379015568439817, validation losses: 0.4364866168247052\n",
      "Epoch 2245, reconstruction losses: 0.013180678306339264, regression losses: 0.09784976620666327, validation losses: 0.4292474330918197\n",
      "Epoch 2246, reconstruction losses: 0.012544325606486464, regression losses: 0.09398167788414573, validation losses: 0.45474849838255993\n",
      "Epoch 2247, reconstruction losses: 0.013171030615516784, regression losses: 0.0997354038720438, validation losses: 0.442324355531705\n",
      "Epoch 2248, reconstruction losses: 0.017584584221740984, regression losses: 0.10421915476961227, validation losses: 0.42104731387887295\n",
      "Epoch 2249, reconstruction losses: 0.01444487979799279, regression losses: 0.08269033735784236, validation losses: 0.44882947402483275\n",
      "Epoch 2250, reconstruction losses: 0.014816067288407548, regression losses: 0.11808102818395748, validation losses: 0.41311299339500707\n",
      "Epoch 2251, reconstruction losses: 0.010960845827569773, regression losses: 0.08573139183793543, validation losses: 0.422957506208551\n",
      "Epoch 2252, reconstruction losses: 0.01554714391093277, regression losses: 0.14039320582045456, validation losses: 0.3992747815591421\n",
      "Epoch 2253, reconstruction losses: 0.013085955212740473, regression losses: 0.1167497762750468, validation losses: 0.40547895529274297\n",
      "Epoch 2254, reconstruction losses: 0.013518643289220032, regression losses: 0.10847074907060526, validation losses: 0.3851288796147082\n",
      "Epoch 2255, reconstruction losses: 0.018035709650878067, regression losses: 0.13042537305719154, validation losses: 0.3868575414549887\n",
      "Epoch 2256, reconstruction losses: 0.017375313418292005, regression losses: 0.12037939909185835, validation losses: 0.41555384484135893\n",
      "Epoch 2257, reconstruction losses: 0.01498456198659112, regression losses: 0.12454995468778246, validation losses: 0.46567838140912726\n",
      "Epoch 2258, reconstruction losses: 0.013572702765877062, regression losses: 0.11887167421570617, validation losses: 0.5380270775388054\n",
      "Epoch 2259, reconstruction losses: 0.01203068794491376, regression losses: 0.08817865022928087, validation losses: 0.4699540519634304\n",
      "Epoch 2260, reconstruction losses: 0.013174710773699888, regression losses: 0.10865011414961466, validation losses: 0.4153855537173569\n",
      "Epoch 2261, reconstruction losses: 0.014367995870599943, regression losses: 0.11910061684628266, validation losses: 0.41059260557918675\n",
      "Epoch 2262, reconstruction losses: 0.014848775538608883, regression losses: 0.12083535448695715, validation losses: 0.48401272020441094\n",
      "Epoch 2263, reconstruction losses: 0.017701184633541596, regression losses: 0.38279730330326, validation losses: 0.42146977990345663\n",
      "Epoch 2264, reconstruction losses: 0.012204390038789063, regression losses: 0.11847366938463456, validation losses: 0.6588993489070039\n",
      "Epoch 2265, reconstruction losses: 0.013906021027463158, regression losses: 0.1127411138099733, validation losses: 0.5769460235279683\n",
      "Epoch 2266, reconstruction losses: 0.012175008685015368, regression losses: 0.1478477438436962, validation losses: 0.44715031063278504\n",
      "Epoch 2267, reconstruction losses: 0.013819679563147703, regression losses: 0.11504636646135175, validation losses: 0.4386611621772054\n",
      "Epoch 2268, reconstruction losses: 0.012418340060364137, regression losses: 0.13593035128195669, validation losses: 0.4213768290895685\n",
      "Epoch 2269, reconstruction losses: 0.014534315425480095, regression losses: 0.11131399080284671, validation losses: 0.5107671793403058\n",
      "Epoch 2270, reconstruction losses: 0.01376494686603854, regression losses: 0.1929360735581091, validation losses: 0.4930173755445735\n",
      "Epoch 2271, reconstruction losses: 0.02685186875162086, regression losses: 0.31848093296491303, validation losses: 0.4959979095647965\n",
      "Epoch 2272, reconstruction losses: 0.016269127646912147, regression losses: 0.40445941432666593, validation losses: 0.8434080259997347\n",
      "Epoch 2273, reconstruction losses: 0.021507344393730886, regression losses: 0.18588552439684478, validation losses: 0.6811601269316305\n",
      "Epoch 2274, reconstruction losses: 0.016022628701526456, regression losses: 0.13174364554714696, validation losses: 0.7410789102399056\n",
      "Epoch 2275, reconstruction losses: 0.017468808191346528, regression losses: 0.14885955880898877, validation losses: 0.7054812101471255\n",
      "Epoch 2276, reconstruction losses: 0.013415767216048141, regression losses: 0.11435022500343986, validation losses: 0.6045514938627758\n",
      "Epoch 2277, reconstruction losses: 0.018745381092621496, regression losses: 0.10944928190343312, validation losses: 0.5545742205457744\n",
      "Epoch 2278, reconstruction losses: 0.013444805808890271, regression losses: 0.10054000465620205, validation losses: 0.49492581946901026\n",
      "Epoch 2279, reconstruction losses: 0.015388376831266032, regression losses: 0.10662837259631512, validation losses: 0.5103919906265157\n",
      "Epoch 2280, reconstruction losses: 0.012291131695271525, regression losses: 0.10070640222157459, validation losses: 0.5389259332232524\n",
      "Epoch 2281, reconstruction losses: 0.022152207541358382, regression losses: 0.48889085761592754, validation losses: 0.48025111424843053\n",
      "Epoch 2282, reconstruction losses: 0.017446923293967787, regression losses: 0.10344322984174262, validation losses: 0.5382954240692938\n",
      "Epoch 2283, reconstruction losses: 0.017100109099945644, regression losses: 0.15136339394831688, validation losses: 0.5326964374574428\n",
      "Epoch 2284, reconstruction losses: 0.014890485612561568, regression losses: 0.13954989528503745, validation losses: 0.47261109550916036\n",
      "Epoch 2285, reconstruction losses: 0.01594631869961249, regression losses: 0.15013087421752486, validation losses: 0.4768009089640022\n",
      "Epoch 2286, reconstruction losses: 0.013003079338806655, regression losses: 0.08501697852916737, validation losses: 0.4405357035260738\n",
      "Epoch 2287, reconstruction losses: 0.015183541911517901, regression losses: 0.13479972825603534, validation losses: 0.4334538040376666\n",
      "Epoch 2288, reconstruction losses: 0.014088101308609016, regression losses: 0.11824735147302665, validation losses: 0.5317199709091627\n",
      "Epoch 2289, reconstruction losses: 0.016097269824085533, regression losses: 0.3040172346416768, validation losses: 0.5571449178682641\n",
      "Epoch 2290, reconstruction losses: 0.018944608250055697, regression losses: 0.18924276524263942, validation losses: 0.6989227224932792\n",
      "Epoch 2291, reconstruction losses: 0.021601487096383133, regression losses: 0.30275539369969284, validation losses: 0.6815122023721718\n",
      "Epoch 2292, reconstruction losses: 0.01505423369598193, regression losses: 0.16350344382746052, validation losses: 0.9898872302973329\n",
      "Epoch 2293, reconstruction losses: 0.01768651469250951, regression losses: 0.16108173500107809, validation losses: 0.8207397205080688\n",
      "Epoch 2294, reconstruction losses: 0.012873209103741118, regression losses: 0.1209443400691209, validation losses: 0.5321316735844888\n",
      "Epoch 2295, reconstruction losses: 0.012512443233423333, regression losses: 0.13515409390972988, validation losses: 0.5124032232190985\n",
      "Epoch 2296, reconstruction losses: 0.013855295643856867, regression losses: 0.1318659937471565, validation losses: 0.512201342279683\n",
      "Epoch 2297, reconstruction losses: 0.01633742733564774, regression losses: 0.13840464518380127, validation losses: 0.4983240308037334\n",
      "Epoch 2298, reconstruction losses: 0.014674882396801215, regression losses: 0.10270775933651495, validation losses: 0.4273115144118054\n",
      "Epoch 2299, reconstruction losses: 0.01449636931690994, regression losses: 0.08596494267855023, validation losses: 0.4106388653918941\n",
      "Epoch 2300, reconstruction losses: 0.014243851294202572, regression losses: 0.13526259607946534, validation losses: 0.42115037251146575\n",
      "Epoch 2301, reconstruction losses: 0.014763532904490093, regression losses: 0.1006419563138426, validation losses: 0.43376480250552957\n",
      "Epoch 2302, reconstruction losses: 0.012938217369432283, regression losses: 0.09993276661019404, validation losses: 0.4598333058519657\n",
      "Epoch 2303, reconstruction losses: 0.012314118447743067, regression losses: 0.103774994112849, validation losses: 0.4224981066245693\n",
      "Epoch 2304, reconstruction losses: 0.013254469304861405, regression losses: 0.08544065139792197, validation losses: 0.4443124066811666\n",
      "Epoch 2305, reconstruction losses: 0.01260056451641875, regression losses: 0.0922969333641421, validation losses: 0.4041213025266489\n",
      "Epoch 2306, reconstruction losses: 0.013587641759652418, regression losses: 0.10600975969105435, validation losses: 0.3848991593332487\n",
      "Epoch 2307, reconstruction losses: 0.015125568167003414, regression losses: 0.09333557546977994, validation losses: 0.3880028024842285\n",
      "Epoch 2308, reconstruction losses: 0.012948481329537385, regression losses: 0.09330699829815552, validation losses: 0.40554687646122095\n",
      "Epoch 2309, reconstruction losses: 0.013790137174121427, regression losses: 0.12383678676415426, validation losses: 0.37899547097611386\n",
      "Epoch 2310, reconstruction losses: 0.013338190179305806, regression losses: 0.1756930918085245, validation losses: 0.37079801141735746\n",
      "Epoch 2311, reconstruction losses: 0.015136290267373238, regression losses: 0.2307164711901445, validation losses: 0.413535114808634\n",
      "Epoch 2312, reconstruction losses: 0.017909734409955316, regression losses: 0.23403330217416624, validation losses: 0.5189422368372697\n",
      "Epoch 2313, reconstruction losses: 0.014540452552747654, regression losses: 0.14292916020046342, validation losses: 0.46305408758043576\n",
      "Epoch 2314, reconstruction losses: 0.013694347671278754, regression losses: 0.10410940897780516, validation losses: 0.4464880778904933\n",
      "Epoch 2315, reconstruction losses: 0.01306422910494445, regression losses: 0.11332383336505353, validation losses: 0.43142017556800016\n",
      "Epoch 2316, reconstruction losses: 0.013645998395284688, regression losses: 0.09916062711019466, validation losses: 0.4054147992792695\n",
      "Epoch 2317, reconstruction losses: 0.017557675407962398, regression losses: 0.37424955504999957, validation losses: 0.42207844693511776\n",
      "Epoch 2318, reconstruction losses: 0.018455648777362096, regression losses: 0.1476763957953884, validation losses: 0.6852125253021261\n",
      "Epoch 2319, reconstruction losses: 0.014758588578301266, regression losses: 0.1327950317852231, validation losses: 0.5467005757835459\n",
      "Epoch 2320, reconstruction losses: 0.014379430504519815, regression losses: 0.11523475220810603, validation losses: 0.4567304956883752\n",
      "Epoch 2321, reconstruction losses: 0.01360019222042061, regression losses: 0.1457919436627462, validation losses: 0.428856348603929\n",
      "Epoch 2322, reconstruction losses: 0.016577917131182892, regression losses: 0.10201495728493905, validation losses: 0.45777669194318044\n",
      "Epoch 2323, reconstruction losses: 0.015460393873613348, regression losses: 0.11498474421160679, validation losses: 0.48520498466404505\n",
      "Epoch 2324, reconstruction losses: 0.01712330254493963, regression losses: 0.10213884101088753, validation losses: 0.47387851563944516\n",
      "Epoch 2325, reconstruction losses: 0.014613167693541968, regression losses: 0.09507834205622161, validation losses: 0.46733601696963545\n",
      "Epoch 2326, reconstruction losses: 0.01304861934058981, regression losses: 0.1111634843527128, validation losses: 0.43512455174662085\n",
      "Epoch 2327, reconstruction losses: 0.011349652001915811, regression losses: 0.08959444809278876, validation losses: 0.419874651196639\n",
      "Epoch 2328, reconstruction losses: 0.01228082704864519, regression losses: 0.11519743260714653, validation losses: 0.3998774175446546\n",
      "Epoch 2329, reconstruction losses: 0.012270894624071337, regression losses: 0.09069014222682104, validation losses: 0.39112006431203816\n",
      "Epoch 2330, reconstruction losses: 0.013521898108018212, regression losses: 0.08260161432183649, validation losses: 0.3867725222443054\n",
      "Epoch 2331, reconstruction losses: 0.012351716498393983, regression losses: 0.116730081942401, validation losses: 0.3790091314167662\n",
      "Epoch 2332, reconstruction losses: 0.013802352452426843, regression losses: 0.11073628449203313, validation losses: 0.4519953796429827\n",
      "Epoch 2333, reconstruction losses: 0.01633083863486034, regression losses: 0.18162262848690963, validation losses: 0.47694792416948345\n",
      "Epoch 2334, reconstruction losses: 0.013941960707025337, regression losses: 0.09750059595780548, validation losses: 0.4963093176443165\n",
      "Epoch 2335, reconstruction losses: 0.012599600231411443, regression losses: 0.13314846927319304, validation losses: 0.6169056557412067\n",
      "Epoch 2336, reconstruction losses: 0.011795337355898218, regression losses: 0.10607637188403894, validation losses: 0.6137834845322854\n",
      "Epoch 2337, reconstruction losses: 0.02283301318975493, regression losses: 0.17562264350558446, validation losses: 0.5897844265759296\n",
      "Epoch 2338, reconstruction losses: 0.012639175191062496, regression losses: 0.10117026639578378, validation losses: 0.5808835809015567\n",
      "Epoch 2339, reconstruction losses: 0.01941372742783325, regression losses: 0.12766914129006438, validation losses: 0.46204294255344164\n",
      "Epoch 2340, reconstruction losses: 0.020359388846748136, regression losses: 0.19467049903886824, validation losses: 0.46252996703916494\n",
      "Epoch 2341, reconstruction losses: 0.014970199097532817, regression losses: 0.11948944115247732, validation losses: 0.5937253060763712\n",
      "Epoch 2342, reconstruction losses: 0.015659261876463517, regression losses: 0.18844872092234613, validation losses: 0.5423207452114202\n",
      "Epoch 2343, reconstruction losses: 0.012460747954447505, regression losses: 0.08771745195497212, validation losses: 0.4963242879486449\n",
      "Epoch 2344, reconstruction losses: 0.02135696346048558, regression losses: 0.1812853641511059, validation losses: 0.46994880586438853\n",
      "Epoch 2345, reconstruction losses: 0.014919756902803994, regression losses: 0.10466403808756684, validation losses: 0.4847999380157281\n",
      "Epoch 2346, reconstruction losses: 0.014388182350271155, regression losses: 0.11603417928242984, validation losses: 0.5090945251702195\n",
      "Epoch 2347, reconstruction losses: 0.014303588064181675, regression losses: 0.10638835382031567, validation losses: 0.46517270721074444\n",
      "Epoch 2348, reconstruction losses: 0.018557686086215698, regression losses: 0.10461065213446827, validation losses: 0.5621009220014554\n",
      "Epoch 2349, reconstruction losses: 0.015785374296306547, regression losses: 0.1045580949850122, validation losses: 0.5552485569833725\n",
      "Epoch 2350, reconstruction losses: 0.01711584516115823, regression losses: 0.08854371243572261, validation losses: 0.48410277949762137\n",
      "Epoch 2351, reconstruction losses: 0.01724727674414849, regression losses: 0.16586065211903958, validation losses: 0.4747696388862566\n",
      "Epoch 2352, reconstruction losses: 0.012236486881081216, regression losses: 0.09508387314548626, validation losses: 0.5207354255328649\n",
      "Epoch 2353, reconstruction losses: 0.016845905867038213, regression losses: 0.12155718082859096, validation losses: 0.44783000193735467\n",
      "Epoch 2354, reconstruction losses: 0.012612884616166022, regression losses: 0.10618187833782765, validation losses: 0.465073371628602\n",
      "Epoch 2355, reconstruction losses: 0.01504555148056853, regression losses: 0.1207403247611548, validation losses: 0.49163846367881353\n",
      "Epoch 2356, reconstruction losses: 0.011239402027552907, regression losses: 0.10334502928309869, validation losses: 0.5017360772227796\n",
      "Epoch 2357, reconstruction losses: 0.011985542054621445, regression losses: 0.10122835351611345, validation losses: 0.5145974201703762\n",
      "Epoch 2358, reconstruction losses: 0.011760358945468178, regression losses: 0.1065500118034023, validation losses: 0.5064603166146231\n",
      "Epoch 2359, reconstruction losses: 0.012352963927068538, regression losses: 0.15141215415593376, validation losses: 0.503090261023263\n",
      "Epoch 2360, reconstruction losses: 0.015307324117359586, regression losses: 0.1294217379095577, validation losses: 0.47381677428705254\n",
      "Epoch 2361, reconstruction losses: 0.01167954783488654, regression losses: 0.08684722994453119, validation losses: 0.440955303088863\n",
      "Epoch 2362, reconstruction losses: 0.015545762125413656, regression losses: 0.1571910869256969, validation losses: 0.4425241461101861\n",
      "Epoch 2363, reconstruction losses: 0.012161075428398792, regression losses: 0.13127429865076065, validation losses: 0.4584897349188527\n",
      "Epoch 2364, reconstruction losses: 0.0133030073451681, regression losses: 0.08894482659302692, validation losses: 0.49277781047201424\n",
      "Epoch 2365, reconstruction losses: 0.0179374289856257, regression losses: 0.15392431460857078, validation losses: 0.4626113506875145\n",
      "Epoch 2366, reconstruction losses: 0.013532447323763852, regression losses: 0.15047044552394087, validation losses: 0.4481240173657412\n",
      "Epoch 2367, reconstruction losses: 0.029372720218597746, regression losses: 0.2988506802082892, validation losses: 0.4499018570529287\n",
      "Epoch 2368, reconstruction losses: 0.013338919394481275, regression losses: 0.11886814619710392, validation losses: 0.5355025840302154\n",
      "Epoch 2369, reconstruction losses: 0.012227738417631934, regression losses: 0.09375996927081852, validation losses: 0.4785376891140189\n",
      "Epoch 2370, reconstruction losses: 0.013174048297006831, regression losses: 0.14023024461476902, validation losses: 0.4644333782545899\n",
      "Epoch 2371, reconstruction losses: 0.015524866044122254, regression losses: 0.1324104985492691, validation losses: 0.4774253414110979\n",
      "Epoch 2372, reconstruction losses: 0.014737721545590674, regression losses: 0.12119636544282257, validation losses: 0.4587747508593671\n",
      "Epoch 2373, reconstruction losses: 0.014623820099914996, regression losses: 0.1420507713705473, validation losses: 0.4850819388299248\n",
      "Epoch 2374, reconstruction losses: 0.012450223853778837, regression losses: 0.09516070539447963, validation losses: 0.42403574050911885\n",
      "Epoch 2375, reconstruction losses: 0.01890755670381894, regression losses: 0.14626990504838833, validation losses: 0.39930581863230846\n",
      "Epoch 2376, reconstruction losses: 0.015911138193528133, regression losses: 0.10533449935129224, validation losses: 0.41453706722402167\n",
      "Epoch 2377, reconstruction losses: 0.016618973161146692, regression losses: 0.1343952283022215, validation losses: 0.5042026377736009\n",
      "Epoch 2378, reconstruction losses: 0.012357070906463609, regression losses: 0.0932937250969645, validation losses: 0.5206240270009348\n",
      "Epoch 2379, reconstruction losses: 0.013192255999916937, regression losses: 0.1204980826045149, validation losses: 0.4556613956540317\n",
      "Epoch 2380, reconstruction losses: 0.012121125650539475, regression losses: 0.10077765751297607, validation losses: 0.4433945504068114\n",
      "Epoch 2381, reconstruction losses: 0.020725467172684794, regression losses: 0.1242066328058381, validation losses: 0.43889674179273386\n",
      "Epoch 2382, reconstruction losses: 0.010839205260356383, regression losses: 0.09233240768007289, validation losses: 0.4685988063830668\n",
      "Epoch 2383, reconstruction losses: 0.011346324481970359, regression losses: 0.0891385896298141, validation losses: 0.486319470493853\n",
      "Epoch 2384, reconstruction losses: 0.012315051907979766, regression losses: 0.08675248893072561, validation losses: 0.46657435951182336\n",
      "Epoch 2385, reconstruction losses: 0.011429179224211609, regression losses: 0.10219346193442955, validation losses: 0.4656607336675996\n",
      "Epoch 2386, reconstruction losses: 0.011329867379482423, regression losses: 0.08194930776204334, validation losses: 0.4697116496730106\n",
      "Epoch 2387, reconstruction losses: 0.014207134019365976, regression losses: 0.11451028518884253, validation losses: 0.4674828257401629\n",
      "Epoch 2388, reconstruction losses: 0.011876625798620666, regression losses: 0.12141799832436936, validation losses: 0.4881634380261582\n",
      "Epoch 2389, reconstruction losses: 0.014702901006724042, regression losses: 0.07454270551282975, validation losses: 0.49703257037709003\n",
      "Epoch 2390, reconstruction losses: 0.01163156943807348, regression losses: 0.08992255429454732, validation losses: 0.47803169258966743\n",
      "Epoch 2391, reconstruction losses: 0.013316227880982337, regression losses: 0.08581976327337064, validation losses: 0.4602172836902591\n",
      "Epoch 2392, reconstruction losses: 0.011673569858682181, regression losses: 0.08863011501610929, validation losses: 0.44360322184256384\n",
      "Epoch 2393, reconstruction losses: 0.01363711394031843, regression losses: 0.0975788913789139, validation losses: 0.4285352692874954\n",
      "Epoch 2394, reconstruction losses: 0.015473520126719698, regression losses: 0.1196514931817754, validation losses: 0.44603034007364006\n",
      "Epoch 2395, reconstruction losses: 0.019770566781094803, regression losses: 0.14500744382229513, validation losses: 0.5018450358643953\n",
      "Epoch 2396, reconstruction losses: 0.013861031407843338, regression losses: 0.12733621233471612, validation losses: 0.486051960925606\n",
      "Epoch 2397, reconstruction losses: 0.012815344360570578, regression losses: 0.10293626614502606, validation losses: 0.4455679354135568\n",
      "Epoch 2398, reconstruction losses: 0.012727101543307343, regression losses: 0.10202518746357747, validation losses: 0.46049986400892307\n",
      "Epoch 2399, reconstruction losses: 0.013005621629322728, regression losses: 0.11026035444654192, validation losses: 0.4755256312714523\n",
      "Epoch 2400, reconstruction losses: 0.014325827415326417, regression losses: 0.10445096793340845, validation losses: 0.43804820414163814\n",
      "Epoch 2401, reconstruction losses: 0.014194156596174765, regression losses: 0.11442018215871566, validation losses: 0.4283221968333741\n",
      "Epoch 2402, reconstruction losses: 0.013554719523878546, regression losses: 0.10825660821539713, validation losses: 0.4391851342749214\n",
      "Epoch 2403, reconstruction losses: 0.013648249634906223, regression losses: 0.10133837625194557, validation losses: 0.44973495174272865\n",
      "Epoch 2404, reconstruction losses: 0.012861138341277166, regression losses: 0.08601153577900512, validation losses: 0.4818509218351462\n",
      "Epoch 2405, reconstruction losses: 0.013628457678065854, regression losses: 0.1307416224470382, validation losses: 0.4362638132617827\n",
      "Epoch 2406, reconstruction losses: 0.011872360389741363, regression losses: 0.08711105500766288, validation losses: 0.49144318250144614\n",
      "Epoch 2407, reconstruction losses: 0.013565529973584144, regression losses: 0.12652106629836476, validation losses: 0.5005633825599302\n",
      "Epoch 2408, reconstruction losses: 0.011983231566374025, regression losses: 0.08576702997939203, validation losses: 0.47732353339810685\n",
      "Epoch 2409, reconstruction losses: 0.017006972016361692, regression losses: 0.14595156138073173, validation losses: 0.4428250432463074\n",
      "Epoch 2410, reconstruction losses: 0.015165618013965602, regression losses: 0.10375682277181839, validation losses: 0.40001046317328515\n",
      "Epoch 2411, reconstruction losses: 0.01627623834694647, regression losses: 0.1577412499664182, validation losses: 0.3941432096885436\n",
      "Epoch 2412, reconstruction losses: 0.016335789774177358, regression losses: 0.10833721626134804, validation losses: 0.45966749750775693\n",
      "Epoch 2413, reconstruction losses: 0.015608984150771554, regression losses: 0.11601098289127368, validation losses: 0.42882417948980955\n",
      "Epoch 2414, reconstruction losses: 0.00987518048933892, regression losses: 0.09204453530761518, validation losses: 0.41096351039731727\n",
      "Epoch 2415, reconstruction losses: 0.011626280853003946, regression losses: 0.08712857084238115, validation losses: 0.442767748112201\n",
      "Epoch 2416, reconstruction losses: 0.014850708071944645, regression losses: 0.12599738734626223, validation losses: 0.4433084257493364\n",
      "Epoch 2417, reconstruction losses: 0.013060838798698248, regression losses: 0.12841937145027404, validation losses: 0.4274868097956026\n",
      "Epoch 2418, reconstruction losses: 0.012318021454637472, regression losses: 0.12138429864232812, validation losses: 0.4466881569189987\n",
      "Epoch 2419, reconstruction losses: 0.012706397829828511, regression losses: 0.09679731268899164, validation losses: 0.5131047501190995\n",
      "Epoch 2420, reconstruction losses: 0.013037273882566416, regression losses: 0.11989468277536507, validation losses: 0.46053347781808\n",
      "Epoch 2421, reconstruction losses: 0.01341505689999343, regression losses: 0.10307823482557235, validation losses: 0.4215234881056433\n",
      "Epoch 2422, reconstruction losses: 0.013243428338711862, regression losses: 0.1382593729630213, validation losses: 0.40353194179786545\n",
      "Epoch 2423, reconstruction losses: 0.01398463020462324, regression losses: 0.09946028961376824, validation losses: 0.4269374259446149\n",
      "Epoch 2424, reconstruction losses: 0.014662216384125997, regression losses: 0.10615774871119858, validation losses: 0.463513244549797\n",
      "Epoch 2425, reconstruction losses: 0.013090919320644686, regression losses: 0.1097341906522121, validation losses: 0.48983365823430847\n",
      "Epoch 2426, reconstruction losses: 0.015701339233262578, regression losses: 0.10330950964086776, validation losses: 0.4285986824042986\n",
      "Epoch 2427, reconstruction losses: 0.014511310833111907, regression losses: 0.09016645471480685, validation losses: 0.4038598903106929\n",
      "Epoch 2428, reconstruction losses: 0.015839409414963, regression losses: 0.1324761729760455, validation losses: 0.4047294517707449\n",
      "Epoch 2429, reconstruction losses: 0.017202547400435465, regression losses: 0.11752303188046745, validation losses: 0.4285895593423422\n",
      "Epoch 2430, reconstruction losses: 0.011979493674601186, regression losses: 0.07094628482242056, validation losses: 0.42481722976787306\n",
      "Epoch 2431, reconstruction losses: 0.013358110128874163, regression losses: 0.14295930102613064, validation losses: 0.43777547891157403\n",
      "Epoch 2432, reconstruction losses: 0.014595372294537277, regression losses: 0.11874093913389142, validation losses: 0.43157593966256597\n",
      "Epoch 2433, reconstruction losses: 0.016557537485087176, regression losses: 0.11692594680421002, validation losses: 0.41403716182452094\n",
      "Epoch 2434, reconstruction losses: 0.011390298687200671, regression losses: 0.106940657565518, validation losses: 0.4156594148831003\n",
      "Epoch 2435, reconstruction losses: 0.013470315562029456, regression losses: 0.13072762596798926, validation losses: 0.4028197699329929\n",
      "Epoch 2436, reconstruction losses: 0.013179311007644398, regression losses: 0.11511607845726726, validation losses: 0.44628640440141004\n",
      "Epoch 2437, reconstruction losses: 0.012311928136573669, regression losses: 0.10184301720123907, validation losses: 0.4324557229527886\n",
      "Epoch 2438, reconstruction losses: 0.013378812565327696, regression losses: 0.0915693331371703, validation losses: 0.4106989237510013\n",
      "Epoch 2439, reconstruction losses: 0.012409136313003801, regression losses: 0.09749958025938119, validation losses: 0.41008444056779153\n",
      "Epoch 2440, reconstruction losses: 0.013585838155179306, regression losses: 0.11571244860411435, validation losses: 0.4157521237837072\n",
      "Epoch 2441, reconstruction losses: 0.01229928300100351, regression losses: 0.07657324837261063, validation losses: 0.45290318893244913\n",
      "Epoch 2442, reconstruction losses: 0.012691732818850644, regression losses: 0.1046073648591805, validation losses: 0.43032028122663507\n",
      "Epoch 2443, reconstruction losses: 0.011258803180805512, regression losses: 0.09726751466605763, validation losses: 0.3865872604483025\n",
      "Epoch 2444, reconstruction losses: 0.013380309311530742, regression losses: 0.10343583334567387, validation losses: 0.3933465066849901\n",
      "Epoch 2445, reconstruction losses: 0.015487516896159816, regression losses: 0.10108347076121381, validation losses: 0.39850278856897053\n",
      "Epoch 2446, reconstruction losses: 0.012659140559725716, regression losses: 0.11695108847603784, validation losses: 0.41879576982557065\n",
      "Epoch 2447, reconstruction losses: 0.01168951028841579, regression losses: 0.09749982786353793, validation losses: 0.4249569539984407\n",
      "Epoch 2448, reconstruction losses: 0.012489498853010381, regression losses: 0.10839136793605417, validation losses: 0.40760309268775435\n",
      "Epoch 2449, reconstruction losses: 0.01437921107448657, regression losses: 0.17411908871905427, validation losses: 0.4312411358326319\n",
      "Epoch 2450, reconstruction losses: 0.012221168196441715, regression losses: 0.11764798815404126, validation losses: 0.4194600344993944\n",
      "Epoch 2451, reconstruction losses: 0.014112496817682922, regression losses: 0.11685573799013242, validation losses: 0.42145095530033994\n",
      "Epoch 2452, reconstruction losses: 0.01614641097308226, regression losses: 0.12213322412328181, validation losses: 0.3980159536318875\n",
      "Epoch 2453, reconstruction losses: 0.011226772319960065, regression losses: 0.10001250342115829, validation losses: 0.47884083987846426\n",
      "Epoch 2454, reconstruction losses: 0.011883759438124968, regression losses: 0.10862872750027418, validation losses: 0.47778179162512024\n",
      "Epoch 2455, reconstruction losses: 0.013539101176917432, regression losses: 0.12184559727702081, validation losses: 0.4466765709016707\n",
      "Epoch 2456, reconstruction losses: 0.012757119662057325, regression losses: 0.10889226062321766, validation losses: 0.41663679427781075\n",
      "Epoch 2457, reconstruction losses: 0.01328403856735458, regression losses: 0.06678616772571361, validation losses: 0.4152175334985047\n",
      "Epoch 2458, reconstruction losses: 0.012263269700609513, regression losses: 0.09487405620648479, validation losses: 0.38885352132353534\n",
      "Epoch 2459, reconstruction losses: 0.014825650040819845, regression losses: 0.11768317428235049, validation losses: 0.4029238478326382\n",
      "Epoch 2460, reconstruction losses: 0.01564632067686097, regression losses: 0.14170014271405434, validation losses: 0.3977524964841621\n",
      "Epoch 2461, reconstruction losses: 0.01476726668358757, regression losses: 0.12805622883112283, validation losses: 0.4432954824339269\n",
      "Epoch 2462, reconstruction losses: 0.0180263763250095, regression losses: 0.1849585417259873, validation losses: 0.4267527563267998\n",
      "Epoch 2463, reconstruction losses: 0.014836296451530933, regression losses: 0.10744548922420386, validation losses: 0.5717127059836484\n",
      "Epoch 2464, reconstruction losses: 0.01389899696447849, regression losses: 0.11706760370860607, validation losses: 0.5012580569515895\n",
      "Epoch 2465, reconstruction losses: 0.013443029537565338, regression losses: 0.10536080912515879, validation losses: 0.4286821483118124\n",
      "Epoch 2466, reconstruction losses: 0.01411613891112758, regression losses: 0.15442053643985654, validation losses: 0.4467607495645923\n",
      "Epoch 2467, reconstruction losses: 0.014017936985818855, regression losses: 0.12909910513496783, validation losses: 0.49255572429822053\n",
      "Epoch 2468, reconstruction losses: 0.01703128405631817, regression losses: 0.40909915502286404, validation losses: 0.40773823366406553\n",
      "Epoch 2469, reconstruction losses: 0.013240840370286534, regression losses: 0.10134809759361729, validation losses: 0.8006257195553019\n",
      "Epoch 2470, reconstruction losses: 0.015842283836923817, regression losses: 0.1428068783205793, validation losses: 0.8746584323625324\n",
      "Epoch 2471, reconstruction losses: 0.013607268178350191, regression losses: 0.12161690560988117, validation losses: 0.5798652812111187\n",
      "Epoch 2472, reconstruction losses: 0.011122286057001168, regression losses: 0.09894771022617918, validation losses: 0.45151898036565674\n",
      "Epoch 2473, reconstruction losses: 0.012125034895392043, regression losses: 0.09095990316841998, validation losses: 0.4568144682739115\n",
      "Epoch 2474, reconstruction losses: 0.011675417539115605, regression losses: 0.08779963442594747, validation losses: 0.45424395489737307\n",
      "Epoch 2475, reconstruction losses: 0.018308757812150363, regression losses: 0.1808565563441929, validation losses: 0.4739192016665323\n",
      "Epoch 2476, reconstruction losses: 0.016785105040560168, regression losses: 0.16082858115449128, validation losses: 0.8334008475701644\n",
      "Epoch 2477, reconstruction losses: 0.019242487484906316, regression losses: 0.20808952423023067, validation losses: 0.6269644851959782\n",
      "Epoch 2478, reconstruction losses: 0.01670292867958634, regression losses: 0.12779420764613852, validation losses: 0.7332066087709102\n",
      "Epoch 2479, reconstruction losses: 0.01703645367941656, regression losses: 0.15323074279252027, validation losses: 0.7821625478516906\n",
      "Epoch 2480, reconstruction losses: 0.016361795567815057, regression losses: 0.12358843199697188, validation losses: 0.52280969621711\n",
      "Epoch 2481, reconstruction losses: 0.01660491823289089, regression losses: 0.11124441340885938, validation losses: 0.48651165448296485\n",
      "Epoch 2482, reconstruction losses: 0.013840187010100622, regression losses: 0.18654659487767616, validation losses: 0.4647427413311193\n",
      "Epoch 2483, reconstruction losses: 0.013419623083853973, regression losses: 0.08632411745045822, validation losses: 0.47298798479126564\n",
      "Epoch 2484, reconstruction losses: 0.01680243860883762, regression losses: 0.1038170790759693, validation losses: 0.4663859942376949\n",
      "Epoch 2485, reconstruction losses: 0.021768603309883963, regression losses: 0.17886836817686042, validation losses: 0.4900530207649408\n",
      "Epoch 2486, reconstruction losses: 0.014713229217377182, regression losses: 0.09259456460624904, validation losses: 0.5409164280406957\n",
      "Epoch 2487, reconstruction losses: 0.014310525219082026, regression losses: 0.12799777660550543, validation losses: 0.604419643509464\n",
      "Epoch 2488, reconstruction losses: 0.013831675360636194, regression losses: 0.13633000122320477, validation losses: 0.40788414348820157\n",
      "Epoch 2489, reconstruction losses: 0.018200965949088856, regression losses: 0.18603729884818912, validation losses: 0.40574775206799896\n",
      "Epoch 2490, reconstruction losses: 0.01432968065102726, regression losses: 0.13119203233960364, validation losses: 0.45437613961551576\n",
      "Epoch 2491, reconstruction losses: 0.015241265052972498, regression losses: 0.1475812557754469, validation losses: 0.47457401638046687\n",
      "Epoch 2492, reconstruction losses: 0.013705503476981453, regression losses: 0.1164484680155929, validation losses: 0.49781891444804277\n",
      "Epoch 2493, reconstruction losses: 0.013325025146236784, regression losses: 0.13154243934911763, validation losses: 0.5016944378107928\n",
      "Epoch 2494, reconstruction losses: 0.014673480634727001, regression losses: 0.10962962716387348, validation losses: 0.5033247447777067\n",
      "Epoch 2495, reconstruction losses: 0.013495908181802248, regression losses: 0.09778904312979146, validation losses: 0.47016645792474127\n",
      "Epoch 2496, reconstruction losses: 0.01346034500850056, regression losses: 0.0969470601267015, validation losses: 0.4382024127398133\n",
      "Epoch 2497, reconstruction losses: 0.019204673437572872, regression losses: 0.11112737607714737, validation losses: 0.42897637958558377\n",
      "Epoch 2498, reconstruction losses: 0.014374494446682009, regression losses: 0.11271485124573662, validation losses: 0.4894754693427975\n",
      "Epoch 2499, reconstruction losses: 0.013681554317825419, regression losses: 0.09272689357276274, validation losses: 0.47302784636603046\n",
      "Epoch 2500, reconstruction losses: 0.013746328182795427, regression losses: 0.08548599535789894, validation losses: 0.48333524757326046\n",
      "Epoch 2501, reconstruction losses: 0.011432239365508537, regression losses: 0.09883923751340566, validation losses: 0.47490708912725044\n",
      "Epoch 2502, reconstruction losses: 0.012642316505373983, regression losses: 0.07837220853284152, validation losses: 0.43216142583315564\n",
      "Epoch 2503, reconstruction losses: 0.01752643105251663, regression losses: 0.24990904075587256, validation losses: 0.4374949849839571\n",
      "Epoch 2504, reconstruction losses: 0.012062604013139178, regression losses: 0.0813908949718345, validation losses: 0.4210534315288562\n",
      "Epoch 2505, reconstruction losses: 0.012292915368894953, regression losses: 0.09770856952840827, validation losses: 0.4092688691619388\n",
      "Epoch 2506, reconstruction losses: 0.016316997015022136, regression losses: 0.09772352192050618, validation losses: 0.39574074349346555\n",
      "Epoch 2507, reconstruction losses: 0.012534781188627327, regression losses: 0.1003195846252118, validation losses: 0.4339202069731777\n",
      "Epoch 2508, reconstruction losses: 0.01071729329263088, regression losses: 0.09128269641833638, validation losses: 0.4463911419517269\n",
      "Epoch 2509, reconstruction losses: 0.01282733823077489, regression losses: 0.15053293353792013, validation losses: 0.43786539976433597\n",
      "Epoch 2510, reconstruction losses: 0.014199079378134517, regression losses: 0.13555206407382725, validation losses: 0.45595373269215783\n",
      "Epoch 2511, reconstruction losses: 0.013451416722776263, regression losses: 0.12313718388515046, validation losses: 0.46520317670795597\n",
      "Epoch 2512, reconstruction losses: 0.014874096389461872, regression losses: 0.12630011247613182, validation losses: 0.4512931164412153\n",
      "Epoch 2513, reconstruction losses: 0.012752507665011483, regression losses: 0.1895541604772527, validation losses: 0.45341331493948833\n",
      "Epoch 2514, reconstruction losses: 0.012363492099749556, regression losses: 0.11203534412148447, validation losses: 0.47458074650835136\n",
      "Epoch 2515, reconstruction losses: 0.011648954682268682, regression losses: 0.10745876444680971, validation losses: 0.5015999708767132\n",
      "Epoch 2516, reconstruction losses: 0.013190354413849638, regression losses: 0.09853137983304017, validation losses: 0.454161142430637\n",
      "Epoch 2517, reconstruction losses: 0.012745145702974872, regression losses: 0.10721118012176473, validation losses: 0.4523397144655615\n",
      "Epoch 2518, reconstruction losses: 0.015061592628631286, regression losses: 0.13187070152315444, validation losses: 0.4404063486665397\n",
      "Epoch 2519, reconstruction losses: 0.01425543763800405, regression losses: 0.09575833491372691, validation losses: 0.4171516564250058\n",
      "Epoch 2520, reconstruction losses: 0.013788526628671466, regression losses: 0.09796665060630286, validation losses: 0.3997724167787802\n",
      "Epoch 2521, reconstruction losses: 0.021870396541994862, regression losses: 0.12297380244942571, validation losses: 0.39301181435043575\n",
      "Epoch 2522, reconstruction losses: 0.011469689995039332, regression losses: 0.09675051913115643, validation losses: 0.4143559603292449\n",
      "Epoch 2523, reconstruction losses: 0.014186485066662874, regression losses: 0.1089219616214191, validation losses: 0.4270921773645905\n",
      "Epoch 2524, reconstruction losses: 0.013573520280788173, regression losses: 0.10755791565329771, validation losses: 0.4418867650957742\n",
      "Epoch 2525, reconstruction losses: 0.01667348322499375, regression losses: 0.13792010245217678, validation losses: 0.43533240979912824\n",
      "Epoch 2526, reconstruction losses: 0.01632192883688961, regression losses: 0.1320530100318407, validation losses: 0.49475003895365666\n",
      "Epoch 2527, reconstruction losses: 0.01605306889489231, regression losses: 0.11655258151047024, validation losses: 0.5127351383282774\n",
      "Epoch 2528, reconstruction losses: 0.013073854396381259, regression losses: 0.1075457568762483, validation losses: 0.5267117363682877\n",
      "Epoch 2529, reconstruction losses: 0.014131219607199949, regression losses: 0.14284168150692392, validation losses: 0.5941449204033628\n",
      "Epoch 2530, reconstruction losses: 0.01267767594525761, regression losses: 0.08714044723847704, validation losses: 0.5289395607551965\n",
      "Epoch 2531, reconstruction losses: 0.012774471176832785, regression losses: 0.1052745033056116, validation losses: 0.481411160153253\n",
      "Epoch 2532, reconstruction losses: 0.01477866682100055, regression losses: 0.10000393556008763, validation losses: 0.4763077969963171\n",
      "Epoch 2533, reconstruction losses: 0.0166916499885304, regression losses: 0.09649151015587966, validation losses: 0.4624451236901215\n",
      "Epoch 2534, reconstruction losses: 0.013014641721824472, regression losses: 0.14435519615210118, validation losses: 0.4415728776817554\n",
      "Epoch 2535, reconstruction losses: 0.010314563701529878, regression losses: 0.07274957941272522, validation losses: 0.43570616965442316\n",
      "Epoch 2536, reconstruction losses: 0.011855690561582482, regression losses: 0.11370439370778816, validation losses: 0.42053886987777855\n",
      "Epoch 2537, reconstruction losses: 0.0128757251872114, regression losses: 0.1127398533802054, validation losses: 0.4087977517507826\n",
      "Epoch 2538, reconstruction losses: 0.011175551712113997, regression losses: 0.13854153611435369, validation losses: 0.4341763048254836\n",
      "Epoch 2539, reconstruction losses: 0.016672478547267375, regression losses: 0.10789018415954953, validation losses: 0.45324279208857376\n",
      "Epoch 2540, reconstruction losses: 0.012425565094150949, regression losses: 0.13342309020265875, validation losses: 0.45436074959769646\n",
      "Epoch 2541, reconstruction losses: 0.013209784662969577, regression losses: 0.11842550234899599, validation losses: 0.557116401351581\n",
      "Epoch 2542, reconstruction losses: 0.013438732473770006, regression losses: 0.13765273339887144, validation losses: 0.5480185916164271\n",
      "Epoch 2543, reconstruction losses: 0.012878012647683927, regression losses: 0.13148688412097814, validation losses: 0.46921799485753096\n",
      "Epoch 2544, reconstruction losses: 0.012736048412970656, regression losses: 0.09022696564850076, validation losses: 0.42606995356480876\n",
      "Epoch 2545, reconstruction losses: 0.013463827806217347, regression losses: 0.11996890496606866, validation losses: 0.4361394976998436\n",
      "Epoch 2546, reconstruction losses: 0.012505250240613759, regression losses: 0.11538942531015589, validation losses: 0.41488685253929747\n",
      "Epoch 2547, reconstruction losses: 0.012599034201701453, regression losses: 0.11109153127969659, validation losses: 0.42959365547884165\n",
      "Epoch 2548, reconstruction losses: 0.014707756579473864, regression losses: 0.10626335294323555, validation losses: 0.41261800505772334\n",
      "Epoch 2549, reconstruction losses: 0.015063998955239511, regression losses: 0.11234810886807688, validation losses: 0.39399451234432376\n",
      "Epoch 2550, reconstruction losses: 0.01402508585095618, regression losses: 0.16294107863791918, validation losses: 0.43268964356658246\n",
      "Epoch 2551, reconstruction losses: 0.015369924456595496, regression losses: 0.12901183583386017, validation losses: 0.6157463037511961\n",
      "Epoch 2552, reconstruction losses: 0.014087079003261812, regression losses: 0.14028839310862937, validation losses: 0.48266415589172246\n",
      "Epoch 2553, reconstruction losses: 0.013185213814270942, regression losses: 0.17449220796634207, validation losses: 0.48110834788466206\n",
      "Epoch 2554, reconstruction losses: 0.015587849815823125, regression losses: 0.14032503101883806, validation losses: 0.6458673526599847\n",
      "Epoch 2555, reconstruction losses: 0.014161853057202054, regression losses: 0.13690130076545282, validation losses: 0.49753831926597875\n",
      "Epoch 2556, reconstruction losses: 0.013355629787073216, regression losses: 0.08871709232000029, validation losses: 0.47159024379494324\n",
      "Epoch 2557, reconstruction losses: 0.01583334077347573, regression losses: 0.12393359949592345, validation losses: 0.46831465194306726\n",
      "Epoch 2558, reconstruction losses: 0.01318236555457576, regression losses: 0.09266494992207862, validation losses: 0.45559983821410505\n",
      "Epoch 2559, reconstruction losses: 0.010612400031882366, regression losses: 0.08795860247925232, validation losses: 0.47050347588721075\n",
      "Epoch 2560, reconstruction losses: 0.014341818484680795, regression losses: 0.11710212048234542, validation losses: 0.4975329142041007\n",
      "Epoch 2561, reconstruction losses: 0.01285562993332955, regression losses: 0.11058286657946449, validation losses: 0.4582698525797837\n",
      "Epoch 2562, reconstruction losses: 0.011616727234562607, regression losses: 0.10999680832963543, validation losses: 0.43417237950955817\n",
      "Epoch 2563, reconstruction losses: 0.012541051709938402, regression losses: 0.09671936126210588, validation losses: 0.42466532520529465\n",
      "Epoch 2564, reconstruction losses: 0.011684442234574523, regression losses: 0.09838242041963162, validation losses: 0.4121118541798785\n",
      "Epoch 2565, reconstruction losses: 0.01226274861848888, regression losses: 0.10639760264706966, validation losses: 0.41817833841565166\n",
      "Epoch 2566, reconstruction losses: 0.0121691465936063, regression losses: 0.09182771712732629, validation losses: 0.5163619954424696\n",
      "Epoch 2567, reconstruction losses: 0.015141927399072334, regression losses: 0.10435383685395976, validation losses: 0.5023892995607547\n",
      "Epoch 2568, reconstruction losses: 0.013860048392835243, regression losses: 0.10026713808545011, validation losses: 0.4355084136914749\n",
      "Epoch 2569, reconstruction losses: 0.01220696984223806, regression losses: 0.11473307705117547, validation losses: 0.4393013347619173\n",
      "Epoch 2570, reconstruction losses: 0.013068040733089224, regression losses: 0.11071903592259205, validation losses: 0.4201862810563309\n",
      "Epoch 2571, reconstruction losses: 0.012223481709176597, regression losses: 0.09563103110562514, validation losses: 0.46297014882707227\n",
      "Epoch 2572, reconstruction losses: 0.013468209553700069, regression losses: 0.09376560251749252, validation losses: 0.3973941588136108\n",
      "Epoch 2573, reconstruction losses: 0.013698442361890476, regression losses: 0.10558030732172818, validation losses: 0.39421530594961607\n",
      "Epoch 2574, reconstruction losses: 0.01276250813072181, regression losses: 0.1148981018177338, validation losses: 0.40448900794134834\n",
      "Epoch 2575, reconstruction losses: 0.017059708697742735, regression losses: 0.10200206325822067, validation losses: 0.42707201540208006\n",
      "Epoch 2576, reconstruction losses: 0.0121189145539363, regression losses: 0.12103438908829038, validation losses: 0.47821921616206736\n",
      "Epoch 2577, reconstruction losses: 0.012605746250863314, regression losses: 0.0955842238511296, validation losses: 0.4512705629794363\n",
      "Epoch 2578, reconstruction losses: 0.012099571330303021, regression losses: 0.11762379687697228, validation losses: 0.4238399786911334\n",
      "Epoch 2579, reconstruction losses: 0.014023956310233579, regression losses: 0.12280052818975437, validation losses: 0.43824007596602865\n",
      "Epoch 2580, reconstruction losses: 0.013387563450900353, regression losses: 0.12796944137935312, validation losses: 0.4014217477452189\n",
      "Epoch 2581, reconstruction losses: 0.01528599594812764, regression losses: 0.12340221616507527, validation losses: 0.49141550492269304\n",
      "Epoch 2582, reconstruction losses: 0.0256622890179566, regression losses: 0.33593900080578587, validation losses: 0.5284688273503878\n",
      "Epoch 2583, reconstruction losses: 0.012236621835528528, regression losses: 0.09934103014989766, validation losses: 0.6067904086884811\n",
      "Epoch 2584, reconstruction losses: 0.012639632533653888, regression losses: 0.11000557333960607, validation losses: 0.5596316386509321\n",
      "Epoch 2585, reconstruction losses: 0.013460720605275155, regression losses: 0.12216259479733525, validation losses: 0.46547752416299143\n",
      "Epoch 2586, reconstruction losses: 0.013007066951738144, regression losses: 0.08571318951473277, validation losses: 0.5170141277441261\n",
      "Epoch 2587, reconstruction losses: 0.011786811352187626, regression losses: 0.09588448623752946, validation losses: 0.5628123680563711\n",
      "Epoch 2588, reconstruction losses: 0.01795427535510725, regression losses: 0.10708120425534715, validation losses: 0.482087874394996\n",
      "Epoch 2589, reconstruction losses: 0.013554219193920186, regression losses: 0.12464465051615693, validation losses: 0.4573701013089675\n",
      "Epoch 2590, reconstruction losses: 0.014476485965887416, regression losses: 0.08577594140557543, validation losses: 0.4668365200049881\n",
      "Epoch 2591, reconstruction losses: 0.012689036834544845, regression losses: 0.11759503881170036, validation losses: 0.47266299561364034\n",
      "Epoch 2592, reconstruction losses: 0.013073078316406538, regression losses: 0.11201819140003995, validation losses: 0.4759530120226331\n",
      "Epoch 2593, reconstruction losses: 0.01400016729406332, regression losses: 0.0908256767165818, validation losses: 0.4575884671877312\n",
      "Epoch 2594, reconstruction losses: 0.01312391221921428, regression losses: 0.11737197816976447, validation losses: 0.42682962905701427\n",
      "Epoch 2595, reconstruction losses: 0.012715921989873038, regression losses: 0.117972311050916, validation losses: 0.4120122667105078\n",
      "Epoch 2596, reconstruction losses: 0.016325129870308517, regression losses: 0.09745136503588246, validation losses: 0.39842801614389545\n",
      "Epoch 2597, reconstruction losses: 0.01547041430172422, regression losses: 0.3567157638471636, validation losses: 0.4352269425577262\n",
      "Epoch 2598, reconstruction losses: 0.01322780881587114, regression losses: 0.12825141103344437, validation losses: 0.661825849810417\n",
      "Epoch 2599, reconstruction losses: 0.01358752944942413, regression losses: 0.09888029229042863, validation losses: 0.5866854189806862\n",
      "Epoch 2600, reconstruction losses: 0.014218685658175616, regression losses: 0.14192822127323915, validation losses: 0.5082242210093252\n",
      "Epoch 2601, reconstruction losses: 0.013990639470069099, regression losses: 0.1038135327658325, validation losses: 0.48603599377659673\n",
      "Epoch 2602, reconstruction losses: 0.01327839788049232, regression losses: 0.09681666859198461, validation losses: 0.5109306458489123\n",
      "Epoch 2603, reconstruction losses: 0.01366836657457992, regression losses: 0.12951478457117113, validation losses: 0.4940212191234374\n",
      "Epoch 2604, reconstruction losses: 0.014448947268426243, regression losses: 0.16669388740746047, validation losses: 0.4435334256627774\n",
      "Epoch 2605, reconstruction losses: 0.013601796353943362, regression losses: 0.0879272186785127, validation losses: 0.4662722564956857\n",
      "Epoch 2606, reconstruction losses: 0.016842003283057794, regression losses: 0.14492999244273602, validation losses: 0.4300980750850608\n",
      "Epoch 2607, reconstruction losses: 0.013826746406729578, regression losses: 0.10724850752650504, validation losses: 0.4284649508549552\n",
      "Epoch 2608, reconstruction losses: 0.012640620578492665, regression losses: 0.08285457546457203, validation losses: 0.4899624149802295\n",
      "Epoch 2609, reconstruction losses: 0.01574785920302092, regression losses: 0.12525425114080546, validation losses: 0.541780395012792\n",
      "Epoch 2610, reconstruction losses: 0.013028242588878318, regression losses: 0.10925419872125625, validation losses: 0.539320686499887\n",
      "Epoch 2611, reconstruction losses: 0.011619015062027787, regression losses: 0.12055271575132034, validation losses: 0.5103218300532947\n",
      "Epoch 2612, reconstruction losses: 0.016679075736291335, regression losses: 0.16013083667764297, validation losses: 0.47338105294261706\n",
      "Epoch 2613, reconstruction losses: 0.012192427310240155, regression losses: 0.0910382856832885, validation losses: 0.49229144602587105\n",
      "Epoch 2614, reconstruction losses: 0.012866077268910323, regression losses: 0.11839141567782194, validation losses: 0.5143375123943804\n",
      "Epoch 2615, reconstruction losses: 0.012584267016680757, regression losses: 0.15155681457938294, validation losses: 0.4250323886653194\n",
      "Epoch 2616, reconstruction losses: 0.012602219303689401, regression losses: 0.10788765489496227, validation losses: 0.3965458634940498\n",
      "Epoch 2617, reconstruction losses: 0.013952437470484053, regression losses: 0.11725315083735587, validation losses: 0.39885377282122064\n",
      "Epoch 2618, reconstruction losses: 0.0104959161779716, regression losses: 0.06989240860350193, validation losses: 0.45371946877796293\n",
      "Epoch 2619, reconstruction losses: 0.012847951561327698, regression losses: 0.1179499915195063, validation losses: 0.4371450069486919\n",
      "Epoch 2620, reconstruction losses: 0.012353037145225454, regression losses: 0.10290592798696625, validation losses: 0.39845858788832994\n",
      "Epoch 2621, reconstruction losses: 0.014279866902182022, regression losses: 0.30208292446518226, validation losses: 0.40735443978934327\n",
      "Epoch 2622, reconstruction losses: 0.012148135716172768, regression losses: 0.08920496846660213, validation losses: 0.5411482640413989\n",
      "Epoch 2623, reconstruction losses: 0.018088368013347258, regression losses: 0.11936927447619108, validation losses: 0.5330831680517439\n",
      "Epoch 2624, reconstruction losses: 0.012792824298209984, regression losses: 0.10546158829701165, validation losses: 0.4896124555937196\n",
      "Epoch 2625, reconstruction losses: 0.014018031666551503, regression losses: 0.12433348385445168, validation losses: 0.5149350519224892\n",
      "Epoch 2626, reconstruction losses: 0.012289448471684008, regression losses: 0.08352126397346718, validation losses: 0.49911978168606685\n",
      "Epoch 2627, reconstruction losses: 0.012564738406942366, regression losses: 0.11450350709015476, validation losses: 0.49874074848499017\n",
      "Epoch 2628, reconstruction losses: 0.014817732262933548, regression losses: 0.1696985605625482, validation losses: 0.4605813163553636\n",
      "Epoch 2629, reconstruction losses: 0.011814999123614396, regression losses: 0.07876259349494102, validation losses: 0.5280164603482786\n",
      "Epoch 2630, reconstruction losses: 0.013891851784414254, regression losses: 0.12433863232460295, validation losses: 0.5710214289506667\n",
      "Epoch 2631, reconstruction losses: 0.011629560690856466, regression losses: 0.14746911595522633, validation losses: 0.5751945065530741\n",
      "Epoch 2632, reconstruction losses: 0.012115529764275051, regression losses: 0.10441977981753252, validation losses: 0.5460651868621691\n",
      "Epoch 2633, reconstruction losses: 0.014147137636860185, regression losses: 0.14279627093953898, validation losses: 0.45451207486676376\n",
      "Epoch 2634, reconstruction losses: 0.01706095006828111, regression losses: 0.12107079956706526, validation losses: 0.4261986974750519\n",
      "Epoch 2635, reconstruction losses: 0.013323587383344465, regression losses: 0.09459443919274343, validation losses: 0.4092464685494349\n",
      "Epoch 2636, reconstruction losses: 0.015559786579891342, regression losses: 0.11833674139406004, validation losses: 0.41215497820138564\n",
      "Epoch 2637, reconstruction losses: 0.022092248156735283, regression losses: 0.1883158967507679, validation losses: 0.41408892296087463\n",
      "Epoch 2638, reconstruction losses: 0.01317228427729834, regression losses: 0.08975908726707624, validation losses: 0.4434218112078552\n",
      "Epoch 2639, reconstruction losses: 0.011823258245516591, regression losses: 0.09561963579541978, validation losses: 0.47911433759988936\n",
      "Epoch 2640, reconstruction losses: 0.01752320282323935, regression losses: 0.17904380200283143, validation losses: 0.47271472236265677\n",
      "Epoch 2641, reconstruction losses: 0.01648846003338248, regression losses: 0.10961726312437615, validation losses: 0.5662866261729151\n",
      "Epoch 2642, reconstruction losses: 0.012047475017685823, regression losses: 0.07738501238748909, validation losses: 0.44355281794778545\n",
      "Epoch 2643, reconstruction losses: 0.012861619444145031, regression losses: 0.1017000251517351, validation losses: 0.4227041650073693\n",
      "Epoch 2644, reconstruction losses: 0.01185446295520447, regression losses: 0.1077143743047271, validation losses: 0.4109132951178643\n",
      "Epoch 2645, reconstruction losses: 0.014099992274013423, regression losses: 0.09450796529666718, validation losses: 0.41580234142633615\n",
      "Epoch 2646, reconstruction losses: 0.014544513145233156, regression losses: 0.07867165371329692, validation losses: 0.4453000366290023\n",
      "Epoch 2647, reconstruction losses: 0.01123176231784599, regression losses: 0.09027886175563413, validation losses: 0.4701620366286423\n",
      "Epoch 2648, reconstruction losses: 0.012737885101508462, regression losses: 0.08556742227234382, validation losses: 0.40455223183734823\n",
      "Epoch 2649, reconstruction losses: 0.013769672760459775, regression losses: 0.08930978811740081, validation losses: 0.38777591491886804\n",
      "Epoch 2650, reconstruction losses: 0.011187246685520937, regression losses: 0.09428560195932428, validation losses: 0.4218922034788643\n",
      "Epoch 2651, reconstruction losses: 0.012992189827063079, regression losses: 0.17015080076723416, validation losses: 0.426147720566041\n",
      "Epoch 2652, reconstruction losses: 0.012009591509431431, regression losses: 0.08820653691152824, validation losses: 0.4089234619305919\n",
      "Epoch 2653, reconstruction losses: 0.013159601233997056, regression losses: 0.10890034955555614, validation losses: 0.41090960543209865\n",
      "Epoch 2654, reconstruction losses: 0.017552064094584804, regression losses: 0.10675677092379295, validation losses: 0.3934561920141497\n",
      "Epoch 2655, reconstruction losses: 0.020453913148264283, regression losses: 0.1464251337722417, validation losses: 0.40146006770967807\n",
      "Epoch 2656, reconstruction losses: 0.014487323957031489, regression losses: 0.16683149327153673, validation losses: 0.4491601560670939\n",
      "Epoch 2657, reconstruction losses: 0.01128780826803531, regression losses: 0.0996610891394452, validation losses: 0.4018022662858475\n",
      "Epoch 2658, reconstruction losses: 0.014448180340148, regression losses: 0.13258080538813355, validation losses: 0.4394823996386723\n",
      "Epoch 2659, reconstruction losses: 0.011763020011697089, regression losses: 0.10727350901145918, validation losses: 0.46777556798881337\n",
      "Epoch 2660, reconstruction losses: 0.011899082075628878, regression losses: 0.103771310388001, validation losses: 0.431641374366831\n",
      "Epoch 2661, reconstruction losses: 0.014158791464063618, regression losses: 0.09861141435420821, validation losses: 0.46510244266100986\n",
      "Epoch 2662, reconstruction losses: 0.012056826558482142, regression losses: 0.07590816114910956, validation losses: 0.45779570964423366\n",
      "Epoch 2663, reconstruction losses: 0.014899992273328264, regression losses: 0.10412329742419181, validation losses: 0.4641054920818544\n",
      "Epoch 2664, reconstruction losses: 0.011620350108507614, regression losses: 0.12284958098058389, validation losses: 0.4201553459480274\n",
      "Epoch 2665, reconstruction losses: 0.013588088411132876, regression losses: 0.10086955041317461, validation losses: 0.43137168598879616\n",
      "Epoch 2666, reconstruction losses: 0.011618312285533354, regression losses: 0.08658064690696288, validation losses: 0.4231315948354497\n",
      "Epoch 2667, reconstruction losses: 0.014073914784357265, regression losses: 0.10750350977625309, validation losses: 0.43378903846099304\n",
      "Epoch 2668, reconstruction losses: 0.011333184200844122, regression losses: 0.08736861154693511, validation losses: 0.4658604001403225\n",
      "Epoch 2669, reconstruction losses: 0.015691239306772832, regression losses: 0.1612737224740953, validation losses: 0.39848312557266\n",
      "Epoch 2670, reconstruction losses: 0.013123317768136002, regression losses: 0.10456690521199606, validation losses: 0.3885765325316709\n",
      "Epoch 2671, reconstruction losses: 0.01581772997421915, regression losses: 0.09166584352280525, validation losses: 0.3920266051602453\n",
      "Epoch 2672, reconstruction losses: 0.015654945608772293, regression losses: 0.1480935618427687, validation losses: 0.3946517571039183\n",
      "Epoch 2673, reconstruction losses: 0.014848888304740841, regression losses: 0.11824449082491335, validation losses: 0.3780643620140093\n",
      "Epoch 2674, reconstruction losses: 0.01190730073007468, regression losses: 0.08283365451809355, validation losses: 0.4170615968322742\n",
      "Epoch 2675, reconstruction losses: 0.011447049741515754, regression losses: 0.11920441385353871, validation losses: 0.3953483495658928\n",
      "Epoch 2676, reconstruction losses: 0.010726815462411606, regression losses: 0.0887481766516447, validation losses: 0.3709328739498326\n",
      "Epoch 2677, reconstruction losses: 0.013067257043654808, regression losses: 0.10168883663467397, validation losses: 0.37487195055332856\n",
      "Epoch 2678, reconstruction losses: 0.012947632298430435, regression losses: 0.11991966267015462, validation losses: 0.39828858352844004\n",
      "Epoch 2679, reconstruction losses: 0.016298582259665628, regression losses: 0.11146175643701776, validation losses: 0.392972941793703\n",
      "Epoch 2680, reconstruction losses: 0.013325009298684949, regression losses: 0.0813791285809776, validation losses: 0.4114336506618308\n",
      "Epoch 2681, reconstruction losses: 0.012990672902886845, regression losses: 0.13489191424005118, validation losses: 0.42298509355620684\n",
      "Epoch 2682, reconstruction losses: 0.013961990240555182, regression losses: 0.10252041266189935, validation losses: 0.4324025506872661\n",
      "Epoch 2683, reconstruction losses: 0.014194993295730636, regression losses: 0.11002783626986502, validation losses: 0.41586966561782784\n",
      "Epoch 2684, reconstruction losses: 0.011928287928125565, regression losses: 0.10576238198867474, validation losses: 0.42788060179059223\n",
      "Epoch 2685, reconstruction losses: 0.012359187778083555, regression losses: 0.08429321057504421, validation losses: 0.4369391021499076\n",
      "Epoch 2686, reconstruction losses: 0.014333253147283842, regression losses: 0.11386038676455194, validation losses: 0.414486796167391\n",
      "Epoch 2687, reconstruction losses: 0.011451160417750374, regression losses: 0.09416062679237804, validation losses: 0.42318066680399335\n",
      "Epoch 2688, reconstruction losses: 0.013538683352272785, regression losses: 0.08408562416124961, validation losses: 0.4270053996697073\n",
      "Epoch 2689, reconstruction losses: 0.01466923745701828, regression losses: 0.13047315542709415, validation losses: 0.4116420292255176\n",
      "Epoch 2690, reconstruction losses: 0.014123904601945259, regression losses: 0.10185729568639529, validation losses: 0.3972545890439442\n",
      "Epoch 2691, reconstruction losses: 0.010803931817886369, regression losses: 0.08140466155452737, validation losses: 0.38863427279659124\n",
      "Epoch 2692, reconstruction losses: 0.013753509607171666, regression losses: 0.10164786731799386, validation losses: 0.3757599801724542\n",
      "Epoch 2693, reconstruction losses: 0.020773901067008806, regression losses: 0.21869567879483592, validation losses: 0.3929679701944327\n",
      "Epoch 2694, reconstruction losses: 0.011526003771042294, regression losses: 0.07982581650215945, validation losses: 0.697703410376243\n",
      "Epoch 2695, reconstruction losses: 0.0164634891297055, regression losses: 0.1858881672888707, validation losses: 0.6192712169766379\n",
      "Epoch 2696, reconstruction losses: 0.01597435950068841, regression losses: 0.15309670993448166, validation losses: 0.6108847319073801\n",
      "Epoch 2697, reconstruction losses: 0.016083444576004823, regression losses: 0.14743673165365412, validation losses: 0.6093031929329165\n",
      "Epoch 2698, reconstruction losses: 0.014823152596212691, regression losses: 0.14457205382493366, validation losses: 0.5426589928149843\n",
      "Epoch 2699, reconstruction losses: 0.013266048768619525, regression losses: 0.13020163572597995, validation losses: 0.45471565447804835\n",
      "Epoch 2700, reconstruction losses: 0.01447518367889383, regression losses: 0.09544988418109193, validation losses: 0.4682447210077746\n",
      "Epoch 2701, reconstruction losses: 0.012824116255021624, regression losses: 0.13378958599356616, validation losses: 0.4596268616538382\n",
      "Epoch 2702, reconstruction losses: 0.012658140219618955, regression losses: 0.08654306758930788, validation losses: 0.3817302230513036\n",
      "Epoch 2703, reconstruction losses: 0.014872290677649516, regression losses: 0.10583356495664555, validation losses: 0.3823004290572604\n",
      "Epoch 2704, reconstruction losses: 0.011441490672678198, regression losses: 0.10825362999864216, validation losses: 0.38090617831239765\n",
      "Epoch 2705, reconstruction losses: 0.012814436367823874, regression losses: 0.14595398362726109, validation losses: 0.42859371965466697\n",
      "Epoch 2706, reconstruction losses: 0.01798739783717545, regression losses: 0.14372870753021214, validation losses: 0.49533799751217017\n",
      "Epoch 2707, reconstruction losses: 0.01479066351716804, regression losses: 0.12399499771664847, validation losses: 0.6144411548172438\n",
      "Epoch 2708, reconstruction losses: 0.01419737609673275, regression losses: 0.1273446192082895, validation losses: 0.4402158292900727\n",
      "Epoch 2709, reconstruction losses: 0.013159912543700417, regression losses: 0.10792826366197225, validation losses: 0.4887979253501649\n",
      "Epoch 2710, reconstruction losses: 0.013580227944522088, regression losses: 0.10102897484522871, validation losses: 0.44196573913473935\n",
      "Epoch 2711, reconstruction losses: 0.012119188877389145, regression losses: 0.08764349739081453, validation losses: 0.3777004253227589\n",
      "Epoch 2712, reconstruction losses: 0.01281963832313265, regression losses: 0.09354095325269576, validation losses: 0.39032489836076223\n",
      "Epoch 2713, reconstruction losses: 0.010630684830960122, regression losses: 0.06284955622143382, validation losses: 0.3947435714490428\n",
      "Epoch 2714, reconstruction losses: 0.014677886094664559, regression losses: 0.1173319571199589, validation losses: 0.3902362154048464\n",
      "Epoch 2715, reconstruction losses: 0.011982990424725556, regression losses: 0.1340920770571762, validation losses: 0.3796135600924919\n",
      "Epoch 2716, reconstruction losses: 0.012479969045168992, regression losses: 0.0893799407573598, validation losses: 0.3813477516491057\n",
      "Epoch 2717, reconstruction losses: 0.012820210016133904, regression losses: 0.1593612705252047, validation losses: 0.36945580193822475\n",
      "Epoch 2718, reconstruction losses: 0.013985134879722704, regression losses: 0.1275907066667131, validation losses: 0.37519179206953196\n",
      "Epoch 2719, reconstruction losses: 0.01147608646020827, regression losses: 0.07907385736193284, validation losses: 0.39007121364697944\n",
      "Epoch 2720, reconstruction losses: 0.010366886711998426, regression losses: 0.06733884535593211, validation losses: 0.4129538876384956\n",
      "Epoch 2721, reconstruction losses: 0.01294729278495392, regression losses: 0.09149533863777398, validation losses: 0.3797157615154806\n",
      "Epoch 2722, reconstruction losses: 0.015013330974117764, regression losses: 0.08662842568928704, validation losses: 0.39076564648775075\n",
      "Epoch 2723, reconstruction losses: 0.014928285409993669, regression losses: 0.12286776432887234, validation losses: 0.3886500534375366\n",
      "Epoch 2724, reconstruction losses: 0.012227830000115299, regression losses: 0.1396205571682497, validation losses: 0.48806764437773786\n",
      "Epoch 2725, reconstruction losses: 0.012870301633961292, regression losses: 0.08257619923274263, validation losses: 0.5381995493486673\n",
      "Epoch 2726, reconstruction losses: 0.011647902532060404, regression losses: 0.14501929512883335, validation losses: 0.45713452516481135\n",
      "Epoch 2727, reconstruction losses: 0.013019731705082414, regression losses: 0.07893147891826346, validation losses: 0.38813296671033987\n",
      "Epoch 2728, reconstruction losses: 0.013956058185199982, regression losses: 0.11324869161393783, validation losses: 0.41367481661824285\n",
      "Epoch 2729, reconstruction losses: 0.013745265125027288, regression losses: 0.10428159133318836, validation losses: 0.369205110659213\n",
      "Epoch 2730, reconstruction losses: 0.01466610291749364, regression losses: 0.10400036149469939, validation losses: 0.40064704039642646\n",
      "Epoch 2731, reconstruction losses: 0.011390618700983148, regression losses: 0.11173227032704398, validation losses: 0.4108488601945729\n",
      "Epoch 2732, reconstruction losses: 0.013918620926810272, regression losses: 0.10077999066183282, validation losses: 0.41266823251648904\n",
      "Epoch 2733, reconstruction losses: 0.013500702221635692, regression losses: 0.0904676579380833, validation losses: 0.4100460678160228\n",
      "Epoch 2734, reconstruction losses: 0.01474174263992811, regression losses: 0.08140538380738954, validation losses: 0.417074627043233\n",
      "Epoch 2735, reconstruction losses: 0.012630411102602932, regression losses: 0.13508792573057707, validation losses: 0.37778896786242255\n",
      "Epoch 2736, reconstruction losses: 0.01269202513643761, regression losses: 0.09975799172636754, validation losses: 0.3825985449390654\n",
      "Epoch 2737, reconstruction losses: 0.012867957785288814, regression losses: 0.11054671986383881, validation losses: 0.37516927680095974\n",
      "Epoch 2738, reconstruction losses: 0.013213031666048604, regression losses: 0.11979026522191945, validation losses: 0.435993897947995\n",
      "Epoch 2739, reconstruction losses: 0.015485263540070716, regression losses: 0.11800129461019761, validation losses: 0.4570131436097956\n",
      "Epoch 2740, reconstruction losses: 0.013908597747042884, regression losses: 0.1690306059799213, validation losses: 0.5083629384284978\n",
      "Epoch 2741, reconstruction losses: 0.022086674081209588, regression losses: 0.11418711094360443, validation losses: 0.5772992381788185\n",
      "Epoch 2742, reconstruction losses: 0.01179547942702706, regression losses: 0.11834186055452005, validation losses: 0.5427163803636219\n",
      "Epoch 2743, reconstruction losses: 0.012825106020268092, regression losses: 0.10445094012056638, validation losses: 0.4856445283390979\n",
      "Epoch 2744, reconstruction losses: 0.01899714860112762, regression losses: 0.13727548909359627, validation losses: 0.4427660370697385\n",
      "Epoch 2745, reconstruction losses: 0.01164023855660548, regression losses: 0.07894217669374547, validation losses: 0.44456560906056397\n",
      "Epoch 2746, reconstruction losses: 0.017691430830499944, regression losses: 0.24642580595039654, validation losses: 0.42920911087668406\n",
      "Epoch 2747, reconstruction losses: 0.013106945023079254, regression losses: 0.11209989086413333, validation losses: 0.7059513368207585\n",
      "Epoch 2748, reconstruction losses: 0.013487001705464317, regression losses: 0.12337812503328904, validation losses: 0.6014818198040704\n",
      "Epoch 2749, reconstruction losses: 0.014324394662643843, regression losses: 0.10622715364600913, validation losses: 0.4253056474509891\n",
      "Epoch 2750, reconstruction losses: 0.016877749513124842, regression losses: 0.13001643829827886, validation losses: 0.39404195035356226\n",
      "Epoch 2751, reconstruction losses: 0.016083161958715578, regression losses: 0.1340252785095338, validation losses: 0.4227504917060446\n",
      "Epoch 2752, reconstruction losses: 0.01254801291927382, regression losses: 0.14966118107354875, validation losses: 0.41473390804006394\n",
      "Epoch 2753, reconstruction losses: 0.021921944679387264, regression losses: 0.1390104705877519, validation losses: 0.45990356413029276\n",
      "Epoch 2754, reconstruction losses: 0.01563456895776427, regression losses: 0.07981688706300094, validation losses: 0.5199767315334562\n",
      "Epoch 2755, reconstruction losses: 0.015781659644045178, regression losses: 0.1232350635320234, validation losses: 0.4572389952528922\n",
      "Epoch 2756, reconstruction losses: 0.011814195984545818, regression losses: 0.089988118901258, validation losses: 0.4588804978734692\n",
      "Epoch 2757, reconstruction losses: 0.017798469887830196, regression losses: 0.1314062885049258, validation losses: 0.49043097152748716\n",
      "Epoch 2758, reconstruction losses: 0.017076759275509105, regression losses: 0.13119884821623645, validation losses: 0.4071778181491012\n",
      "Epoch 2759, reconstruction losses: 0.014432205136986, regression losses: 0.11925284115549592, validation losses: 0.4062342066968958\n",
      "Epoch 2760, reconstruction losses: 0.013286112380511922, regression losses: 0.0914217820382607, validation losses: 0.4434532316111516\n",
      "Epoch 2761, reconstruction losses: 0.012759244435127812, regression losses: 0.12204865282819344, validation losses: 0.42176873751931354\n",
      "Epoch 2762, reconstruction losses: 0.013172498198560607, regression losses: 0.11667150948936847, validation losses: 0.42319227728777314\n",
      "Epoch 2763, reconstruction losses: 0.013471592944387455, regression losses: 0.13858331392015483, validation losses: 0.4133016211811804\n",
      "Epoch 2764, reconstruction losses: 0.014301160059442503, regression losses: 0.11394334006791058, validation losses: 0.41398314377020007\n",
      "Epoch 2765, reconstruction losses: 0.012289108576861335, regression losses: 0.10032071285512532, validation losses: 0.42266133570439063\n",
      "Epoch 2766, reconstruction losses: 0.012837029389034197, regression losses: 0.0953123575913844, validation losses: 0.41558499593409304\n",
      "Epoch 2767, reconstruction losses: 0.012148931235515735, regression losses: 0.08758768743318895, validation losses: 0.39845409459509384\n",
      "Epoch 2768, reconstruction losses: 0.01582616932524427, regression losses: 0.1159227476577202, validation losses: 0.42021023003853886\n",
      "Epoch 2769, reconstruction losses: 0.014804657818695496, regression losses: 0.10017982614434807, validation losses: 0.46857297859451047\n",
      "Epoch 2770, reconstruction losses: 0.012785713752700024, regression losses: 0.06992966186389651, validation losses: 0.4429137031530036\n",
      "Epoch 2771, reconstruction losses: 0.01417871508609828, regression losses: 0.11367306151627905, validation losses: 0.41108057615477045\n",
      "Epoch 2772, reconstruction losses: 0.011270357723342134, regression losses: 0.08066658007321835, validation losses: 0.4033507610364748\n",
      "Epoch 2773, reconstruction losses: 0.0112561978389256, regression losses: 0.08637357079548688, validation losses: 0.39697755563842946\n",
      "Epoch 2774, reconstruction losses: 0.013956711054398578, regression losses: 0.23531410091547034, validation losses: 0.3874615969512718\n",
      "Epoch 2775, reconstruction losses: 0.012759834054032108, regression losses: 0.11174735278737069, validation losses: 0.3883463907587906\n",
      "Epoch 2776, reconstruction losses: 0.010558210291866786, regression losses: 0.09351971348751265, validation losses: 0.42622717437567337\n",
      "Epoch 2777, reconstruction losses: 0.01905425081535512, regression losses: 0.3824543272390948, validation losses: 0.4810428259530168\n",
      "Epoch 2778, reconstruction losses: 0.014672123681578447, regression losses: 0.1333200810782292, validation losses: 0.8188898603065715\n",
      "Epoch 2779, reconstruction losses: 0.014116983229819862, regression losses: 0.15391086618520666, validation losses: 0.6451594861944203\n",
      "Epoch 2780, reconstruction losses: 0.013474194205468491, regression losses: 0.10744462601482263, validation losses: 0.5245921774918597\n",
      "Epoch 2781, reconstruction losses: 0.013132795726658058, regression losses: 0.1197984064699754, validation losses: 0.4605819886582832\n",
      "Epoch 2782, reconstruction losses: 0.01625044118074976, regression losses: 0.11050400327816415, validation losses: 0.4557640781592904\n",
      "Epoch 2783, reconstruction losses: 0.01633291236744706, regression losses: 0.08928871345387933, validation losses: 0.4547747833527353\n",
      "Epoch 2784, reconstruction losses: 0.016073416448701416, regression losses: 0.10319234093134678, validation losses: 0.46007654398130104\n",
      "Epoch 2785, reconstruction losses: 0.010809595404876847, regression losses: 0.07880087342490778, validation losses: 0.4375566126611171\n",
      "Epoch 2786, reconstruction losses: 0.013320491429425076, regression losses: 0.09772517097695467, validation losses: 0.4202194575506268\n",
      "Epoch 2787, reconstruction losses: 0.011838612816394643, regression losses: 0.09958334533185122, validation losses: 0.39633077766531133\n",
      "Epoch 2788, reconstruction losses: 0.011327651003261892, regression losses: 0.06802116561155053, validation losses: 0.411457047011249\n",
      "Epoch 2789, reconstruction losses: 0.01240017879955109, regression losses: 0.14157763736427423, validation losses: 0.4463565748649574\n",
      "Epoch 2790, reconstruction losses: 0.012727448247942256, regression losses: 0.10048318733210149, validation losses: 0.5066694750298919\n",
      "Epoch 2791, reconstruction losses: 0.015795915695579893, regression losses: 0.11412789881472667, validation losses: 0.4552170939352704\n",
      "Epoch 2792, reconstruction losses: 0.012425023694616006, regression losses: 0.08812732182389696, validation losses: 0.40667172077160235\n",
      "Epoch 2793, reconstruction losses: 0.012252572922471483, regression losses: 0.10756222751486517, validation losses: 0.38333323730075797\n",
      "Epoch 2794, reconstruction losses: 0.012160940574906716, regression losses: 0.10304104939459416, validation losses: 0.38294114773044674\n",
      "Epoch 2795, reconstruction losses: 0.012248786980273797, regression losses: 0.11713067044222955, validation losses: 0.37501811450478556\n",
      "Epoch 2796, reconstruction losses: 0.011056373452409273, regression losses: 0.08958390217332719, validation losses: 0.377077949993707\n",
      "Epoch 2797, reconstruction losses: 0.013841145757923614, regression losses: 0.12998967158676786, validation losses: 0.39385854114459373\n",
      "Epoch 2798, reconstruction losses: 0.012655676297355629, regression losses: 0.13165935055950154, validation losses: 0.3939736056513203\n",
      "Epoch 2799, reconstruction losses: 0.013606978939502204, regression losses: 0.11682771261036401, validation losses: 0.42706186303591215\n",
      "Epoch 2800, reconstruction losses: 0.012721265857137435, regression losses: 0.1111958215621001, validation losses: 0.4313141606367381\n",
      "Epoch 2801, reconstruction losses: 0.017120188830374843, regression losses: 0.09209793770680685, validation losses: 0.41288405363400765\n",
      "Epoch 2802, reconstruction losses: 0.014422243138670758, regression losses: 0.09858845307930826, validation losses: 0.3817852069424074\n",
      "Epoch 2803, reconstruction losses: 0.011591963492513582, regression losses: 0.13489388755781123, validation losses: 0.37594367624205743\n",
      "Epoch 2804, reconstruction losses: 0.016572481843550407, regression losses: 0.11937515898188572, validation losses: 0.3884734212272853\n",
      "Epoch 2805, reconstruction losses: 0.014287495943299144, regression losses: 0.12254485493740266, validation losses: 0.45814180924574194\n",
      "Epoch 2806, reconstruction losses: 0.02271788445337941, regression losses: 0.1855881514091873, validation losses: 0.4032578008281503\n",
      "Epoch 2807, reconstruction losses: 0.018315947010276758, regression losses: 0.16840242759511342, validation losses: 0.4258275939059403\n",
      "Epoch 2808, reconstruction losses: 0.014977439444010261, regression losses: 0.08993154758305935, validation losses: 0.39661865294096826\n",
      "Epoch 2809, reconstruction losses: 0.012696055290654758, regression losses: 0.10102337386602986, validation losses: 0.40905790555290855\n",
      "Epoch 2810, reconstruction losses: 0.017302160500777777, regression losses: 0.32885414494463405, validation losses: 0.44390245862935684\n",
      "Epoch 2811, reconstruction losses: 0.014360532559384145, regression losses: 0.07835890237297158, validation losses: 0.5678453396232506\n",
      "Epoch 2812, reconstruction losses: 0.014203768842509956, regression losses: 0.13257739251738773, validation losses: 0.5066054661996943\n",
      "Epoch 2813, reconstruction losses: 0.014121504409681403, regression losses: 0.11013455938570606, validation losses: 0.5160150219420828\n",
      "Epoch 2814, reconstruction losses: 0.013246066860477988, regression losses: 0.10666212507439204, validation losses: 0.47031802354340374\n",
      "Epoch 2815, reconstruction losses: 0.012147775689065598, regression losses: 0.09801989032804238, validation losses: 0.4507512503497937\n",
      "Epoch 2816, reconstruction losses: 0.01137120572720151, regression losses: 0.10079476733582576, validation losses: 0.47074571380051516\n",
      "Epoch 2817, reconstruction losses: 0.012494332447278699, regression losses: 0.08949543292544858, validation losses: 0.5152380287407555\n",
      "Epoch 2818, reconstruction losses: 0.014392736497761256, regression losses: 0.11931361270800843, validation losses: 0.49834482397923996\n",
      "Epoch 2819, reconstruction losses: 0.01222583240160281, regression losses: 0.09601768271957592, validation losses: 0.4890387206583716\n",
      "Epoch 2820, reconstruction losses: 0.011413594347548808, regression losses: 0.0857226825042097, validation losses: 0.45397087371032274\n",
      "Epoch 2821, reconstruction losses: 0.010645947682793724, regression losses: 0.0927523124750695, validation losses: 0.4393652376519271\n",
      "Epoch 2822, reconstruction losses: 0.012405952713132211, regression losses: 0.12290190140991668, validation losses: 0.42737271479407574\n",
      "Epoch 2823, reconstruction losses: 0.012130260509065603, regression losses: 0.11350130927803218, validation losses: 0.40451862187147336\n",
      "Epoch 2824, reconstruction losses: 0.01391971044973386, regression losses: 0.09362027968412398, validation losses: 0.41145204015989384\n",
      "Epoch 2825, reconstruction losses: 0.011240609161605996, regression losses: 0.09460623502211836, validation losses: 0.41340520530885916\n",
      "Epoch 2826, reconstruction losses: 0.012369920669778402, regression losses: 0.11041923350396975, validation losses: 0.3913906824529512\n",
      "Epoch 2827, reconstruction losses: 0.011896016518049824, regression losses: 0.11209135816010952, validation losses: 0.4111375449240889\n",
      "Epoch 2828, reconstruction losses: 0.011871859513431521, regression losses: 0.0961668932095375, validation losses: 0.3980007066788653\n",
      "Epoch 2829, reconstruction losses: 0.010853451229977742, regression losses: 0.08890594685348181, validation losses: 0.3786754281608246\n",
      "Epoch 2830, reconstruction losses: 0.02456258279440761, regression losses: 0.3432799768716431, validation losses: 0.3667577666939672\n",
      "Epoch 2831, reconstruction losses: 0.012546624477968137, regression losses: 0.09470663012279096, validation losses: 0.538987249786221\n",
      "Epoch 2832, reconstruction losses: 0.01450656745272051, regression losses: 0.10862288318633345, validation losses: 0.5084582673090905\n",
      "Epoch 2833, reconstruction losses: 0.01282002968189604, regression losses: 0.12616284998246097, validation losses: 0.4078673714628955\n",
      "Epoch 2834, reconstruction losses: 0.012424095855080253, regression losses: 0.10793733031793183, validation losses: 0.42123923918180456\n",
      "Epoch 2835, reconstruction losses: 0.012016256109334895, regression losses: 0.17991445980047005, validation losses: 0.4035414290883265\n",
      "Epoch 2836, reconstruction losses: 0.010666989135315542, regression losses: 0.08782983493136395, validation losses: 0.4014859555791346\n",
      "Epoch 2837, reconstruction losses: 0.011317277819280757, regression losses: 0.15888837264703953, validation losses: 0.3976106577878191\n",
      "Epoch 2838, reconstruction losses: 0.011069253517302063, regression losses: 0.09768078687950005, validation losses: 0.42253923676593697\n",
      "Epoch 2839, reconstruction losses: 0.011590660850006183, regression losses: 0.09752394099991275, validation losses: 0.4383640005054258\n",
      "Epoch 2840, reconstruction losses: 0.012382294518180677, regression losses: 0.09049519930565987, validation losses: 0.40986388895375686\n",
      "Epoch 2841, reconstruction losses: 0.012690679022581176, regression losses: 0.11500958729490723, validation losses: 0.38329276429498105\n",
      "Epoch 2842, reconstruction losses: 0.01171617349929065, regression losses: 0.10567044648241142, validation losses: 0.3987568756649395\n",
      "Epoch 2843, reconstruction losses: 0.013030919404015549, regression losses: 0.10368443166740338, validation losses: 0.4325716336146924\n",
      "Epoch 2844, reconstruction losses: 0.015036249687123707, regression losses: 0.1540504924647746, validation losses: 0.40914437246729335\n",
      "Epoch 2845, reconstruction losses: 0.01292120423680675, regression losses: 0.12703916024320883, validation losses: 0.3948960620557755\n",
      "Epoch 2846, reconstruction losses: 0.011605023206760608, regression losses: 0.1176433257716561, validation losses: 0.4029484678550421\n",
      "Epoch 2847, reconstruction losses: 0.012637121370521118, regression losses: 0.14669688464045216, validation losses: 0.42809071351545636\n",
      "Epoch 2848, reconstruction losses: 0.012757905160154702, regression losses: 0.0974939162000284, validation losses: 0.6214573800781669\n",
      "Epoch 2849, reconstruction losses: 0.015485893193950405, regression losses: 0.15400290747257236, validation losses: 0.5417639488420708\n",
      "Epoch 2850, reconstruction losses: 0.013058822376783012, regression losses: 0.11890794021323403, validation losses: 0.4353082130952727\n",
      "Epoch 2851, reconstruction losses: 0.011475811203084897, regression losses: 0.10939200342868828, validation losses: 0.42748240155936656\n",
      "Epoch 2852, reconstruction losses: 0.01122660928857987, regression losses: 0.08903995775270838, validation losses: 0.40532760946727087\n",
      "Epoch 2853, reconstruction losses: 0.010356578937269814, regression losses: 0.09288351974549186, validation losses: 0.39845555388067394\n",
      "Epoch 2854, reconstruction losses: 0.013428969934952054, regression losses: 0.10751175000007668, validation losses: 0.40449810673049635\n",
      "Epoch 2855, reconstruction losses: 0.012157588350248253, regression losses: 0.10709414512023328, validation losses: 0.37466185038411814\n",
      "Epoch 2856, reconstruction losses: 0.012821908429072775, regression losses: 0.11436931266756462, validation losses: 0.40629063742680316\n",
      "Epoch 2857, reconstruction losses: 0.013048249393371484, regression losses: 0.09312313860419486, validation losses: 0.4049398334462745\n",
      "Epoch 2858, reconstruction losses: 0.012320669937763484, regression losses: 0.07951407905317066, validation losses: 0.38851622553569093\n",
      "Epoch 2859, reconstruction losses: 0.01901510132547806, regression losses: 0.17633633007937063, validation losses: 0.36376776395583044\n",
      "Epoch 2860, reconstruction losses: 0.019132728514461954, regression losses: 0.14066008357691828, validation losses: 0.39362769705718204\n",
      "Epoch 2861, reconstruction losses: 0.013908428275012052, regression losses: 0.11567156033615542, validation losses: 0.40439583742789453\n",
      "Epoch 2862, reconstruction losses: 0.01230023644436565, regression losses: 0.07743812701743742, validation losses: 0.41052945810471897\n",
      "Epoch 2863, reconstruction losses: 0.01309524013910881, regression losses: 0.10731203014642307, validation losses: 0.3711053218134475\n",
      "Epoch 2864, reconstruction losses: 0.013683859575041871, regression losses: 0.10014804894400198, validation losses: 0.365669569419019\n",
      "Epoch 2865, reconstruction losses: 0.014469098468712614, regression losses: 0.08830951732269615, validation losses: 0.4009727301843513\n",
      "Epoch 2866, reconstruction losses: 0.011877529873904641, regression losses: 0.10278097445925978, validation losses: 0.39281118286196326\n",
      "Epoch 2867, reconstruction losses: 0.011667363506816745, regression losses: 0.09949694684711906, validation losses: 0.38965285645999825\n",
      "Epoch 2868, reconstruction losses: 0.011548019460148808, regression losses: 0.0793100448668734, validation losses: 0.35038544778715963\n",
      "Epoch 2869, reconstruction losses: 0.012062136580061906, regression losses: 0.09291977693886387, validation losses: 0.35453498766862146\n",
      "Epoch 2870, reconstruction losses: 0.014753758479509027, regression losses: 0.112727772236624, validation losses: 0.36216878460984997\n",
      "Epoch 2871, reconstruction losses: 0.01249558480811714, regression losses: 0.1074247177851153, validation losses: 0.36827661933082384\n",
      "Epoch 2872, reconstruction losses: 0.01165379270509209, regression losses: 0.09557843409563625, validation losses: 0.37809452423005546\n",
      "Epoch 2873, reconstruction losses: 0.013696449313769097, regression losses: 0.14129648564186661, validation losses: 0.35427852857305375\n",
      "Epoch 2874, reconstruction losses: 0.011339756267225486, regression losses: 0.09922390467250444, validation losses: 0.4437431329602343\n",
      "Epoch 2875, reconstruction losses: 0.013155589629568752, regression losses: 0.1200586372906395, validation losses: 0.45885688380307654\n",
      "Epoch 2876, reconstruction losses: 0.011785689126314933, regression losses: 0.09197596115926049, validation losses: 0.4532760204541171\n",
      "Epoch 2877, reconstruction losses: 0.011992469699856328, regression losses: 0.09321988832873157, validation losses: 0.42705221777504865\n",
      "Epoch 2878, reconstruction losses: 0.012630617694225134, regression losses: 0.10864476362819804, validation losses: 0.42500385292957976\n",
      "Epoch 2879, reconstruction losses: 0.012823293693114456, regression losses: 0.10740992792869503, validation losses: 0.41043494335759145\n",
      "Epoch 2880, reconstruction losses: 0.017815847290915836, regression losses: 0.1546930225541819, validation losses: 0.4167880221012418\n",
      "Epoch 2881, reconstruction losses: 0.012021733641879771, regression losses: 0.09892906670816773, validation losses: 0.39402551932954405\n",
      "Epoch 2882, reconstruction losses: 0.010198783921269782, regression losses: 0.07720900686491489, validation losses: 0.38719471281335854\n",
      "Epoch 2883, reconstruction losses: 0.014610872736915128, regression losses: 0.12080782833156967, validation losses: 0.3867732227269567\n",
      "Epoch 2884, reconstruction losses: 0.012420478900300572, regression losses: 0.10167929242036368, validation losses: 0.37328606452266155\n",
      "Epoch 2885, reconstruction losses: 0.015935535914751997, regression losses: 0.11187959978824721, validation losses: 0.36952901757905543\n",
      "Epoch 2886, reconstruction losses: 0.012246506877554108, regression losses: 0.08833515108942666, validation losses: 0.37902398685801014\n",
      "Epoch 2887, reconstruction losses: 0.01320490110922225, regression losses: 0.09069354180869345, validation losses: 0.35926190268690184\n",
      "Epoch 2888, reconstruction losses: 0.012926954181555584, regression losses: 0.07357048984712877, validation losses: 0.3650457542321098\n",
      "Epoch 2889, reconstruction losses: 0.014594966295475026, regression losses: 0.23306867544253854, validation losses: 0.3818210198961141\n",
      "Epoch 2890, reconstruction losses: 0.0136980355580094, regression losses: 0.13649072305342866, validation losses: 0.5126619566706361\n",
      "Epoch 2891, reconstruction losses: 0.009802423343636743, regression losses: 0.07408018509450075, validation losses: 0.4969737469099212\n",
      "Epoch 2892, reconstruction losses: 0.0153144262545361, regression losses: 0.12420823413278181, validation losses: 0.4376674032821028\n",
      "Epoch 2893, reconstruction losses: 0.010537568834173245, regression losses: 0.10258700490538848, validation losses: 0.4131029417227296\n",
      "Epoch 2894, reconstruction losses: 0.014503799172764805, regression losses: 0.13074975786016008, validation losses: 0.3896633326269858\n",
      "Epoch 2895, reconstruction losses: 0.011037293346450858, regression losses: 0.08015638901300035, validation losses: 0.36800353180266143\n",
      "Epoch 2896, reconstruction losses: 0.013343733959229286, regression losses: 0.10088949520375515, validation losses: 0.391645115143102\n",
      "Epoch 2897, reconstruction losses: 0.01950842853874325, regression losses: 0.16522185733795738, validation losses: 0.3838361740066746\n",
      "Epoch 2898, reconstruction losses: 0.011263097911055148, regression losses: 0.11048914583331808, validation losses: 0.5273336600642642\n",
      "Epoch 2899, reconstruction losses: 0.013355827665254097, regression losses: 0.12810380639026858, validation losses: 0.4883502368681846\n",
      "Epoch 2900, reconstruction losses: 0.013036547005421874, regression losses: 0.09025951705546212, validation losses: 0.40720380823679986\n",
      "Epoch 2901, reconstruction losses: 0.017395160782498614, regression losses: 0.10321276087751396, validation losses: 0.41177326144394144\n",
      "Epoch 2902, reconstruction losses: 0.013886525069793298, regression losses: 0.11498798191345867, validation losses: 0.38015180135200966\n",
      "Epoch 2903, reconstruction losses: 0.015217531967371653, regression losses: 0.13307532171638575, validation losses: 0.36488776610423\n",
      "Epoch 2904, reconstruction losses: 0.010975311432031128, regression losses: 0.07844901241135548, validation losses: 0.403080985110731\n",
      "Epoch 2905, reconstruction losses: 0.013731242442333322, regression losses: 0.10727379676846938, validation losses: 0.4079907237826107\n",
      "Epoch 2906, reconstruction losses: 0.014975589216057673, regression losses: 0.10724315696197102, validation losses: 0.3873493409203398\n",
      "Epoch 2907, reconstruction losses: 0.011323394302069753, regression losses: 0.10237232684402459, validation losses: 0.39494491250012276\n",
      "Epoch 2908, reconstruction losses: 0.012866236123410877, regression losses: 0.11362698211015221, validation losses: 0.3764962580217782\n",
      "Epoch 2909, reconstruction losses: 0.01258006038727203, regression losses: 0.09960049322249132, validation losses: 0.35694261820424256\n",
      "Epoch 2910, reconstruction losses: 0.0197271577546281, regression losses: 0.39317349525996215, validation losses: 0.3751191711594608\n",
      "Epoch 2911, reconstruction losses: 0.012099498384712167, regression losses: 0.09530014422915511, validation losses: 0.7534542013476498\n",
      "Epoch 2912, reconstruction losses: 0.011744301021641599, regression losses: 0.1823130785356072, validation losses: 0.6318483386067896\n",
      "Epoch 2913, reconstruction losses: 0.011098389173117992, regression losses: 0.09398989941070542, validation losses: 0.38088416517532464\n",
      "Epoch 2914, reconstruction losses: 0.016429025398643188, regression losses: 0.18444493745598822, validation losses: 0.42583376061598077\n",
      "Epoch 2915, reconstruction losses: 0.025078010276512335, regression losses: 0.4430771533382267, validation losses: 0.40423163559698017\n",
      "Epoch 2916, reconstruction losses: 0.01343432914035536, regression losses: 0.1266060685783351, validation losses: 0.7423754378354024\n",
      "Epoch 2917, reconstruction losses: 0.015455931330125452, regression losses: 0.1369206480404009, validation losses: 0.9561779318554559\n",
      "Epoch 2918, reconstruction losses: 0.015162872097118842, regression losses: 0.28180724790813066, validation losses: 0.7377174333436276\n",
      "Epoch 2919, reconstruction losses: 0.012620644869922534, regression losses: 0.1359146143080839, validation losses: 0.6226304031720223\n",
      "Epoch 2920, reconstruction losses: 0.015423782603882132, regression losses: 0.1193501123274059, validation losses: 0.5183876409623793\n",
      "Epoch 2921, reconstruction losses: 0.010939135468626479, regression losses: 0.09636671033815374, validation losses: 0.5054361804211537\n",
      "Epoch 2922, reconstruction losses: 0.016809945415778457, regression losses: 0.15774282813494966, validation losses: 0.4611290820951134\n",
      "Epoch 2923, reconstruction losses: 0.013878281399108879, regression losses: 0.12243913703553418, validation losses: 0.4309234440218912\n",
      "Epoch 2924, reconstruction losses: 0.01274935827548385, regression losses: 0.10959087205165452, validation losses: 0.41935514211114655\n",
      "Epoch 2925, reconstruction losses: 0.01273842072833429, regression losses: 0.089082365861496, validation losses: 0.3717681079311287\n",
      "Epoch 2926, reconstruction losses: 0.011673859366869847, regression losses: 0.08429782251795781, validation losses: 0.38371559011937745\n",
      "Epoch 2927, reconstruction losses: 0.012705662308383379, regression losses: 0.11446649382248705, validation losses: 0.38486468016038644\n",
      "Epoch 2928, reconstruction losses: 0.014771853406256908, regression losses: 0.11094457925058956, validation losses: 0.3849089531167385\n",
      "Epoch 2929, reconstruction losses: 0.014130304913387574, regression losses: 0.08312669111136874, validation losses: 0.3706700608812102\n",
      "Epoch 2930, reconstruction losses: 0.016151596925781775, regression losses: 0.11974701232828934, validation losses: 0.37076493923404213\n",
      "Epoch 2931, reconstruction losses: 0.014400610342878163, regression losses: 0.08493815853083414, validation losses: 0.4046611114214408\n",
      "Epoch 2932, reconstruction losses: 0.012605733429767448, regression losses: 0.09428719133352823, validation losses: 0.4149808549602596\n",
      "Epoch 2933, reconstruction losses: 0.01165252628777276, regression losses: 0.1156108734236305, validation losses: 0.42549423648773804\n",
      "Epoch 2934, reconstruction losses: 0.012130871411239698, regression losses: 0.10184387845739679, validation losses: 0.446370331419129\n",
      "Epoch 2935, reconstruction losses: 0.014724464432637717, regression losses: 0.13934020396168578, validation losses: 0.37372547366323416\n",
      "Epoch 2936, reconstruction losses: 0.014506345484268782, regression losses: 0.11216564667066839, validation losses: 0.38493728229237395\n",
      "Epoch 2937, reconstruction losses: 0.012638729174397994, regression losses: 0.08620773466520862, validation losses: 0.40163203869120523\n",
      "Epoch 2938, reconstruction losses: 0.016783849725448625, regression losses: 0.09082118743980684, validation losses: 0.36296876366259795\n",
      "Epoch 2939, reconstruction losses: 0.01312451951523408, regression losses: 0.11328163810250963, validation losses: 0.37755399300786086\n",
      "Epoch 2940, reconstruction losses: 0.013304541333381447, regression losses: 0.11333650018931694, validation losses: 0.3711312546237565\n",
      "Epoch 2941, reconstruction losses: 0.013346328027619736, regression losses: 0.10603467003239002, validation losses: 0.3807384056358293\n",
      "Epoch 2942, reconstruction losses: 0.015166057208685382, regression losses: 0.11470919848764738, validation losses: 0.4157375317145838\n",
      "Epoch 2943, reconstruction losses: 0.017177142551787185, regression losses: 0.1329077904295059, validation losses: 0.44082297143890825\n",
      "Epoch 2944, reconstruction losses: 0.016733301744311833, regression losses: 0.16075067112859762, validation losses: 0.35288345756140604\n",
      "Epoch 2945, reconstruction losses: 0.01418843196245379, regression losses: 0.09444363483301908, validation losses: 0.4043249437506192\n",
      "Epoch 2946, reconstruction losses: 0.012439291149289683, regression losses: 0.09405349059611395, validation losses: 0.4030895775646375\n",
      "Epoch 2947, reconstruction losses: 0.011612555468855038, regression losses: 0.083673251418704, validation losses: 0.34418964291822735\n",
      "Epoch 2948, reconstruction losses: 0.014307329805923037, regression losses: 0.1080532115075707, validation losses: 0.3787644398268981\n",
      "Epoch 2949, reconstruction losses: 0.01592065138442648, regression losses: 0.0995599155786979, validation losses: 0.38836993562396077\n",
      "Epoch 2950, reconstruction losses: 0.012731171484129488, regression losses: 0.1372959844074383, validation losses: 0.37767528728321\n",
      "Epoch 2951, reconstruction losses: 0.013724697924146954, regression losses: 0.0931360030160976, validation losses: 0.41368437199802216\n",
      "Epoch 2952, reconstruction losses: 0.015599293120398344, regression losses: 0.15478137088078256, validation losses: 0.3653567532946174\n",
      "Epoch 2953, reconstruction losses: 0.013446805530620113, regression losses: 0.1444893927359901, validation losses: 0.371746181532734\n",
      "Epoch 2954, reconstruction losses: 0.01113136309635621, regression losses: 0.10908059156367694, validation losses: 0.4140940335895973\n",
      "Epoch 2955, reconstruction losses: 0.012600795322269768, regression losses: 0.1236162497535411, validation losses: 0.39514531121479407\n",
      "Epoch 2956, reconstruction losses: 0.011245142986273675, regression losses: 0.09824059250073648, validation losses: 0.37852371190957934\n",
      "Epoch 2957, reconstruction losses: 0.01395661563003289, regression losses: 0.11145823189897885, validation losses: 0.4012610943297222\n",
      "Epoch 2958, reconstruction losses: 0.011965685066725532, regression losses: 0.09982438557377, validation losses: 0.3999580630688259\n",
      "Epoch 2959, reconstruction losses: 0.012857960991047749, regression losses: 0.12501112151321261, validation losses: 0.38650064789330424\n",
      "Epoch 2960, reconstruction losses: 0.015870939957509284, regression losses: 0.15849372831606495, validation losses: 0.37992543571298515\n",
      "Epoch 2961, reconstruction losses: 0.013925453190661052, regression losses: 0.30061058525316786, validation losses: 0.4114670876615295\n",
      "Epoch 2962, reconstruction losses: 0.013495962449416284, regression losses: 0.11882670108178123, validation losses: 0.672987067759933\n",
      "Epoch 2963, reconstruction losses: 0.016925688161051906, regression losses: 0.16037655978118298, validation losses: 0.8397600872235496\n",
      "Epoch 2964, reconstruction losses: 0.0107583515703518, regression losses: 0.11937933627289893, validation losses: 0.7339010773994437\n",
      "Epoch 2965, reconstruction losses: 0.016796491340353506, regression losses: 0.13261489727062323, validation losses: 0.6346550354830504\n",
      "Epoch 2966, reconstruction losses: 0.013500426354207905, regression losses: 0.11863008584485699, validation losses: 0.5867764527061536\n",
      "Epoch 2967, reconstruction losses: 0.014420612194965442, regression losses: 0.09041464207840394, validation losses: 0.5420376990482767\n",
      "Epoch 2968, reconstruction losses: 0.013241796283810234, regression losses: 0.13561741233434313, validation losses: 0.49787615450839895\n",
      "Epoch 2969, reconstruction losses: 0.01243924838002318, regression losses: 0.11644246373094949, validation losses: 0.4510080417091781\n",
      "Epoch 2970, reconstruction losses: 0.014255144254154544, regression losses: 0.09292620893600874, validation losses: 0.4243915762323188\n",
      "Epoch 2971, reconstruction losses: 0.011582994609225336, regression losses: 0.1070778966755762, validation losses: 0.43258701444378433\n",
      "Epoch 2972, reconstruction losses: 0.011779074429336631, regression losses: 0.10814548124929614, validation losses: 0.42006527455618536\n",
      "Epoch 2973, reconstruction losses: 0.012299247619387919, regression losses: 0.1216021003993296, validation losses: 0.4246175739997593\n",
      "Epoch 2974, reconstruction losses: 0.01057099812964266, regression losses: 0.07673805232230635, validation losses: 0.40700379786758767\n",
      "Epoch 2975, reconstruction losses: 0.01126558474442584, regression losses: 0.08458301418764437, validation losses: 0.38661454294340686\n",
      "Epoch 2976, reconstruction losses: 0.013308295908757525, regression losses: 0.10841740739703096, validation losses: 0.3560753271228901\n",
      "Epoch 2977, reconstruction losses: 0.011719282745846271, regression losses: 0.0979920235765023, validation losses: 0.3543613104778183\n",
      "Epoch 2978, reconstruction losses: 0.015541484147445127, regression losses: 0.11351564610913459, validation losses: 0.3554693131064429\n",
      "Epoch 2979, reconstruction losses: 0.011187640268775586, regression losses: 0.09001056051929568, validation losses: 0.43517896521489574\n",
      "Epoch 2980, reconstruction losses: 0.012763998550408053, regression losses: 0.10501868031220116, validation losses: 0.3829109557350069\n",
      "Epoch 2981, reconstruction losses: 0.01284953158161271, regression losses: 0.10323207675377855, validation losses: 0.36983405587411466\n",
      "Epoch 2982, reconstruction losses: 0.011512720610593545, regression losses: 0.09915867483286789, validation losses: 0.3696502650666428\n",
      "Epoch 2983, reconstruction losses: 0.014072691162874655, regression losses: 0.13471029684770197, validation losses: 0.35952498948585987\n",
      "Epoch 2984, reconstruction losses: 0.015208268666787404, regression losses: 0.09914946058277972, validation losses: 0.39826366749168396\n",
      "Epoch 2985, reconstruction losses: 0.01118195116330429, regression losses: 0.0868971682867598, validation losses: 0.37036899331061157\n",
      "Epoch 2986, reconstruction losses: 0.01162219087448898, regression losses: 0.09175745230145642, validation losses: 0.37542184997409717\n",
      "Epoch 2987, reconstruction losses: 0.015430826206104581, regression losses: 0.10100138037733407, validation losses: 0.38016719915982145\n",
      "Epoch 2988, reconstruction losses: 0.013084221497295379, regression losses: 0.12407080923340455, validation losses: 0.3767400710170899\n",
      "Epoch 2989, reconstruction losses: 0.013566092407316852, regression losses: 0.10906786818893939, validation losses: 0.39004025132332465\n",
      "Epoch 2990, reconstruction losses: 0.011183420189970662, regression losses: 0.10562043315273688, validation losses: 0.36422168499271645\n",
      "Epoch 2991, reconstruction losses: 0.010993254168970403, regression losses: 0.08243019062576344, validation losses: 0.3549763029202302\n",
      "Epoch 2992, reconstruction losses: 0.011733582260565877, regression losses: 0.08719645690386399, validation losses: 0.34903901100789403\n",
      "Epoch 2993, reconstruction losses: 0.01500066448962218, regression losses: 0.12599764594493618, validation losses: 0.3448704488028382\n",
      "Epoch 2994, reconstruction losses: 0.011310871189625028, regression losses: 0.10441574990014689, validation losses: 0.37609740276535875\n",
      "Epoch 2995, reconstruction losses: 0.013453114791496173, regression losses: 0.16189066349362294, validation losses: 0.520002713232975\n",
      "Epoch 2996, reconstruction losses: 0.01916493384608539, regression losses: 0.2242163864778805, validation losses: 0.5205499994351128\n",
      "Epoch 2997, reconstruction losses: 0.010755440971980676, regression losses: 0.07705854864829759, validation losses: 0.5858523811512412\n",
      "Epoch 2998, reconstruction losses: 0.014721298552286214, regression losses: 0.10415978349266189, validation losses: 0.43934678834918206\n",
      "Epoch 2999, reconstruction losses: 0.013831395711453448, regression losses: 0.12371380154755197, validation losses: 0.3954659277058418\n",
      "Epoch 3000, reconstruction losses: 0.013063086666873372, regression losses: 0.1174760314094997, validation losses: 0.38847473253919096\n",
      "Epoch 3001, reconstruction losses: 0.013586479620949396, regression losses: 0.19662439709190682, validation losses: 0.41589858806427243\n",
      "Epoch 3002, reconstruction losses: 0.012144383780088235, regression losses: 0.11503547122887593, validation losses: 0.5164459541352389\n",
      "Epoch 3003, reconstruction losses: 0.013566618053486829, regression losses: 0.12253830464100902, validation losses: 0.47665861269348153\n",
      "Epoch 3004, reconstruction losses: 0.011081198687404106, regression losses: 0.07423844467033888, validation losses: 0.4323053409872627\n",
      "Epoch 3005, reconstruction losses: 0.011087054642812498, regression losses: 0.09567555848075826, validation losses: 0.4315573007864617\n",
      "Epoch 3006, reconstruction losses: 0.01222213464288092, regression losses: 0.09643025422919695, validation losses: 0.42909296425214416\n",
      "Epoch 3007, reconstruction losses: 0.012743506050158126, regression losses: 0.10323149876822452, validation losses: 0.40987065840994585\n",
      "Epoch 3008, reconstruction losses: 0.01032456896911901, regression losses: 0.08528355266785159, validation losses: 0.38948767481223445\n",
      "Epoch 3009, reconstruction losses: 0.011308051431512886, regression losses: 0.11447510805292702, validation losses: 0.37032856434737804\n",
      "Epoch 3010, reconstruction losses: 0.015515004608039819, regression losses: 0.11666711621826804, validation losses: 0.3574839527745208\n",
      "Epoch 3011, reconstruction losses: 0.012399440160713746, regression losses: 0.09216218695560129, validation losses: 0.36866781168016455\n",
      "Epoch 3012, reconstruction losses: 0.013016217888097828, regression losses: 0.09515444215310538, validation losses: 0.3678640089801111\n",
      "Epoch 3013, reconstruction losses: 0.012124562237838348, regression losses: 0.12321943567622295, validation losses: 0.37996699485674523\n",
      "Epoch 3014, reconstruction losses: 0.014338343692990214, regression losses: 0.11885446408043879, validation losses: 0.3862323471878654\n",
      "Epoch 3015, reconstruction losses: 0.01810530235358375, regression losses: 0.23391687276334872, validation losses: 0.42335454902098146\n",
      "Epoch 3016, reconstruction losses: 0.014141944939653404, regression losses: 0.12935347920783533, validation losses: 0.48861668772845773\n",
      "Epoch 3017, reconstruction losses: 0.011560209428638474, regression losses: 0.11272832586625409, validation losses: 0.4366327958558455\n",
      "Epoch 3018, reconstruction losses: 0.011528256735614568, regression losses: 0.08879008653818707, validation losses: 0.4185541643766601\n",
      "Epoch 3019, reconstruction losses: 0.011532053243417155, regression losses: 0.1054937055094577, validation losses: 0.41832579227891564\n",
      "Epoch 3020, reconstruction losses: 0.012744618477668728, regression losses: 0.12202404073049103, validation losses: 0.40612095069017795\n",
      "Epoch 3021, reconstruction losses: 0.010380188017118323, regression losses: 0.08677205841049598, validation losses: 0.3599791199576146\n",
      "Epoch 3022, reconstruction losses: 0.011726164396129618, regression losses: 0.07215887983908614, validation losses: 0.34614006370079214\n",
      "Epoch 3023, reconstruction losses: 0.011184665163378078, regression losses: 0.07558964730973579, validation losses: 0.35183082188935644\n",
      "Epoch 3024, reconstruction losses: 0.01263207597934252, regression losses: 0.10093481181316455, validation losses: 0.3468202298951174\n",
      "Epoch 3025, reconstruction losses: 0.01331338482121225, regression losses: 0.09015649763167656, validation losses: 0.3496295866135865\n",
      "Epoch 3026, reconstruction losses: 0.013319923767391866, regression losses: 0.13785992967296198, validation losses: 0.4129485791636967\n",
      "Epoch 3027, reconstruction losses: 0.013490991983985427, regression losses: 0.10777104702768708, validation losses: 0.37957408813125815\n",
      "Epoch 3028, reconstruction losses: 0.01047261635706631, regression losses: 0.08753569534459775, validation losses: 0.367435555907331\n",
      "Epoch 3029, reconstruction losses: 0.01998789018320917, regression losses: 0.1684288709406644, validation losses: 0.373812829219842\n",
      "Epoch 3030, reconstruction losses: 0.012309119098200883, regression losses: 0.07743269616591501, validation losses: 0.4868179769800017\n",
      "Epoch 3031, reconstruction losses: 0.016000821805520204, regression losses: 0.15573017477008738, validation losses: 0.41124371932231485\n",
      "Epoch 3032, reconstruction losses: 0.013348134160648275, regression losses: 0.11362631952413911, validation losses: 0.36411400295955726\n",
      "Epoch 3033, reconstruction losses: 0.011740811448641869, regression losses: 0.09088019865293431, validation losses: 0.3743978412856098\n",
      "Epoch 3034, reconstruction losses: 0.011523068305975978, regression losses: 0.080071996004948, validation losses: 0.3778907964242451\n",
      "Epoch 3035, reconstruction losses: 0.010738412659086444, regression losses: 0.10430743726030745, validation losses: 0.37608554814382317\n",
      "Epoch 3036, reconstruction losses: 0.011645313088034279, regression losses: 0.09729657608339758, validation losses: 0.3546032839167037\n",
      "Epoch 3037, reconstruction losses: 0.01957283243030305, regression losses: 0.16508429893024645, validation losses: 0.35949354676902323\n",
      "Epoch 3038, reconstruction losses: 0.01278324193934095, regression losses: 0.10755843106624435, validation losses: 0.43718870020065986\n",
      "Epoch 3039, reconstruction losses: 0.01352672155055611, regression losses: 0.11482855478787975, validation losses: 0.4310534006960818\n",
      "Epoch 3040, reconstruction losses: 0.012146144629322831, regression losses: 0.09979978998334389, validation losses: 0.3874117170542031\n",
      "Epoch 3041, reconstruction losses: 0.010873604455511714, regression losses: 0.06410556209932752, validation losses: 0.36115234336545493\n",
      "Epoch 3042, reconstruction losses: 0.013626566082791378, regression losses: 0.09386356232757041, validation losses: 0.3514274615978523\n",
      "Epoch 3043, reconstruction losses: 0.011958473336248379, regression losses: 0.08566808937147315, validation losses: 0.3478963098254343\n",
      "Epoch 3044, reconstruction losses: 0.012753248286108826, regression losses: 0.09254116569465655, validation losses: 0.3368739597605111\n",
      "Epoch 3045, reconstruction losses: 0.014381163423420227, regression losses: 0.09526580242860132, validation losses: 0.3608272657919921\n",
      "Epoch 3046, reconstruction losses: 0.011376329573738485, regression losses: 0.07458920142705305, validation losses: 0.35756799062589284\n",
      "Epoch 3047, reconstruction losses: 0.015403760731974792, regression losses: 0.10450866483103002, validation losses: 0.3390805805196114\n",
      "Epoch 3048, reconstruction losses: 0.012223954564908313, regression losses: 0.1590571778992711, validation losses: 0.34622616464327793\n",
      "Epoch 3049, reconstruction losses: 0.013297063814175863, regression losses: 0.1286990586366222, validation losses: 0.3669386829380002\n",
      "Epoch 3050, reconstruction losses: 0.01239098304318715, regression losses: 0.12687481110726437, validation losses: 0.3704504338661791\n",
      "Epoch 3051, reconstruction losses: 0.011981123249198936, regression losses: 0.10419737412150783, validation losses: 0.37748953167083865\n",
      "Epoch 3052, reconstruction losses: 0.011501290161346192, regression losses: 0.08040854787155961, validation losses: 0.3959668133751659\n",
      "Epoch 3053, reconstruction losses: 0.011131937777644728, regression losses: 0.08450579074910317, validation losses: 0.3961949652177572\n",
      "Epoch 3054, reconstruction losses: 0.014159295882198724, regression losses: 0.118164429655485, validation losses: 0.3644049799915097\n",
      "Epoch 3055, reconstruction losses: 0.013906490556937563, regression losses: 0.07992393595126582, validation losses: 0.3871495629565657\n",
      "Epoch 3056, reconstruction losses: 0.013375987951048263, regression losses: 0.10132040302447756, validation losses: 0.39963080654438654\n",
      "Epoch 3057, reconstruction losses: 0.013148255144016796, regression losses: 0.10118621765785886, validation losses: 0.38513899858815703\n",
      "Epoch 3058, reconstruction losses: 0.013211930589861066, regression losses: 0.12284318462680197, validation losses: 0.3625938528239828\n",
      "Epoch 3059, reconstruction losses: 0.01453593661858955, regression losses: 0.1461517785713901, validation losses: 0.3758843765199258\n",
      "Epoch 3060, reconstruction losses: 0.018477246525739753, regression losses: 0.12253274058978708, validation losses: 0.39168749048355783\n",
      "Epoch 3061, reconstruction losses: 0.013247556379751666, regression losses: 0.09920442110818228, validation losses: 0.42020082041999784\n",
      "Epoch 3062, reconstruction losses: 0.015418268291965173, regression losses: 0.1547102382944724, validation losses: 0.3590222424909469\n",
      "Epoch 3063, reconstruction losses: 0.01997378890234317, regression losses: 0.14067336105438233, validation losses: 0.42096850238182415\n",
      "Epoch 3064, reconstruction losses: 0.011741922281572247, regression losses: 0.09956473954881741, validation losses: 0.4714865768935118\n",
      "Epoch 3065, reconstruction losses: 0.01493684619282657, regression losses: 0.14994249281074923, validation losses: 0.3659796945108232\n",
      "Epoch 3066, reconstruction losses: 0.01416655160612853, regression losses: 0.12369278584538058, validation losses: 0.34156555341006534\n",
      "Epoch 3067, reconstruction losses: 0.011296708386048203, regression losses: 0.08424202613549692, validation losses: 0.33453496491391865\n",
      "Epoch 3068, reconstruction losses: 0.012495852770780599, regression losses: 0.11536428625544429, validation losses: 0.34026120354395256\n",
      "Epoch 3069, reconstruction losses: 0.01436567050997786, regression losses: 0.11856963622479258, validation losses: 0.3664491089739378\n",
      "Epoch 3070, reconstruction losses: 0.01304744885617362, regression losses: 0.1090115858971506, validation losses: 0.35184378666594224\n",
      "Epoch 3071, reconstruction losses: 0.013636810535472185, regression losses: 0.08629941745826655, validation losses: 0.34464713228102145\n",
      "Epoch 3072, reconstruction losses: 0.011930330241711877, regression losses: 0.08505785866917265, validation losses: 0.3668299523874226\n",
      "Epoch 3073, reconstruction losses: 0.011773053365789857, regression losses: 0.09980940326660505, validation losses: 0.39534435671747636\n",
      "Epoch 3074, reconstruction losses: 0.01554022338169908, regression losses: 0.12026438284582291, validation losses: 0.37688941120665603\n",
      "Epoch 3075, reconstruction losses: 0.01902289753632728, regression losses: 0.21385202111961849, validation losses: 0.35735867354240236\n",
      "Epoch 3076, reconstruction losses: 0.014446371384300395, regression losses: 0.10675573189323212, validation losses: 0.4608028512489858\n",
      "Epoch 3077, reconstruction losses: 0.012986000646024438, regression losses: 0.1177178588388846, validation losses: 0.4174384948306688\n",
      "Epoch 3078, reconstruction losses: 0.014081842358037269, regression losses: 0.12503411152293153, validation losses: 0.41454254318781286\n",
      "Epoch 3079, reconstruction losses: 0.013417866527247559, regression losses: 0.1055536759392129, validation losses: 0.4063974246557701\n",
      "Epoch 3080, reconstruction losses: 0.013145437155271528, regression losses: 0.10154507729947629, validation losses: 0.4936933497926341\n",
      "Epoch 3081, reconstruction losses: 0.01215966687139556, regression losses: 0.08585309022910965, validation losses: 0.47427508848419847\n",
      "Epoch 3082, reconstruction losses: 0.018324518370407737, regression losses: 0.11228602581798311, validation losses: 0.4000561783557739\n",
      "Epoch 3083, reconstruction losses: 0.01172986664232377, regression losses: 0.10763663527099523, validation losses: 0.3677748786131767\n",
      "Epoch 3084, reconstruction losses: 0.01124787695137987, regression losses: 0.107769075373744, validation losses: 0.3504129778066345\n",
      "Epoch 3085, reconstruction losses: 0.011535576816277378, regression losses: 0.10027759792603654, validation losses: 0.33488121829474893\n",
      "Epoch 3086, reconstruction losses: 0.012323958590847709, regression losses: 0.07277271109302816, validation losses: 0.33998554568635675\n",
      "Epoch 3087, reconstruction losses: 0.010688275341207212, regression losses: 0.08385779073809946, validation losses: 0.35941934169679446\n",
      "Epoch 3088, reconstruction losses: 0.012083079007968208, regression losses: 0.09012854827229197, validation losses: 0.3464252600820555\n",
      "Epoch 3089, reconstruction losses: 0.011155352930568027, regression losses: 0.09521779697048925, validation losses: 0.36925673565188744\n",
      "Epoch 3090, reconstruction losses: 0.012824440013626233, regression losses: 0.09704572825322555, validation losses: 0.3795392924612632\n",
      "Epoch 3091, reconstruction losses: 0.013998984086604467, regression losses: 0.11441001591379397, validation losses: 0.37040012455209914\n",
      "Epoch 3092, reconstruction losses: 0.014059639659443275, regression losses: 0.10091304348286124, validation losses: 0.387929567462658\n",
      "Epoch 3093, reconstruction losses: 0.013469848197353631, regression losses: 0.11162413418056097, validation losses: 0.36684313854445383\n",
      "Epoch 3094, reconstruction losses: 0.013499266385932969, regression losses: 0.1100757958771456, validation losses: 0.3455406916822686\n",
      "Epoch 3095, reconstruction losses: 0.011644039659068541, regression losses: 0.09238586541027272, validation losses: 0.34972869273738433\n",
      "Epoch 3096, reconstruction losses: 0.013237749822509536, regression losses: 0.10080012331347415, validation losses: 0.3490470521004249\n",
      "Epoch 3097, reconstruction losses: 0.011177336696278121, regression losses: 0.1043078471894366, validation losses: 0.3469530076315427\n",
      "Epoch 3098, reconstruction losses: 0.011255266541777848, regression losses: 0.09842925747491964, validation losses: 0.35768171100755547\n",
      "Epoch 3099, reconstruction losses: 0.013413276843551819, regression losses: 0.13177968218218006, validation losses: 0.35439252667776794\n",
      "Epoch 3100, reconstruction losses: 0.011807142216933051, regression losses: 0.10466536341570014, validation losses: 0.3468106972018467\n",
      "Epoch 3101, reconstruction losses: 0.011100333269989918, regression losses: 0.09421528376928268, validation losses: 0.33808477779391927\n",
      "Epoch 3102, reconstruction losses: 0.013924272209427702, regression losses: 0.08861386235781989, validation losses: 0.337598134907208\n",
      "Epoch 3103, reconstruction losses: 0.011395895528368814, regression losses: 0.10056119846249287, validation losses: 0.3537300479711371\n",
      "Epoch 3104, reconstruction losses: 0.013787990155809522, regression losses: 0.10114776988676398, validation losses: 0.3440721351797424\n",
      "Epoch 3105, reconstruction losses: 0.013983046428562688, regression losses: 0.09510101902559429, validation losses: 0.35165291388793496\n",
      "Epoch 3106, reconstruction losses: 0.014451787967528027, regression losses: 0.13424702573102926, validation losses: 0.3626850791097799\n",
      "Epoch 3107, reconstruction losses: 0.0154220353600512, regression losses: 0.3085963809539616, validation losses: 0.3779617837107421\n",
      "Epoch 3108, reconstruction losses: 0.014127314814118453, regression losses: 0.10421892111634468, validation losses: 0.5330139168881025\n",
      "Epoch 3109, reconstruction losses: 0.01622316778528484, regression losses: 0.15664946736213814, validation losses: 0.690436028972677\n",
      "Epoch 3110, reconstruction losses: 0.011442537876082582, regression losses: 0.12650835537072896, validation losses: 0.6167392879806943\n",
      "Epoch 3111, reconstruction losses: 0.013090049588305591, regression losses: 0.0982176531551972, validation losses: 0.5570640512752437\n",
      "Epoch 3112, reconstruction losses: 0.014051384979058003, regression losses: 0.1184084505429989, validation losses: 0.5445276568963863\n",
      "Epoch 3113, reconstruction losses: 0.017626063961298313, regression losses: 0.130316573975812, validation losses: 0.49734329732921523\n",
      "Epoch 3114, reconstruction losses: 0.014343811010110123, regression losses: 0.3185462010769724, validation losses: 0.5520912154331301\n",
      "Epoch 3115, reconstruction losses: 0.014020657295289344, regression losses: 0.11200639481929527, validation losses: 0.7403708750184769\n",
      "Epoch 3116, reconstruction losses: 0.012034430459543681, regression losses: 0.09444633772829887, validation losses: 0.7458889920043964\n",
      "Epoch 3117, reconstruction losses: 0.01677218482766569, regression losses: 0.128615929376697, validation losses: 0.5561867465733874\n",
      "Epoch 3118, reconstruction losses: 0.01292156371904212, regression losses: 0.11578562870758839, validation losses: 0.5221152574294754\n",
      "Epoch 3119, reconstruction losses: 0.02019879829864306, regression losses: 0.3334439827524015, validation losses: 0.4649954614084303\n",
      "Epoch 3120, reconstruction losses: 0.011518295214851286, regression losses: 0.15647345419542308, validation losses: 0.7199565573557267\n",
      "Epoch 3121, reconstruction losses: 0.014395158036486824, regression losses: 0.137134620364892, validation losses: 0.7186114840347948\n",
      "Epoch 3122, reconstruction losses: 0.015463385415854262, regression losses: 0.1299640836667586, validation losses: 0.6825644361169567\n",
      "Epoch 3123, reconstruction losses: 0.013807987830641397, regression losses: 0.12655728503725713, validation losses: 0.6340807670866717\n",
      "Epoch 3124, reconstruction losses: 0.012772025606201318, regression losses: 0.11646672257592623, validation losses: 0.600130691323598\n",
      "Epoch 3125, reconstruction losses: 0.019403381893988166, regression losses: 0.14961957065661585, validation losses: 0.5491658660749287\n",
      "Epoch 3126, reconstruction losses: 0.01272211200502793, regression losses: 0.11312214485188235, validation losses: 0.5948478575269983\n",
      "Epoch 3127, reconstruction losses: 0.013942531277902057, regression losses: 0.10955179640743408, validation losses: 0.5895596254725082\n",
      "Epoch 3128, reconstruction losses: 0.012671692229235967, regression losses: 0.10348981061150714, validation losses: 0.5432764093801137\n",
      "Epoch 3129, reconstruction losses: 0.012387526568414584, regression losses: 0.09629845270271438, validation losses: 0.5255556523115229\n",
      "Epoch 3130, reconstruction losses: 0.010857141991289523, regression losses: 0.07717590928068453, validation losses: 0.5140642461403996\n",
      "Epoch 3131, reconstruction losses: 0.014180553622940214, regression losses: 0.11288028849596925, validation losses: 0.4996035664646949\n",
      "Epoch 3132, reconstruction losses: 0.010653595367024465, regression losses: 0.08362820965164272, validation losses: 0.4600211765362008\n",
      "Epoch 3133, reconstruction losses: 0.015336763365569776, regression losses: 0.149329287136642, validation losses: 0.4866960303873147\n",
      "Epoch 3134, reconstruction losses: 0.016260759974892538, regression losses: 0.17893887406382325, validation losses: 0.6608902344623949\n",
      "Epoch 3135, reconstruction losses: 0.011987550544203305, regression losses: 0.11389319168308257, validation losses: 0.6783811876629939\n",
      "Epoch 3136, reconstruction losses: 0.015705972666195073, regression losses: 0.09355049882813779, validation losses: 0.6150851658080153\n",
      "Epoch 3137, reconstruction losses: 0.01572658557123033, regression losses: 0.13296824473020658, validation losses: 0.5443826105342101\n",
      "Epoch 3138, reconstruction losses: 0.014768370933356275, regression losses: 0.09298933992631356, validation losses: 0.5131445468061322\n",
      "Epoch 3139, reconstruction losses: 0.012052008810136548, regression losses: 0.09104124635446456, validation losses: 0.4754386243814708\n",
      "Epoch 3140, reconstruction losses: 0.010821889365048557, regression losses: 0.09010170195157735, validation losses: 0.4461045754622333\n",
      "Epoch 3141, reconstruction losses: 0.01255494052727917, regression losses: 0.1010355180923202, validation losses: 0.43809851931464633\n",
      "Epoch 3142, reconstruction losses: 0.013945294748644428, regression losses: 0.10354907659351228, validation losses: 0.423448580704015\n",
      "Epoch 3143, reconstruction losses: 0.013115393328162974, regression losses: 0.0892322148342045, validation losses: 0.39411979291406335\n",
      "Epoch 3144, reconstruction losses: 0.013158740731992686, regression losses: 0.12369372077139298, validation losses: 0.40851989420100693\n",
      "Epoch 3145, reconstruction losses: 0.01379683820229179, regression losses: 0.10521690772298774, validation losses: 0.4135881026462429\n",
      "Epoch 3146, reconstruction losses: 0.015238242425143463, regression losses: 0.09158989928280219, validation losses: 0.3978850310476944\n",
      "Epoch 3147, reconstruction losses: 0.012101367238695366, regression losses: 0.0943422512968186, validation losses: 0.4066302747001562\n",
      "Epoch 3148, reconstruction losses: 0.010549466121461138, regression losses: 0.09384120653171123, validation losses: 0.3965546619517845\n",
      "Epoch 3149, reconstruction losses: 0.012120050252085936, regression losses: 0.08511566728455716, validation losses: 0.40017361003749885\n",
      "Epoch 3150, reconstruction losses: 0.011119494826718724, regression losses: 0.07899882276271541, validation losses: 0.3952353144403213\n",
      "Epoch 3151, reconstruction losses: 0.022777533631641925, regression losses: 0.31436177580627, validation losses: 0.39623921389785566\n",
      "Epoch 3152, reconstruction losses: 0.013648679144293746, regression losses: 0.11991808907919788, validation losses: 0.5202260780471563\n",
      "Epoch 3153, reconstruction losses: 0.015216127334535836, regression losses: 0.16188924992840886, validation losses: 0.5391745194802616\n",
      "Epoch 3154, reconstruction losses: 0.013961717988789861, regression losses: 0.1179734790522352, validation losses: 0.5217111404838245\n",
      "Epoch 3155, reconstruction losses: 0.014349117831199732, regression losses: 0.15260602311223703, validation losses: 0.5078388960640299\n",
      "Epoch 3156, reconstruction losses: 0.013708867884520571, regression losses: 0.10069375261307743, validation losses: 0.45450140246128445\n",
      "Epoch 3157, reconstruction losses: 0.012830374969105426, regression losses: 0.08854654951046043, validation losses: 0.3717102163189005\n",
      "Epoch 3158, reconstruction losses: 0.01307305416058251, regression losses: 0.10221229371791267, validation losses: 0.36884970612273016\n",
      "Epoch 3159, reconstruction losses: 0.012930605893809009, regression losses: 0.10953408017888554, validation losses: 0.35967250377798565\n",
      "Epoch 3160, reconstruction losses: 0.010502338320332193, regression losses: 0.07726588594925995, validation losses: 0.35711998531899136\n",
      "Epoch 3161, reconstruction losses: 0.012093742738362166, regression losses: 0.09276755680067823, validation losses: 0.4015258837100616\n",
      "Epoch 3162, reconstruction losses: 0.014142971664729432, regression losses: 0.1107414355163979, validation losses: 0.3954440864489212\n",
      "Epoch 3163, reconstruction losses: 0.012376751589514077, regression losses: 0.09685106240433343, validation losses: 0.41572350154027166\n",
      "Epoch 3164, reconstruction losses: 0.013341226550005364, regression losses: 0.09295259032479715, validation losses: 0.4266360556472376\n",
      "Epoch 3165, reconstruction losses: 0.010180700310305955, regression losses: 0.12327594669470733, validation losses: 0.4576501050197858\n",
      "Epoch 3166, reconstruction losses: 0.013208178424989385, regression losses: 0.15025791267617428, validation losses: 0.4673149382223807\n",
      "Epoch 3167, reconstruction losses: 0.011720739407110636, regression losses: 0.10165758098564541, validation losses: 0.3808464682170385\n",
      "Epoch 3168, reconstruction losses: 0.01171515915365804, regression losses: 0.12043390525012769, validation losses: 0.3568836732119579\n",
      "Epoch 3169, reconstruction losses: 0.011412164641511959, regression losses: 0.09884666874395821, validation losses: 0.3669077877748831\n",
      "Epoch 3170, reconstruction losses: 0.011845380410866012, regression losses: 0.10083537689991932, validation losses: 0.41621564629953156\n",
      "Epoch 3171, reconstruction losses: 0.013606527422973332, regression losses: 0.10921525078569681, validation losses: 0.40422391335182184\n",
      "Epoch 3172, reconstruction losses: 0.011355917334103644, regression losses: 0.12133184781852951, validation losses: 0.40152290042260474\n",
      "Epoch 3173, reconstruction losses: 0.012236680814336442, regression losses: 0.13245253761505565, validation losses: 0.37940898438674137\n",
      "Epoch 3174, reconstruction losses: 0.010944191319525436, regression losses: 0.07867931960471308, validation losses: 0.3816012227258333\n",
      "Epoch 3175, reconstruction losses: 0.013523803439230077, regression losses: 0.12159316210602024, validation losses: 0.37871738897063556\n",
      "Epoch 3176, reconstruction losses: 0.013245403292784768, regression losses: 0.13963612840005912, validation losses: 0.37892816670965584\n",
      "Epoch 3177, reconstruction losses: 0.01372098286927112, regression losses: 0.0843334283289605, validation losses: 0.3804238762747172\n",
      "Epoch 3178, reconstruction losses: 0.017158308352605463, regression losses: 0.14222373166956664, validation losses: 0.4052689055106036\n",
      "Epoch 3179, reconstruction losses: 0.013441363547049025, regression losses: 0.12374189750034797, validation losses: 0.4230032130041923\n",
      "Epoch 3180, reconstruction losses: 0.013156561934140911, regression losses: 0.11385769258904585, validation losses: 0.43086616546642514\n",
      "Epoch 3181, reconstruction losses: 0.017501172948555896, regression losses: 0.12331217501425884, validation losses: 0.4928960450905727\n",
      "Epoch 3182, reconstruction losses: 0.01297187532051577, regression losses: 0.10777631368606409, validation losses: 0.4003501802472815\n",
      "Epoch 3183, reconstruction losses: 0.012558423249029555, regression losses: 0.11417578524716541, validation losses: 0.3853259916576412\n",
      "Epoch 3184, reconstruction losses: 0.010726745497615757, regression losses: 0.1076677957416675, validation losses: 0.36387845835781996\n",
      "Epoch 3185, reconstruction losses: 0.011727469989914514, regression losses: 0.09083357326451148, validation losses: 0.37578535619013204\n",
      "Epoch 3186, reconstruction losses: 0.01223010863319999, regression losses: 0.10043983187293604, validation losses: 0.4173802284366672\n",
      "Epoch 3187, reconstruction losses: 0.012842550332367853, regression losses: 0.1773444631134784, validation losses: 0.43208124435827555\n",
      "Epoch 3188, reconstruction losses: 0.014004157959801547, regression losses: 0.10591920034598526, validation losses: 0.3956921672485819\n",
      "Epoch 3189, reconstruction losses: 0.011139818334374581, regression losses: 0.0877818742431631, validation losses: 0.36538292498077535\n",
      "Epoch 3190, reconstruction losses: 0.012061687150385664, regression losses: 0.09709849841555002, validation losses: 0.3773644427745442\n",
      "Epoch 3191, reconstruction losses: 0.011773135537558252, regression losses: 0.09722974842910888, validation losses: 0.40681689884048394\n",
      "Epoch 3192, reconstruction losses: 0.012276473056186104, regression losses: 0.08496135264546884, validation losses: 0.3904238637099808\n",
      "Epoch 3193, reconstruction losses: 0.011733273773036509, regression losses: 0.11471663741123918, validation losses: 0.38811477951902784\n",
      "Epoch 3194, reconstruction losses: 0.010788201386143637, regression losses: 0.07971418861301932, validation losses: 0.4227761674814543\n",
      "Epoch 3195, reconstruction losses: 0.01370735070046723, regression losses: 0.12928367936470567, validation losses: 0.37044836489280375\n",
      "Epoch 3196, reconstruction losses: 0.011996513837986474, regression losses: 0.09874711536257091, validation losses: 0.34609148024009717\n",
      "Epoch 3197, reconstruction losses: 0.011546914254423769, regression losses: 0.08935127268546557, validation losses: 0.3446885615979176\n",
      "Epoch 3198, reconstruction losses: 0.01230094465628431, regression losses: 0.12509782616571108, validation losses: 0.36098395077079376\n",
      "Epoch 3199, reconstruction losses: 0.0107269509974495, regression losses: 0.08354046078508559, validation losses: 0.3748139791855308\n",
      "Epoch 3200, reconstruction losses: 0.015170408868491206, regression losses: 0.1436306139996356, validation losses: 0.35334639442436944\n",
      "Epoch 3201, reconstruction losses: 0.01353539017751713, regression losses: 0.11996834061773877, validation losses: 0.3551335569792069\n",
      "Epoch 3202, reconstruction losses: 0.010084648903091645, regression losses: 0.06591442646462213, validation losses: 0.34737087940252054\n",
      "Epoch 3203, reconstruction losses: 0.009132302435423264, regression losses: 0.06673783883623628, validation losses: 0.35485423762513757\n",
      "Epoch 3204, reconstruction losses: 0.010412782591122948, regression losses: 0.09435488169819424, validation losses: 0.35581823668004714\n",
      "Epoch 3205, reconstruction losses: 0.010679633120752681, regression losses: 0.0972293393477916, validation losses: 0.34540297948233534\n",
      "Epoch 3206, reconstruction losses: 0.01242227375735685, regression losses: 0.09322203128687637, validation losses: 0.3449177185462947\n",
      "Epoch 3207, reconstruction losses: 0.01717590812022939, regression losses: 0.3379283390765303, validation losses: 0.36967735964659393\n",
      "Epoch 3208, reconstruction losses: 0.014480742098117387, regression losses: 0.11899643204037084, validation losses: 0.6788762468605639\n",
      "Epoch 3209, reconstruction losses: 0.014325434195750025, regression losses: 0.18531338302157202, validation losses: 0.5639503358556723\n",
      "Epoch 3210, reconstruction losses: 0.013081198354424764, regression losses: 0.13051885161939442, validation losses: 0.37917837715859615\n",
      "Epoch 3211, reconstruction losses: 0.011649319809991239, regression losses: 0.10908252666444962, validation losses: 0.4194529511989059\n",
      "Epoch 3212, reconstruction losses: 0.014192040836263728, regression losses: 0.08246077414186598, validation losses: 0.3533361982272701\n",
      "Epoch 3213, reconstruction losses: 0.012813746665305197, regression losses: 0.15638007653365688, validation losses: 0.36767310006166487\n",
      "Epoch 3214, reconstruction losses: 0.013820629365612472, regression losses: 0.1181526637984858, validation losses: 0.3679183462503903\n",
      "Epoch 3215, reconstruction losses: 0.012092615242475662, regression losses: 0.10672387835377682, validation losses: 0.3530161998297362\n",
      "Epoch 3216, reconstruction losses: 0.016803742819830117, regression losses: 0.10748721720674555, validation losses: 0.3481608797801877\n",
      "Epoch 3217, reconstruction losses: 0.021499205689279235, regression losses: 0.23399338534636552, validation losses: 0.3343774757266505\n",
      "Epoch 3218, reconstruction losses: 0.015851730215728728, regression losses: 0.09740876479318755, validation losses: 0.4476470539404782\n",
      "Epoch 3219, reconstruction losses: 0.014395073897562435, regression losses: 0.15461262593251107, validation losses: 0.4316207454335058\n",
      "Epoch 3220, reconstruction losses: 0.014244736630487564, regression losses: 0.12420419954737515, validation losses: 0.40910676482204644\n",
      "Epoch 3221, reconstruction losses: 0.011856716536371263, regression losses: 0.10919913921103944, validation losses: 0.3544853349159014\n",
      "Epoch 3222, reconstruction losses: 0.010747853651697684, regression losses: 0.10534356781039735, validation losses: 0.36229345298145565\n",
      "Epoch 3223, reconstruction losses: 0.010217120821848273, regression losses: 0.08119146478067375, validation losses: 0.3888665419414217\n",
      "Epoch 3224, reconstruction losses: 0.009846324762238793, regression losses: 0.10326661658446945, validation losses: 0.37206387413902037\n",
      "Epoch 3225, reconstruction losses: 0.012080678366541291, regression losses: 0.16165867496311404, validation losses: 0.3548352354291355\n",
      "Epoch 3226, reconstruction losses: 0.012211185707906622, regression losses: 0.119278427986866, validation losses: 0.35900366030216957\n",
      "Epoch 3227, reconstruction losses: 0.011351230940935847, regression losses: 0.18607240099703193, validation losses: 0.3846003261043179\n",
      "Epoch 3228, reconstruction losses: 0.012241877873276652, regression losses: 0.11712003485808262, validation losses: 0.42367692949879426\n",
      "Epoch 3229, reconstruction losses: 0.012903073005875716, regression losses: 0.10110841426211542, validation losses: 0.4024362702562987\n",
      "Epoch 3230, reconstruction losses: 0.011418556453786227, regression losses: 0.12447250002227547, validation losses: 0.39245364395966126\n",
      "Epoch 3231, reconstruction losses: 0.016696114987818145, regression losses: 0.10448683421266303, validation losses: 0.42145605533551467\n",
      "Epoch 3232, reconstruction losses: 0.01036209813007664, regression losses: 0.11608991881941835, validation losses: 0.3406550921191236\n",
      "Epoch 3233, reconstruction losses: 0.012823531347090172, regression losses: 0.09091746351517543, validation losses: 0.33218588637927626\n",
      "Epoch 3234, reconstruction losses: 0.01068061439228432, regression losses: 0.09214894743929208, validation losses: 0.3566783866918809\n",
      "Epoch 3235, reconstruction losses: 0.01353188771624915, regression losses: 0.11522127792708008, validation losses: 0.3750653284682329\n",
      "Epoch 3236, reconstruction losses: 0.015587648678285502, regression losses: 0.15658370352392748, validation losses: 0.4629600585123679\n",
      "Epoch 3237, reconstruction losses: 0.012246041237411817, regression losses: 0.13021135109551948, validation losses: 0.49845979902042625\n",
      "Epoch 3238, reconstruction losses: 0.019780099293923034, regression losses: 0.27864170310571906, validation losses: 0.3453376084862235\n",
      "Epoch 3239, reconstruction losses: 0.0134997217096743, regression losses: 0.12556946642106526, validation losses: 0.8231471061528882\n",
      "Epoch 3240, reconstruction losses: 0.016561481272586918, regression losses: 0.2209516485853601, validation losses: 0.5117302423849722\n",
      "Epoch 3241, reconstruction losses: 0.015008882726019912, regression losses: 0.20244907815902657, validation losses: 0.6019741360586179\n",
      "Epoch 3242, reconstruction losses: 0.013186470791003742, regression losses: 0.14881693383375352, validation losses: 0.9374578869346156\n",
      "Epoch 3243, reconstruction losses: 0.016896804294621277, regression losses: 0.14724247421336817, validation losses: 0.7277484043005171\n",
      "Epoch 3244, reconstruction losses: 0.013404230553402507, regression losses: 0.1669386958632948, validation losses: 0.5077842847685742\n",
      "Epoch 3245, reconstruction losses: 0.013725280394404165, regression losses: 0.1697839981425666, validation losses: 0.5267572735252424\n",
      "Epoch 3246, reconstruction losses: 0.016146076247917307, regression losses: 0.16747402298660619, validation losses: 0.5662256488115363\n",
      "Epoch 3247, reconstruction losses: 0.013790266287931998, regression losses: 0.1189098500277174, validation losses: 0.4561182943741206\n",
      "Epoch 3248, reconstruction losses: 0.012079092346542124, regression losses: 0.09185910791040294, validation losses: 0.40916095793762763\n",
      "Epoch 3249, reconstruction losses: 0.016433253790197593, regression losses: 0.13431807958855735, validation losses: 0.3722172705214435\n",
      "Epoch 3250, reconstruction losses: 0.013697000483819109, regression losses: 0.09426957123452681, validation losses: 0.3990935262872286\n",
      "Epoch 3251, reconstruction losses: 0.011698285452427114, regression losses: 0.10095787834766443, validation losses: 0.3837253239603514\n",
      "Epoch 3252, reconstruction losses: 0.010760553440959124, regression losses: 0.09456498444524501, validation losses: 0.3533720604421076\n",
      "Epoch 3253, reconstruction losses: 0.013610279787708275, regression losses: 0.11978106315125046, validation losses: 0.33581308541995547\n",
      "Epoch 3254, reconstruction losses: 0.011507250961741967, regression losses: 0.06446034938499925, validation losses: 0.324128546547243\n",
      "Epoch 3255, reconstruction losses: 0.012851980238258436, regression losses: 0.10945424749996155, validation losses: 0.3206376671608417\n",
      "Epoch 3256, reconstruction losses: 0.011296267052789983, regression losses: 0.09601314683521268, validation losses: 0.327102917199328\n",
      "Epoch 3257, reconstruction losses: 0.010091339015641508, regression losses: 0.12447992485597538, validation losses: 0.3339509603612539\n",
      "Epoch 3258, reconstruction losses: 0.012635537050646755, regression losses: 0.11485824941673586, validation losses: 0.33897211309319686\n",
      "Epoch 3259, reconstruction losses: 0.012146504566876775, regression losses: 0.15430920894326888, validation losses: 0.33255568901158133\n",
      "Epoch 3260, reconstruction losses: 0.010930955930988006, regression losses: 0.07484950950050205, validation losses: 0.3433502910978532\n",
      "Epoch 3261, reconstruction losses: 0.011072935032946672, regression losses: 0.09806471143990099, validation losses: 0.34068037429449005\n",
      "Epoch 3262, reconstruction losses: 0.01055007303496901, regression losses: 0.09583414259942556, validation losses: 0.3613530114033289\n",
      "Epoch 3263, reconstruction losses: 0.011016861822674296, regression losses: 0.10335518193063001, validation losses: 0.3529284537483284\n",
      "Epoch 3264, reconstruction losses: 0.011626583353643107, regression losses: 0.1449411415075881, validation losses: 0.35063395115035323\n",
      "Epoch 3265, reconstruction losses: 0.014292721349655233, regression losses: 0.08372735592680153, validation losses: 0.3603757277244881\n",
      "Epoch 3266, reconstruction losses: 0.014213726843022977, regression losses: 0.12724965664112436, validation losses: 0.3504518623696145\n",
      "Epoch 3267, reconstruction losses: 0.01015650430531426, regression losses: 0.08657468532494753, validation losses: 0.36127228290722935\n",
      "Epoch 3268, reconstruction losses: 0.010046556284450859, regression losses: 0.0896829085867985, validation losses: 0.3406374308806184\n",
      "Epoch 3269, reconstruction losses: 0.011691681139629956, regression losses: 0.0810880396437186, validation losses: 0.33006703143987054\n",
      "Epoch 3270, reconstruction losses: 0.011250080570807227, regression losses: 0.0913863435763022, validation losses: 0.3482668158601458\n",
      "Epoch 3271, reconstruction losses: 0.009625498338675409, regression losses: 0.0829250244037477, validation losses: 0.3396273461853086\n",
      "Epoch 3272, reconstruction losses: 0.01056043462880914, regression losses: 0.0868051407622081, validation losses: 0.3283094913525667\n",
      "Epoch 3273, reconstruction losses: 0.010864894604739097, regression losses: 0.09700646368247796, validation losses: 0.32296957068584925\n",
      "Epoch 3274, reconstruction losses: 0.010878969086277578, regression losses: 0.14571714398962426, validation losses: 0.3316274186175392\n",
      "Epoch 3275, reconstruction losses: 0.012674626806399159, regression losses: 0.10102893126974133, validation losses: 0.3569006610581913\n",
      "Epoch 3276, reconstruction losses: 0.01349657123389723, regression losses: 0.12449311921100525, validation losses: 0.3447873542098783\n",
      "Epoch 3277, reconstruction losses: 0.01247842430791793, regression losses: 0.0851499519820775, validation losses: 0.33809242443134996\n",
      "Epoch 3278, reconstruction losses: 0.011597299237527236, regression losses: 0.08559704153920673, validation losses: 0.34773140400579505\n",
      "Epoch 3279, reconstruction losses: 0.01336483085532506, regression losses: 0.08374148360132663, validation losses: 0.3782088378847022\n",
      "Epoch 3280, reconstruction losses: 0.011780942145590114, regression losses: 0.11390688924888609, validation losses: 0.3645788609805907\n",
      "Epoch 3281, reconstruction losses: 0.01248016609731774, regression losses: 0.071891109426294, validation losses: 0.32433680392651376\n",
      "Epoch 3282, reconstruction losses: 0.011478218294184467, regression losses: 0.1128877347743065, validation losses: 0.31949483529392386\n",
      "Epoch 3283, reconstruction losses: 0.012452821371744778, regression losses: 0.08954172148841696, validation losses: 0.3338404488420032\n",
      "Epoch 3284, reconstruction losses: 0.009963877090006418, regression losses: 0.07407627456349154, validation losses: 0.37720017769349884\n",
      "Epoch 3285, reconstruction losses: 0.010217049307185687, regression losses: 0.07265159281249112, validation losses: 0.36128287497085604\n",
      "Epoch 3286, reconstruction losses: 0.011466356337688392, regression losses: 0.09327348812525368, validation losses: 0.3386383753199899\n",
      "Epoch 3287, reconstruction losses: 0.012508691115877095, regression losses: 0.11344602788729342, validation losses: 0.32391625032309573\n",
      "Epoch 3288, reconstruction losses: 0.011872753369164655, regression losses: 0.09448641823475996, validation losses: 0.3246499765427631\n",
      "Epoch 3289, reconstruction losses: 0.01103918769692718, regression losses: 0.05982658618403693, validation losses: 0.31873427536267\n",
      "Epoch 3290, reconstruction losses: 0.013250451880239331, regression losses: 0.11304574516401246, validation losses: 0.3214192722435822\n",
      "Epoch 3291, reconstruction losses: 0.01150992029349388, regression losses: 0.08397157907730007, validation losses: 0.3252348275455054\n",
      "Epoch 3292, reconstruction losses: 0.010922966112486337, regression losses: 0.10031812519087865, validation losses: 0.32913621197427023\n",
      "Epoch 3293, reconstruction losses: 0.012802615994396247, regression losses: 0.09351667220557909, validation losses: 0.3466225750781585\n",
      "Epoch 3294, reconstruction losses: 0.01238002352490494, regression losses: 0.09476614638447532, validation losses: 0.3507873682859752\n",
      "Epoch 3295, reconstruction losses: 0.01105948953662586, regression losses: 0.09184601668682622, validation losses: 0.34932831475902226\n",
      "Epoch 3296, reconstruction losses: 0.01095906730542517, regression losses: 0.12115921457719564, validation losses: 0.3508180926908671\n",
      "Epoch 3297, reconstruction losses: 0.013163758339707201, regression losses: 0.11557918792364431, validation losses: 0.3993661097303943\n",
      "Epoch 3298, reconstruction losses: 0.010286021446737487, regression losses: 0.11830297982374181, validation losses: 0.3889105634834788\n",
      "Epoch 3299, reconstruction losses: 0.011876732538741379, regression losses: 0.09374715120257153, validation losses: 0.3349273159740167\n",
      "Epoch 3300, reconstruction losses: 0.011487475094219652, regression losses: 0.08974081179362096, validation losses: 0.3446168972532042\n",
      "Epoch 3301, reconstruction losses: 0.011036252420925449, regression losses: 0.09309262114883998, validation losses: 0.34294459595016413\n",
      "Epoch 3302, reconstruction losses: 0.011328109742158607, regression losses: 0.10023806967157045, validation losses: 0.32353657621888354\n",
      "Epoch 3303, reconstruction losses: 0.010779705101411375, regression losses: 0.07554157338876198, validation losses: 0.32795534227147555\n",
      "Epoch 3304, reconstruction losses: 0.012080842451062205, regression losses: 0.11266435846061357, validation losses: 0.32424395922451693\n",
      "Epoch 3305, reconstruction losses: 0.013036420517576367, regression losses: 0.1272970857684919, validation losses: 0.371891430996547\n",
      "Epoch 3306, reconstruction losses: 0.013609756288797929, regression losses: 0.11102899218487378, validation losses: 0.3415207320136474\n",
      "Epoch 3307, reconstruction losses: 0.010256652526333428, regression losses: 0.08578620756457687, validation losses: 0.3185319158847943\n",
      "Epoch 3308, reconstruction losses: 0.010879601547311959, regression losses: 0.09820946800604556, validation losses: 0.33185147163625556\n",
      "Epoch 3309, reconstruction losses: 0.013583179041870353, regression losses: 0.08376187679645279, validation losses: 0.35486242089260644\n",
      "Epoch 3310, reconstruction losses: 0.014253249562558901, regression losses: 0.09965096010467372, validation losses: 0.42270222686740677\n",
      "Epoch 3311, reconstruction losses: 0.013346377287155018, regression losses: 0.09718868767782561, validation losses: 0.38527861496934\n",
      "Epoch 3312, reconstruction losses: 0.012394534566834396, regression losses: 0.1260717612042334, validation losses: 0.3250195115934057\n",
      "Epoch 3313, reconstruction losses: 0.012354301660696747, regression losses: 0.078664628801588, validation losses: 0.35093583101155046\n",
      "Epoch 3314, reconstruction losses: 0.01704581582736745, regression losses: 0.1323059867769879, validation losses: 0.33174591045951884\n",
      "Epoch 3315, reconstruction losses: 0.01217926661602338, regression losses: 0.10980144644690219, validation losses: 0.3640850014347936\n",
      "Epoch 3316, reconstruction losses: 0.012954160283372405, regression losses: 0.08686728822216529, validation losses: 0.360455655044896\n",
      "Epoch 3317, reconstruction losses: 0.016717458108915444, regression losses: 0.1742407200093551, validation losses: 0.34318627072112934\n",
      "Epoch 3318, reconstruction losses: 0.013803363702346973, regression losses: 0.12778505625700676, validation losses: 0.37173601549095986\n",
      "Epoch 3319, reconstruction losses: 0.011784268895949518, regression losses: 0.09445957448509994, validation losses: 0.40069596936653545\n",
      "Epoch 3320, reconstruction losses: 0.012268790160189141, regression losses: 0.12422733008144066, validation losses: 0.3812649803516176\n",
      "Epoch 3321, reconstruction losses: 0.010852644949609844, regression losses: 0.08630755802389171, validation losses: 0.36957644101590237\n",
      "Epoch 3322, reconstruction losses: 0.013032330021756137, regression losses: 0.11825257077428462, validation losses: 0.4029481746567684\n",
      "Epoch 3323, reconstruction losses: 0.01067913233221556, regression losses: 0.0963694994538593, validation losses: 0.41037947476692177\n",
      "Epoch 3324, reconstruction losses: 0.009970521508491209, regression losses: 0.09318024447662554, validation losses: 0.3746681078217767\n",
      "Epoch 3325, reconstruction losses: 0.011944952358406898, regression losses: 0.1049414892334298, validation losses: 0.3450448127831718\n",
      "Epoch 3326, reconstruction losses: 0.01164229708741124, regression losses: 0.08719653816586319, validation losses: 0.34109069488924887\n",
      "Epoch 3327, reconstruction losses: 0.011917502269393317, regression losses: 0.10449135356621635, validation losses: 0.35616133647416603\n",
      "Epoch 3328, reconstruction losses: 0.012266489830278133, regression losses: 0.08198090190860673, validation losses: 0.3455554908771664\n",
      "Epoch 3329, reconstruction losses: 0.01106881312342914, regression losses: 0.09218189767755602, validation losses: 0.34515098795757165\n",
      "Epoch 3330, reconstruction losses: 0.01631609096989886, regression losses: 0.12507892258592357, validation losses: 0.38802777872102534\n",
      "Epoch 3331, reconstruction losses: 0.010573766959278488, regression losses: 0.07268845447338108, validation losses: 0.432754904152731\n",
      "Epoch 3332, reconstruction losses: 0.013735505466230829, regression losses: 0.11943601803135119, validation losses: 0.38127837506033585\n",
      "Epoch 3333, reconstruction losses: 0.012188663894789998, regression losses: 0.13997604293190008, validation losses: 0.3389726782841982\n",
      "Epoch 3334, reconstruction losses: 0.014440625960364047, regression losses: 0.0893404347132968, validation losses: 0.3479493701052342\n",
      "Epoch 3335, reconstruction losses: 0.012991596546155707, regression losses: 0.09461977674704788, validation losses: 0.3558474441221454\n",
      "Epoch 3336, reconstruction losses: 0.012059277197238235, regression losses: 0.11712810975069368, validation losses: 0.370075270117473\n",
      "Epoch 3337, reconstruction losses: 0.011076519443027498, regression losses: 0.09615644539287363, validation losses: 0.3540775966412471\n",
      "Epoch 3338, reconstruction losses: 0.010429561275233307, regression losses: 0.09380126285140247, validation losses: 0.37531494040675933\n",
      "Epoch 3339, reconstruction losses: 0.014405514040804078, regression losses: 0.12897401499599337, validation losses: 0.39948286952432993\n",
      "Epoch 3340, reconstruction losses: 0.010278250590044103, regression losses: 0.08394593003856485, validation losses: 0.4088074787457877\n",
      "Epoch 3341, reconstruction losses: 0.01057649433892566, regression losses: 0.07561706414588974, validation losses: 0.33922188685063515\n",
      "Epoch 3342, reconstruction losses: 0.01204531038774558, regression losses: 0.10838044796119425, validation losses: 0.34977910343569707\n",
      "Epoch 3343, reconstruction losses: 0.010737105140321881, regression losses: 0.0706450026694099, validation losses: 0.3745050747453614\n",
      "Epoch 3344, reconstruction losses: 0.012859398066176784, regression losses: 0.09428585532417551, validation losses: 0.35167145981219505\n",
      "Epoch 3345, reconstruction losses: 0.014188993995223881, regression losses: 0.1012190561562002, validation losses: 0.33288457614181605\n",
      "Epoch 3346, reconstruction losses: 0.015810245954421653, regression losses: 0.14841516261513604, validation losses: 0.3424157056341976\n",
      "Epoch 3347, reconstruction losses: 0.012260728268931272, regression losses: 0.09491551164407108, validation losses: 0.35287735066646037\n",
      "Epoch 3348, reconstruction losses: 0.012010191857773623, regression losses: 0.09376403729729066, validation losses: 0.3708995142655746\n",
      "Epoch 3349, reconstruction losses: 0.011740115345726165, regression losses: 0.14190259321311602, validation losses: 0.3442438143819035\n",
      "Epoch 3350, reconstruction losses: 0.017111701447768208, regression losses: 0.3936668892472296, validation losses: 0.3310914544792498\n",
      "Epoch 3351, reconstruction losses: 0.012486729702459882, regression losses: 0.1332709806872748, validation losses: 0.3475403606376994\n",
      "Epoch 3352, reconstruction losses: 0.013258676446753792, regression losses: 0.08070366839470915, validation losses: 0.3272793462938482\n",
      "Epoch 3353, reconstruction losses: 0.012328413719390117, regression losses: 0.1171090378059276, validation losses: 0.3996174745943728\n",
      "Epoch 3354, reconstruction losses: 0.011120546352852378, regression losses: 0.08329283352593424, validation losses: 0.4196936880995057\n",
      "Epoch 3355, reconstruction losses: 0.010550003710613143, regression losses: 0.09653224551999823, validation losses: 0.3811253913336557\n",
      "Epoch 3356, reconstruction losses: 0.011096613099166775, regression losses: 0.06826654415791203, validation losses: 0.351923121825575\n",
      "Epoch 3357, reconstruction losses: 0.013207049660021704, regression losses: 0.13957138616713577, validation losses: 0.32989873180836465\n",
      "Epoch 3358, reconstruction losses: 0.012753057634269134, regression losses: 0.1172717225864176, validation losses: 0.33012360359308873\n",
      "Epoch 3359, reconstruction losses: 0.011178885604137476, regression losses: 0.09935311354949161, validation losses: 0.33020504158329456\n",
      "Epoch 3360, reconstruction losses: 0.011313821527553187, regression losses: 0.09788247810428616, validation losses: 0.346591371665067\n",
      "Epoch 3361, reconstruction losses: 0.012311329492113929, regression losses: 0.09570615132383821, validation losses: 0.3709559802085262\n",
      "Epoch 3362, reconstruction losses: 0.014382214106898616, regression losses: 0.14619880684642003, validation losses: 0.35853992751231345\n",
      "Epoch 3363, reconstruction losses: 0.010947779989070837, regression losses: 0.0723131097248643, validation losses: 0.3293641915311011\n",
      "Epoch 3364, reconstruction losses: 0.011192312618001125, regression losses: 0.07749560707954048, validation losses: 0.32533291986766777\n",
      "Epoch 3365, reconstruction losses: 0.0110822994955159, regression losses: 0.11350669120538728, validation losses: 0.3383480993589765\n",
      "Epoch 3366, reconstruction losses: 0.012409125416654388, regression losses: 0.09773588170614461, validation losses: 0.39465900117317154\n",
      "Epoch 3367, reconstruction losses: 0.01132969304902207, regression losses: 0.11214186507347178, validation losses: 0.3571480064632177\n",
      "Epoch 3368, reconstruction losses: 0.015583062247909528, regression losses: 0.2049079400629285, validation losses: 0.3363425847604765\n",
      "Epoch 3369, reconstruction losses: 0.010686958770277968, regression losses: 0.07789189352723676, validation losses: 0.3455265896026164\n",
      "Epoch 3370, reconstruction losses: 0.010025518198128879, regression losses: 0.08044237217363666, validation losses: 0.3353199825085869\n",
      "Epoch 3371, reconstruction losses: 0.012329293795386444, regression losses: 0.09017788787318176, validation losses: 0.320834447075124\n",
      "Epoch 3372, reconstruction losses: 0.010973796472848569, regression losses: 0.07403401275208434, validation losses: 0.3137938428782052\n",
      "Epoch 3373, reconstruction losses: 0.010923765899307429, regression losses: 0.09412226207455349, validation losses: 0.30726524090920115\n",
      "Epoch 3374, reconstruction losses: 0.009733131972454725, regression losses: 0.06821094508670732, validation losses: 0.32448403669631776\n",
      "Epoch 3375, reconstruction losses: 0.012469001826044617, regression losses: 0.1004470321923502, validation losses: 0.33278847249020826\n",
      "Epoch 3376, reconstruction losses: 0.011552074977996752, regression losses: 0.12930623275523578, validation losses: 0.32331108941085973\n",
      "Epoch 3377, reconstruction losses: 0.01284220821436813, regression losses: 0.11097148143970663, validation losses: 0.34605896185403184\n",
      "Epoch 3378, reconstruction losses: 0.011240757795724265, regression losses: 0.09691477151349283, validation losses: 0.3533411859128942\n",
      "Epoch 3379, reconstruction losses: 0.016154971692406137, regression losses: 0.16352475018111146, validation losses: 0.32169258083368246\n",
      "Epoch 3380, reconstruction losses: 0.013839841223993541, regression losses: 0.10079202303386206, validation losses: 0.3010653019285416\n",
      "Epoch 3381, reconstruction losses: 0.013861584055248916, regression losses: 0.163980380129382, validation losses: 0.3170011458299504\n",
      "Epoch 3382, reconstruction losses: 0.01588059655079546, regression losses: 0.11587547937664587, validation losses: 0.3408611488663085\n",
      "Epoch 3383, reconstruction losses: 0.0173747427896803, regression losses: 0.1028861231830547, validation losses: 0.39497666844165386\n",
      "Epoch 3384, reconstruction losses: 0.012246564664878055, regression losses: 0.11212461661840577, validation losses: 0.5328260115875716\n",
      "Epoch 3385, reconstruction losses: 0.013707515440667409, regression losses: 0.11463983995195923, validation losses: 0.4828016012335106\n",
      "Epoch 3386, reconstruction losses: 0.015707731370117255, regression losses: 0.13363094531070288, validation losses: 0.36762145028320486\n",
      "Epoch 3387, reconstruction losses: 0.01460715856638928, regression losses: 0.34626884160498916, validation losses: 0.3510824800630338\n",
      "Epoch 3388, reconstruction losses: 0.01366950395453575, regression losses: 0.10325271941823662, validation losses: 0.5185309212782353\n",
      "Epoch 3389, reconstruction losses: 0.010412604039519232, regression losses: 0.11099823928140154, validation losses: 0.4536146727107659\n",
      "Epoch 3390, reconstruction losses: 0.011825243527807006, regression losses: 0.08113141979595487, validation losses: 0.35289898075519965\n",
      "Epoch 3391, reconstruction losses: 0.012338403978961594, regression losses: 0.10691432409465293, validation losses: 0.35087969416330866\n",
      "Epoch 3392, reconstruction losses: 0.012020403361301203, regression losses: 0.10358661535137981, validation losses: 0.3489003986748214\n",
      "Epoch 3393, reconstruction losses: 0.015534055544739061, regression losses: 0.10359531195906205, validation losses: 0.3610237296876049\n",
      "Epoch 3394, reconstruction losses: 0.01097519267192256, regression losses: 0.09389776745845475, validation losses: 0.3497696595248277\n",
      "Epoch 3395, reconstruction losses: 0.012518407517024432, regression losses: 0.09216978805761976, validation losses: 0.34760386752448713\n",
      "Epoch 3396, reconstruction losses: 0.013752365380609432, regression losses: 0.10074334086971187, validation losses: 0.3572479743072984\n",
      "Epoch 3397, reconstruction losses: 0.012977202578169266, regression losses: 0.382396476975453, validation losses: 0.3660212613543712\n",
      "Epoch 3398, reconstruction losses: 0.01475047946092951, regression losses: 0.16408192291572865, validation losses: 0.6859441501438017\n",
      "Epoch 3399, reconstruction losses: 0.012979421496123226, regression losses: 0.15036094814392822, validation losses: 0.78193499409946\n",
      "Epoch 3400, reconstruction losses: 0.016894328241351373, regression losses: 0.1774682944516246, validation losses: 0.5672060577277038\n",
      "Epoch 3401, reconstruction losses: 0.01407498404671993, regression losses: 0.1752363860634889, validation losses: 0.48020889900009117\n",
      "Epoch 3402, reconstruction losses: 0.014053755225272664, regression losses: 0.12768107938898454, validation losses: 0.4201610554498285\n",
      "Epoch 3403, reconstruction losses: 0.012607869279581407, regression losses: 0.1586744836359254, validation losses: 0.3950854711789333\n",
      "Epoch 3404, reconstruction losses: 0.013028943265094189, regression losses: 0.08527424270370475, validation losses: 0.38080270617046136\n",
      "Epoch 3405, reconstruction losses: 0.011776819877106638, regression losses: 0.09237170260096551, validation losses: 0.3892392406925802\n",
      "Epoch 3406, reconstruction losses: 0.010549035979026357, regression losses: 0.0781205727277154, validation losses: 0.3596677423460452\n",
      "Epoch 3407, reconstruction losses: 0.011386960905493923, regression losses: 0.08813990070331104, validation losses: 0.3517485299750498\n",
      "Epoch 3408, reconstruction losses: 0.014754896596038947, regression losses: 0.10425843809964687, validation losses: 0.3872694983106676\n",
      "Epoch 3409, reconstruction losses: 0.011796335443577315, regression losses: 0.09327292379379361, validation losses: 0.3569398252022\n",
      "Epoch 3410, reconstruction losses: 0.011604913470833249, regression losses: 0.09107972348124076, validation losses: 0.3724508583238837\n",
      "Epoch 3411, reconstruction losses: 0.011346166386140399, regression losses: 0.0953891347109124, validation losses: 0.36466454949409155\n",
      "Epoch 3412, reconstruction losses: 0.011364438880147834, regression losses: 0.14353524247666882, validation losses: 0.3665353972312557\n",
      "Epoch 3413, reconstruction losses: 0.011297475913399767, regression losses: 0.0979785927031173, validation losses: 0.34442245122963067\n",
      "Epoch 3414, reconstruction losses: 0.01191718095416796, regression losses: 0.10197078641743736, validation losses: 0.34518089053093604\n",
      "Epoch 3415, reconstruction losses: 0.01375817611931666, regression losses: 0.13012127554813271, validation losses: 0.3347470324428695\n",
      "Epoch 3416, reconstruction losses: 0.012198767656421392, regression losses: 0.12401130316436475, validation losses: 0.3274627749094643\n",
      "Epoch 3417, reconstruction losses: 0.015850505872084492, regression losses: 0.06736273755227287, validation losses: 0.36945206467122466\n",
      "Epoch 3418, reconstruction losses: 0.012349661688296078, regression losses: 0.10545946527302723, validation losses: 0.4007194264626832\n",
      "Epoch 3419, reconstruction losses: 0.016974554678116954, regression losses: 0.1778143264201439, validation losses: 0.4014226017874332\n",
      "Epoch 3420, reconstruction losses: 0.010413109096272563, regression losses: 0.1405778319245718, validation losses: 0.7084697382395775\n",
      "Epoch 3421, reconstruction losses: 0.016955486543934493, regression losses: 0.16749233489691648, validation losses: 0.6451421590512223\n",
      "Epoch 3422, reconstruction losses: 0.014059090393982543, regression losses: 0.11831892766995494, validation losses: 0.41784910706999173\n",
      "Epoch 3423, reconstruction losses: 0.013739285012858628, regression losses: 0.14870128728568366, validation losses: 0.4684554216686584\n",
      "Epoch 3424, reconstruction losses: 0.011131422834140025, regression losses: 0.11754372791584507, validation losses: 0.4576873188827564\n",
      "Epoch 3425, reconstruction losses: 0.01308818045730426, regression losses: 0.12396371276703604, validation losses: 0.3766890511060308\n",
      "Epoch 3426, reconstruction losses: 0.013463738744732247, regression losses: 0.13360234766984272, validation losses: 0.37151826361529783\n",
      "Epoch 3427, reconstruction losses: 0.01111037742072563, regression losses: 0.09843329950844038, validation losses: 0.35628932638935845\n",
      "Epoch 3428, reconstruction losses: 0.013503161342604294, regression losses: 0.09953575858477348, validation losses: 0.36197486005973656\n",
      "Epoch 3429, reconstruction losses: 0.012855784444856638, regression losses: 0.0986455118788622, validation losses: 0.3520530233298898\n",
      "Epoch 3430, reconstruction losses: 0.011453191693357775, regression losses: 0.08513296686320433, validation losses: 0.35370241840418437\n",
      "Epoch 3431, reconstruction losses: 0.012287198361134481, regression losses: 0.11826073374757821, validation losses: 0.35906706955021367\n",
      "Epoch 3432, reconstruction losses: 0.012058530743093702, regression losses: 0.071730461788837, validation losses: 0.35019106208447626\n",
      "Epoch 3433, reconstruction losses: 0.011413695901666143, regression losses: 0.08923568987330682, validation losses: 0.3634501666226195\n",
      "Epoch 3434, reconstruction losses: 0.010019859125110662, regression losses: 0.08508760689088887, validation losses: 0.35505896444143514\n",
      "Epoch 3435, reconstruction losses: 0.011021990138799082, regression losses: 0.07798837262994977, validation losses: 0.3468919623340312\n",
      "Epoch 3436, reconstruction losses: 0.010885145337731798, regression losses: 0.06822826113663574, validation losses: 0.34485501890986714\n",
      "Epoch 3437, reconstruction losses: 0.011047498895563746, regression losses: 0.06831206468286091, validation losses: 0.3414340492892878\n",
      "Epoch 3438, reconstruction losses: 0.012712627426645591, regression losses: 0.12528238720097312, validation losses: 0.33998521504386625\n",
      "Epoch 3439, reconstruction losses: 0.012919087390899694, regression losses: 0.09834527089872346, validation losses: 0.34734300528376916\n",
      "Epoch 3440, reconstruction losses: 0.011506555149395983, regression losses: 0.07711212526789155, validation losses: 0.34394242823869237\n",
      "Epoch 3441, reconstruction losses: 0.015376333617367392, regression losses: 0.2828160717477175, validation losses: 0.3769936794909683\n",
      "Epoch 3442, reconstruction losses: 0.019494228527050135, regression losses: 0.15140927557918132, validation losses: 0.5353825648195419\n",
      "Epoch 3443, reconstruction losses: 0.010701803966943355, regression losses: 0.1038029950439503, validation losses: 0.5921457808373514\n",
      "Epoch 3444, reconstruction losses: 0.015577829105863836, regression losses: 0.14227465258177222, validation losses: 0.5066830978676593\n",
      "Epoch 3445, reconstruction losses: 0.012862241562292228, regression losses: 0.11012242014993223, validation losses: 0.47893234416410296\n",
      "Epoch 3446, reconstruction losses: 0.010177763221213167, regression losses: 0.10323273492838433, validation losses: 0.43754064695397454\n",
      "Epoch 3447, reconstruction losses: 0.013536891554259346, regression losses: 0.10089584369782227, validation losses: 0.38409165122893585\n",
      "Epoch 3448, reconstruction losses: 0.01436596212285996, regression losses: 0.0812997260542763, validation losses: 0.3493886723732212\n",
      "Epoch 3449, reconstruction losses: 0.018043629798223857, regression losses: 0.10527926376584015, validation losses: 0.34484292725142945\n",
      "Epoch 3450, reconstruction losses: 0.013860408977779461, regression losses: 0.09313650077119053, validation losses: 0.3607635314990588\n",
      "Epoch 3451, reconstruction losses: 0.01441922597034639, regression losses: 0.09800311371203933, validation losses: 0.37093508729271774\n",
      "Epoch 3452, reconstruction losses: 0.010973572748541783, regression losses: 0.09850514329099569, validation losses: 0.3999374086813267\n",
      "Epoch 3453, reconstruction losses: 0.013874123553146912, regression losses: 0.10697638399276356, validation losses: 0.40647021293094665\n",
      "Epoch 3454, reconstruction losses: 0.01135958291192274, regression losses: 0.09395964914508309, validation losses: 0.4028435848454463\n",
      "Epoch 3455, reconstruction losses: 0.01410302820166562, regression losses: 0.13111460641732486, validation losses: 0.39245856814145247\n",
      "Epoch 3456, reconstruction losses: 0.00984158238476786, regression losses: 0.08646913999472342, validation losses: 0.38506200948632546\n",
      "Epoch 3457, reconstruction losses: 0.015538409719635375, regression losses: 0.08506118837432348, validation losses: 0.367857395483073\n",
      "Epoch 3458, reconstruction losses: 0.013838324797638031, regression losses: 0.18571657519023227, validation losses: 0.3512625446613661\n",
      "Epoch 3459, reconstruction losses: 0.013002819617126064, regression losses: 0.10414265406264991, validation losses: 0.44988590528308064\n",
      "Epoch 3460, reconstruction losses: 0.01212708220049979, regression losses: 0.09783277618056649, validation losses: 0.46246905085441026\n",
      "Epoch 3461, reconstruction losses: 0.010696211670047097, regression losses: 0.08386228424668425, validation losses: 0.3813904942874275\n",
      "Epoch 3462, reconstruction losses: 0.011451266075465939, regression losses: 0.09607124682545189, validation losses: 0.41884689034043043\n",
      "Epoch 3463, reconstruction losses: 0.01282114504246877, regression losses: 0.1075633360406438, validation losses: 0.4159349386193604\n",
      "Epoch 3464, reconstruction losses: 0.015351029769664987, regression losses: 0.15396076308950196, validation losses: 0.4202373940751341\n",
      "Epoch 3465, reconstruction losses: 0.015278523963249253, regression losses: 0.09507537861766818, validation losses: 0.380614101185732\n",
      "Epoch 3466, reconstruction losses: 0.013278500515898118, regression losses: 0.11335042662027026, validation losses: 0.3489462145326372\n",
      "Epoch 3467, reconstruction losses: 0.010355779403426729, regression losses: 0.07870243878792815, validation losses: 0.34215292668408953\n",
      "Epoch 3468, reconstruction losses: 0.012055842833212309, regression losses: 0.09026866438818786, validation losses: 0.33588049746554527\n",
      "Epoch 3469, reconstruction losses: 0.012110455801712485, regression losses: 0.12457351427348723, validation losses: 0.33314659228141474\n",
      "Epoch 3470, reconstruction losses: 0.012460469984071998, regression losses: 0.11256522617469968, validation losses: 0.3182505358817776\n",
      "Epoch 3471, reconstruction losses: 0.013563228310256945, regression losses: 0.10861754681521027, validation losses: 0.33871996119796305\n",
      "Epoch 3472, reconstruction losses: 0.011735872881342596, regression losses: 0.09620124440662231, validation losses: 0.3313937599908966\n",
      "Epoch 3473, reconstruction losses: 0.013990800810113876, regression losses: 0.12199723806469617, validation losses: 0.3400563143456989\n",
      "Epoch 3474, reconstruction losses: 0.012800678827408962, regression losses: 0.11643462273512474, validation losses: 0.3571667302551955\n",
      "Epoch 3475, reconstruction losses: 0.010645226765647792, regression losses: 0.08822950577358529, validation losses: 0.3547468852656208\n",
      "Epoch 3476, reconstruction losses: 0.017301414167928533, regression losses: 0.1539525100968982, validation losses: 0.35149636579746424\n",
      "Epoch 3477, reconstruction losses: 0.011049887347782674, regression losses: 0.08372726199759559, validation losses: 0.40214801598904837\n",
      "Epoch 3478, reconstruction losses: 0.0125216772048819, regression losses: 0.20737178217167168, validation losses: 0.3854057973903665\n",
      "Epoch 3479, reconstruction losses: 0.010948983866258774, regression losses: 0.09728378083484954, validation losses: 0.355860523720714\n",
      "Epoch 3480, reconstruction losses: 0.015620075439920677, regression losses: 0.12269204235070211, validation losses: 0.3715016100639564\n",
      "Epoch 3481, reconstruction losses: 0.011091204384078046, regression losses: 0.11419104833310526, validation losses: 0.3846532708099434\n",
      "Epoch 3482, reconstruction losses: 0.012696075053542262, regression losses: 0.08901103589404687, validation losses: 0.3758899777645365\n",
      "Epoch 3483, reconstruction losses: 0.012876787721863132, regression losses: 0.09583300228531393, validation losses: 0.4300203631936809\n",
      "Epoch 3484, reconstruction losses: 0.013810225994402361, regression losses: 0.12409563302795926, validation losses: 0.3790174080767358\n",
      "Epoch 3485, reconstruction losses: 0.014047196821492011, regression losses: 0.155155157606795, validation losses: 0.3751158784541134\n",
      "Epoch 3486, reconstruction losses: 0.013558359406209555, regression losses: 0.12574785071137615, validation losses: 0.43626814772560973\n",
      "Epoch 3487, reconstruction losses: 0.012818388256136811, regression losses: 0.1142607850868861, validation losses: 0.41491400516069904\n",
      "Epoch 3488, reconstruction losses: 0.014824039410294474, regression losses: 0.11589229123133862, validation losses: 0.38497136944729377\n",
      "Epoch 3489, reconstruction losses: 0.012614348118215431, regression losses: 0.11559213612423049, validation losses: 0.3509183787544267\n",
      "Epoch 3490, reconstruction losses: 0.013478230721772379, regression losses: 0.09658104517647333, validation losses: 0.35639756291529257\n",
      "Epoch 3491, reconstruction losses: 0.016377933648139116, regression losses: 0.16639720972847105, validation losses: 0.3976191108629479\n",
      "Epoch 3492, reconstruction losses: 0.010926445434109316, regression losses: 0.08410813238004658, validation losses: 0.3773727562720317\n",
      "Epoch 3493, reconstruction losses: 0.011230753086809198, regression losses: 0.094070582262827, validation losses: 0.3687148920178924\n",
      "Epoch 3494, reconstruction losses: 0.012900010412817804, regression losses: 0.11671064948710268, validation losses: 0.36051478584110963\n",
      "Epoch 3495, reconstruction losses: 0.011076522873950915, regression losses: 0.08597080333121301, validation losses: 0.364043325344079\n",
      "Epoch 3496, reconstruction losses: 0.01046186090993359, regression losses: 0.12580608448490624, validation losses: 0.382448220624191\n",
      "Epoch 3497, reconstruction losses: 0.011570750972814499, regression losses: 0.16036929640405434, validation losses: 0.40107508186150354\n",
      "Epoch 3498, reconstruction losses: 0.013045163311626385, regression losses: 0.16551620002359357, validation losses: 0.4016788433236339\n",
      "Epoch 3499, reconstruction losses: 0.013111994982344256, regression losses: 0.09157850955469735, validation losses: 0.4366441462390202\n",
      "Epoch 3500, reconstruction losses: 0.010663010975920617, regression losses: 0.10020600095246342, validation losses: 0.37850243737123695\n",
      "Epoch 3501, reconstruction losses: 0.010748274067324358, regression losses: 0.07065435939985337, validation losses: 0.36080386772944956\n",
      "Epoch 3502, reconstruction losses: 0.01134926381217454, regression losses: 0.10071893091932099, validation losses: 0.36763422323532285\n",
      "Epoch 3503, reconstruction losses: 0.011421498470086196, regression losses: 0.10118294153360474, validation losses: 0.3406530891219276\n",
      "Epoch 3504, reconstruction losses: 0.01406573179842041, regression losses: 0.3362436841582132, validation losses: 0.3291815158235017\n",
      "Epoch 3505, reconstruction losses: 0.012754093973005975, regression losses: 0.13347292476962508, validation losses: 0.40447351633738643\n",
      "Epoch 3506, reconstruction losses: 0.013218112210902421, regression losses: 0.11272766008682544, validation losses: 0.4881794237690636\n",
      "Epoch 3507, reconstruction losses: 0.011946932899180253, regression losses: 0.09813746888908617, validation losses: 0.4577630854318031\n",
      "Epoch 3508, reconstruction losses: 0.0110951354331654, regression losses: 0.09134732797222879, validation losses: 0.3796028922364571\n",
      "Epoch 3509, reconstruction losses: 0.01426279614203455, regression losses: 0.09740544856199176, validation losses: 0.35971006114376586\n",
      "Epoch 3510, reconstruction losses: 0.013817848912424886, regression losses: 0.10146109140136683, validation losses: 0.36020549871726854\n",
      "Epoch 3511, reconstruction losses: 0.013254350746424576, regression losses: 0.1052259815498908, validation losses: 0.33704650522760127\n",
      "Epoch 3512, reconstruction losses: 0.010443718197380249, regression losses: 0.07316867141324303, validation losses: 0.34480303077156554\n",
      "Epoch 3513, reconstruction losses: 0.012876506804027832, regression losses: 0.1019752802046854, validation losses: 0.34742038134479253\n",
      "Epoch 3514, reconstruction losses: 0.011159337308958229, regression losses: 0.09987208907522062, validation losses: 0.3460131206552109\n",
      "Epoch 3515, reconstruction losses: 0.010848099659079097, regression losses: 0.09146337296329954, validation losses: 0.34505918226183074\n",
      "Epoch 3516, reconstruction losses: 0.011377043126619562, regression losses: 0.07858058572678613, validation losses: 0.3382539952432696\n",
      "Epoch 3517, reconstruction losses: 0.013355084648963114, regression losses: 0.1270656753339554, validation losses: 0.33968175809812007\n",
      "Epoch 3518, reconstruction losses: 0.011114968483808343, regression losses: 0.10710206647510179, validation losses: 0.38967720699980185\n",
      "Epoch 3519, reconstruction losses: 0.01106571726524039, regression losses: 0.09879687831625673, validation losses: 0.35731158783780564\n",
      "Epoch 3520, reconstruction losses: 0.013046006669334411, regression losses: 0.10707789245917175, validation losses: 0.3752477738593941\n",
      "Epoch 3521, reconstruction losses: 0.01136481587707138, regression losses: 0.09813238166123756, validation losses: 0.4813483545490137\n",
      "Epoch 3522, reconstruction losses: 0.013540384502114646, regression losses: 0.13558198047885742, validation losses: 0.3950064264865659\n",
      "Epoch 3523, reconstruction losses: 0.013349578341735877, regression losses: 0.13910221491719285, validation losses: 0.35016601929327007\n",
      "Epoch 3524, reconstruction losses: 0.013600120745688594, regression losses: 0.0778359581349966, validation losses: 0.4391763337091651\n",
      "Epoch 3525, reconstruction losses: 0.014568429218786899, regression losses: 0.1366451613374304, validation losses: 0.4030112144839648\n",
      "Epoch 3526, reconstruction losses: 0.012109500590590707, regression losses: 0.07937029052083315, validation losses: 0.33862664341778304\n",
      "Epoch 3527, reconstruction losses: 0.012448470328091338, regression losses: 0.10297956803847667, validation losses: 0.3192970176356259\n",
      "Epoch 3528, reconstruction losses: 0.020947262662259516, regression losses: 0.239256992853201, validation losses: 0.33841647341937714\n",
      "Epoch 3529, reconstruction losses: 0.012745797338680082, regression losses: 0.13843018659192552, validation losses: 0.5794493995723365\n",
      "Epoch 3530, reconstruction losses: 0.013898355582773927, regression losses: 0.2411373994378065, validation losses: 0.42572263584665176\n",
      "Epoch 3531, reconstruction losses: 0.013291435447784971, regression losses: 0.11442967972090824, validation losses: 0.4532686289227391\n",
      "Epoch 3532, reconstruction losses: 0.011898098432574323, regression losses: 0.15007877150734583, validation losses: 0.4827920357856754\n",
      "Epoch 3533, reconstruction losses: 0.018055441449938613, regression losses: 0.2321747907335152, validation losses: 0.5047560688142402\n",
      "Epoch 3534, reconstruction losses: 0.018616906362314334, regression losses: 0.11325206293911273, validation losses: 0.8466593295470631\n",
      "Epoch 3535, reconstruction losses: 0.016302391808497227, regression losses: 0.18798022343881673, validation losses: 0.6838423782571786\n",
      "Epoch 3536, reconstruction losses: 0.016814761233799082, regression losses: 0.17105465430424913, validation losses: 0.39531745167377297\n",
      "Epoch 3537, reconstruction losses: 0.01595751622202222, regression losses: 0.10613169649315343, validation losses: 0.3930142578706527\n",
      "Epoch 3538, reconstruction losses: 0.014039361315509515, regression losses: 0.14910738655021485, validation losses: 0.422507281414907\n",
      "Epoch 3539, reconstruction losses: 0.01093174022733047, regression losses: 0.09652419647911924, validation losses: 0.34859833703692333\n",
      "Epoch 3540, reconstruction losses: 0.011630845215285733, regression losses: 0.07035269058437169, validation losses: 0.31672470866893965\n",
      "Epoch 3541, reconstruction losses: 0.01596951193833226, regression losses: 0.14033210915587047, validation losses: 0.32979255442423744\n",
      "Epoch 3542, reconstruction losses: 0.015580026440960558, regression losses: 0.11834610362950979, validation losses: 0.3441650148199441\n",
      "Epoch 3543, reconstruction losses: 0.01579534806928467, regression losses: 0.10960937571475102, validation losses: 0.33078222633862875\n",
      "Epoch 3544, reconstruction losses: 0.01223609146243804, regression losses: 0.1521995555712132, validation losses: 0.3457239313156079\n",
      "Epoch 3545, reconstruction losses: 0.01168266407598302, regression losses: 0.09046684720375052, validation losses: 0.4304557671766403\n",
      "Epoch 3546, reconstruction losses: 0.01194201389989956, regression losses: 0.09200791414287042, validation losses: 0.47667150558242277\n",
      "Epoch 3547, reconstruction losses: 0.012308013757500966, regression losses: 0.15660862711427923, validation losses: 0.4083574981576292\n",
      "Epoch 3548, reconstruction losses: 0.014511573158725356, regression losses: 0.3187457320082363, validation losses: 0.35392208007038917\n",
      "Epoch 3549, reconstruction losses: 0.018943683827501633, regression losses: 0.13666472907415864, validation losses: 0.4871222179564828\n",
      "Epoch 3550, reconstruction losses: 0.013290591766888515, regression losses: 0.19092831743450156, validation losses: 0.47819154989734286\n",
      "Epoch 3551, reconstruction losses: 0.013064610895282571, regression losses: 0.1358654882560224, validation losses: 0.4077334418460612\n",
      "Epoch 3552, reconstruction losses: 0.015949118480918664, regression losses: 0.1049311116362388, validation losses: 0.3937968066612789\n",
      "Epoch 3553, reconstruction losses: 0.020269449531286662, regression losses: 0.1497756278570652, validation losses: 0.35513483004641916\n",
      "Epoch 3554, reconstruction losses: 0.012032050413983456, regression losses: 0.12216544606238078, validation losses: 0.43697441099702466\n",
      "Epoch 3555, reconstruction losses: 0.011914126163888528, regression losses: 0.0951875215908764, validation losses: 0.3880711383711329\n",
      "Epoch 3556, reconstruction losses: 0.011959136443381542, regression losses: 0.09899678621771492, validation losses: 0.38559962068221043\n",
      "Epoch 3557, reconstruction losses: 0.013372020764755398, regression losses: 0.1227013077109519, validation losses: 0.40560222735244106\n",
      "Epoch 3558, reconstruction losses: 0.011894018484955136, regression losses: 0.10083697700049916, validation losses: 0.34743251069402503\n",
      "Epoch 3559, reconstruction losses: 0.010262494671073544, regression losses: 0.07249800596428377, validation losses: 0.32048263855462533\n",
      "Epoch 3560, reconstruction losses: 0.011205138874307678, regression losses: 0.09553454659105133, validation losses: 0.31608647629689757\n",
      "Epoch 3561, reconstruction losses: 0.012448596388348748, regression losses: 0.12140088891695061, validation losses: 0.3381439835801438\n",
      "Epoch 3562, reconstruction losses: 0.010373529835662256, regression losses: 0.07173129354174185, validation losses: 0.3469982712334217\n",
      "Epoch 3563, reconstruction losses: 0.012137702511154492, regression losses: 0.1148115437240918, validation losses: 0.35568101975479094\n",
      "Epoch 3564, reconstruction losses: 0.01319941796170377, regression losses: 0.07912945372372258, validation losses: 0.35078696272524634\n",
      "Epoch 3565, reconstruction losses: 0.012280138568673625, regression losses: 0.11131955784559616, validation losses: 0.3489725154160312\n",
      "Epoch 3566, reconstruction losses: 0.012432849431673606, regression losses: 0.05829489563327581, validation losses: 0.3399867100285732\n",
      "Epoch 3567, reconstruction losses: 0.009045881734459268, regression losses: 0.05930945118899288, validation losses: 0.3473362463132795\n",
      "Epoch 3568, reconstruction losses: 0.013533036573644044, regression losses: 0.08639419298347754, validation losses: 0.33823913518296134\n",
      "Epoch 3569, reconstruction losses: 0.01240591414819623, regression losses: 0.09272972119576423, validation losses: 0.3444942860498825\n",
      "Epoch 3570, reconstruction losses: 0.015135045116901353, regression losses: 0.10234893621188806, validation losses: 0.34229174235968135\n",
      "Epoch 3571, reconstruction losses: 0.01270169616454547, regression losses: 0.08893614348300445, validation losses: 0.33044852050014845\n",
      "Epoch 3572, reconstruction losses: 0.009781466696767889, regression losses: 0.10451487462516106, validation losses: 0.32785894568847723\n",
      "Epoch 3573, reconstruction losses: 0.01501815130007968, regression losses: 0.12301946933159733, validation losses: 0.32806533492037526\n",
      "Epoch 3574, reconstruction losses: 0.012781906013654143, regression losses: 0.1070372263286954, validation losses: 0.43398472226644463\n",
      "Epoch 3575, reconstruction losses: 0.011064517331777109, regression losses: 0.09818890958396621, validation losses: 0.4084105384692678\n",
      "Epoch 3576, reconstruction losses: 0.012283735140508241, regression losses: 0.10781827466802021, validation losses: 0.35644420133184584\n",
      "Epoch 3577, reconstruction losses: 0.012826798447612146, regression losses: 0.10928486764704048, validation losses: 0.3968670287909768\n",
      "Epoch 3578, reconstruction losses: 0.011095075890948443, regression losses: 0.09722160686475359, validation losses: 0.44164516420501704\n",
      "Epoch 3579, reconstruction losses: 0.013198361278922053, regression losses: 0.13230563175645843, validation losses: 0.40263498879386506\n",
      "Epoch 3580, reconstruction losses: 0.012434216777217401, regression losses: 0.1657778894034781, validation losses: 0.359364641073283\n",
      "Epoch 3581, reconstruction losses: 0.011617396120899142, regression losses: 0.07748612176034486, validation losses: 0.37523032539527246\n",
      "Epoch 3582, reconstruction losses: 0.011890163898372495, regression losses: 0.0935699108491114, validation losses: 0.38444851647229267\n",
      "Epoch 3583, reconstruction losses: 0.012336936690289787, regression losses: 0.103807709595073, validation losses: 0.3885939224759205\n",
      "Epoch 3584, reconstruction losses: 0.012864071276237735, regression losses: 0.08512438454219311, validation losses: 0.3740403156449188\n",
      "Epoch 3585, reconstruction losses: 0.010696775169997154, regression losses: 0.08560777950061702, validation losses: 0.37760385609912195\n",
      "Epoch 3586, reconstruction losses: 0.01332752703907459, regression losses: 0.1431871003720779, validation losses: 0.33220709809129745\n",
      "Epoch 3587, reconstruction losses: 0.013653743962532014, regression losses: 0.23172536523318424, validation losses: 0.34511403811744606\n",
      "Epoch 3588, reconstruction losses: 0.011539763515655863, regression losses: 0.08569890726236824, validation losses: 0.34656961278786863\n",
      "Epoch 3589, reconstruction losses: 0.012709947325195464, regression losses: 0.11128112479055187, validation losses: 0.3653617439818744\n",
      "Epoch 3590, reconstruction losses: 0.012041671843950245, regression losses: 0.08471843447111588, validation losses: 0.36928399800000944\n",
      "Epoch 3591, reconstruction losses: 0.011733355716301009, regression losses: 0.08695157012698027, validation losses: 0.3551332792114352\n",
      "Epoch 3592, reconstruction losses: 0.011781573837112952, regression losses: 0.0882962318307415, validation losses: 0.40091795228314664\n",
      "Epoch 3593, reconstruction losses: 0.009941264587639251, regression losses: 0.07464625805706714, validation losses: 0.3864079409197127\n",
      "Epoch 3594, reconstruction losses: 0.011391583737308886, regression losses: 0.08967923300917069, validation losses: 0.342180365536323\n",
      "Epoch 3595, reconstruction losses: 0.010830890555353684, regression losses: 0.09448658474284052, validation losses: 0.31692072599500076\n",
      "Epoch 3596, reconstruction losses: 0.010813524230991488, regression losses: 0.07966541887620594, validation losses: 0.31681684277116867\n",
      "Epoch 3597, reconstruction losses: 0.011648993647391482, regression losses: 0.08367821100398463, validation losses: 0.3184668022498193\n",
      "Epoch 3598, reconstruction losses: 0.018627693701084372, regression losses: 0.13944603881454654, validation losses: 0.3526315622786376\n",
      "Epoch 3599, reconstruction losses: 0.012265865357942, regression losses: 0.09855585281131894, validation losses: 0.3806260198615114\n",
      "Epoch 3600, reconstruction losses: 0.011721501705279644, regression losses: 0.1315133168755727, validation losses: 0.3866970151031849\n",
      "Epoch 3601, reconstruction losses: 0.016285187551917935, regression losses: 0.3665719229642148, validation losses: 0.35431258263812915\n",
      "Epoch 3602, reconstruction losses: 0.013798302332968429, regression losses: 0.20860628304993184, validation losses: 0.6033373297034181\n",
      "Epoch 3603, reconstruction losses: 0.014372731229771757, regression losses: 0.13507981116339984, validation losses: 0.5130486135602985\n",
      "Epoch 3604, reconstruction losses: 0.012930975967383736, regression losses: 0.09919441821236223, validation losses: 0.40284640876914174\n",
      "Epoch 3605, reconstruction losses: 0.012261338234620339, regression losses: 0.10100869179190113, validation losses: 0.38239671847692447\n",
      "Epoch 3606, reconstruction losses: 0.011269807036258463, regression losses: 0.10074999991472523, validation losses: 0.3673064080227305\n",
      "Epoch 3607, reconstruction losses: 0.012326864747268202, regression losses: 0.08487890331084119, validation losses: 0.37785571935914225\n",
      "Epoch 3608, reconstruction losses: 0.011682943150092325, regression losses: 0.09415506939360987, validation losses: 0.3871174095353628\n",
      "Epoch 3609, reconstruction losses: 0.014273110616910084, regression losses: 0.06742052649157118, validation losses: 0.38465869416262066\n",
      "Epoch 3610, reconstruction losses: 0.01023622676795392, regression losses: 0.06589870805313265, validation losses: 0.37378787321864887\n",
      "Epoch 3611, reconstruction losses: 0.014785413104158564, regression losses: 0.10431046686566643, validation losses: 0.3750126129270656\n",
      "Epoch 3612, reconstruction losses: 0.011367904610152716, regression losses: 0.10168972381720004, validation losses: 0.3654872532191268\n",
      "Epoch 3613, reconstruction losses: 0.010952925057790303, regression losses: 0.09033591714756299, validation losses: 0.34607297546726074\n",
      "Epoch 3614, reconstruction losses: 0.01100208707500242, regression losses: 0.07899248558631222, validation losses: 0.33584133383363113\n",
      "Epoch 3615, reconstruction losses: 0.014549786879159275, regression losses: 0.19756945268320164, validation losses: 0.3348315182446131\n",
      "Epoch 3616, reconstruction losses: 0.015124352376429033, regression losses: 0.08061532574372315, validation losses: 0.5044088987744976\n",
      "Epoch 3617, reconstruction losses: 0.012579349755656463, regression losses: 0.11697664740704658, validation losses: 0.5344022715772779\n",
      "Epoch 3618, reconstruction losses: 0.012472717578560624, regression losses: 0.1669146832052357, validation losses: 0.42837578549741107\n",
      "Epoch 3619, reconstruction losses: 0.014495590045454846, regression losses: 0.13868566191229914, validation losses: 0.4352942331928246\n",
      "Epoch 3620, reconstruction losses: 0.014823237523506526, regression losses: 0.12847236078637175, validation losses: 0.48609896030111427\n",
      "Epoch 3621, reconstruction losses: 0.013357287447915416, regression losses: 0.13293707981723252, validation losses: 0.4288498211780018\n",
      "Epoch 3622, reconstruction losses: 0.012027749679442708, regression losses: 0.10687063128010924, validation losses: 0.3634724951365408\n",
      "Epoch 3623, reconstruction losses: 0.016102238714927334, regression losses: 0.13653176923088445, validation losses: 0.35350869731926005\n",
      "Epoch 3624, reconstruction losses: 0.011014096092605136, regression losses: 0.07914257408819088, validation losses: 0.35102171520205394\n",
      "Epoch 3625, reconstruction losses: 0.010538223534719319, regression losses: 0.08184345557889941, validation losses: 0.33239791811762087\n",
      "Epoch 3626, reconstruction losses: 0.011663970333270724, regression losses: 0.08429603917952207, validation losses: 0.31126566156863256\n",
      "Epoch 3627, reconstruction losses: 0.01466365756686605, regression losses: 0.11600633512553432, validation losses: 0.31175572365356996\n",
      "Epoch 3628, reconstruction losses: 0.014364569685195307, regression losses: 0.10659671058199928, validation losses: 0.3191767939005235\n",
      "Epoch 3629, reconstruction losses: 0.013916823743110155, regression losses: 0.13508296725641203, validation losses: 0.3277985492721922\n",
      "Epoch 3630, reconstruction losses: 0.009536808751479785, regression losses: 0.09129733620999796, validation losses: 0.3688462775111347\n",
      "Epoch 3631, reconstruction losses: 0.01640343295826632, regression losses: 0.1436583113929365, validation losses: 0.37166250009279855\n",
      "Epoch 3632, reconstruction losses: 0.014086331399602886, regression losses: 0.09565140532084439, validation losses: 0.3547827114746201\n",
      "Epoch 3633, reconstruction losses: 0.01108380944282601, regression losses: 0.06923694679060745, validation losses: 0.3794840677937053\n",
      "Epoch 3634, reconstruction losses: 0.01206067277410279, regression losses: 0.10997589626679723, validation losses: 0.4347948322610345\n",
      "Epoch 3635, reconstruction losses: 0.012252470211936876, regression losses: 0.11584039434611726, validation losses: 0.4116650630027045\n",
      "Epoch 3636, reconstruction losses: 0.02397476653212424, regression losses: 0.5639526775945547, validation losses: 0.35063222991257287\n",
      "Epoch 3637, reconstruction losses: 0.012558176760092445, regression losses: 0.12193253471754681, validation losses: 0.4669591334537386\n",
      "Epoch 3638, reconstruction losses: 0.015281263741133146, regression losses: 0.10872632032548903, validation losses: 0.4963697602768382\n",
      "Epoch 3639, reconstruction losses: 0.012717448206783416, regression losses: 0.08141887502832301, validation losses: 0.47169661105861266\n",
      "Epoch 3640, reconstruction losses: 0.013911243736010204, regression losses: 0.08239293062967962, validation losses: 0.45153604253045576\n",
      "Epoch 3641, reconstruction losses: 0.0240137158884517, regression losses: 0.16217032530776354, validation losses: 0.40513042699699375\n",
      "Epoch 3642, reconstruction losses: 0.013710195529123347, regression losses: 0.09435499152646554, validation losses: 0.42008894526384505\n",
      "Epoch 3643, reconstruction losses: 0.012269507802239784, regression losses: 0.10374405372107168, validation losses: 0.4175472888790465\n",
      "Epoch 3644, reconstruction losses: 0.012250332021895833, regression losses: 0.09785881300110215, validation losses: 0.384835246156233\n",
      "Epoch 3645, reconstruction losses: 0.011660246114582018, regression losses: 0.12382229192057867, validation losses: 0.44612573647022236\n",
      "Epoch 3646, reconstruction losses: 0.013912487519903774, regression losses: 0.12342015935867506, validation losses: 0.3882804955706698\n",
      "Epoch 3647, reconstruction losses: 0.014941369230125949, regression losses: 0.13615779494428878, validation losses: 0.37246962755406415\n",
      "Epoch 3648, reconstruction losses: 0.012015134578864788, regression losses: 0.10419235815666168, validation losses: 0.37918901253865495\n",
      "Epoch 3649, reconstruction losses: 0.012820634152809419, regression losses: 0.13274867367332907, validation losses: 0.37296215808250704\n",
      "Epoch 3650, reconstruction losses: 0.010616896315498307, regression losses: 0.08937911702617385, validation losses: 0.37202842860635676\n",
      "Epoch 3651, reconstruction losses: 0.013449624794597426, regression losses: 0.08188462205685265, validation losses: 0.37823390655051614\n",
      "Epoch 3652, reconstruction losses: 0.012017539342389368, regression losses: 0.0945890476111206, validation losses: 0.4140187657815977\n",
      "Epoch 3653, reconstruction losses: 0.010599724638057901, regression losses: 0.08429746927592208, validation losses: 0.351688102108538\n",
      "Epoch 3654, reconstruction losses: 0.013049378607187431, regression losses: 0.10412658364229167, validation losses: 0.3458129624799279\n",
      "Epoch 3655, reconstruction losses: 0.015810225380780207, regression losses: 0.13011951008270922, validation losses: 0.35738375562966473\n",
      "Epoch 3656, reconstruction losses: 0.015879900539393622, regression losses: 0.13541554339474993, validation losses: 0.3931110112644569\n",
      "Epoch 3657, reconstruction losses: 0.013325005675156484, regression losses: 0.1049823154084326, validation losses: 0.36551071224546544\n",
      "Epoch 3658, reconstruction losses: 0.011577885060217674, regression losses: 0.0975660674826038, validation losses: 0.37907455839500137\n",
      "Epoch 3659, reconstruction losses: 0.01245704889857491, regression losses: 0.115135029832845, validation losses: 0.3783541681123609\n",
      "Epoch 3660, reconstruction losses: 0.012615744652106922, regression losses: 0.12934550056955077, validation losses: 0.3895263763302734\n",
      "Epoch 3661, reconstruction losses: 0.014945230093149006, regression losses: 0.1098262749887237, validation losses: 0.38367953866294335\n",
      "Epoch 3662, reconstruction losses: 0.010275060438371812, regression losses: 0.07901379585579017, validation losses: 0.3775537126540449\n",
      "Epoch 3663, reconstruction losses: 0.012949470325914326, regression losses: 0.09500243331489414, validation losses: 0.39456318814923386\n",
      "Epoch 3664, reconstruction losses: 0.010364245142421768, regression losses: 0.0884514221874609, validation losses: 0.39764084875748834\n",
      "Epoch 3665, reconstruction losses: 0.011067588973631937, regression losses: 0.0867392401274706, validation losses: 0.36528086535483323\n",
      "Epoch 3666, reconstruction losses: 0.009983091492147562, regression losses: 0.07809252313666333, validation losses: 0.3562644046553206\n",
      "Epoch 3667, reconstruction losses: 0.014568599769734583, regression losses: 0.11092725830217964, validation losses: 0.3380769189076065\n",
      "Epoch 3668, reconstruction losses: 0.01180413785710109, regression losses: 0.21057211475834078, validation losses: 0.35910692070711875\n",
      "Epoch 3669, reconstruction losses: 0.014713017193346358, regression losses: 0.101552751706217, validation losses: 0.3700748126527916\n",
      "Epoch 3670, reconstruction losses: 0.012825649187084596, regression losses: 0.1210816483250198, validation losses: 0.37892459592297634\n",
      "Epoch 3671, reconstruction losses: 0.015922226003925365, regression losses: 0.12716458727601154, validation losses: 0.42594386773707776\n",
      "Epoch 3672, reconstruction losses: 0.0109071009223257, regression losses: 0.0848771319496895, validation losses: 0.40939623035737205\n",
      "Epoch 3673, reconstruction losses: 0.013465590354232433, regression losses: 0.08857485255765425, validation losses: 0.35442981194788503\n",
      "Epoch 3674, reconstruction losses: 0.017908571793681192, regression losses: 0.14026455444433067, validation losses: 0.3529888718752927\n",
      "Epoch 3675, reconstruction losses: 0.01293788327031499, regression losses: 0.06563912984112194, validation losses: 0.3496434789743797\n",
      "Epoch 3676, reconstruction losses: 0.019290211058344425, regression losses: 0.1770440593477028, validation losses: 0.3548981624894278\n",
      "Epoch 3677, reconstruction losses: 0.015189100386780787, regression losses: 0.12711338606929817, validation losses: 0.4899659059978847\n",
      "Epoch 3678, reconstruction losses: 0.01487106714011365, regression losses: 0.1271595536148183, validation losses: 0.36519420803051206\n",
      "Epoch 3679, reconstruction losses: 0.01844894492725647, regression losses: 0.1465024279132812, validation losses: 0.40712063191528247\n",
      "Epoch 3680, reconstruction losses: 0.021655001350803345, regression losses: 0.3780364273623039, validation losses: 0.6463250338351506\n",
      "Epoch 3681, reconstruction losses: 0.01654601834484381, regression losses: 0.1415589678362585, validation losses: 1.0523528654512662\n",
      "Epoch 3682, reconstruction losses: 0.014523501562408687, regression losses: 0.2054619683854556, validation losses: 0.7672207234537294\n",
      "Epoch 3683, reconstruction losses: 0.015919407653927926, regression losses: 0.20128150760167918, validation losses: 0.4833523227469481\n",
      "Epoch 3684, reconstruction losses: 0.011949514780777127, regression losses: 0.10552982424786339, validation losses: 0.5262543467608489\n",
      "Epoch 3685, reconstruction losses: 0.01061448908821042, regression losses: 0.0980739523624798, validation losses: 0.48002440006725206\n",
      "Epoch 3686, reconstruction losses: 0.012214627766149417, regression losses: 0.10558067042718436, validation losses: 0.4008652040937468\n",
      "Epoch 3687, reconstruction losses: 0.011454780479371743, regression losses: 0.09897237223035453, validation losses: 0.34070805884245325\n",
      "Epoch 3688, reconstruction losses: 0.01237396023578337, regression losses: 0.0888648726672415, validation losses: 0.3284818633213774\n",
      "Epoch 3689, reconstruction losses: 0.01227823717546277, regression losses: 0.19187939579025756, validation losses: 0.380861212026126\n",
      "Epoch 3690, reconstruction losses: 0.013956629960077217, regression losses: 0.14841594910177436, validation losses: 0.3945849627306661\n",
      "Epoch 3691, reconstruction losses: 0.01067645019999977, regression losses: 0.08144709207101554, validation losses: 0.37789689217250855\n",
      "Epoch 3692, reconstruction losses: 0.011105446542168917, regression losses: 0.11000768506929895, validation losses: 0.35706884132192335\n",
      "Epoch 3693, reconstruction losses: 0.00918459176614554, regression losses: 0.09147847222789096, validation losses: 0.3428936856351204\n",
      "Epoch 3694, reconstruction losses: 0.011640359093225652, regression losses: 0.09832923004787812, validation losses: 0.32219774440594484\n",
      "Epoch 3695, reconstruction losses: 0.011787007435175346, regression losses: 0.10102035241033852, validation losses: 0.32746281278611405\n",
      "Epoch 3696, reconstruction losses: 0.010873671968211525, regression losses: 0.09762311307272069, validation losses: 0.33772048269651356\n",
      "Epoch 3697, reconstruction losses: 0.012078045755781266, regression losses: 0.09597299300617858, validation losses: 0.3391113984880786\n",
      "Epoch 3698, reconstruction losses: 0.011590821755407458, regression losses: 0.09309655451451405, validation losses: 0.33749192733617916\n",
      "Epoch 3699, reconstruction losses: 0.010550868675517145, regression losses: 0.06348325258415154, validation losses: 0.343763184911078\n",
      "Epoch 3700, reconstruction losses: 0.012047599083597343, regression losses: 0.11030113577513638, validation losses: 0.3469379337163306\n",
      "Epoch 3701, reconstruction losses: 0.010914089552566439, regression losses: 0.105187908520534, validation losses: 0.34394993176556815\n",
      "Epoch 3702, reconstruction losses: 0.016062846397655157, regression losses: 0.16432452662274039, validation losses: 0.34883756400593807\n",
      "Epoch 3703, reconstruction losses: 0.01391109266208032, regression losses: 0.14622969796797455, validation losses: 0.32869771094328787\n",
      "Epoch 3704, reconstruction losses: 0.013618036724880643, regression losses: 0.1048978395237108, validation losses: 0.3355550704881145\n",
      "Epoch 3705, reconstruction losses: 0.013000869387902469, regression losses: 0.20171278232328918, validation losses: 0.38088682407766217\n",
      "Epoch 3706, reconstruction losses: 0.015466997747459743, regression losses: 0.1217815552005536, validation losses: 0.36367895383451365\n",
      "Epoch 3707, reconstruction losses: 0.012308528897837963, regression losses: 0.12556486616723503, validation losses: 0.3777074804013598\n",
      "Epoch 3708, reconstruction losses: 0.010786691285302867, regression losses: 0.10790920539571017, validation losses: 0.37298269464693534\n",
      "Epoch 3709, reconstruction losses: 0.011724774072599187, regression losses: 0.09199616260426412, validation losses: 0.3520107502577283\n",
      "Epoch 3710, reconstruction losses: 0.011850179033956784, regression losses: 0.09182105143958286, validation losses: 0.32644745673694425\n",
      "Epoch 3711, reconstruction losses: 0.014304211968268907, regression losses: 0.15340048769329206, validation losses: 0.31308180015036374\n",
      "Epoch 3712, reconstruction losses: 0.011943456463400955, regression losses: 0.11162220062017159, validation losses: 0.3241163666973776\n",
      "Epoch 3713, reconstruction losses: 0.013541567534780329, regression losses: 0.1432286053018181, validation losses: 0.3336577906114716\n",
      "Epoch 3714, reconstruction losses: 0.012253667998526268, regression losses: 0.08996785230563127, validation losses: 0.32083762837064095\n",
      "Epoch 3715, reconstruction losses: 0.012678021831491873, regression losses: 0.09905880504760797, validation losses: 0.34666613372942007\n",
      "Epoch 3716, reconstruction losses: 0.011034431218959856, regression losses: 0.08742223589029169, validation losses: 0.3554875421186394\n",
      "Epoch 3717, reconstruction losses: 0.01750191328006026, regression losses: 0.1115084360180353, validation losses: 0.3198474938374222\n",
      "Epoch 3718, reconstruction losses: 0.00996086184377209, regression losses: 0.07787975673860684, validation losses: 0.31237000031079765\n",
      "Epoch 3719, reconstruction losses: 0.014818152494491952, regression losses: 0.14213215174335778, validation losses: 0.31552061940954607\n",
      "Epoch 3720, reconstruction losses: 0.014567777177367644, regression losses: 0.14743510584577976, validation losses: 0.3282496304752577\n",
      "Epoch 3721, reconstruction losses: 0.01478111128911356, regression losses: 0.11009553096072763, validation losses: 0.3471797762346946\n",
      "Epoch 3722, reconstruction losses: 0.01116948006220487, regression losses: 0.11392064270531901, validation losses: 0.34192324084341086\n",
      "Epoch 3723, reconstruction losses: 0.01443160607521256, regression losses: 0.10866830751388008, validation losses: 0.3439877626986059\n",
      "Epoch 3724, reconstruction losses: 0.0166696457108106, regression losses: 0.16612142558696963, validation losses: 0.4128417321759996\n",
      "Epoch 3725, reconstruction losses: 0.012078749209245268, regression losses: 0.1303399943862164, validation losses: 0.5330246684766068\n",
      "Epoch 3726, reconstruction losses: 0.026949760109545265, regression losses: 0.2610809041752707, validation losses: 0.45362684859988794\n",
      "Epoch 3727, reconstruction losses: 0.015287068949633765, regression losses: 0.12059599534629666, validation losses: 0.5308634246904586\n",
      "Epoch 3728, reconstruction losses: 0.0119571865771714, regression losses: 0.08172232668198205, validation losses: 0.5602764052506343\n",
      "Epoch 3729, reconstruction losses: 0.017113082904833175, regression losses: 0.10621631824594722, validation losses: 0.47985011360467955\n",
      "Epoch 3730, reconstruction losses: 0.012991794273346062, regression losses: 0.08883114128959901, validation losses: 0.4055177495386321\n",
      "Epoch 3731, reconstruction losses: 0.013262051773468501, regression losses: 0.10932968097783495, validation losses: 0.3339156038351083\n",
      "Epoch 3732, reconstruction losses: 0.011220972860262201, regression losses: 0.0738691096998956, validation losses: 0.32716716452246\n",
      "Epoch 3733, reconstruction losses: 0.011544656010381646, regression losses: 0.08553848838486096, validation losses: 0.3194644234704275\n",
      "Epoch 3734, reconstruction losses: 0.01384892212494181, regression losses: 0.17393265939040783, validation losses: 0.32476916914533216\n",
      "Epoch 3735, reconstruction losses: 0.013171727148505157, regression losses: 0.12171437422224256, validation losses: 0.36006524265624523\n",
      "Epoch 3736, reconstruction losses: 0.015453194911638133, regression losses: 0.13268020955234985, validation losses: 0.3513631503380135\n",
      "Epoch 3737, reconstruction losses: 0.013987221624167559, regression losses: 0.12493790311080695, validation losses: 0.34935527204195915\n",
      "Epoch 3738, reconstruction losses: 0.012075316434479238, regression losses: 0.09626567017815253, validation losses: 0.3739182983916872\n",
      "Epoch 3739, reconstruction losses: 0.013383796194227204, regression losses: 0.10068137841187581, validation losses: 0.3150920898511953\n",
      "Epoch 3740, reconstruction losses: 0.012957145105576752, regression losses: 0.12681951444430292, validation losses: 0.354610839466907\n",
      "Epoch 3741, reconstruction losses: 0.010193717815682228, regression losses: 0.08381944876877145, validation losses: 0.352156617098233\n",
      "Epoch 3742, reconstruction losses: 0.011777698745717343, regression losses: 0.10944012297210419, validation losses: 0.30072883694059316\n",
      "Epoch 3743, reconstruction losses: 0.009093059809964488, regression losses: 0.08553556755157138, validation losses: 0.3064674660425745\n",
      "Epoch 3744, reconstruction losses: 0.013248999677528489, regression losses: 0.14092254644249483, validation losses: 0.3094442587608342\n",
      "Epoch 3745, reconstruction losses: 0.011931065365770871, regression losses: 0.10162416687961333, validation losses: 0.33293894684014874\n",
      "Epoch 3746, reconstruction losses: 0.011033963800344342, regression losses: 0.11288015090796631, validation losses: 0.3498685254939419\n",
      "Epoch 3747, reconstruction losses: 0.010744598250052334, regression losses: 0.1549777783414228, validation losses: 0.3508874973526839\n",
      "Epoch 3748, reconstruction losses: 0.0099259961072561, regression losses: 0.0766437190465804, validation losses: 0.3831819113109204\n",
      "Epoch 3749, reconstruction losses: 0.012444941115740528, regression losses: 0.11336225681436378, validation losses: 0.38117381211198104\n",
      "Epoch 3750, reconstruction losses: 0.015053214255597473, regression losses: 0.12961268239266643, validation losses: 0.3606216339877755\n",
      "Epoch 3751, reconstruction losses: 0.011996101128377462, regression losses: 0.12692885755021632, validation losses: 0.3402742421329042\n",
      "Epoch 3752, reconstruction losses: 0.013187540046214755, regression losses: 0.08937030739536321, validation losses: 0.3353312749513078\n",
      "Epoch 3753, reconstruction losses: 0.012170297316114412, regression losses: 0.1720524645203017, validation losses: 0.3375458150176343\n",
      "Epoch 3754, reconstruction losses: 0.010528653569415696, regression losses: 0.1016705922262378, validation losses: 0.33541266277719345\n",
      "Epoch 3755, reconstruction losses: 0.015213695744975265, regression losses: 0.099114082439644, validation losses: 0.33632356004337793\n",
      "Epoch 3756, reconstruction losses: 0.019019979089078407, regression losses: 0.26323158211610087, validation losses: 0.3950916258151676\n",
      "Epoch 3757, reconstruction losses: 0.011575431246622737, regression losses: 0.10337168269003717, validation losses: 0.4809778626813846\n",
      "Epoch 3758, reconstruction losses: 0.01334963933910645, regression losses: 0.12933333031202024, validation losses: 0.43368920434132957\n",
      "Epoch 3759, reconstruction losses: 0.010950198527020982, regression losses: 0.09516519808589585, validation losses: 0.3860950749976904\n",
      "Epoch 3760, reconstruction losses: 0.01479551572583516, regression losses: 0.11783418199943631, validation losses: 0.39329148081291393\n",
      "Epoch 3761, reconstruction losses: 0.011276276576000298, regression losses: 0.10888990635660252, validation losses: 0.3891923689470586\n",
      "Epoch 3762, reconstruction losses: 0.011903339340652755, regression losses: 0.08254742409915142, validation losses: 0.3244598523240996\n",
      "Epoch 3763, reconstruction losses: 0.011851694509420533, regression losses: 0.0749084889471124, validation losses: 0.3543798629945591\n",
      "Epoch 3764, reconstruction losses: 0.010342465533108717, regression losses: 0.08484100124182478, validation losses: 0.36174186729331104\n",
      "Epoch 3765, reconstruction losses: 0.012249876163148838, regression losses: 0.07681570033883772, validation losses: 0.3254117072270779\n",
      "Epoch 3766, reconstruction losses: 0.012119844722306823, regression losses: 0.10479450113112047, validation losses: 0.30362023622823714\n",
      "Epoch 3767, reconstruction losses: 0.013441018659964069, regression losses: 0.09933045436371052, validation losses: 0.30294942401092767\n",
      "Epoch 3768, reconstruction losses: 0.0113455764822086, regression losses: 0.08482362505748398, validation losses: 0.3092189028034802\n",
      "Epoch 3769, reconstruction losses: 0.011563411698265521, regression losses: 0.08695848593472501, validation losses: 0.323267237959428\n",
      "Epoch 3770, reconstruction losses: 0.013190122618707922, regression losses: 0.10668860013895293, validation losses: 0.34068900162623844\n",
      "Epoch 3771, reconstruction losses: 0.01253690927902587, regression losses: 0.09030116974501179, validation losses: 0.32867670038444585\n",
      "Epoch 3772, reconstruction losses: 0.012520167762521975, regression losses: 0.1458712613669135, validation losses: 0.3229729525868477\n",
      "Epoch 3773, reconstruction losses: 0.010456972058113025, regression losses: 0.09836634705151825, validation losses: 0.3246715244993219\n",
      "Epoch 3774, reconstruction losses: 0.01208612657421773, regression losses: 0.08121801763037365, validation losses: 0.3284650663560116\n",
      "Epoch 3775, reconstruction losses: 0.01231165610489937, regression losses: 0.1018023226157421, validation losses: 0.3503099412858155\n",
      "Epoch 3776, reconstruction losses: 0.009723516281007682, regression losses: 0.06567700072975483, validation losses: 0.3837461163194714\n",
      "Epoch 3777, reconstruction losses: 0.012621812212082585, regression losses: 0.13477816878445223, validation losses: 0.3802281486507554\n",
      "Epoch 3778, reconstruction losses: 0.01072859462097011, regression losses: 0.06682472461901968, validation losses: 0.34323444772339146\n",
      "Epoch 3779, reconstruction losses: 0.010286489792116615, regression losses: 0.07644135111013753, validation losses: 0.3158978823057733\n",
      "Epoch 3780, reconstruction losses: 0.011006975513823647, regression losses: 0.11471721814852164, validation losses: 0.30598360416064857\n",
      "Epoch 3781, reconstruction losses: 0.012233655485763988, regression losses: 0.0975554156694795, validation losses: 0.30601561421981494\n",
      "Epoch 3782, reconstruction losses: 0.011711917082274424, regression losses: 0.08810379741474866, validation losses: 0.29570444121494727\n",
      "Epoch 3783, reconstruction losses: 0.013463129483025834, regression losses: 0.11984375644107842, validation losses: 0.28073458540835394\n",
      "Epoch 3784, reconstruction losses: 0.01458589929389021, regression losses: 0.11557287330940064, validation losses: 0.2928995799266624\n",
      "Epoch 3785, reconstruction losses: 0.011138361402472602, regression losses: 0.08459246519025199, validation losses: 0.30889709041532976\n",
      "Epoch 3786, reconstruction losses: 0.01236041661890497, regression losses: 0.12714012960223586, validation losses: 0.339291419570463\n",
      "Epoch 3787, reconstruction losses: 0.012429361253603177, regression losses: 0.09969615691323253, validation losses: 0.38557401068278224\n",
      "Epoch 3788, reconstruction losses: 0.014033837809060444, regression losses: 0.09018515510287012, validation losses: 0.4505072474791385\n",
      "Epoch 3789, reconstruction losses: 0.011338648010375745, regression losses: 0.07457037495520359, validation losses: 0.3927878165477148\n",
      "Epoch 3790, reconstruction losses: 0.01863540732091566, regression losses: 0.3686689632249318, validation losses: 0.3466059184849449\n",
      "Epoch 3791, reconstruction losses: 0.011734181293153659, regression losses: 0.0864219572704023, validation losses: 0.610131213500376\n",
      "Epoch 3792, reconstruction losses: 0.013445244606007968, regression losses: 0.11464572266397935, validation losses: 0.6802528304825048\n",
      "Epoch 3793, reconstruction losses: 0.01879075261951131, regression losses: 0.5165538635645919, validation losses: 0.6410648781174726\n",
      "Epoch 3794, reconstruction losses: 0.01146705637247961, regression losses: 0.11939212514742994, validation losses: 0.8215552588809927\n",
      "Epoch 3795, reconstruction losses: 0.01306566990720829, regression losses: 0.15045231724281732, validation losses: 0.794298802713124\n",
      "Epoch 3796, reconstruction losses: 0.012461144311847736, regression losses: 0.15412224194016716, validation losses: 0.5671938387734253\n",
      "Epoch 3797, reconstruction losses: 0.010975750448833818, regression losses: 0.11820456971473897, validation losses: 0.5171918041797392\n",
      "Epoch 3798, reconstruction losses: 0.025931691047457198, regression losses: 0.31920896664785553, validation losses: 0.49909496741865994\n",
      "Epoch 3799, reconstruction losses: 0.01609626368828777, regression losses: 0.2538450130227496, validation losses: 0.7292187071145004\n",
      "Epoch 3800, reconstruction losses: 0.013600408935437281, regression losses: 0.1299430994449079, validation losses: 0.5660714488103001\n",
      "Epoch 3801, reconstruction losses: 0.012396441389727777, regression losses: 0.11395644955261278, validation losses: 0.47732445923008593\n",
      "Epoch 3802, reconstruction losses: 0.012849155452873812, regression losses: 0.10461463447819384, validation losses: 0.41480319405161264\n",
      "Epoch 3803, reconstruction losses: 0.01262796961855599, regression losses: 0.12169021359386986, validation losses: 0.3513617952037128\n",
      "Epoch 3804, reconstruction losses: 0.011292481691091124, regression losses: 0.08291086160977841, validation losses: 0.3292083227563985\n",
      "Epoch 3805, reconstruction losses: 0.012127146080422282, regression losses: 0.09783227549672552, validation losses: 0.34387021851475497\n",
      "Epoch 3806, reconstruction losses: 0.01162756293734925, regression losses: 0.11203010140031336, validation losses: 0.32977159313434184\n",
      "Epoch 3807, reconstruction losses: 0.012141446911385637, regression losses: 0.10505046890041321, validation losses: 0.3235454478358263\n",
      "Epoch 3808, reconstruction losses: 0.009163623346921914, regression losses: 0.07876004014884026, validation losses: 0.35371771900086074\n",
      "Epoch 3809, reconstruction losses: 0.011666666384729482, regression losses: 0.11484783736064604, validation losses: 0.35957101159532046\n",
      "Epoch 3810, reconstruction losses: 0.011909166426880568, regression losses: 0.08041933184418347, validation losses: 0.38126725456121996\n",
      "Epoch 3811, reconstruction losses: 0.009553620368926131, regression losses: 0.14610717709491713, validation losses: 0.35761525892261475\n",
      "Epoch 3812, reconstruction losses: 0.01156191245031654, regression losses: 0.10862336932408867, validation losses: 0.35582380405001707\n",
      "Epoch 3813, reconstruction losses: 0.010984826576489743, regression losses: 0.08897796702485786, validation losses: 0.3742476515768932\n",
      "Epoch 3814, reconstruction losses: 0.01339018031980127, regression losses: 0.07403843411036798, validation losses: 0.35138414988205413\n",
      "Epoch 3815, reconstruction losses: 0.011058733485952021, regression losses: 0.10038150299425505, validation losses: 0.33302645719280916\n",
      "Epoch 3816, reconstruction losses: 0.010799620109362078, regression losses: 0.07361803753741594, validation losses: 0.35341095124154204\n",
      "Epoch 3817, reconstruction losses: 0.014486692374593338, regression losses: 0.08450714915322752, validation losses: 0.35654242579823286\n",
      "Epoch 3818, reconstruction losses: 0.012860260739601588, regression losses: 0.1565794445916059, validation losses: 0.36666059399183376\n",
      "Epoch 3819, reconstruction losses: 0.01264639705467279, regression losses: 0.12214522725960024, validation losses: 0.45353763470196057\n",
      "Epoch 3820, reconstruction losses: 0.009945214112331856, regression losses: 0.1079797138139907, validation losses: 0.43681563653578004\n",
      "Epoch 3821, reconstruction losses: 0.01189984802963527, regression losses: 0.1102945501036885, validation losses: 0.36434239613206165\n",
      "Epoch 3822, reconstruction losses: 0.011995833103684305, regression losses: 0.13597365838787656, validation losses: 0.3497228898411204\n",
      "Epoch 3823, reconstruction losses: 0.012013730743581152, regression losses: 0.11408195284217906, validation losses: 0.3701645619938741\n",
      "Epoch 3824, reconstruction losses: 0.009734313413704057, regression losses: 0.09488923023083419, validation losses: 0.34748985386597175\n",
      "Epoch 3825, reconstruction losses: 0.011215066281965134, regression losses: 0.08637892344961022, validation losses: 0.34149754545101274\n",
      "Epoch 3826, reconstruction losses: 0.012059344186637747, regression losses: 0.08223361009906285, validation losses: 0.33443072731919815\n",
      "Epoch 3827, reconstruction losses: 0.01257066642119051, regression losses: 0.09092398891965653, validation losses: 0.3180878353867268\n",
      "Epoch 3828, reconstruction losses: 0.013423143907879583, regression losses: 0.14543525450198216, validation losses: 0.31199835834483486\n",
      "Epoch 3829, reconstruction losses: 0.012212308442179149, regression losses: 0.1022530402058573, validation losses: 0.3045075896041046\n",
      "Epoch 3830, reconstruction losses: 0.01238213256917865, regression losses: 0.11411433301244645, validation losses: 0.3042116530357585\n",
      "Epoch 3831, reconstruction losses: 0.012558163166866063, regression losses: 0.10563012301925014, validation losses: 0.3083815210831767\n",
      "Epoch 3832, reconstruction losses: 0.01616426240967323, regression losses: 0.1433178027940831, validation losses: 0.3184696556281765\n",
      "Epoch 3833, reconstruction losses: 0.013303648668030823, regression losses: 0.14431682617179825, validation losses: 0.3621400819650859\n",
      "Epoch 3834, reconstruction losses: 0.010087357354670725, regression losses: 0.0802922672672442, validation losses: 0.43077330102410616\n",
      "Epoch 3835, reconstruction losses: 0.012558498987165875, regression losses: 0.10811632851013107, validation losses: 0.40073528266529296\n",
      "Epoch 3836, reconstruction losses: 0.011069800047430071, regression losses: 0.0910674242536378, validation losses: 0.35025035249185665\n",
      "Epoch 3837, reconstruction losses: 0.011309981572887231, regression losses: 0.14175191937022513, validation losses: 0.33348056767955586\n",
      "Epoch 3838, reconstruction losses: 0.014179024856392783, regression losses: 0.16860954583079524, validation losses: 0.3260752197005946\n",
      "Epoch 3839, reconstruction losses: 0.011648589927838142, regression losses: 0.09620064690532873, validation losses: 0.3910939386383363\n",
      "Epoch 3840, reconstruction losses: 0.01173812161805825, regression losses: 0.08196230219235082, validation losses: 0.41681908760103037\n",
      "Epoch 3841, reconstruction losses: 0.011272696267462207, regression losses: 0.09792519368046446, validation losses: 0.37401234576181663\n",
      "Epoch 3842, reconstruction losses: 0.011546194163843587, regression losses: 0.08696933545552187, validation losses: 0.3370766698398502\n",
      "Epoch 3843, reconstruction losses: 0.010392360275189446, regression losses: 0.08770403242917651, validation losses: 0.34211059749335515\n",
      "Epoch 3844, reconstruction losses: 0.009968799533397757, regression losses: 0.07997162135212375, validation losses: 0.32664844651255\n",
      "Epoch 3845, reconstruction losses: 0.011947364924023906, regression losses: 0.11005185441674328, validation losses: 0.31997543926736627\n",
      "Epoch 3846, reconstruction losses: 0.01202082924512481, regression losses: 0.09901539356390764, validation losses: 0.3038379196163516\n",
      "Epoch 3847, reconstruction losses: 0.015582601911944686, regression losses: 0.12263785005922517, validation losses: 0.312999499217741\n",
      "Epoch 3848, reconstruction losses: 0.012229663663262223, regression losses: 0.10226671225727586, validation losses: 0.3038412906404235\n",
      "Epoch 3849, reconstruction losses: 0.010300915886549189, regression losses: 0.06349264228929842, validation losses: 0.3317620665872362\n",
      "Epoch 3850, reconstruction losses: 0.01188612553484508, regression losses: 0.09128248455371477, validation losses: 0.32299511181846857\n",
      "Epoch 3851, reconstruction losses: 0.012152795899939733, regression losses: 0.09421072339846606, validation losses: 0.30479838976443036\n",
      "Epoch 3852, reconstruction losses: 0.011371918354606136, regression losses: 0.09505742935206604, validation losses: 0.30965643903902734\n",
      "Epoch 3853, reconstruction losses: 0.012085315154914055, regression losses: 0.09852910689624894, validation losses: 0.3054511736032003\n",
      "Epoch 3854, reconstruction losses: 0.01110918455613783, regression losses: 0.1106182709523436, validation losses: 0.32426843182160725\n",
      "Epoch 3855, reconstruction losses: 0.011339002406761077, regression losses: 0.10820588463803388, validation losses: 0.33040111495073843\n",
      "Epoch 3856, reconstruction losses: 0.010697692687461543, regression losses: 0.07525334369729648, validation losses: 0.30120690147034934\n",
      "Epoch 3857, reconstruction losses: 0.013714637905955458, regression losses: 0.10489008699910332, validation losses: 0.30599815581769557\n",
      "Epoch 3858, reconstruction losses: 0.013430656692807245, regression losses: 0.10585362304015475, validation losses: 0.31308083136960074\n",
      "Epoch 3859, reconstruction losses: 0.011984656956529262, regression losses: 0.0944836346522774, validation losses: 0.3183948472052612\n",
      "Epoch 3860, reconstruction losses: 0.013624940038437509, regression losses: 0.11047240579869223, validation losses: 0.3133916622810399\n",
      "Epoch 3861, reconstruction losses: 0.012108637142331723, regression losses: 0.11080720553618846, validation losses: 0.34691707659187204\n",
      "Epoch 3862, reconstruction losses: 0.0115581090234868, regression losses: 0.08069686871139341, validation losses: 0.3475439621589958\n",
      "Epoch 3863, reconstruction losses: 0.017457265291981952, regression losses: 0.09474550373588875, validation losses: 0.34897696084405044\n",
      "Epoch 3864, reconstruction losses: 0.01768998346635671, regression losses: 0.10161136881216706, validation losses: 0.38038143897406207\n",
      "Epoch 3865, reconstruction losses: 0.014225737738816914, regression losses: 0.1089480189969583, validation losses: 0.3723869284785577\n",
      "Epoch 3866, reconstruction losses: 0.011813015903563161, regression losses: 0.0746504821812012, validation losses: 0.3367070996962857\n",
      "Epoch 3867, reconstruction losses: 0.011394851604507473, regression losses: 0.08022221775003355, validation losses: 0.3405156786687329\n",
      "Epoch 3868, reconstruction losses: 0.012704575423844934, regression losses: 0.1275914364052716, validation losses: 0.3565504378771413\n",
      "Epoch 3869, reconstruction losses: 0.010749198061011657, regression losses: 0.10358097856454465, validation losses: 0.35556290991923756\n",
      "Epoch 3870, reconstruction losses: 0.014074379739102342, regression losses: 0.1260954063934874, validation losses: 0.3131904851396824\n",
      "Epoch 3871, reconstruction losses: 0.010827890882085616, regression losses: 0.08214830305687681, validation losses: 0.305581454900789\n",
      "Epoch 3872, reconstruction losses: 0.011759093426063816, regression losses: 0.08306577633852476, validation losses: 0.29721530699696663\n",
      "Epoch 3873, reconstruction losses: 0.013370744638132185, regression losses: 0.11676112151391856, validation losses: 0.286221791297062\n",
      "Epoch 3874, reconstruction losses: 0.010633223281702821, regression losses: 0.08285440192810864, validation losses: 0.30434025939347137\n",
      "Epoch 3875, reconstruction losses: 0.01183804167126818, regression losses: 0.08802531074512375, validation losses: 0.31354516876998106\n",
      "Epoch 3876, reconstruction losses: 0.01326032245823, regression losses: 0.15498931834518162, validation losses: 0.31096294747550346\n",
      "Epoch 3877, reconstruction losses: 0.01015462397736449, regression losses: 0.08286578263298516, validation losses: 0.3072422181781227\n",
      "Epoch 3878, reconstruction losses: 0.013923022084183037, regression losses: 0.09263406560106678, validation losses: 0.32443810817901747\n",
      "Epoch 3879, reconstruction losses: 0.010186163068577645, regression losses: 0.07507261137145986, validation losses: 0.30408431446336015\n",
      "Epoch 3880, reconstruction losses: 0.011274469463561561, regression losses: 0.12153501062786429, validation losses: 0.3149048188786574\n",
      "Epoch 3881, reconstruction losses: 0.013267779181873616, regression losses: 0.12941304410231627, validation losses: 0.3719631893011671\n",
      "Epoch 3882, reconstruction losses: 0.012686716367608054, regression losses: 0.10648485328168311, validation losses: 0.3877925440537288\n",
      "Epoch 3883, reconstruction losses: 0.013345363001522536, regression losses: 0.11716861158469745, validation losses: 0.35778400022318696\n",
      "Epoch 3884, reconstruction losses: 0.01270186922019493, regression losses: 0.09969850122144705, validation losses: 0.3248268884935922\n",
      "Epoch 3885, reconstruction losses: 0.011761584678063361, regression losses: 0.11134739747178245, validation losses: 0.3208704234473576\n",
      "Epoch 3886, reconstruction losses: 0.012507964961693726, regression losses: 0.10023898803255399, validation losses: 0.3161103737014667\n",
      "Epoch 3887, reconstruction losses: 0.011981681716155287, regression losses: 0.09442182211714176, validation losses: 0.3211167027807219\n",
      "Epoch 3888, reconstruction losses: 0.012238730792649328, regression losses: 0.10181956874817921, validation losses: 0.3215380393920727\n",
      "Epoch 3889, reconstruction losses: 0.012451380811186519, regression losses: 0.08628421176232742, validation losses: 0.327857916022767\n",
      "Epoch 3890, reconstruction losses: 0.010468889588407448, regression losses: 0.09704131172883564, validation losses: 0.32003955617539853\n",
      "Epoch 3891, reconstruction losses: 0.015233964067237014, regression losses: 0.3268913400649681, validation losses: 0.38484201942408514\n",
      "Epoch 3892, reconstruction losses: 0.0130324223271897, regression losses: 0.11555361658457532, validation losses: 0.8820419959734621\n",
      "Epoch 3893, reconstruction losses: 0.021812097668127507, regression losses: 0.441898780893648, validation losses: 0.8012357332209397\n",
      "Epoch 3894, reconstruction losses: 0.014116772654880169, regression losses: 0.1127698844579072, validation losses: 0.7508521445221523\n",
      "Epoch 3895, reconstruction losses: 0.013289512585018032, regression losses: 0.11883392970445122, validation losses: 0.6866774499028637\n",
      "Epoch 3896, reconstruction losses: 0.013529411005990184, regression losses: 0.13076927857951978, validation losses: 0.5723924169436081\n",
      "Epoch 3897, reconstruction losses: 0.01483207307088753, regression losses: 0.19309448086365694, validation losses: 0.5046440483166899\n",
      "Epoch 3898, reconstruction losses: 0.01256732498324519, regression losses: 0.11151736770252989, validation losses: 0.4714354992445634\n",
      "Epoch 3899, reconstruction losses: 0.014579149574117834, regression losses: 0.15109124296062904, validation losses: 0.46911872220219875\n",
      "Epoch 3900, reconstruction losses: 0.013701832277760412, regression losses: 0.12614461346799044, validation losses: 0.5152358259783038\n",
      "Epoch 3901, reconstruction losses: 0.014691082921389246, regression losses: 0.13906904466409278, validation losses: 0.539331673260421\n",
      "Epoch 3902, reconstruction losses: 0.01142171521906695, regression losses: 0.0969470808598792, validation losses: 0.4733701029433124\n",
      "Epoch 3903, reconstruction losses: 0.017848275492408527, regression losses: 0.1500604273023145, validation losses: 0.44673240287565846\n",
      "Epoch 3904, reconstruction losses: 0.013529070481660556, regression losses: 0.10316141976582217, validation losses: 0.4693639088035242\n",
      "Epoch 3905, reconstruction losses: 0.01117139630244156, regression losses: 0.1259539226982562, validation losses: 0.4364324840506443\n",
      "Epoch 3906, reconstruction losses: 0.01158477263947685, regression losses: 0.08616401760049411, validation losses: 0.44569102946141825\n",
      "Epoch 3907, reconstruction losses: 0.011781891609996398, regression losses: 0.17834421605789008, validation losses: 0.43441190551085657\n",
      "Epoch 3908, reconstruction losses: 0.014048809717550802, regression losses: 0.14216601724173783, validation losses: 0.40870802059749173\n",
      "Epoch 3909, reconstruction losses: 0.013100038006931623, regression losses: 0.1035634006306868, validation losses: 0.4267402276697801\n",
      "Epoch 3910, reconstruction losses: 0.011785171359034606, regression losses: 0.09917766603278966, validation losses: 0.40532528019211445\n",
      "Epoch 3911, reconstruction losses: 0.011299354016469712, regression losses: 0.1144260694738126, validation losses: 0.42897500209327816\n",
      "Epoch 3912, reconstruction losses: 0.011951431139175565, regression losses: 0.1305859437980666, validation losses: 0.40084774555723507\n",
      "Epoch 3913, reconstruction losses: 0.01193883461282657, regression losses: 0.1162059184862909, validation losses: 0.36014758768236865\n",
      "Epoch 3914, reconstruction losses: 0.010973297023646569, regression losses: 0.08599926113637839, validation losses: 0.3868350049615645\n",
      "Epoch 3915, reconstruction losses: 0.011108341035207803, regression losses: 0.14055548368323573, validation losses: 0.3819825976544159\n",
      "Epoch 3916, reconstruction losses: 0.013455512034272091, regression losses: 0.08688233620529233, validation losses: 0.3703401200603459\n",
      "Epoch 3917, reconstruction losses: 0.012628574491773212, regression losses: 0.10991463220617559, validation losses: 0.3991631972024269\n",
      "Epoch 3918, reconstruction losses: 0.012008458615623111, regression losses: 0.08417283403153678, validation losses: 0.3536225163669089\n",
      "Epoch 3919, reconstruction losses: 0.011318945971216448, regression losses: 0.10386312532953883, validation losses: 0.34345631198425375\n",
      "Epoch 3920, reconstruction losses: 0.012963176164168363, regression losses: 0.0889900528832368, validation losses: 0.3452959523357828\n",
      "Epoch 3921, reconstruction losses: 0.01123985967624374, regression losses: 0.09799868285872469, validation losses: 0.35011865167860723\n",
      "Epoch 3922, reconstruction losses: 0.01122000696226251, regression losses: 0.08525658424469892, validation losses: 0.3724307958452519\n",
      "Epoch 3923, reconstruction losses: 0.011271019365855428, regression losses: 0.09251084936274587, validation losses: 0.36895674566617565\n",
      "Epoch 3924, reconstruction losses: 0.01073725699235183, regression losses: 0.09037775539950467, validation losses: 0.34787322183505043\n",
      "Epoch 3925, reconstruction losses: 0.010740353487024321, regression losses: 0.11449126833586787, validation losses: 0.3430930549449254\n",
      "Epoch 3926, reconstruction losses: 0.012626594123299315, regression losses: 0.09600346901670452, validation losses: 0.3401618443531324\n",
      "Epoch 3927, reconstruction losses: 0.010313396724319489, regression losses: 0.07710323015893117, validation losses: 0.33816334625544775\n",
      "Epoch 3928, reconstruction losses: 0.014401818190987316, regression losses: 0.11240026484553886, validation losses: 0.335201859174634\n",
      "Epoch 3929, reconstruction losses: 0.010564617198139118, regression losses: 0.07253686066884141, validation losses: 0.3528211789546674\n",
      "Epoch 3930, reconstruction losses: 0.016877347087136056, regression losses: 0.101593359114814, validation losses: 0.3697010590552715\n",
      "Epoch 3931, reconstruction losses: 0.013703558949230898, regression losses: 0.14351542963740896, validation losses: 0.3916673506606371\n",
      "Epoch 3932, reconstruction losses: 0.01463190995276814, regression losses: 0.17257849266617845, validation losses: 0.39231406823753134\n",
      "Epoch 3933, reconstruction losses: 0.01270882367264823, regression losses: 0.10127693740066548, validation losses: 0.40918437148328834\n",
      "Epoch 3934, reconstruction losses: 0.012133563270447005, regression losses: 0.09041330491805519, validation losses: 0.3994368452746405\n",
      "Epoch 3935, reconstruction losses: 0.01401642655419701, regression losses: 0.11646712009213073, validation losses: 0.38844545987976764\n",
      "Epoch 3936, reconstruction losses: 0.014494623700343772, regression losses: 0.131384469293654, validation losses: 0.36553994201131795\n",
      "Epoch 3937, reconstruction losses: 0.015514284825036941, regression losses: 0.3282757879402276, validation losses: 0.39753425736668946\n",
      "Epoch 3938, reconstruction losses: 0.012406416876068584, regression losses: 0.15516284828677301, validation losses: 0.5806958392111905\n",
      "Epoch 3939, reconstruction losses: 0.012213647797468113, regression losses: 0.13183410510528923, validation losses: 0.5198139257738006\n",
      "Epoch 3940, reconstruction losses: 0.011723053197846335, regression losses: 0.11989798356113997, validation losses: 0.43228477805221427\n",
      "Epoch 3941, reconstruction losses: 0.012367002253102787, regression losses: 0.09991765412627247, validation losses: 0.3346799355638793\n",
      "Epoch 3942, reconstruction losses: 0.014930155526469313, regression losses: 0.28864191407122464, validation losses: 0.3031954687637878\n",
      "Epoch 3943, reconstruction losses: 0.012840890818549106, regression losses: 0.09398220040584213, validation losses: 0.4286240869145582\n",
      "Epoch 3944, reconstruction losses: 0.010302886441507626, regression losses: 0.08191359543750797, validation losses: 0.4965949085028025\n",
      "Epoch 3945, reconstruction losses: 0.012016610278252198, regression losses: 0.12691193867876874, validation losses: 0.4017041546935733\n",
      "Epoch 3946, reconstruction losses: 0.010938608865704788, regression losses: 0.11364304814515584, validation losses: 0.3263712822187041\n",
      "Epoch 3947, reconstruction losses: 0.012173170405435264, regression losses: 0.08428076244826434, validation losses: 0.2941244246064675\n",
      "Epoch 3948, reconstruction losses: 0.014366600088927949, regression losses: 0.13687468168888955, validation losses: 0.29288500341059837\n",
      "Epoch 3949, reconstruction losses: 0.010738302783268712, regression losses: 0.08925949663759494, validation losses: 0.3271995150541729\n",
      "Epoch 3950, reconstruction losses: 0.012142643424079756, regression losses: 0.09860007876947434, validation losses: 0.360521637304006\n",
      "Epoch 3951, reconstruction losses: 0.013002663968615148, regression losses: 0.09068103628758808, validation losses: 0.3250016348428303\n",
      "Epoch 3952, reconstruction losses: 0.01037001829607502, regression losses: 0.07403961701063962, validation losses: 0.3006983951941226\n",
      "Epoch 3953, reconstruction losses: 0.011777036657985195, regression losses: 0.09645429737702774, validation losses: 0.31408404628355713\n",
      "Epoch 3954, reconstruction losses: 0.010827798169492945, regression losses: 0.13271448030808175, validation losses: 0.321768229085029\n",
      "Epoch 3955, reconstruction losses: 0.009718063199892673, regression losses: 0.0796361212736061, validation losses: 0.40363740586746344\n",
      "Epoch 3956, reconstruction losses: 0.012086258210614702, regression losses: 0.08225747968849731, validation losses: 0.4068797755674854\n",
      "Epoch 3957, reconstruction losses: 0.010737764820825448, regression losses: 0.081672433841274, validation losses: 0.36746554885647986\n",
      "Epoch 3958, reconstruction losses: 0.013970763370889679, regression losses: 0.1278905287883864, validation losses: 0.3507015558854426\n",
      "Epoch 3959, reconstruction losses: 0.011135884106564055, regression losses: 0.07924832013539888, validation losses: 0.35026118913963983\n",
      "Epoch 3960, reconstruction losses: 0.012144848051715465, regression losses: 0.08783097669816935, validation losses: 0.34713597839548715\n",
      "Epoch 3961, reconstruction losses: 0.009764724036502937, regression losses: 0.0801216785755961, validation losses: 0.330673583437872\n",
      "Epoch 3962, reconstruction losses: 0.011161175429309713, regression losses: 0.10452566668474597, validation losses: 0.3128146133655021\n",
      "Epoch 3963, reconstruction losses: 0.01062094738293645, regression losses: 0.06747816007149178, validation losses: 0.3057769500528868\n",
      "Epoch 3964, reconstruction losses: 0.010398693507360593, regression losses: 0.12620174255482355, validation losses: 0.2981443207345475\n",
      "Epoch 3965, reconstruction losses: 0.012754419660810437, regression losses: 0.14965960591908206, validation losses: 0.3042298606293902\n",
      "Epoch 3966, reconstruction losses: 0.01279148311237108, regression losses: 0.10423026328754577, validation losses: 0.3028816599557345\n",
      "Epoch 3967, reconstruction losses: 0.010933795509055927, regression losses: 0.09006492454325274, validation losses: 0.3050528812887426\n",
      "Epoch 3968, reconstruction losses: 0.01178708225892166, regression losses: 0.10343205652065185, validation losses: 0.29654984751241736\n",
      "Epoch 3969, reconstruction losses: 0.01048044311413236, regression losses: 0.1021383344748691, validation losses: 0.29672944979310134\n",
      "Epoch 3970, reconstruction losses: 0.01326751808015499, regression losses: 0.12007145304613456, validation losses: 0.3095131512794391\n",
      "Epoch 3971, reconstruction losses: 0.011310133204653796, regression losses: 0.09933563508762543, validation losses: 0.32737458973417705\n",
      "Epoch 3972, reconstruction losses: 0.01164520374426835, regression losses: 0.10283436828396422, validation losses: 0.3517015138967181\n",
      "Epoch 3973, reconstruction losses: 0.011661241804145574, regression losses: 0.0930863127553821, validation losses: 0.34614461800948404\n",
      "Epoch 3974, reconstruction losses: 0.017751916764783715, regression losses: 0.10723135316116984, validation losses: 0.32452895574339446\n",
      "Epoch 3975, reconstruction losses: 0.01142285064026248, regression losses: 0.05741225516122139, validation losses: 0.3180744524648062\n",
      "Epoch 3976, reconstruction losses: 0.012525035872292315, regression losses: 0.08101901600215301, validation losses: 0.3072708507631268\n",
      "Epoch 3977, reconstruction losses: 0.010356099192116101, regression losses: 0.07813458343854654, validation losses: 0.30740813734747974\n",
      "Epoch 3978, reconstruction losses: 0.012713332973970242, regression losses: 0.09846967855223815, validation losses: 0.31093629524208144\n",
      "Epoch 3979, reconstruction losses: 0.01326652627453426, regression losses: 0.10895023330328314, validation losses: 0.29281895026988614\n",
      "Epoch 3980, reconstruction losses: 0.012940488993430274, regression losses: 0.12330543417490297, validation losses: 0.30645620307030763\n",
      "Epoch 3981, reconstruction losses: 0.010656764982470956, regression losses: 0.09537364204071873, validation losses: 0.3002282608227796\n",
      "Epoch 3982, reconstruction losses: 0.011422387506544038, regression losses: 0.09854312113227306, validation losses: 0.2886748359901661\n",
      "Epoch 3983, reconstruction losses: 0.014374459564484583, regression losses: 0.12096276167006556, validation losses: 0.2903396860714898\n",
      "Epoch 3984, reconstruction losses: 0.010482954908920778, regression losses: 0.06979632075082881, validation losses: 0.30477235481868253\n",
      "Epoch 3985, reconstruction losses: 0.011140452929231541, regression losses: 0.13232056169114098, validation losses: 0.28186211290791247\n",
      "Epoch 3986, reconstruction losses: 0.01647721338308336, regression losses: 0.1315740228110219, validation losses: 0.28581345949258763\n",
      "Epoch 3987, reconstruction losses: 0.011446309817131736, regression losses: 0.10918960581352799, validation losses: 0.38164856192386076\n",
      "Epoch 3988, reconstruction losses: 0.015215794383725518, regression losses: 0.10911224280204357, validation losses: 0.35678432952179\n",
      "Epoch 3989, reconstruction losses: 0.012779926561425991, regression losses: 0.13806784674271105, validation losses: 0.3288859003272765\n",
      "Epoch 3990, reconstruction losses: 0.011629746437349573, regression losses: 0.11469618311180148, validation losses: 0.3345054058456375\n",
      "Epoch 3991, reconstruction losses: 0.012477620131853362, regression losses: 0.14268642687180125, validation losses: 0.3535574709092807\n",
      "Epoch 3992, reconstruction losses: 0.013747128584051579, regression losses: 0.089587764501875, validation losses: 0.28615729998051775\n",
      "Epoch 3993, reconstruction losses: 0.01278204556221121, regression losses: 0.09844417043874842, validation losses: 0.28192948884294167\n",
      "Epoch 3994, reconstruction losses: 0.020844854920628986, regression losses: 0.18378190658055935, validation losses: 0.292169919771801\n",
      "Epoch 3995, reconstruction losses: 0.01160805375231694, regression losses: 0.09550350780989988, validation losses: 0.35707705396080064\n",
      "Epoch 3996, reconstruction losses: 0.012593568223267283, regression losses: 0.12745775956434888, validation losses: 0.3399775651113204\n",
      "Epoch 3997, reconstruction losses: 0.010723961147366168, regression losses: 0.08185313166697354, validation losses: 0.3488694638497381\n",
      "Epoch 3998, reconstruction losses: 0.010972343712014816, regression losses: 0.11283191740901867, validation losses: 0.3564228951046522\n",
      "Epoch 3999, reconstruction losses: 0.012039148739791141, regression losses: 0.11908823861807553, validation losses: 0.3682958397805069\n",
      "Epoch 4000, reconstruction losses: 0.010972246389685865, regression losses: 0.101305940179212, validation losses: 0.41669833058121863\n",
      "Epoch 4001, reconstruction losses: 0.01271456927487774, regression losses: 0.11183025256977597, validation losses: 0.4143546457897991\n",
      "Epoch 4002, reconstruction losses: 0.010196165644416527, regression losses: 0.07019589562767788, validation losses: 0.3463176761796\n",
      "Epoch 4003, reconstruction losses: 0.011026500893361772, regression losses: 0.07970558603801496, validation losses: 0.32057596972922536\n",
      "Epoch 4004, reconstruction losses: 0.014174443286104899, regression losses: 0.07802113024280732, validation losses: 0.3557320915883162\n",
      "Epoch 4005, reconstruction losses: 0.012325428143333164, regression losses: 0.079553867612854, validation losses: 0.38766472747774583\n",
      "Epoch 4006, reconstruction losses: 0.012791459291091288, regression losses: 0.08665724144901091, validation losses: 0.3606534515843613\n",
      "Epoch 4007, reconstruction losses: 0.010933224413601861, regression losses: 0.08880274800507608, validation losses: 0.3517912843238662\n",
      "Epoch 4008, reconstruction losses: 0.014301533590397326, regression losses: 0.24582235821447065, validation losses: 0.34363826013523174\n",
      "Epoch 4009, reconstruction losses: 0.011931665794626067, regression losses: 0.11346692123372697, validation losses: 0.47698923859445275\n",
      "Epoch 4010, reconstruction losses: 0.011845879808489104, regression losses: 0.10805109252956538, validation losses: 0.401040299563341\n",
      "Epoch 4011, reconstruction losses: 0.014699501459387927, regression losses: 0.11434323765006547, validation losses: 0.38425211633815615\n",
      "Epoch 4012, reconstruction losses: 0.01494383254223242, regression losses: 0.07985069448938929, validation losses: 0.362694150863502\n",
      "Epoch 4013, reconstruction losses: 0.010777074656178626, regression losses: 0.0851728437848089, validation losses: 0.3436077781573103\n",
      "Epoch 4014, reconstruction losses: 0.011880191306630589, regression losses: 0.10757551416831632, validation losses: 0.3614009299490772\n",
      "Epoch 4015, reconstruction losses: 0.010570164290451925, regression losses: 0.09373184513084834, validation losses: 0.33834989706612156\n",
      "Epoch 4016, reconstruction losses: 0.011600175675196398, regression losses: 0.07596038305992545, validation losses: 0.3281044971506638\n",
      "Epoch 4017, reconstruction losses: 0.011218266943207735, regression losses: 0.11643464409835953, validation losses: 0.3145476628485427\n",
      "Epoch 4018, reconstruction losses: 0.011341554843088702, regression losses: 0.08541058956113158, validation losses: 0.30815849244829935\n",
      "Epoch 4019, reconstruction losses: 0.011517809856994203, regression losses: 0.09661144918726969, validation losses: 0.3205029261978548\n",
      "Epoch 4020, reconstruction losses: 0.013698826832478896, regression losses: 0.13371389879572645, validation losses: 0.32892132690997417\n",
      "Epoch 4021, reconstruction losses: 0.011140513481710797, regression losses: 0.10269456424389391, validation losses: 0.34359531977098395\n",
      "Epoch 4022, reconstruction losses: 0.011269979299573992, regression losses: 0.08683873873535362, validation losses: 0.34405090477999056\n",
      "Epoch 4023, reconstruction losses: 0.012963367934585558, regression losses: 0.09756821511865288, validation losses: 0.340652364436719\n",
      "Epoch 4024, reconstruction losses: 0.01850437934735312, regression losses: 0.19628499745207273, validation losses: 0.3220329195911096\n",
      "Epoch 4025, reconstruction losses: 0.02011982281791099, regression losses: 0.21253428422303533, validation losses: 0.4814289758869089\n",
      "Epoch 4026, reconstruction losses: 0.014585834342636095, regression losses: 0.15305327820646342, validation losses: 0.8060321713269443\n",
      "Epoch 4027, reconstruction losses: 0.014388496183042113, regression losses: 0.18549344163713602, validation losses: 0.5869929385733003\n",
      "Epoch 4028, reconstruction losses: 0.01385604605582859, regression losses: 0.16004418055932196, validation losses: 0.4658229129221315\n",
      "Epoch 4029, reconstruction losses: 0.014698366717157985, regression losses: 0.13302881967649496, validation losses: 0.6274998432667604\n",
      "Epoch 4030, reconstruction losses: 0.01703510311681641, regression losses: 0.13523877464247797, validation losses: 0.7069803047257972\n",
      "Epoch 4031, reconstruction losses: 0.012041829085831348, regression losses: 0.14369469974332438, validation losses: 0.5620055073754834\n",
      "Epoch 4032, reconstruction losses: 0.013039408178752428, regression losses: 0.12728641875880214, validation losses: 0.39321259163182487\n",
      "Epoch 4033, reconstruction losses: 0.012910057099332815, regression losses: 0.08595287509616825, validation losses: 0.3516639340190546\n",
      "Epoch 4034, reconstruction losses: 0.013084079540461502, regression losses: 0.1045899537640908, validation losses: 0.3442468326364357\n",
      "Epoch 4035, reconstruction losses: 0.01798154002698003, regression losses: 0.144310322753486, validation losses: 0.3484912109953928\n",
      "Epoch 4036, reconstruction losses: 0.014518206228579156, regression losses: 0.12032674775857857, validation losses: 0.3850138833580419\n",
      "Epoch 4037, reconstruction losses: 0.011807500655680472, regression losses: 0.08349902437444152, validation losses: 0.3490913322535079\n",
      "Epoch 4038, reconstruction losses: 0.012436209768130507, regression losses: 0.1116655105607223, validation losses: 0.34569992951268286\n",
      "Epoch 4039, reconstruction losses: 0.011786817750464978, regression losses: 0.10228067748936967, validation losses: 0.3570287435491237\n",
      "Epoch 4040, reconstruction losses: 0.011356888780561463, regression losses: 0.08074361832160754, validation losses: 0.3554143371500956\n",
      "Epoch 4041, reconstruction losses: 0.013374116707226826, regression losses: 0.08225975626895043, validation losses: 0.3458564325735044\n",
      "Epoch 4042, reconstruction losses: 0.012668716655402697, regression losses: 0.1068011743501469, validation losses: 0.35590875969685687\n",
      "Epoch 4043, reconstruction losses: 0.012792870585546663, regression losses: 0.11551274410498778, validation losses: 0.38856075780540106\n",
      "Epoch 4044, reconstruction losses: 0.01240403039803817, regression losses: 0.09905976954798715, validation losses: 0.36184210813562867\n",
      "Epoch 4045, reconstruction losses: 0.012842379001559719, regression losses: 0.08500544185560521, validation losses: 0.3429078806950926\n",
      "Epoch 4046, reconstruction losses: 0.010454130308114066, regression losses: 0.0880185907878079, validation losses: 0.34504507515233285\n",
      "Epoch 4047, reconstruction losses: 0.011792432391641523, regression losses: 0.08252394250715263, validation losses: 0.3670743665597317\n",
      "Epoch 4048, reconstruction losses: 0.013125880204180573, regression losses: 0.08989815931346971, validation losses: 0.3545427469477368\n",
      "Epoch 4049, reconstruction losses: 0.011607024309935888, regression losses: 0.09132426712241454, validation losses: 0.3354719622511302\n",
      "Epoch 4050, reconstruction losses: 0.010394352469099137, regression losses: 0.07193877272284914, validation losses: 0.33843224592371096\n",
      "Epoch 4051, reconstruction losses: 0.014049060270131536, regression losses: 0.09766254843993823, validation losses: 0.3338778553014428\n",
      "Epoch 4052, reconstruction losses: 0.011201119789867747, regression losses: 0.13430282654308906, validation losses: 0.3209327060603362\n",
      "Epoch 4053, reconstruction losses: 0.01293970950323394, regression losses: 0.13415061771380568, validation losses: 0.3420180350173633\n",
      "Epoch 4054, reconstruction losses: 0.010522896425493372, regression losses: 0.07509228229595423, validation losses: 0.3251442760514281\n",
      "Epoch 4055, reconstruction losses: 0.012717043448639002, regression losses: 0.1133383184262948, validation losses: 0.33126377809174773\n",
      "Epoch 4056, reconstruction losses: 0.011181949567422817, regression losses: 0.08473530308993173, validation losses: 0.36050178851944187\n",
      "Epoch 4057, reconstruction losses: 0.011620866728608792, regression losses: 0.11262133838526879, validation losses: 0.38111576818827614\n",
      "Epoch 4058, reconstruction losses: 0.011829941314173285, regression losses: 0.10148472272157541, validation losses: 0.35501413770453744\n",
      "Epoch 4059, reconstruction losses: 0.013011087420885952, regression losses: 0.12950245572636437, validation losses: 0.3285416732155957\n",
      "Epoch 4060, reconstruction losses: 0.012861463002555565, regression losses: 0.12461691783030149, validation losses: 0.36704965037556464\n",
      "Epoch 4061, reconstruction losses: 0.010080764307315951, regression losses: 0.09099791007057947, validation losses: 0.3455329136599118\n",
      "Epoch 4062, reconstruction losses: 0.010481686614723356, regression losses: 0.09739813097853557, validation losses: 0.31281041230981377\n",
      "Epoch 4063, reconstruction losses: 0.010755524746067408, regression losses: 0.06831978200933865, validation losses: 0.33867239225457996\n",
      "Epoch 4064, reconstruction losses: 0.0118097687994153, regression losses: 0.1017217803858426, validation losses: 0.3530562780371757\n",
      "Epoch 4065, reconstruction losses: 0.013198158233563127, regression losses: 0.2071627891887873, validation losses: 0.3565811883476419\n",
      "Epoch 4066, reconstruction losses: 0.009921740025866562, regression losses: 0.12287723535918581, validation losses: 0.47767235774495476\n",
      "Epoch 4067, reconstruction losses: 0.013907795827068638, regression losses: 0.12002980302361399, validation losses: 0.513965146948129\n",
      "Epoch 4068, reconstruction losses: 0.011727523421244728, regression losses: 0.12326627143127837, validation losses: 0.4455581201897024\n",
      "Epoch 4069, reconstruction losses: 0.010285012396463386, regression losses: 0.08688653395236662, validation losses: 0.3637793346066287\n",
      "Epoch 4070, reconstruction losses: 0.012325503560717602, regression losses: 0.10787821478453517, validation losses: 0.3245613315541696\n",
      "Epoch 4071, reconstruction losses: 0.011958652545818191, regression losses: 0.09561783416847106, validation losses: 0.3401717609461801\n",
      "Epoch 4072, reconstruction losses: 0.015089289713930518, regression losses: 0.17678345917828736, validation losses: 0.3572623609528816\n",
      "Epoch 4073, reconstruction losses: 0.014662607660393033, regression losses: 0.13714560593781164, validation losses: 0.33400950363705767\n",
      "Epoch 4074, reconstruction losses: 0.011814631096237128, regression losses: 0.09214307454299665, validation losses: 0.336949331713079\n",
      "Epoch 4075, reconstruction losses: 0.01184528708993135, regression losses: 0.0896200687463442, validation losses: 0.30981911233852605\n",
      "Epoch 4076, reconstruction losses: 0.019245237194329183, regression losses: 0.1425992065987432, validation losses: 0.32187327001602883\n",
      "Epoch 4077, reconstruction losses: 0.013113396654299014, regression losses: 0.11179840797117038, validation losses: 0.37738655322871084\n",
      "Epoch 4078, reconstruction losses: 0.015787749798231093, regression losses: 0.20662293561239156, validation losses: 0.316449575206457\n",
      "Epoch 4079, reconstruction losses: 0.016653673754656644, regression losses: 0.13118335170025064, validation losses: 0.34491951915268604\n",
      "Epoch 4080, reconstruction losses: 0.01591867797500355, regression losses: 0.18354991967083278, validation losses: 0.455796256737386\n",
      "Epoch 4081, reconstruction losses: 0.013696564994538415, regression losses: 0.14080075934372727, validation losses: 0.31953738801700604\n",
      "Epoch 4082, reconstruction losses: 0.010693808725406316, regression losses: 0.06933089849947077, validation losses: 0.3536955598724562\n",
      "Epoch 4083, reconstruction losses: 0.014810053245951228, regression losses: 0.12593936675779524, validation losses: 0.34735618142658875\n",
      "Epoch 4084, reconstruction losses: 0.013398360182514463, regression losses: 0.09840346166581765, validation losses: 0.29976890721366967\n",
      "Epoch 4085, reconstruction losses: 0.012691382224176637, regression losses: 0.08839699754709178, validation losses: 0.2975616479248882\n",
      "Epoch 4086, reconstruction losses: 0.011257051124123908, regression losses: 0.08036734514657352, validation losses: 0.3066623486127607\n",
      "Epoch 4087, reconstruction losses: 0.009661840455618133, regression losses: 0.07126824232165593, validation losses: 0.31868984927468874\n",
      "Epoch 4088, reconstruction losses: 0.012408052828424773, regression losses: 0.06343354868075991, validation losses: 0.3257703859348662\n",
      "Epoch 4089, reconstruction losses: 0.012938317009640295, regression losses: 0.10151249258287018, validation losses: 0.32568718008335124\n",
      "Epoch 4090, reconstruction losses: 0.011623065609311273, regression losses: 0.1049012170455318, validation losses: 0.32267629041002394\n",
      "Epoch 4091, reconstruction losses: 0.011627781902735753, regression losses: 0.09293089592917196, validation losses: 0.3422492196467445\n",
      "Epoch 4092, reconstruction losses: 0.010987756857649716, regression losses: 0.08189772903983016, validation losses: 0.35981177591719504\n",
      "Epoch 4093, reconstruction losses: 0.012310903989685883, regression losses: 0.12101452315446626, validation losses: 0.3371592479430333\n",
      "Epoch 4094, reconstruction losses: 0.012197197170299587, regression losses: 0.12556816169446783, validation losses: 0.31219261463255926\n",
      "Epoch 4095, reconstruction losses: 0.011580669257216536, regression losses: 0.09407686933455589, validation losses: 0.3227114445588613\n",
      "Epoch 4096, reconstruction losses: 0.012537670236821367, regression losses: 0.11385513221304895, validation losses: 0.3229017087706799\n",
      "Epoch 4097, reconstruction losses: 0.012083878740039657, regression losses: 0.08972571025970516, validation losses: 0.32789825222632385\n",
      "Epoch 4098, reconstruction losses: 0.01238040256806836, regression losses: 0.11167437829131287, validation losses: 0.31343846448315127\n",
      "Epoch 4099, reconstruction losses: 0.01787308588296318, regression losses: 0.13298116446802843, validation losses: 0.31848525768362257\n",
      "Epoch 4100, reconstruction losses: 0.01124393023105512, regression losses: 0.07722990012301907, validation losses: 0.3992033725294145\n",
      "Epoch 4101, reconstruction losses: 0.011949488095999643, regression losses: 0.10227686498261765, validation losses: 0.4139271469157012\n",
      "Epoch 4102, reconstruction losses: 0.016009059742977706, regression losses: 0.09926470639302365, validation losses: 0.372531209840187\n",
      "Epoch 4103, reconstruction losses: 0.01143478344343198, regression losses: 0.08874438866694637, validation losses: 0.3576508669962952\n",
      "Epoch 4104, reconstruction losses: 0.012394690717223052, regression losses: 0.11381793909900532, validation losses: 0.36066562500244126\n",
      "Epoch 4105, reconstruction losses: 0.013000540367678901, regression losses: 0.08920783406339478, validation losses: 0.3539666705624334\n",
      "Epoch 4106, reconstruction losses: 0.010705669469423262, regression losses: 0.10404389218927429, validation losses: 0.349427076501263\n",
      "Epoch 4107, reconstruction losses: 0.01447098465381082, regression losses: 0.13373274074234054, validation losses: 0.37188989753439916\n",
      "Epoch 4108, reconstruction losses: 0.011814618342336037, regression losses: 0.067145277323297, validation losses: 0.42195866087581\n",
      "Epoch 4109, reconstruction losses: 0.010761265736767622, regression losses: 0.11030196694135991, validation losses: 0.3625414713971663\n",
      "Epoch 4110, reconstruction losses: 0.012629155370308977, regression losses: 0.10366520474009627, validation losses: 0.3316018079771581\n",
      "Epoch 4111, reconstruction losses: 0.013005964806060215, regression losses: 0.10020547481767203, validation losses: 0.3198552726469886\n",
      "Epoch 4112, reconstruction losses: 0.011205278030248038, regression losses: 0.10187023200861907, validation losses: 0.315689296969594\n",
      "Epoch 4113, reconstruction losses: 0.010793279143266691, regression losses: 0.11543931151090009, validation losses: 0.31838214795897446\n",
      "Epoch 4114, reconstruction losses: 0.012612626200511602, regression losses: 0.20107518448132805, validation losses: 0.3165006668805125\n",
      "Epoch 4115, reconstruction losses: 0.012055229689135008, regression losses: 0.0958264528480903, validation losses: 0.36903796320912785\n",
      "Epoch 4116, reconstruction losses: 0.014263541697976346, regression losses: 0.13625290086970282, validation losses: 0.37403601952381293\n",
      "Epoch 4117, reconstruction losses: 0.013053579638854432, regression losses: 0.14095581443069052, validation losses: 0.36739603609673754\n",
      "Epoch 4118, reconstruction losses: 0.011521401925483078, regression losses: 0.09459307054308419, validation losses: 0.4039793899112579\n",
      "Epoch 4119, reconstruction losses: 0.012899536382530597, regression losses: 0.11579763455510113, validation losses: 0.4729654667552543\n",
      "Epoch 4120, reconstruction losses: 0.011944076835897597, regression losses: 0.09542500644153544, validation losses: 0.4302958999405859\n",
      "Epoch 4121, reconstruction losses: 0.011721439158971104, regression losses: 0.09447407084649775, validation losses: 0.3818194011276637\n",
      "Epoch 4122, reconstruction losses: 0.012404943946096496, regression losses: 0.125111168096635, validation losses: 0.3731433258832048\n",
      "Epoch 4123, reconstruction losses: 0.013235876184881049, regression losses: 0.09777527978837186, validation losses: 0.362490465167621\n",
      "Epoch 4124, reconstruction losses: 0.01066194736345253, regression losses: 0.1139621862714567, validation losses: 0.35188269736027145\n",
      "Epoch 4125, reconstruction losses: 0.012392046972234847, regression losses: 0.11815763305694266, validation losses: 0.33500318363203396\n",
      "Epoch 4126, reconstruction losses: 0.012877088697067272, regression losses: 0.09385511867209426, validation losses: 0.3857563645101813\n",
      "Epoch 4127, reconstruction losses: 0.012153759598500328, regression losses: 0.1202350798351757, validation losses: 0.41531401691944875\n",
      "Epoch 4128, reconstruction losses: 0.01173182234689394, regression losses: 0.11303150672650228, validation losses: 0.3509024086804906\n",
      "Epoch 4129, reconstruction losses: 0.011237519108012854, regression losses: 0.06504246931369083, validation losses: 0.32834887083532904\n",
      "Epoch 4130, reconstruction losses: 0.01103783877241882, regression losses: 0.09178438612255102, validation losses: 0.33206949482055254\n",
      "Epoch 4131, reconstruction losses: 0.013357964751213449, regression losses: 0.11425895440809586, validation losses: 0.32755893724321267\n",
      "Epoch 4132, reconstruction losses: 0.010511586621323253, regression losses: 0.09763084724423367, validation losses: 0.31758152618607627\n",
      "Epoch 4133, reconstruction losses: 0.010454907358900081, regression losses: 0.08366862040471029, validation losses: 0.31204204800686364\n",
      "Epoch 4134, reconstruction losses: 0.013485498129523387, regression losses: 0.21430527985540296, validation losses: 0.3057522918570846\n",
      "Epoch 4135, reconstruction losses: 0.01462975543530517, regression losses: 0.15693168188112955, validation losses: 0.3404020942244843\n",
      "Epoch 4136, reconstruction losses: 0.011049091855944116, regression losses: 0.1115004316772535, validation losses: 0.3720416889769391\n",
      "Epoch 4137, reconstruction losses: 0.012432024707433926, regression losses: 0.06970657448869234, validation losses: 0.37882960197867727\n",
      "Epoch 4138, reconstruction losses: 0.014233920493841961, regression losses: 0.11338105214268769, validation losses: 0.35178170459491304\n",
      "Epoch 4139, reconstruction losses: 0.012853605800894657, regression losses: 0.11815228524234733, validation losses: 0.31494883420286635\n",
      "Epoch 4140, reconstruction losses: 0.011765537576048585, regression losses: 0.09698106329735172, validation losses: 0.30798062260563996\n",
      "Epoch 4141, reconstruction losses: 0.010221462550829279, regression losses: 0.08103639625408111, validation losses: 0.3107975071296339\n",
      "Epoch 4142, reconstruction losses: 0.013040207147789485, regression losses: 0.114351325605889, validation losses: 0.3189670664417626\n",
      "Epoch 4143, reconstruction losses: 0.013791773936462215, regression losses: 0.10322079813233886, validation losses: 0.3194103749688431\n",
      "Epoch 4144, reconstruction losses: 0.011544179150704999, regression losses: 0.08669979768963607, validation losses: 0.32402271998885573\n",
      "Epoch 4145, reconstruction losses: 0.01149890716701739, regression losses: 0.08597308492785821, validation losses: 0.3121370176438197\n",
      "Epoch 4146, reconstruction losses: 0.012025366314911554, regression losses: 0.11749250937027865, validation losses: 0.31383567383664585\n",
      "Epoch 4147, reconstruction losses: 0.011313996223086556, regression losses: 0.1181516405237573, validation losses: 0.3004177644586815\n",
      "Epoch 4148, reconstruction losses: 0.011878021382002949, regression losses: 0.09246121404861743, validation losses: 0.3052754953505998\n",
      "Epoch 4149, reconstruction losses: 0.011439753067157688, regression losses: 0.10466039005816113, validation losses: 0.33689895494356326\n",
      "Epoch 4150, reconstruction losses: 0.011331144558792906, regression losses: 0.08888667110208061, validation losses: 0.3255174680201019\n",
      "Epoch 4151, reconstruction losses: 0.01267188056449568, regression losses: 0.1526071682578991, validation losses: 0.3100219052086618\n",
      "Epoch 4152, reconstruction losses: 0.014147455884137189, regression losses: 0.18740380504735077, validation losses: 0.31771379240521913\n",
      "Epoch 4153, reconstruction losses: 0.011705569741556433, regression losses: 0.09603369000178244, validation losses: 0.35300236747415986\n",
      "Epoch 4154, reconstruction losses: 0.012359377444835527, regression losses: 0.13178457739739569, validation losses: 0.41206607088767416\n",
      "Epoch 4155, reconstruction losses: 0.010128248915718145, regression losses: 0.06880849001873282, validation losses: 0.3426789942939761\n",
      "Epoch 4156, reconstruction losses: 0.016417369323154043, regression losses: 0.35299098076690505, validation losses: 0.3345336486577016\n",
      "Epoch 4157, reconstruction losses: 0.013938113127965942, regression losses: 0.1127755829377454, validation losses: 0.5065789555449846\n",
      "Epoch 4158, reconstruction losses: 0.014243571387114072, regression losses: 0.1816230794278429, validation losses: 0.5378651701386703\n",
      "Epoch 4159, reconstruction losses: 0.013191208280818332, regression losses: 0.08224282848762779, validation losses: 0.3884260849534676\n",
      "Epoch 4160, reconstruction losses: 0.012279787347437156, regression losses: 0.08537378821558124, validation losses: 0.36507943457878894\n",
      "Epoch 4161, reconstruction losses: 0.012239577047680795, regression losses: 0.10592445764518756, validation losses: 0.35721041989502333\n",
      "Epoch 4162, reconstruction losses: 0.013192511471457303, regression losses: 0.10579873917735172, validation losses: 0.3653867577041018\n",
      "Epoch 4163, reconstruction losses: 0.011573026806884086, regression losses: 0.09598653098090959, validation losses: 0.3792533004911069\n",
      "Epoch 4164, reconstruction losses: 0.01207043892809015, regression losses: 0.09899817198903728, validation losses: 0.3374753645753437\n",
      "Epoch 4165, reconstruction losses: 0.01342263318233815, regression losses: 0.12993133668768078, validation losses: 0.32008514421761514\n",
      "Epoch 4166, reconstruction losses: 0.011880500073159106, regression losses: 0.11090578367557542, validation losses: 0.321942681943756\n",
      "Epoch 4167, reconstruction losses: 0.012004932935884643, regression losses: 0.12766275596570537, validation losses: 0.33459503340201685\n",
      "Epoch 4168, reconstruction losses: 0.013897431958248276, regression losses: 0.10945016579226165, validation losses: 0.34347281156377674\n",
      "Epoch 4169, reconstruction losses: 0.014510053587476826, regression losses: 0.13219140291328813, validation losses: 0.3267457464246052\n",
      "Epoch 4170, reconstruction losses: 0.0119130311211404, regression losses: 0.09123524183376089, validation losses: 0.345505676691711\n",
      "Epoch 4171, reconstruction losses: 0.013209975591548902, regression losses: 0.11101768311706721, validation losses: 0.3471518728333257\n",
      "Epoch 4172, reconstruction losses: 0.015177384438455718, regression losses: 0.10928074800991475, validation losses: 0.3373391476684209\n",
      "Epoch 4173, reconstruction losses: 0.009893019486494055, regression losses: 0.08138217732015027, validation losses: 0.3410518164543915\n",
      "Epoch 4174, reconstruction losses: 0.012918222031104295, regression losses: 0.09347374368306785, validation losses: 0.3229387689417972\n",
      "Epoch 4175, reconstruction losses: 0.010912533598870424, regression losses: 0.07747060644078095, validation losses: 0.3111887132425948\n",
      "Epoch 4176, reconstruction losses: 0.011049518792076767, regression losses: 0.07507541421554978, validation losses: 0.3049758046418311\n",
      "Epoch 4177, reconstruction losses: 0.009995923804446503, regression losses: 0.06920177304267644, validation losses: 0.30730387672257653\n",
      "Epoch 4178, reconstruction losses: 0.010600895233269328, regression losses: 0.09544903624904384, validation losses: 0.2926075930738655\n",
      "Epoch 4179, reconstruction losses: 0.010962772594154072, regression losses: 0.09324260850628904, validation losses: 0.3012451707759012\n",
      "Epoch 4180, reconstruction losses: 0.013379860791172043, regression losses: 0.10103516207936089, validation losses: 0.3483045832714738\n",
      "Epoch 4181, reconstruction losses: 0.012513971312254141, regression losses: 0.09549968228774798, validation losses: 0.34555367972736956\n",
      "Epoch 4182, reconstruction losses: 0.010941858795839837, regression losses: 0.08725475490933242, validation losses: 0.34491130127707\n",
      "Epoch 4183, reconstruction losses: 0.010950002990332806, regression losses: 0.1323974781292845, validation losses: 0.3343400465978006\n",
      "Epoch 4184, reconstruction losses: 0.011902921620971053, regression losses: 0.0986161641012786, validation losses: 0.3240904807558118\n",
      "Epoch 4185, reconstruction losses: 0.011904863133156987, regression losses: 0.12178194445414695, validation losses: 0.322340700723572\n",
      "Epoch 4186, reconstruction losses: 0.011587207304110838, regression losses: 0.12195858376815871, validation losses: 0.3215916370492612\n",
      "Epoch 4187, reconstruction losses: 0.01152883017848808, regression losses: 0.09740776065415717, validation losses: 0.32083226191538816\n",
      "Epoch 4188, reconstruction losses: 0.010636557505959425, regression losses: 0.07113977858895051, validation losses: 0.32030045606829394\n",
      "Epoch 4189, reconstruction losses: 0.012882925463709031, regression losses: 0.08716479544827785, validation losses: 0.31258794461416156\n",
      "Epoch 4190, reconstruction losses: 0.011515519848207614, regression losses: 0.18550906620111401, validation losses: 0.30588539286639954\n",
      "Epoch 4191, reconstruction losses: 0.01109840604357416, regression losses: 0.10583219526589609, validation losses: 0.3062724028821673\n",
      "Epoch 4192, reconstruction losses: 0.011456200940257816, regression losses: 0.10005466942727653, validation losses: 0.3225677720513076\n",
      "Epoch 4193, reconstruction losses: 0.010580683374725963, regression losses: 0.09088719268795142, validation losses: 0.3196692014496395\n",
      "Epoch 4194, reconstruction losses: 0.011508002430644806, regression losses: 0.10489568471067667, validation losses: 0.31696319144779467\n",
      "Epoch 4195, reconstruction losses: 0.01011359692538048, regression losses: 0.09487360721069002, validation losses: 0.3318045161556632\n",
      "Epoch 4196, reconstruction losses: 0.013327157540636743, regression losses: 0.10384362957939886, validation losses: 0.3162774659717601\n",
      "Epoch 4197, reconstruction losses: 0.011453140854560733, regression losses: 0.09578790838960119, validation losses: 0.3114322747976508\n",
      "Epoch 4198, reconstruction losses: 0.011856165597166226, regression losses: 0.0750863233474132, validation losses: 0.3119597487806227\n",
      "Epoch 4199, reconstruction losses: 0.011749962121579572, regression losses: 0.0913270778817966, validation losses: 0.3384010724784052\n",
      "Epoch 4200, reconstruction losses: 0.011766816699558204, regression losses: 0.08685921424309481, validation losses: 0.33737199954296915\n",
      "Epoch 4201, reconstruction losses: 0.011254259374743673, regression losses: 0.13858593418836204, validation losses: 0.3242625208013709\n",
      "Epoch 4202, reconstruction losses: 0.014705055509290665, regression losses: 0.11902974662893764, validation losses: 0.3952473182592322\n",
      "Epoch 4203, reconstruction losses: 0.012328074592303674, regression losses: 0.116570560775435, validation losses: 0.3964306629249934\n",
      "Epoch 4204, reconstruction losses: 0.011950110277054485, regression losses: 0.11439967997334875, validation losses: 0.37137746574512265\n",
      "Epoch 4205, reconstruction losses: 0.014579767581516946, regression losses: 0.12701203197582842, validation losses: 0.34879458959174287\n",
      "Epoch 4206, reconstruction losses: 0.013520823299866161, regression losses: 0.10082910571817479, validation losses: 0.3689401068830666\n",
      "Epoch 4207, reconstruction losses: 0.011390157594604482, regression losses: 0.0661994479853379, validation losses: 0.3456597986858114\n",
      "Epoch 4208, reconstruction losses: 0.010656025796580707, regression losses: 0.08629079848895793, validation losses: 0.3452121664503511\n",
      "Epoch 4209, reconstruction losses: 0.01364715287588864, regression losses: 0.16101567438378742, validation losses: 0.32628896861499634\n",
      "Epoch 4210, reconstruction losses: 0.011576631821398052, regression losses: 0.16836439851920842, validation losses: 0.3417165759269134\n",
      "Epoch 4211, reconstruction losses: 0.013231009433831835, regression losses: 0.15642160600165855, validation losses: 0.3956456971967678\n",
      "Epoch 4212, reconstruction losses: 0.01107842892788776, regression losses: 0.09345413814641182, validation losses: 0.3896841992191876\n",
      "Epoch 4213, reconstruction losses: 0.014296201995065498, regression losses: 0.12423035701334839, validation losses: 0.32029500138909295\n",
      "Epoch 4214, reconstruction losses: 0.015040714470700302, regression losses: 0.09597450634443191, validation losses: 0.31550394165801954\n",
      "Epoch 4215, reconstruction losses: 0.015237593238742814, regression losses: 0.09662080413812216, validation losses: 0.3194028110719888\n",
      "Epoch 4216, reconstruction losses: 0.01290851214427869, regression losses: 0.11188190294440692, validation losses: 0.365738376992402\n",
      "Epoch 4217, reconstruction losses: 0.012601293691156399, regression losses: 0.15885277050906677, validation losses: 0.35172013064094737\n",
      "Epoch 4218, reconstruction losses: 0.011235268710547459, regression losses: 0.09256855256356987, validation losses: 0.34838806653715376\n",
      "Epoch 4219, reconstruction losses: 0.013057146089792714, regression losses: 0.0837927769590012, validation losses: 0.319448022475441\n",
      "Epoch 4220, reconstruction losses: 0.01089942574445954, regression losses: 0.09215313333830696, validation losses: 0.3020918050444361\n",
      "Epoch 4221, reconstruction losses: 0.01206796830762326, regression losses: 0.09930663204339209, validation losses: 0.30510050629954116\n",
      "Epoch 4222, reconstruction losses: 0.011061759539502104, regression losses: 0.09935344712466004, validation losses: 0.3322702846120762\n",
      "Epoch 4223, reconstruction losses: 0.009722888554520021, regression losses: 0.09068690095764596, validation losses: 0.31622101008345993\n",
      "Epoch 4224, reconstruction losses: 0.011889542541013952, regression losses: 0.08430209376155445, validation losses: 0.2908192764271468\n",
      "Epoch 4225, reconstruction losses: 0.011095114547961537, regression losses: 0.1034353223475635, validation losses: 0.31342110053164085\n",
      "Epoch 4226, reconstruction losses: 0.013310257441629274, regression losses: 0.09249067667796469, validation losses: 0.3333150579078271\n",
      "Epoch 4227, reconstruction losses: 0.011639110939882952, regression losses: 0.09993909871688979, validation losses: 0.3297472057638362\n",
      "Epoch 4228, reconstruction losses: 0.011909141505749236, regression losses: 0.08564575212388782, validation losses: 0.303276503114382\n",
      "Epoch 4229, reconstruction losses: 0.01569402197027053, regression losses: 0.10978447878806782, validation losses: 0.30055240098158664\n",
      "Epoch 4230, reconstruction losses: 0.010867746673263267, regression losses: 0.10152279787939059, validation losses: 0.3072902219033842\n",
      "Epoch 4231, reconstruction losses: 0.010803577253582277, regression losses: 0.08302108449804185, validation losses: 0.3049754898331304\n",
      "Epoch 4232, reconstruction losses: 0.009884778451463207, regression losses: 0.08660755769726095, validation losses: 0.29596292363432875\n",
      "Epoch 4233, reconstruction losses: 0.012018648044784148, regression losses: 0.12165890576480923, validation losses: 0.354241846083385\n",
      "Epoch 4234, reconstruction losses: 0.011317414544233021, regression losses: 0.10227866867308108, validation losses: 0.3773027391477764\n",
      "Epoch 4235, reconstruction losses: 0.012447199445453276, regression losses: 0.13122348684049379, validation losses: 0.340371526057745\n",
      "Epoch 4236, reconstruction losses: 0.012153782903872014, regression losses: 0.1100222334581259, validation losses: 0.34534737642689334\n",
      "Epoch 4237, reconstruction losses: 0.01363229799502792, regression losses: 0.09453141613582927, validation losses: 0.32568547903196\n",
      "Epoch 4238, reconstruction losses: 0.01434462245462557, regression losses: 0.1482231541797476, validation losses: 0.3330066980036975\n",
      "Epoch 4239, reconstruction losses: 0.01286870695218678, regression losses: 0.10791001366780979, validation losses: 0.39844011183721245\n",
      "Epoch 4240, reconstruction losses: 0.011818247038578788, regression losses: 0.11323539054476128, validation losses: 0.32996484489113564\n",
      "Epoch 4241, reconstruction losses: 0.011327072268782042, regression losses: 0.0799768329154964, validation losses: 0.3177216181076912\n",
      "Epoch 4242, reconstruction losses: 0.013012973541017839, regression losses: 0.0766722851528946, validation losses: 0.3411528905296329\n",
      "Epoch 4243, reconstruction losses: 0.015323823810721303, regression losses: 0.10886643469590883, validation losses: 0.3519259880997448\n",
      "Epoch 4244, reconstruction losses: 0.012414841805721409, regression losses: 0.08664837331055206, validation losses: 0.35225666382686494\n",
      "Epoch 4245, reconstruction losses: 0.010305746628975224, regression losses: 0.08541986802971042, validation losses: 0.2972523705236193\n",
      "Epoch 4246, reconstruction losses: 0.010122980557211614, regression losses: 0.07017641844086846, validation losses: 0.29167547373354363\n",
      "Epoch 4247, reconstruction losses: 0.010352578289057472, regression losses: 0.08258454545128215, validation losses: 0.29893437558409547\n",
      "Epoch 4248, reconstruction losses: 0.010520609738714382, regression losses: 0.07337311741245883, validation losses: 0.3059152425850671\n",
      "Epoch 4249, reconstruction losses: 0.01256791201422388, regression losses: 0.2433269208254465, validation losses: 0.3544647915616168\n",
      "Epoch 4250, reconstruction losses: 0.0124983958928199, regression losses: 0.13315464098006083, validation losses: 0.8006294430390785\n",
      "Epoch 4251, reconstruction losses: 0.012720925265213125, regression losses: 0.08871517660897095, validation losses: 0.6694916230535111\n",
      "Epoch 4252, reconstruction losses: 0.012684979187240143, regression losses: 0.10005239686596874, validation losses: 0.5442397637179257\n",
      "Epoch 4253, reconstruction losses: 0.01420282240825314, regression losses: 0.12156424120871935, validation losses: 0.5007193041070751\n",
      "Epoch 4254, reconstruction losses: 0.013661729634138616, regression losses: 0.11404838520496813, validation losses: 0.4779835579640788\n",
      "Epoch 4255, reconstruction losses: 0.012798500808090054, regression losses: 0.09964111788586008, validation losses: 0.46405483465386216\n",
      "Epoch 4256, reconstruction losses: 0.014776312088923972, regression losses: 0.1304067360875962, validation losses: 0.5011317490358052\n",
      "Epoch 4257, reconstruction losses: 0.012532674645599545, regression losses: 0.0963169626041224, validation losses: 0.5064605108547007\n",
      "Epoch 4258, reconstruction losses: 0.013973797392270945, regression losses: 0.1423015988888116, validation losses: 0.4598401282535518\n",
      "Epoch 4259, reconstruction losses: 0.012840038049769839, regression losses: 0.1340406432880302, validation losses: 0.4085138336128832\n",
      "Epoch 4260, reconstruction losses: 0.014809300745998333, regression losses: 0.15744632927991203, validation losses: 0.4445446697245463\n",
      "Epoch 4261, reconstruction losses: 0.011590059116174046, regression losses: 0.16547699103815755, validation losses: 0.4091419088648121\n",
      "Epoch 4262, reconstruction losses: 0.015292935278988638, regression losses: 0.13878647524986287, validation losses: 0.44090603657272787\n",
      "Epoch 4263, reconstruction losses: 0.01195645368184031, regression losses: 0.12474016056986233, validation losses: 0.45764426064999\n",
      "Epoch 4264, reconstruction losses: 0.015000081146014787, regression losses: 0.10890819385245092, validation losses: 0.37658241683243376\n",
      "Epoch 4265, reconstruction losses: 0.011594311983541253, regression losses: 0.08779061313902761, validation losses: 0.3961715326918689\n",
      "Epoch 4266, reconstruction losses: 0.011280449686451916, regression losses: 0.10137026795992747, validation losses: 0.34867455184721363\n",
      "Epoch 4267, reconstruction losses: 0.017644774881819626, regression losses: 0.1262495690676329, validation losses: 0.3297831694617187\n",
      "Epoch 4268, reconstruction losses: 0.012953144630026604, regression losses: 0.12435992561059658, validation losses: 0.35369737645582894\n",
      "Epoch 4269, reconstruction losses: 0.01242998652681417, regression losses: 0.09885073492735146, validation losses: 0.370664810121117\n",
      "Epoch 4270, reconstruction losses: 0.015104441565103315, regression losses: 0.1192692002857352, validation losses: 0.3672742833885375\n",
      "Epoch 4271, reconstruction losses: 0.011771311744298425, regression losses: 0.12222701934528153, validation losses: 0.398787492757707\n",
      "Epoch 4272, reconstruction losses: 0.02074218399288063, regression losses: 0.12349317351301783, validation losses: 0.3845399033181256\n",
      "Epoch 4273, reconstruction losses: 0.011901755765010172, regression losses: 0.08537725340736807, validation losses: 0.3434368458965731\n",
      "Epoch 4274, reconstruction losses: 0.01258696367254066, regression losses: 0.09582359901682352, validation losses: 0.36242991203405495\n",
      "Epoch 4275, reconstruction losses: 0.014248457956058194, regression losses: 0.1221760835449534, validation losses: 0.36788337181104763\n",
      "Epoch 4276, reconstruction losses: 0.012718429341639075, regression losses: 0.14737997776288358, validation losses: 0.3656935500546437\n",
      "Epoch 4277, reconstruction losses: 0.01068827366547378, regression losses: 0.08494165704870422, validation losses: 0.3787754317798731\n",
      "Epoch 4278, reconstruction losses: 0.011148327265315184, regression losses: 0.10456035372718152, validation losses: 0.3477276861239702\n",
      "Epoch 4279, reconstruction losses: 0.014308322622377818, regression losses: 0.13700549562246603, validation losses: 0.34893210760324966\n",
      "Epoch 4280, reconstruction losses: 0.011546666695144545, regression losses: 0.08699195627577998, validation losses: 0.3357866017353275\n",
      "Epoch 4281, reconstruction losses: 0.01085762820916892, regression losses: 0.09241202281756312, validation losses: 0.31623777595743047\n",
      "Epoch 4282, reconstruction losses: 0.012543134587011005, regression losses: 0.09080511323339675, validation losses: 0.30501282093984566\n",
      "Epoch 4283, reconstruction losses: 0.011711191585068337, regression losses: 0.09490562031451594, validation losses: 0.32195646946619705\n",
      "Epoch 4284, reconstruction losses: 0.011835820916983838, regression losses: 0.09959933599289075, validation losses: 0.29879289407362064\n",
      "Epoch 4285, reconstruction losses: 0.010848309539150863, regression losses: 0.09023667519012256, validation losses: 0.3011285806641386\n",
      "Epoch 4286, reconstruction losses: 0.009248109220091996, regression losses: 0.07157062205483321, validation losses: 0.3284288396872028\n",
      "Epoch 4287, reconstruction losses: 0.01107291924909972, regression losses: 0.10660884943290681, validation losses: 0.3151483595786318\n",
      "Epoch 4288, reconstruction losses: 0.01256810400206774, regression losses: 0.1083751903480778, validation losses: 0.3349646187934689\n",
      "Epoch 4289, reconstruction losses: 0.010681116606399612, regression losses: 0.08854162148329348, validation losses: 0.32553337179614344\n",
      "Epoch 4290, reconstruction losses: 0.013193085245695922, regression losses: 0.10826619662099457, validation losses: 0.30434631964945263\n",
      "Epoch 4291, reconstruction losses: 0.011886918985098433, regression losses: 0.06945953083856041, validation losses: 0.34246525652381143\n",
      "Epoch 4292, reconstruction losses: 0.012697975429479145, regression losses: 0.14372316304383337, validation losses: 0.3235574043826839\n",
      "Epoch 4293, reconstruction losses: 0.017022779756280956, regression losses: 0.1188564418274084, validation losses: 0.30438098652248347\n",
      "Epoch 4294, reconstruction losses: 0.012249705438310637, regression losses: 0.08049765427304638, validation losses: 0.3011973135656115\n",
      "Epoch 4295, reconstruction losses: 0.012714969480991729, regression losses: 0.11106885325338807, validation losses: 0.298757694982307\n",
      "Epoch 4296, reconstruction losses: 0.012018833691018367, regression losses: 0.10666128177326518, validation losses: 0.30086919130159084\n",
      "Epoch 4297, reconstruction losses: 0.0113794978778057, regression losses: 0.17484286147090772, validation losses: 0.298127542684014\n",
      "Epoch 4298, reconstruction losses: 0.014142890493734945, regression losses: 0.30750832943807493, validation losses: 0.35838800115993535\n",
      "Epoch 4299, reconstruction losses: 0.011358518784463008, regression losses: 0.08312069836351567, validation losses: 0.44349163359031585\n",
      "Epoch 4300, reconstruction losses: 0.02839659787356908, regression losses: 0.3255311908801713, validation losses: 0.5332316212752791\n",
      "Epoch 4301, reconstruction losses: 0.013451296987688093, regression losses: 0.10653274290820916, validation losses: 0.5224178434537301\n",
      "Epoch 4302, reconstruction losses: 0.012895089958618124, regression losses: 0.10717196028252933, validation losses: 0.49073958881344165\n",
      "Epoch 4303, reconstruction losses: 0.012470742168364166, regression losses: 0.101941237848184, validation losses: 0.4637564499034193\n",
      "Epoch 4304, reconstruction losses: 0.012707472410744117, regression losses: 0.12683894138325943, validation losses: 0.4292849755793185\n",
      "Epoch 4305, reconstruction losses: 0.01125776164177821, regression losses: 0.09217812383303062, validation losses: 0.3769589909509531\n",
      "Epoch 4306, reconstruction losses: 0.0111565032085064, regression losses: 0.10413877654345799, validation losses: 0.3207296581191606\n",
      "Epoch 4307, reconstruction losses: 0.01214011450561114, regression losses: 0.09643746393615356, validation losses: 0.30660936399309546\n",
      "Epoch 4308, reconstruction losses: 0.015431192676668714, regression losses: 0.15102553595990084, validation losses: 0.32290286634837406\n",
      "Epoch 4309, reconstruction losses: 0.014118071949314945, regression losses: 0.1358971644480637, validation losses: 0.325966987845346\n",
      "Epoch 4310, reconstruction losses: 0.013015288833998297, regression losses: 0.10475709616370732, validation losses: 0.31623719692937124\n",
      "Epoch 4311, reconstruction losses: 0.010976922101391921, regression losses: 0.11511461042894308, validation losses: 0.3432857789640363\n",
      "Epoch 4312, reconstruction losses: 0.014049980744465658, regression losses: 0.10025501424879633, validation losses: 0.3131978133859771\n",
      "Epoch 4313, reconstruction losses: 0.011522405162907721, regression losses: 0.08211062683068567, validation losses: 0.32547926096697666\n",
      "Epoch 4314, reconstruction losses: 0.013677082990706592, regression losses: 0.08922537246038799, validation losses: 0.3043639267825273\n",
      "Epoch 4315, reconstruction losses: 0.012318829104847358, regression losses: 0.09709889964690496, validation losses: 0.301138367804506\n",
      "Epoch 4316, reconstruction losses: 0.011056380848191735, regression losses: 0.08343725287237333, validation losses: 0.3101772473232798\n",
      "Epoch 4317, reconstruction losses: 0.01272460321511279, regression losses: 0.10654711478654562, validation losses: 0.31241361478447033\n",
      "Epoch 4318, reconstruction losses: 0.013691815040268838, regression losses: 0.1233514078758301, validation losses: 0.3200880470726527\n",
      "Epoch 4319, reconstruction losses: 0.01256629151193415, regression losses: 0.06847663947176438, validation losses: 0.30902032868748414\n",
      "Epoch 4320, reconstruction losses: 0.012448088348121167, regression losses: 0.116366124771039, validation losses: 0.31646158974710753\n",
      "Epoch 4321, reconstruction losses: 0.011523973544132598, regression losses: 0.11610331023099554, validation losses: 0.32138381219113\n",
      "Epoch 4322, reconstruction losses: 0.015238487942379895, regression losses: 0.09947301435452303, validation losses: 0.3103111252193728\n",
      "Epoch 4323, reconstruction losses: 0.010268970200382893, regression losses: 0.0960194680895914, validation losses: 0.31494684081918634\n",
      "Epoch 4324, reconstruction losses: 0.010545802630787889, regression losses: 0.09436568020654379, validation losses: 0.30394759656747583\n",
      "Epoch 4325, reconstruction losses: 0.013054168388383492, regression losses: 0.09638653767970644, validation losses: 0.2905071984847906\n",
      "Epoch 4326, reconstruction losses: 0.012629765351172845, regression losses: 0.08887252166979943, validation losses: 0.28036252280005447\n",
      "Epoch 4327, reconstruction losses: 0.011623925106290482, regression losses: 0.08848193424113823, validation losses: 0.27979623562607453\n",
      "Epoch 4328, reconstruction losses: 0.01245830138621258, regression losses: 0.09979608585412848, validation losses: 0.2876588290845694\n",
      "Epoch 4329, reconstruction losses: 0.014996148038401914, regression losses: 0.10178729066605535, validation losses: 0.2832086465815914\n",
      "Epoch 4330, reconstruction losses: 0.013019399953315532, regression losses: 0.09074678839958383, validation losses: 0.2708533987356031\n",
      "Epoch 4331, reconstruction losses: 0.012886997750878206, regression losses: 0.07316879482085907, validation losses: 0.2729482214825065\n",
      "Epoch 4332, reconstruction losses: 0.009869099899227424, regression losses: 0.09858548378255137, validation losses: 0.2768248212864523\n",
      "Epoch 4333, reconstruction losses: 0.014151377428906353, regression losses: 0.12451129739662423, validation losses: 0.29035868368920087\n",
      "Epoch 4334, reconstruction losses: 0.0133298398976231, regression losses: 0.16326047944252908, validation losses: 0.31801145755795207\n",
      "Epoch 4335, reconstruction losses: 0.010787694390189725, regression losses: 0.07538011072558069, validation losses: 0.5169090248302317\n",
      "Epoch 4336, reconstruction losses: 0.014945107467086188, regression losses: 0.1771882933627299, validation losses: 0.5416969775259094\n",
      "Epoch 4337, reconstruction losses: 0.0136236929990005, regression losses: 0.1002954270907582, validation losses: 0.503886222386847\n",
      "Epoch 4338, reconstruction losses: 0.013616054147807423, regression losses: 0.12861902829374888, validation losses: 0.5370541379698367\n",
      "Epoch 4339, reconstruction losses: 0.013007518489853771, regression losses: 0.1321285636861554, validation losses: 0.5053556271356211\n",
      "Epoch 4340, reconstruction losses: 0.011332313758927385, regression losses: 0.11775072824481145, validation losses: 0.41709068330584737\n",
      "Epoch 4341, reconstruction losses: 0.010507455863408377, regression losses: 0.07704777582799373, validation losses: 0.3398971119444958\n",
      "Epoch 4342, reconstruction losses: 0.010610029034610896, regression losses: 0.08806802231735217, validation losses: 0.35169391988409365\n",
      "Epoch 4343, reconstruction losses: 0.0138142349506237, regression losses: 0.09309395862998261, validation losses: 0.3392949664767498\n",
      "Epoch 4344, reconstruction losses: 0.013253242442240305, regression losses: 0.07936230069417563, validation losses: 0.329979544565902\n",
      "Epoch 4345, reconstruction losses: 0.011379078701263578, regression losses: 0.09669162881971288, validation losses: 0.34361598205733457\n",
      "Epoch 4346, reconstruction losses: 0.012917222527701376, regression losses: 0.10353420379647862, validation losses: 0.3334285890673109\n",
      "Epoch 4347, reconstruction losses: 0.011339567308601537, regression losses: 0.09885603140295814, validation losses: 0.3461073735014305\n",
      "Epoch 4348, reconstruction losses: 0.012079271756878401, regression losses: 0.09110027264484433, validation losses: 0.3290612085673436\n",
      "Epoch 4349, reconstruction losses: 0.01358731655426633, regression losses: 0.15152897727954634, validation losses: 0.3145208807892245\n",
      "Epoch 4350, reconstruction losses: 0.011468992010887476, regression losses: 0.09529859388770194, validation losses: 0.33431576054153106\n",
      "Epoch 4351, reconstruction losses: 0.012965218408141304, regression losses: 0.10726906743975957, validation losses: 0.32901452876152126\n",
      "Epoch 4352, reconstruction losses: 0.011083418560033876, regression losses: 0.07349177991057158, validation losses: 0.34040571485978777\n",
      "Epoch 4353, reconstruction losses: 0.012290677465326107, regression losses: 0.10642386215543219, validation losses: 0.34644286985367334\n",
      "Epoch 4354, reconstruction losses: 0.014385996808682426, regression losses: 0.08767363678464957, validation losses: 0.3300271239389876\n",
      "Epoch 4355, reconstruction losses: 0.01079969810027203, regression losses: 0.09700190120819624, validation losses: 0.31642500658895256\n",
      "Epoch 4356, reconstruction losses: 0.015862836477241328, regression losses: 0.18292179384320778, validation losses: 0.3022488696342182\n",
      "Epoch 4357, reconstruction losses: 0.012892903496389541, regression losses: 0.17924613752382035, validation losses: 0.4397315611374422\n",
      "Epoch 4358, reconstruction losses: 0.01701220952839531, regression losses: 0.15957543660485554, validation losses: 0.3804704539019583\n",
      "Epoch 4359, reconstruction losses: 0.011543563156516026, regression losses: 0.08084395842393784, validation losses: 0.3594893146664344\n",
      "Epoch 4360, reconstruction losses: 0.01318979296380021, regression losses: 0.11737748634881853, validation losses: 0.4094867200268696\n",
      "Epoch 4361, reconstruction losses: 0.012587059348686173, regression losses: 0.09789190026924806, validation losses: 0.34490816176093786\n",
      "Epoch 4362, reconstruction losses: 0.010692102341441821, regression losses: 0.06964607819909241, validation losses: 0.32959942631493755\n",
      "Epoch 4363, reconstruction losses: 0.01588960750571971, regression losses: 0.1298587589757033, validation losses: 0.326299884073197\n",
      "Epoch 4364, reconstruction losses: 0.014095826231495563, regression losses: 0.16255946298920657, validation losses: 0.3138427475650717\n",
      "Epoch 4365, reconstruction losses: 0.009583798548187627, regression losses: 0.077568286711691, validation losses: 0.34830215624655814\n",
      "Epoch 4366, reconstruction losses: 0.01161539746124409, regression losses: 0.09806529117893321, validation losses: 0.3069192099920555\n",
      "Epoch 4367, reconstruction losses: 0.010996178739700997, regression losses: 0.12398638941460133, validation losses: 0.29853184847570574\n",
      "Epoch 4368, reconstruction losses: 0.011558865408300797, regression losses: 0.0990300721731832, validation losses: 0.32524579984143653\n",
      "Epoch 4369, reconstruction losses: 0.012605991604088169, regression losses: 0.08393678352807696, validation losses: 0.29561859855125683\n",
      "Epoch 4370, reconstruction losses: 0.011799160367958823, regression losses: 0.08206715288674662, validation losses: 0.28504360004837925\n",
      "Epoch 4371, reconstruction losses: 0.011777694612809914, regression losses: 0.09321621166995389, validation losses: 0.2852700222203054\n",
      "Epoch 4372, reconstruction losses: 0.01118372379648214, regression losses: 0.16175447878419813, validation losses: 0.2749971463276196\n",
      "Epoch 4373, reconstruction losses: 0.015280086160406003, regression losses: 0.10872187894517266, validation losses: 0.3078307432996532\n",
      "Epoch 4374, reconstruction losses: 0.014973293633361447, regression losses: 0.15917687740313685, validation losses: 0.28829658814427966\n",
      "Epoch 4375, reconstruction losses: 0.013077817700641937, regression losses: 0.10949712929589332, validation losses: 0.32761537473101177\n",
      "Epoch 4376, reconstruction losses: 0.017469193450556496, regression losses: 0.16736938211536287, validation losses: 0.33677088905500263\n",
      "Epoch 4377, reconstruction losses: 0.01233934281214838, regression losses: 0.08996912014122704, validation losses: 0.324834679552205\n",
      "Epoch 4378, reconstruction losses: 0.012194106214049791, regression losses: 0.08718327226539511, validation losses: 0.34290704327276417\n",
      "Epoch 4379, reconstruction losses: 0.011378485225984412, regression losses: 0.10694992403632428, validation losses: 0.3164717030910206\n",
      "Epoch 4380, reconstruction losses: 0.015825724263209218, regression losses: 0.09524538400699246, validation losses: 0.2907043927891604\n",
      "Epoch 4381, reconstruction losses: 0.010806836798351824, regression losses: 0.07504140457508937, validation losses: 0.2793580278609498\n",
      "Epoch 4382, reconstruction losses: 0.011933169102051696, regression losses: 0.10135982910517168, validation losses: 0.2869292596447121\n",
      "Epoch 4383, reconstruction losses: 0.010575778051709898, regression losses: 0.054326342601237726, validation losses: 0.296738303740049\n",
      "Epoch 4384, reconstruction losses: 0.013013757053118552, regression losses: 0.10971994891696807, validation losses: 0.28649554229387797\n",
      "Epoch 4385, reconstruction losses: 0.013998200325125956, regression losses: 0.10715331285281504, validation losses: 0.29620296310012256\n",
      "Epoch 4386, reconstruction losses: 0.009875141843042837, regression losses: 0.07993680597127081, validation losses: 0.28783588069106847\n",
      "Epoch 4387, reconstruction losses: 0.012896276463833553, regression losses: 0.08446483807844782, validation losses: 0.28526920429057584\n",
      "Epoch 4388, reconstruction losses: 0.009696361563137629, regression losses: 0.0691401650091085, validation losses: 0.3175658986002603\n",
      "Epoch 4389, reconstruction losses: 0.015302578594336008, regression losses: 0.12430224225163389, validation losses: 0.3344231095506381\n",
      "Epoch 4390, reconstruction losses: 0.01134815350545877, regression losses: 0.10964424747129606, validation losses: 0.3604065587099606\n",
      "Epoch 4391, reconstruction losses: 0.01034385818957839, regression losses: 0.09831695056164819, validation losses: 0.33192554117108797\n",
      "Epoch 4392, reconstruction losses: 0.010464386240724563, regression losses: 0.09507281130127537, validation losses: 0.3222025938308474\n",
      "Epoch 4393, reconstruction losses: 0.011938674969742867, regression losses: 0.09833860589769712, validation losses: 0.311853586751337\n",
      "Epoch 4394, reconstruction losses: 0.01117209249319755, regression losses: 0.09444545146049585, validation losses: 0.29067343671688645\n",
      "Epoch 4395, reconstruction losses: 0.012843522070647975, regression losses: 0.14025120412050432, validation losses: 0.28861621977056795\n",
      "Epoch 4396, reconstruction losses: 0.013235066051905258, regression losses: 0.09599524442154625, validation losses: 0.3039945557418383\n",
      "Epoch 4397, reconstruction losses: 0.011628106035406153, regression losses: 0.09648355444082263, validation losses: 0.27802707325027226\n",
      "Epoch 4398, reconstruction losses: 0.011436967962215105, regression losses: 0.08589426375066467, validation losses: 0.2841512045392374\n",
      "Epoch 4399, reconstruction losses: 0.012952424618707294, regression losses: 0.10462691970799365, validation losses: 0.2952352395392425\n",
      "Epoch 4400, reconstruction losses: 0.01221307893151623, regression losses: 0.09860519956789128, validation losses: 0.29399085379175777\n",
      "Epoch 4401, reconstruction losses: 0.011612932339324759, regression losses: 0.10629903117436706, validation losses: 0.28442961113154763\n",
      "Epoch 4402, reconstruction losses: 0.012218475651463832, regression losses: 0.1112443489367543, validation losses: 0.28554731807050315\n",
      "Epoch 4403, reconstruction losses: 0.009213133426714244, regression losses: 0.06816357734379987, validation losses: 0.33113075227329025\n",
      "Epoch 4404, reconstruction losses: 0.012670525890712648, regression losses: 0.10954902025910437, validation losses: 0.39186006864323564\n",
      "Epoch 4405, reconstruction losses: 0.012718984246076134, regression losses: 0.1095001916811069, validation losses: 0.4167887324650953\n",
      "Epoch 4406, reconstruction losses: 0.014484532890509022, regression losses: 0.1039904318704531, validation losses: 0.37132008499777475\n",
      "Epoch 4407, reconstruction losses: 0.01161520437108163, regression losses: 0.09811529381042025, validation losses: 0.323410886711016\n",
      "Epoch 4408, reconstruction losses: 0.012617092290687384, regression losses: 0.12218663947843472, validation losses: 0.2781939608463642\n",
      "Epoch 4409, reconstruction losses: 0.011363778887158189, regression losses: 0.09408353171346608, validation losses: 0.27200174465765237\n",
      "Epoch 4410, reconstruction losses: 0.011218487791788433, regression losses: 0.11101387903089664, validation losses: 0.3116911979786467\n",
      "Epoch 4411, reconstruction losses: 0.010500241001442529, regression losses: 0.10517798943135981, validation losses: 0.30427504074242034\n",
      "Epoch 4412, reconstruction losses: 0.011711336661979556, regression losses: 0.08086467176877393, validation losses: 0.31342548859933783\n",
      "Epoch 4413, reconstruction losses: 0.012108067447972007, regression losses: 0.09242827514563788, validation losses: 0.3179114192824927\n",
      "Epoch 4414, reconstruction losses: 0.012114584119972634, regression losses: 0.12033008513715357, validation losses: 0.29109384437835534\n",
      "Epoch 4415, reconstruction losses: 0.01176224252011697, regression losses: 0.08663741920605815, validation losses: 0.2906406994964577\n",
      "Epoch 4416, reconstruction losses: 0.012556594935839554, regression losses: 0.09525407800341523, validation losses: 0.3284256692930348\n",
      "Epoch 4417, reconstruction losses: 0.00979041368355992, regression losses: 0.10175164884136526, validation losses: 0.3253547825738418\n",
      "Epoch 4418, reconstruction losses: 0.01346693053686378, regression losses: 0.08423098821804623, validation losses: 0.3062478373983949\n",
      "Epoch 4419, reconstruction losses: 0.013268254548515816, regression losses: 0.10242453530523335, validation losses: 0.30862180271967693\n",
      "Epoch 4420, reconstruction losses: 0.012219032637874244, regression losses: 0.09870123672455478, validation losses: 0.3055693789454223\n",
      "Epoch 4421, reconstruction losses: 0.0138924740856578, regression losses: 0.08514278038903444, validation losses: 0.29679063213946866\n",
      "Epoch 4422, reconstruction losses: 0.011554611331135117, regression losses: 0.0801510936353558, validation losses: 0.31201491746573645\n",
      "Epoch 4423, reconstruction losses: 0.013244082478956785, regression losses: 0.10375269962956002, validation losses: 0.2906277167393484\n",
      "Epoch 4424, reconstruction losses: 0.012961415379331018, regression losses: 0.10838245872839958, validation losses: 0.2840625346354007\n",
      "Epoch 4425, reconstruction losses: 0.011030715690481079, regression losses: 0.0927936405949197, validation losses: 0.28344254052258583\n",
      "Epoch 4426, reconstruction losses: 0.012791077965084484, regression losses: 0.13432706671076405, validation losses: 0.28537376872358566\n",
      "Epoch 4427, reconstruction losses: 0.010921594431415415, regression losses: 0.10633584659076571, validation losses: 0.2986425597800358\n",
      "Epoch 4428, reconstruction losses: 0.01297806464212386, regression losses: 0.1607102641918932, validation losses: 0.3185992256903211\n",
      "Epoch 4429, reconstruction losses: 0.010200472436966484, regression losses: 0.17464077480144552, validation losses: 0.35149569708522665\n",
      "Epoch 4430, reconstruction losses: 0.010372374070662256, regression losses: 0.12152043775055449, validation losses: 0.32018763560957236\n",
      "Epoch 4431, reconstruction losses: 0.010646023526452046, regression losses: 0.08250650233687162, validation losses: 0.34037427490281813\n",
      "Epoch 4432, reconstruction losses: 0.012099269716044967, regression losses: 0.1374590236533709, validation losses: 0.3332360786370078\n",
      "Epoch 4433, reconstruction losses: 0.010437915866234236, regression losses: 0.0761893023378484, validation losses: 0.3125131073523542\n",
      "Epoch 4434, reconstruction losses: 0.011664966066752455, regression losses: 0.1226506315993065, validation losses: 0.30381095180746587\n",
      "Epoch 4435, reconstruction losses: 0.011634045622943897, regression losses: 0.11420835862076875, validation losses: 0.34905843748488513\n",
      "Epoch 4436, reconstruction losses: 0.010753731234715395, regression losses: 0.09089954139817699, validation losses: 0.3996270233860424\n",
      "Epoch 4437, reconstruction losses: 0.01121923914527614, regression losses: 0.09155141105200446, validation losses: 0.35350143354789315\n",
      "Epoch 4438, reconstruction losses: 0.012897969779315614, regression losses: 0.08045691974500133, validation losses: 0.3153617111184966\n",
      "Epoch 4439, reconstruction losses: 0.011775506171555062, regression losses: 0.10952038687526253, validation losses: 0.3068437827106674\n",
      "Epoch 4440, reconstruction losses: 0.014806339896606638, regression losses: 0.10178682271216694, validation losses: 0.315691007862952\n",
      "Epoch 4441, reconstruction losses: 0.01357017964040216, regression losses: 0.09876157803312455, validation losses: 0.36862152221111716\n",
      "Epoch 4442, reconstruction losses: 0.009511596969368465, regression losses: 0.08667514753377877, validation losses: 0.31818106814336944\n",
      "Epoch 4443, reconstruction losses: 0.010349831204024416, regression losses: 0.10056084274383026, validation losses: 0.27978965433684994\n",
      "Epoch 4444, reconstruction losses: 0.012700335665725464, regression losses: 0.0925680358549562, validation losses: 0.27268224753943404\n",
      "Epoch 4445, reconstruction losses: 0.009526988210558715, regression losses: 0.06132933694679696, validation losses: 0.27003683968334397\n",
      "Epoch 4446, reconstruction losses: 0.017114828059823867, regression losses: 0.25116539336140115, validation losses: 0.26719117735325204\n",
      "Epoch 4447, reconstruction losses: 0.014692996777758352, regression losses: 0.08668117549668261, validation losses: 0.30119239588728414\n",
      "Epoch 4448, reconstruction losses: 0.012378326060234202, regression losses: 0.09404871854541753, validation losses: 0.3238660673243418\n",
      "Epoch 4449, reconstruction losses: 0.012987257973054164, regression losses: 0.10153087994654247, validation losses: 0.3104235735395718\n",
      "Epoch 4450, reconstruction losses: 0.014447838469673655, regression losses: 0.094248564889285, validation losses: 0.2984035084035386\n",
      "Epoch 4451, reconstruction losses: 0.011886883341438408, regression losses: 0.0807073771707754, validation losses: 0.2858124649176884\n",
      "Epoch 4452, reconstruction losses: 0.010309164343532752, regression losses: 0.10659873828417651, validation losses: 0.30737245352227976\n",
      "Epoch 4453, reconstruction losses: 0.013723395189935109, regression losses: 0.14791526291976842, validation losses: 0.32921089940726567\n",
      "Epoch 4454, reconstruction losses: 0.020662573603935117, regression losses: 0.3050279654236626, validation losses: 0.3460002221672187\n",
      "Epoch 4455, reconstruction losses: 0.010756334210882427, regression losses: 0.0944033828201716, validation losses: 0.36013028284888615\n",
      "Epoch 4456, reconstruction losses: 0.0138922359013977, regression losses: 0.16784131802003116, validation losses: 0.3436736336407359\n",
      "Epoch 4457, reconstruction losses: 0.013290835576406541, regression losses: 0.09473485962451875, validation losses: 0.3634835354592909\n",
      "Epoch 4458, reconstruction losses: 0.010148019609355415, regression losses: 0.0785828127890743, validation losses: 0.3900420481795195\n",
      "Epoch 4459, reconstruction losses: 0.013722563921939938, regression losses: 0.08734642499272464, validation losses: 0.3755015774096222\n",
      "Epoch 4460, reconstruction losses: 0.012381204865527103, regression losses: 0.11123771666281097, validation losses: 0.3539344245511177\n",
      "Epoch 4461, reconstruction losses: 0.012607489054284313, regression losses: 0.0931786417234382, validation losses: 0.32612310466869526\n",
      "Epoch 4462, reconstruction losses: 0.010622965074455894, regression losses: 0.06762390883121272, validation losses: 0.305905489393015\n",
      "Epoch 4463, reconstruction losses: 0.012730944313120898, regression losses: 0.08683387601384744, validation losses: 0.3005388087718342\n",
      "Epoch 4464, reconstruction losses: 0.009666115198962065, regression losses: 0.07908850778292993, validation losses: 0.29381654902349574\n",
      "Epoch 4465, reconstruction losses: 0.011703157694188617, regression losses: 0.0943484462329917, validation losses: 0.29074985507807216\n",
      "Epoch 4466, reconstruction losses: 0.010276394084843614, regression losses: 0.06798522888866654, validation losses: 0.29792135366294414\n",
      "Epoch 4467, reconstruction losses: 0.011928361226535605, regression losses: 0.08700575293477536, validation losses: 0.293540138921939\n",
      "Epoch 4468, reconstruction losses: 0.011488229825600512, regression losses: 0.06896552805141717, validation losses: 0.3125116645814943\n",
      "Epoch 4469, reconstruction losses: 0.02331478672024941, regression losses: 0.2775807419722424, validation losses: 0.2977231821443538\n",
      "Epoch 4470, reconstruction losses: 0.012165695671812166, regression losses: 0.07126948284511794, validation losses: 0.4791125397177266\n",
      "Epoch 4471, reconstruction losses: 0.012122442482438555, regression losses: 0.12254477488676101, validation losses: 0.4420342576826217\n",
      "Epoch 4472, reconstruction losses: 0.016676489161059266, regression losses: 0.11519991693715331, validation losses: 0.3340853146984425\n",
      "Epoch 4473, reconstruction losses: 0.018135167495255497, regression losses: 0.1587509069818624, validation losses: 0.30569067032588865\n",
      "Epoch 4474, reconstruction losses: 0.012138091570800353, regression losses: 0.08260788243018628, validation losses: 0.30874236463728594\n",
      "Epoch 4475, reconstruction losses: 0.011432340183976463, regression losses: 0.09217267816338527, validation losses: 0.32534967884550064\n",
      "Epoch 4476, reconstruction losses: 0.010834876494079049, regression losses: 0.09349258294979715, validation losses: 0.3250382313573073\n",
      "Epoch 4477, reconstruction losses: 0.013048400967081568, regression losses: 0.10715876483156513, validation losses: 0.36299297719237716\n",
      "Epoch 4478, reconstruction losses: 0.013194387257455606, regression losses: 0.1547464367020679, validation losses: 0.3525520922976331\n",
      "Epoch 4479, reconstruction losses: 0.0121663471571363, regression losses: 0.11947690860524644, validation losses: 0.3313572759210084\n",
      "Epoch 4480, reconstruction losses: 0.012673126719010165, regression losses: 0.1193902449968105, validation losses: 0.3280471999513746\n",
      "Epoch 4481, reconstruction losses: 0.010967625378630292, regression losses: 0.08474786280779294, validation losses: 0.2989004622759612\n",
      "Epoch 4482, reconstruction losses: 0.01111077209874619, regression losses: 0.07661341754816799, validation losses: 0.29537328302072036\n",
      "Epoch 4483, reconstruction losses: 0.010958372117329552, regression losses: 0.1367065470879229, validation losses: 0.3348511900326745\n",
      "Epoch 4484, reconstruction losses: 0.016800313629661123, regression losses: 0.10390951094833807, validation losses: 0.3627737871089033\n",
      "Epoch 4485, reconstruction losses: 0.011032774928448752, regression losses: 0.11188913824254909, validation losses: 0.3344076716258794\n",
      "Epoch 4486, reconstruction losses: 0.014200803477109458, regression losses: 0.17212162444591797, validation losses: 0.301477383476245\n",
      "Epoch 4487, reconstruction losses: 0.015147047232755407, regression losses: 0.1037965032978532, validation losses: 0.3122837969397053\n",
      "Epoch 4488, reconstruction losses: 0.010264364469102604, regression losses: 0.09298714019622163, validation losses: 0.29994503771708186\n",
      "Epoch 4489, reconstruction losses: 0.01180451481177595, regression losses: 0.10104373547413859, validation losses: 0.3036608915411506\n",
      "Epoch 4490, reconstruction losses: 0.01574180749677101, regression losses: 0.21975370230421934, validation losses: 0.3193421920641361\n",
      "Epoch 4491, reconstruction losses: 0.013998635612623116, regression losses: 0.10605881733206787, validation losses: 0.4983570029745426\n",
      "Epoch 4492, reconstruction losses: 0.011828979911039551, regression losses: 0.1512025268589407, validation losses: 0.4371140910366142\n",
      "Epoch 4493, reconstruction losses: 0.01201287602243778, regression losses: 0.10490111158131715, validation losses: 0.3323086129581164\n",
      "Epoch 4494, reconstruction losses: 0.010751334340605823, regression losses: 0.13184343534976486, validation losses: 0.3124951957586602\n",
      "Epoch 4495, reconstruction losses: 0.012890976313712419, regression losses: 0.15023507116581702, validation losses: 0.29501464035233516\n",
      "Epoch 4496, reconstruction losses: 0.013005440615244748, regression losses: 0.09131175096157626, validation losses: 0.29603844288021125\n",
      "Epoch 4497, reconstruction losses: 0.011051339742668387, regression losses: 0.09451147868784424, validation losses: 0.29816997408815615\n",
      "Epoch 4498, reconstruction losses: 0.01200445168219905, regression losses: 0.12444836950170735, validation losses: 0.32639440154899807\n",
      "Epoch 4499, reconstruction losses: 0.010680931016070361, regression losses: 0.07700179851273747, validation losses: 0.3262204869860094\n",
      "Epoch 4500, reconstruction losses: 0.01262529442501263, regression losses: 0.10312632150747642, validation losses: 0.3409563525944393\n",
      "Epoch 4501, reconstruction losses: 0.010152936865852395, regression losses: 0.13349776809085184, validation losses: 0.3337128821019112\n",
      "Epoch 4502, reconstruction losses: 0.01107033082258193, regression losses: 0.11310789036572598, validation losses: 0.32711709292914787\n",
      "Epoch 4503, reconstruction losses: 0.01049809298304758, regression losses: 0.08927024903106534, validation losses: 0.3108384097140541\n",
      "Epoch 4504, reconstruction losses: 0.011301227023593572, regression losses: 0.0834600153397007, validation losses: 0.2867738412966952\n",
      "Epoch 4505, reconstruction losses: 0.015622893260246334, regression losses: 0.12980915064616882, validation losses: 0.28192796212944593\n",
      "Epoch 4506, reconstruction losses: 0.012834991496550282, regression losses: 0.10224376427089274, validation losses: 0.33783146501866396\n",
      "Epoch 4507, reconstruction losses: 0.011325684465808816, regression losses: 0.0882046957433717, validation losses: 0.36327029014715956\n",
      "Epoch 4508, reconstruction losses: 0.013988678076341438, regression losses: 0.1059897444577934, validation losses: 0.31498819896455144\n",
      "Epoch 4509, reconstruction losses: 0.01033942218654107, regression losses: 0.12204103287423795, validation losses: 0.2909782200402872\n",
      "Epoch 4510, reconstruction losses: 0.011021335800352626, regression losses: 0.10557549897292612, validation losses: 0.3162328727088435\n",
      "Epoch 4511, reconstruction losses: 0.011818280035493673, regression losses: 0.08605352715969126, validation losses: 0.35205052400379666\n",
      "Epoch 4512, reconstruction losses: 0.01317751535318416, regression losses: 0.13803671226850772, validation losses: 0.3573635772848064\n",
      "Epoch 4513, reconstruction losses: 0.012158699831744788, regression losses: 0.11765034674072451, validation losses: 0.3632632538917713\n",
      "Epoch 4514, reconstruction losses: 0.010981802109791576, regression losses: 0.10061816984044565, validation losses: 0.3461260511114948\n",
      "Epoch 4515, reconstruction losses: 0.010076559371433098, regression losses: 0.07689566334256323, validation losses: 0.30608659247878894\n",
      "Epoch 4516, reconstruction losses: 0.015561016703994414, regression losses: 0.09371213127197928, validation losses: 0.32872092877575\n",
      "Epoch 4517, reconstruction losses: 0.01100861495565089, regression losses: 0.16074077879566687, validation losses: 0.34162540266095504\n",
      "Epoch 4518, reconstruction losses: 0.010602950981486692, regression losses: 0.08559889625512883, validation losses: 0.3069494404402873\n",
      "Epoch 4519, reconstruction losses: 0.011566212705292383, regression losses: 0.07279273279966962, validation losses: 0.3064182111700948\n",
      "Epoch 4520, reconstruction losses: 0.010267980426314634, regression losses: 0.11650357797739497, validation losses: 0.3079419657737801\n",
      "Epoch 4521, reconstruction losses: 0.012269260731910668, regression losses: 0.09430772480992385, validation losses: 0.30740559908816945\n",
      "Epoch 4522, reconstruction losses: 0.01287775556512262, regression losses: 0.10461954994215039, validation losses: 0.3338693433507528\n",
      "Epoch 4523, reconstruction losses: 0.012009948448000768, regression losses: 0.13669952939953836, validation losses: 0.3188826752299218\n",
      "Epoch 4524, reconstruction losses: 0.011300251473841269, regression losses: 0.10686595160555537, validation losses: 0.30964447949129015\n",
      "Epoch 4525, reconstruction losses: 0.012188031173311492, regression losses: 0.1242515764681839, validation losses: 0.30754402791158186\n",
      "Epoch 4526, reconstruction losses: 0.011396871207363215, regression losses: 0.12818983069083173, validation losses: 0.30799842010067346\n",
      "Epoch 4527, reconstruction losses: 0.011986874169120188, regression losses: 0.1466215619465937, validation losses: 0.3249661488063104\n",
      "Epoch 4528, reconstruction losses: 0.01986374078432704, regression losses: 0.1305686101897391, validation losses: 0.34784441907944\n",
      "Epoch 4529, reconstruction losses: 0.013926122545312686, regression losses: 0.14612021315584842, validation losses: 0.39921721529519427\n",
      "Epoch 4530, reconstruction losses: 0.015550979705091894, regression losses: 0.14881006298260324, validation losses: 0.32648752126722314\n",
      "Epoch 4531, reconstruction losses: 0.010941979788381732, regression losses: 0.08914771899865909, validation losses: 0.3835669542008193\n",
      "Epoch 4532, reconstruction losses: 0.012567496962060812, regression losses: 0.08527762621288801, validation losses: 0.3685104087466915\n",
      "Epoch 4533, reconstruction losses: 0.01313221849125722, regression losses: 0.09226722554026427, validation losses: 0.31796790463132735\n",
      "Epoch 4534, reconstruction losses: 0.011290476221752043, regression losses: 0.103698838502325, validation losses: 0.3084150603343467\n",
      "Epoch 4535, reconstruction losses: 0.01010855596823394, regression losses: 0.0773712767175655, validation losses: 0.31456790296441955\n",
      "Epoch 4536, reconstruction losses: 0.01125505544741356, regression losses: 0.11730819711245594, validation losses: 0.29631407335265736\n",
      "Epoch 4537, reconstruction losses: 0.012055998251773158, regression losses: 0.08871394223838948, validation losses: 0.29150816633649923\n",
      "Epoch 4538, reconstruction losses: 0.011847690586641323, regression losses: 0.11773392824127195, validation losses: 0.30179639734220787\n",
      "Epoch 4539, reconstruction losses: 0.011691611944101052, regression losses: 0.09502324483171737, validation losses: 0.2972961592893609\n",
      "Epoch 4540, reconstruction losses: 0.011711083142714783, regression losses: 0.10470400051693614, validation losses: 0.28117886755768623\n",
      "Epoch 4541, reconstruction losses: 0.010215137646743028, regression losses: 0.10792590121572598, validation losses: 0.2775303981040631\n",
      "Epoch 4542, reconstruction losses: 0.012165131693534654, regression losses: 0.09404190562941214, validation losses: 0.2989564253666818\n",
      "Epoch 4543, reconstruction losses: 0.014606768282513088, regression losses: 0.1044210763917192, validation losses: 0.3109991650155961\n",
      "Epoch 4544, reconstruction losses: 0.011557197709380608, regression losses: 0.10593134469525042, validation losses: 0.3287018333415755\n",
      "Epoch 4545, reconstruction losses: 0.010377838555651333, regression losses: 0.09506597692487018, validation losses: 0.30931265816166376\n",
      "Epoch 4546, reconstruction losses: 0.012939076222883943, regression losses: 0.17970209281445088, validation losses: 0.3001558017843217\n",
      "Epoch 4547, reconstruction losses: 0.011509809657216584, regression losses: 0.09267489787993415, validation losses: 0.3956972506102181\n",
      "Epoch 4548, reconstruction losses: 0.010289021190791878, regression losses: 0.10668167377562267, validation losses: 0.399894351245704\n",
      "Epoch 4549, reconstruction losses: 0.013586932366167712, regression losses: 0.1224296717957115, validation losses: 0.3373078893345762\n",
      "Epoch 4550, reconstruction losses: 0.011506972844093894, regression losses: 0.09193011893478052, validation losses: 0.32632485946730005\n",
      "Epoch 4551, reconstruction losses: 0.01114750496790773, regression losses: 0.07510817632188031, validation losses: 0.3210810012887272\n",
      "Epoch 4552, reconstruction losses: 0.010836746712376112, regression losses: 0.09604025104411595, validation losses: 0.3038784371347144\n",
      "Epoch 4553, reconstruction losses: 0.013662007648414581, regression losses: 0.11257106244304342, validation losses: 0.3013629538771723\n",
      "Epoch 4554, reconstruction losses: 0.011796226316430496, regression losses: 0.09783263439189833, validation losses: 0.35457683766792636\n",
      "Epoch 4555, reconstruction losses: 0.012537603563029062, regression losses: 0.11261544474300966, validation losses: 0.34920721685527334\n",
      "Epoch 4556, reconstruction losses: 0.013403078762458755, regression losses: 0.11150330312609208, validation losses: 0.37374935674403986\n",
      "Epoch 4557, reconstruction losses: 0.011780357169349574, regression losses: 0.11514100921753903, validation losses: 0.371045774305672\n",
      "Epoch 4558, reconstruction losses: 0.013235208467981574, regression losses: 0.09880581919506615, validation losses: 0.32713280808057776\n",
      "Epoch 4559, reconstruction losses: 0.009555709153338397, regression losses: 0.06630939660710258, validation losses: 0.3080526241555613\n",
      "Epoch 4560, reconstruction losses: 0.009974810776187932, regression losses: 0.09355906879321234, validation losses: 0.30643967647856435\n",
      "Epoch 4561, reconstruction losses: 0.011606413320791499, regression losses: 0.08983786907009741, validation losses: 0.329347331225817\n",
      "Epoch 4562, reconstruction losses: 0.012049631654751647, regression losses: 0.09429742429413954, validation losses: 0.3053016461832981\n",
      "Epoch 4563, reconstruction losses: 0.009518340000076717, regression losses: 0.06890242744346169, validation losses: 0.2935546298055176\n",
      "Epoch 4564, reconstruction losses: 0.011020841690628648, regression losses: 0.09064021158990865, validation losses: 0.29894146970511726\n",
      "Epoch 4565, reconstruction losses: 0.013800110011343444, regression losses: 0.11529962001019696, validation losses: 0.3185968800641429\n",
      "Epoch 4566, reconstruction losses: 0.013715641583915968, regression losses: 0.0997863829026982, validation losses: 0.3310452370514349\n",
      "Epoch 4567, reconstruction losses: 0.01332279586416392, regression losses: 0.11671544427870308, validation losses: 0.31906228234704814\n",
      "Epoch 4568, reconstruction losses: 0.013757985703806349, regression losses: 0.10636041651185764, validation losses: 0.30886340730562956\n",
      "Epoch 4569, reconstruction losses: 0.010579070708130293, regression losses: 0.08306569031687568, validation losses: 0.2975394906587353\n",
      "Epoch 4570, reconstruction losses: 0.009536787213596224, regression losses: 0.07510743172309384, validation losses: 0.3040490121688981\n",
      "Epoch 4571, reconstruction losses: 0.012177052546987985, regression losses: 0.09951670115451125, validation losses: 0.3225301055336858\n",
      "Epoch 4572, reconstruction losses: 0.010538328210497524, regression losses: 0.08651469691573993, validation losses: 0.3004117365138319\n",
      "Epoch 4573, reconstruction losses: 0.01175744391368493, regression losses: 0.1662754465702249, validation losses: 0.28388557826821204\n",
      "Epoch 4574, reconstruction losses: 0.01280482262857481, regression losses: 0.08680154285538108, validation losses: 0.31591842831391226\n",
      "Epoch 4575, reconstruction losses: 0.010438926063496187, regression losses: 0.08276867937337003, validation losses: 0.295041082647124\n",
      "Epoch 4576, reconstruction losses: 0.011428171183713396, regression losses: 0.07873510471797736, validation losses: 0.2918324105779917\n",
      "Epoch 4577, reconstruction losses: 0.011111423470628842, regression losses: 0.07068415106900458, validation losses: 0.3145840262973721\n",
      "Epoch 4578, reconstruction losses: 0.012426066731201243, regression losses: 0.08186006866214435, validation losses: 0.29476911188476407\n",
      "Epoch 4579, reconstruction losses: 0.012080183161827886, regression losses: 0.09484094225183298, validation losses: 0.2981493633516883\n",
      "Epoch 4580, reconstruction losses: 0.011262094015869145, regression losses: 0.08996998127042452, validation losses: 0.29595802343049205\n",
      "Epoch 4581, reconstruction losses: 0.013197166254245905, regression losses: 0.11345359040416512, validation losses: 0.28626475228865356\n",
      "Epoch 4582, reconstruction losses: 0.012582964023356657, regression losses: 0.11685016001874333, validation losses: 0.3054118291374822\n",
      "Epoch 4583, reconstruction losses: 0.016230345621274872, regression losses: 0.129473635732075, validation losses: 0.3117203413502522\n",
      "Epoch 4584, reconstruction losses: 0.013642378221344405, regression losses: 0.10228758462793805, validation losses: 0.3160116428049086\n",
      "Epoch 4585, reconstruction losses: 0.011383971389494513, regression losses: 0.08767311573850362, validation losses: 0.3246562527326619\n",
      "Epoch 4586, reconstruction losses: 0.015636737776064478, regression losses: 0.1084825279705489, validation losses: 0.33153428470484153\n",
      "Epoch 4587, reconstruction losses: 0.011846660509922575, regression losses: 0.13296748535837544, validation losses: 0.32059706666996207\n",
      "Epoch 4588, reconstruction losses: 0.015031970034112902, regression losses: 0.1479203030955511, validation losses: 0.2886498790973073\n",
      "Epoch 4589, reconstruction losses: 0.012460771080187224, regression losses: 0.1723699215068332, validation losses: 0.33002000516590296\n",
      "Epoch 4590, reconstruction losses: 0.010999368948524194, regression losses: 0.08773880747606108, validation losses: 0.3522058801532973\n",
      "Epoch 4591, reconstruction losses: 0.013275830318152309, regression losses: 0.09467332437066439, validation losses: 0.31982445659837033\n",
      "Epoch 4592, reconstruction losses: 0.010255781612254593, regression losses: 0.08867647416105547, validation losses: 0.2975208317714868\n",
      "Epoch 4593, reconstruction losses: 0.011550551925678821, regression losses: 0.08807581897980608, validation losses: 0.3169582264635415\n",
      "Epoch 4594, reconstruction losses: 0.011292785200931056, regression losses: 0.07609664073145506, validation losses: 0.3103090604652661\n",
      "Epoch 4595, reconstruction losses: 0.009341083585223363, regression losses: 0.07527965828351242, validation losses: 0.29174102279171366\n",
      "Epoch 4596, reconstruction losses: 0.01195073328077107, regression losses: 0.11053922431411883, validation losses: 0.2859162592242606\n",
      "Epoch 4597, reconstruction losses: 0.010501953487890655, regression losses: 0.10136310055577336, validation losses: 0.2945679725345339\n",
      "Epoch 4598, reconstruction losses: 0.012099823215184142, regression losses: 0.10380257123998357, validation losses: 0.2781243748166714\n",
      "Epoch 4599, reconstruction losses: 0.012528617503462913, regression losses: 0.10848099143276631, validation losses: 0.30113602440342646\n",
      "Epoch 4600, reconstruction losses: 0.01060112091929658, regression losses: 0.08642061160249138, validation losses: 0.2990346616907254\n",
      "Epoch 4601, reconstruction losses: 0.01058263288092337, regression losses: 0.05304495897881638, validation losses: 0.30181647459759287\n",
      "Epoch 4602, reconstruction losses: 0.012694269803001116, regression losses: 0.11721045296815671, validation losses: 0.2841259067947409\n",
      "Epoch 4603, reconstruction losses: 0.010448018604008364, regression losses: 0.09547040957032307, validation losses: 0.270288378008066\n",
      "Epoch 4604, reconstruction losses: 0.00999871358453784, regression losses: 0.07885871793645433, validation losses: 0.267340719212079\n",
      "Epoch 4605, reconstruction losses: 0.011828694146311495, regression losses: 0.11619344432716566, validation losses: 0.2756771050929939\n",
      "Epoch 4606, reconstruction losses: 0.009620417720540377, regression losses: 0.09888378338634493, validation losses: 0.2889413080809077\n",
      "Epoch 4607, reconstruction losses: 0.011586218963521954, regression losses: 0.09299909791378105, validation losses: 0.2708558078660175\n",
      "Epoch 4608, reconstruction losses: 0.011370555524460237, regression losses: 0.07690129995391894, validation losses: 0.2695718307414486\n",
      "Epoch 4609, reconstruction losses: 0.010386443641159916, regression losses: 0.07885331637514587, validation losses: 0.2725715150386365\n",
      "Epoch 4610, reconstruction losses: 0.013866356789613572, regression losses: 0.17286002576363269, validation losses: 0.29654626324194105\n",
      "Epoch 4611, reconstruction losses: 0.012448696350326367, regression losses: 0.1007701198131893, validation losses: 0.35950065292467914\n",
      "Epoch 4612, reconstruction losses: 0.012482338617120654, regression losses: 0.15823972728810665, validation losses: 0.3633607336092071\n",
      "Epoch 4613, reconstruction losses: 0.010260639974792658, regression losses: 0.08219241091469841, validation losses: 0.32951774488476265\n",
      "Epoch 4614, reconstruction losses: 0.00988264963945799, regression losses: 0.08840748361397557, validation losses: 0.3068204636833966\n",
      "Epoch 4615, reconstruction losses: 0.009834598329682703, regression losses: 0.1130689445932673, validation losses: 0.3147078430448376\n",
      "Epoch 4616, reconstruction losses: 0.017002311900811203, regression losses: 0.3092064652808104, validation losses: 0.3125078026836729\n",
      "Epoch 4617, reconstruction losses: 0.01135779282728308, regression losses: 0.09062998791851266, validation losses: 0.414081588774551\n",
      "Epoch 4618, reconstruction losses: 0.011048476672090727, regression losses: 0.12354502748942839, validation losses: 0.3853827304452322\n",
      "Epoch 4619, reconstruction losses: 0.01345402333460215, regression losses: 0.11760376091548477, validation losses: 0.35261759644185897\n",
      "Epoch 4620, reconstruction losses: 0.013907143270649078, regression losses: 0.14108168335889848, validation losses: 0.3548891115423575\n",
      "Epoch 4621, reconstruction losses: 0.015719666871622375, regression losses: 0.10179638028786069, validation losses: 0.41889122642836896\n",
      "Epoch 4622, reconstruction losses: 0.011808431017114459, regression losses: 0.09608225732261946, validation losses: 0.3417039736500683\n",
      "Epoch 4623, reconstruction losses: 0.014292484489036849, regression losses: 0.12134766195541938, validation losses: 0.3032762040379674\n",
      "Epoch 4624, reconstruction losses: 0.013603767391152509, regression losses: 0.11619717753636614, validation losses: 0.3560771960061357\n",
      "Epoch 4625, reconstruction losses: 0.012624871441019047, regression losses: 0.14872045473160464, validation losses: 0.46447583683810667\n",
      "Epoch 4626, reconstruction losses: 0.011429523406960147, regression losses: 0.09942832583842937, validation losses: 0.3147406152488216\n",
      "Epoch 4627, reconstruction losses: 0.011939980008580766, regression losses: 0.11213223590659749, validation losses: 0.3539539387331598\n",
      "Epoch 4628, reconstruction losses: 0.013466436729708495, regression losses: 0.10616818516254747, validation losses: 0.3762874082846184\n",
      "Epoch 4629, reconstruction losses: 0.0141976696367129, regression losses: 0.1074564499833208, validation losses: 0.30411777441062626\n",
      "Epoch 4630, reconstruction losses: 0.014834351230391, regression losses: 0.11041711694923596, validation losses: 0.319246655767594\n",
      "Epoch 4631, reconstruction losses: 0.025866239297830378, regression losses: 0.4999040177273973, validation losses: 0.3215030699753568\n",
      "Epoch 4632, reconstruction losses: 0.010216365879557092, regression losses: 0.08790820863050547, validation losses: 0.5810822503065097\n",
      "Epoch 4633, reconstruction losses: 0.012190195647472613, regression losses: 0.12400207471647837, validation losses: 0.6262687337753634\n",
      "Epoch 4634, reconstruction losses: 0.017935698842327246, regression losses: 0.15969320438947254, validation losses: 0.4409237093711455\n",
      "Epoch 4635, reconstruction losses: 0.013474673063484786, regression losses: 0.12429101878860756, validation losses: 0.3865663493225009\n",
      "Epoch 4636, reconstruction losses: 0.020814766399392642, regression losses: 0.31166395262768654, validation losses: 0.34841356347133967\n",
      "Epoch 4637, reconstruction losses: 0.012453280443977685, regression losses: 0.10701369639298412, validation losses: 0.35823952224730127\n",
      "Epoch 4638, reconstruction losses: 0.011566949761889074, regression losses: 0.09455620577172727, validation losses: 0.37028824564418505\n",
      "Epoch 4639, reconstruction losses: 0.010210708454032966, regression losses: 0.08232669230292755, validation losses: 0.3377892007248581\n",
      "Epoch 4640, reconstruction losses: 0.010736824447695551, regression losses: 0.07769945546766882, validation losses: 0.32873338074930675\n",
      "Epoch 4641, reconstruction losses: 0.011238386963712302, regression losses: 0.10640956184079071, validation losses: 0.32568811881821236\n",
      "Epoch 4642, reconstruction losses: 0.009450142403905567, regression losses: 0.0767757536998772, validation losses: 0.32533418913651957\n",
      "Epoch 4643, reconstruction losses: 0.011180897578446416, regression losses: 0.09062417762425688, validation losses: 0.3415236731197506\n",
      "Epoch 4644, reconstruction losses: 0.01215387847042095, regression losses: 0.11662308332095435, validation losses: 0.33662722700695885\n",
      "Epoch 4645, reconstruction losses: 0.010926278691879421, regression losses: 0.10916257891332794, validation losses: 0.35227801454199037\n",
      "Epoch 4646, reconstruction losses: 0.011287726907226238, regression losses: 0.10111620006318632, validation losses: 0.32606315587140733\n",
      "Epoch 4647, reconstruction losses: 0.011400200136772707, regression losses: 0.07823117167409925, validation losses: 0.3292104824824905\n",
      "Epoch 4648, reconstruction losses: 0.015566137820842069, regression losses: 0.14690934678938822, validation losses: 0.33711122020619305\n",
      "Epoch 4649, reconstruction losses: 0.01128041863588932, regression losses: 0.09693705900796595, validation losses: 0.3830169382143372\n",
      "Epoch 4650, reconstruction losses: 0.014726486782177983, regression losses: 0.08349798496429822, validation losses: 0.3503498152946459\n",
      "Epoch 4651, reconstruction losses: 0.013585216440764476, regression losses: 0.2394369128482021, validation losses: 0.31468865530990303\n",
      "Epoch 4652, reconstruction losses: 0.01273379946679115, regression losses: 0.13117019389677798, validation losses: 0.4241302340488563\n",
      "Epoch 4653, reconstruction losses: 0.011745071232038627, regression losses: 0.123978238272731, validation losses: 0.41646457427448685\n",
      "Epoch 4654, reconstruction losses: 0.01237386410107385, regression losses: 0.15567046668586476, validation losses: 0.37707837053525983\n",
      "Epoch 4655, reconstruction losses: 0.012127598707731082, regression losses: 0.13090951791984168, validation losses: 0.4184610609294776\n",
      "Epoch 4656, reconstruction losses: 0.011125541585163181, regression losses: 0.10091518183702765, validation losses: 0.4335469705048302\n",
      "Epoch 4657, reconstruction losses: 0.012043362701715288, regression losses: 0.16118975651711592, validation losses: 0.36481307846584765\n",
      "Epoch 4658, reconstruction losses: 0.009601391359366352, regression losses: 0.09972664527534558, validation losses: 0.32709293671168727\n",
      "Epoch 4659, reconstruction losses: 0.013271570953065047, regression losses: 0.12450767520868622, validation losses: 0.3460047736302242\n",
      "Epoch 4660, reconstruction losses: 0.012625613223016627, regression losses: 0.10777091313798964, validation losses: 0.3634376335236715\n",
      "Epoch 4661, reconstruction losses: 0.013382918343307803, regression losses: 0.1380676111320036, validation losses: 0.38831805352771337\n",
      "Epoch 4662, reconstruction losses: 0.0098229058959647, regression losses: 0.08475523570802314, validation losses: 0.37903066096845467\n",
      "Epoch 4663, reconstruction losses: 0.012380125162544305, regression losses: 0.102310665681565, validation losses: 0.36369751718297993\n",
      "Epoch 4664, reconstruction losses: 0.010234813020739782, regression losses: 0.0731182161329991, validation losses: 0.3255694948426444\n",
      "Epoch 4665, reconstruction losses: 0.01311933763670849, regression losses: 0.13788366917134545, validation losses: 0.3323837346878816\n",
      "Epoch 4666, reconstruction losses: 0.010385166099830478, regression losses: 0.07818162650722649, validation losses: 0.3154369422391527\n",
      "Epoch 4667, reconstruction losses: 0.010489064903718856, regression losses: 0.07891430182206789, validation losses: 0.33479153754887475\n",
      "Epoch 4668, reconstruction losses: 0.015997453598027376, regression losses: 0.23662740485862116, validation losses: 0.3315372570015193\n",
      "Epoch 4669, reconstruction losses: 0.011236405837736683, regression losses: 0.10732418006511768, validation losses: 0.4540837025882772\n",
      "Epoch 4670, reconstruction losses: 0.011236970807185482, regression losses: 0.13554858845569465, validation losses: 0.47843271680566013\n",
      "Epoch 4671, reconstruction losses: 0.013709405671050995, regression losses: 0.12859199029917956, validation losses: 0.42490383413800376\n",
      "Epoch 4672, reconstruction losses: 0.013184888781149462, regression losses: 0.14839321004224892, validation losses: 0.4239441319637689\n",
      "Epoch 4673, reconstruction losses: 0.018242093006268657, regression losses: 0.19022168412066048, validation losses: 0.3787896997362177\n",
      "Epoch 4674, reconstruction losses: 0.014456211822727709, regression losses: 0.15551912145614666, validation losses: 0.35402311905336176\n",
      "Epoch 4675, reconstruction losses: 0.011640454640337508, regression losses: 0.1050123834995271, validation losses: 0.3499567707888739\n",
      "Epoch 4676, reconstruction losses: 0.012944129825981834, regression losses: 0.09344617813015568, validation losses: 0.3469887225865174\n",
      "Epoch 4677, reconstruction losses: 0.012880250302295495, regression losses: 0.11433713868560158, validation losses: 0.29999524254071486\n",
      "Epoch 4678, reconstruction losses: 0.012373754854717095, regression losses: 0.07538350091596309, validation losses: 0.2966827342279436\n",
      "Epoch 4679, reconstruction losses: 0.009929511586065531, regression losses: 0.07565771398070693, validation losses: 0.3264918605672765\n",
      "Epoch 4680, reconstruction losses: 0.01818456380927283, regression losses: 0.10196494144051141, validation losses: 0.34222757777011326\n",
      "Epoch 4681, reconstruction losses: 0.012066417342434148, regression losses: 0.09119843189058456, validation losses: 0.3644605976954284\n",
      "Epoch 4682, reconstruction losses: 0.010951482216779579, regression losses: 0.07077393237090995, validation losses: 0.3381580174352928\n",
      "Epoch 4683, reconstruction losses: 0.01483019785569053, regression losses: 0.13153341663891138, validation losses: 0.32229362106145065\n",
      "Epoch 4684, reconstruction losses: 0.012378761701660721, regression losses: 0.09454444415963625, validation losses: 0.31475892178524345\n",
      "Epoch 4685, reconstruction losses: 0.013608294682540063, regression losses: 0.117442345945618, validation losses: 0.3117250548188374\n",
      "Epoch 4686, reconstruction losses: 0.012424628004098708, regression losses: 0.0975692677740564, validation losses: 0.31523006387087427\n",
      "Epoch 4687, reconstruction losses: 0.012359770338026646, regression losses: 0.08824399772628849, validation losses: 0.31229699025109187\n",
      "Epoch 4688, reconstruction losses: 0.017349819491141852, regression losses: 0.1279737533145281, validation losses: 0.32376653303124175\n",
      "Epoch 4689, reconstruction losses: 0.009899469531090738, regression losses: 0.08688403042070768, validation losses: 0.30656496590025684\n",
      "Epoch 4690, reconstruction losses: 0.010541775169378188, regression losses: 0.08553963495158687, validation losses: 0.2936263255567162\n",
      "Epoch 4691, reconstruction losses: 0.010150594590801983, regression losses: 0.10018593325367725, validation losses: 0.2890498636901875\n",
      "Epoch 4692, reconstruction losses: 0.011572051441064754, regression losses: 0.08705615550932619, validation losses: 0.3003019498271343\n",
      "Epoch 4693, reconstruction losses: 0.009644264142111343, regression losses: 0.0949456707948218, validation losses: 0.29609529320321515\n",
      "Epoch 4694, reconstruction losses: 0.0099599927594246, regression losses: 0.08640824742915165, validation losses: 0.301337705021475\n",
      "Epoch 4695, reconstruction losses: 0.019310756210148702, regression losses: 0.11227755645121662, validation losses: 0.31344186785505046\n",
      "Epoch 4696, reconstruction losses: 0.011647731591865652, regression losses: 0.10320183503300748, validation losses: 0.3884508351704298\n",
      "Epoch 4697, reconstruction losses: 0.012835313759381396, regression losses: 0.13723552023059649, validation losses: 0.38436321724000433\n",
      "Epoch 4698, reconstruction losses: 0.013400166928762, regression losses: 0.13255859929766542, validation losses: 0.3125188208322291\n",
      "Epoch 4699, reconstruction losses: 0.009657790890336932, regression losses: 0.06860739979611333, validation losses: 0.2925409532542227\n",
      "Epoch 4700, reconstruction losses: 0.01218624472629624, regression losses: 0.08968624074495084, validation losses: 0.2992995881220751\n",
      "Epoch 4701, reconstruction losses: 0.011481876015825818, regression losses: 0.0952860928378907, validation losses: 0.2978462098445039\n",
      "Epoch 4702, reconstruction losses: 0.012775385435198718, regression losses: 0.08241837784954892, validation losses: 0.30025826245841125\n",
      "Epoch 4703, reconstruction losses: 0.011119386042892105, regression losses: 0.07104071560255983, validation losses: 0.2984624219715116\n",
      "Epoch 4704, reconstruction losses: 0.011757468632291605, regression losses: 0.0813124441113413, validation losses: 0.31219355026541185\n",
      "Epoch 4705, reconstruction losses: 0.014072977672563675, regression losses: 0.10841752062965475, validation losses: 0.2958264908787897\n",
      "Epoch 4706, reconstruction losses: 0.01371063707706702, regression losses: 0.07550122249170309, validation losses: 0.2781719741633751\n",
      "Epoch 4707, reconstruction losses: 0.012333499417195366, regression losses: 0.08595841663665171, validation losses: 0.29500100346300373\n",
      "Epoch 4708, reconstruction losses: 0.011185399029793234, regression losses: 0.09842678193721997, validation losses: 0.296383644687545\n",
      "Epoch 4709, reconstruction losses: 0.011377600967048263, regression losses: 0.0727064122681805, validation losses: 0.3324950037073966\n",
      "Epoch 4710, reconstruction losses: 0.0141908396020067, regression losses: 0.21613479603249064, validation losses: 0.31044673742064033\n",
      "Epoch 4711, reconstruction losses: 0.011469945092623989, regression losses: 0.1130030781014196, validation losses: 0.373210998867076\n",
      "Epoch 4712, reconstruction losses: 0.016161661361690022, regression losses: 0.10317816787816107, validation losses: 0.35827275942852926\n",
      "Epoch 4713, reconstruction losses: 0.010349931319589252, regression losses: 0.10051003823413553, validation losses: 0.33876946324988116\n",
      "Epoch 4714, reconstruction losses: 0.012021047205004156, regression losses: 0.08493462440299716, validation losses: 0.32616084846308835\n",
      "Epoch 4715, reconstruction losses: 0.013787912763945849, regression losses: 0.1037413177802333, validation losses: 0.32874332306167475\n",
      "Epoch 4716, reconstruction losses: 0.013434498394312575, regression losses: 0.09498288974224121, validation losses: 0.3268824097054713\n",
      "Epoch 4717, reconstruction losses: 0.012794439018084906, regression losses: 0.09361134828675514, validation losses: 0.31917676837099607\n",
      "Epoch 4718, reconstruction losses: 0.013437646580382656, regression losses: 0.1239273998848293, validation losses: 0.32211193550461786\n",
      "Epoch 4719, reconstruction losses: 0.011660888480468477, regression losses: 0.11605757593167632, validation losses: 0.31037868157484516\n",
      "Epoch 4720, reconstruction losses: 0.013446459975963337, regression losses: 0.09701802969047035, validation losses: 0.29001667291753924\n",
      "Epoch 4721, reconstruction losses: 0.010608036108946853, regression losses: 0.09090986560332794, validation losses: 0.31181477911469724\n",
      "Epoch 4722, reconstruction losses: 0.011497704475923621, regression losses: 0.10009285438099277, validation losses: 0.30170566979912966\n",
      "Epoch 4723, reconstruction losses: 0.013280805244974173, regression losses: 0.11415560790314973, validation losses: 0.2882026078264539\n",
      "Epoch 4724, reconstruction losses: 0.01180830791413275, regression losses: 0.07466182481343189, validation losses: 0.278817310589655\n",
      "Epoch 4725, reconstruction losses: 0.011691450221963752, regression losses: 0.1015204103550443, validation losses: 0.27610593735707634\n",
      "Epoch 4726, reconstruction losses: 0.014261445279993776, regression losses: 0.09894172868976767, validation losses: 0.27303913751868514\n",
      "Epoch 4727, reconstruction losses: 0.013088136910222054, regression losses: 0.10181310835021973, validation losses: 0.27956820151337064\n",
      "Epoch 4728, reconstruction losses: 0.009236080470956413, regression losses: 0.07702097505670491, validation losses: 0.28464398502806215\n",
      "Epoch 4729, reconstruction losses: 0.01032112026756152, regression losses: 0.12617472093964002, validation losses: 0.2787455942853254\n",
      "Epoch 4730, reconstruction losses: 0.016524249166138497, regression losses: 0.0803468684938051, validation losses: 0.28750852000408833\n",
      "Epoch 4731, reconstruction losses: 0.011960637530296017, regression losses: 0.15168247590945277, validation losses: 0.29715226609220746\n",
      "Epoch 4732, reconstruction losses: 0.011573894625610634, regression losses: 0.1171356704216267, validation losses: 0.30656219855097294\n",
      "Epoch 4733, reconstruction losses: 0.013023839523928618, regression losses: 0.16652528109219614, validation losses: 0.307879502165596\n",
      "Epoch 4734, reconstruction losses: 0.01090775151209248, regression losses: 0.08343704524433462, validation losses: 0.334682883409764\n",
      "Epoch 4735, reconstruction losses: 0.010152082307968857, regression losses: 0.07365883847502716, validation losses: 0.3445102499838816\n",
      "Epoch 4736, reconstruction losses: 0.010438878478199378, regression losses: 0.08291334168452283, validation losses: 0.3201759871920621\n",
      "Epoch 4737, reconstruction losses: 0.010514419936909701, regression losses: 0.06617109197384177, validation losses: 0.30577366644372694\n",
      "Epoch 4738, reconstruction losses: 0.012069099946857878, regression losses: 0.10121737983262155, validation losses: 0.3021755538855067\n",
      "Epoch 4739, reconstruction losses: 0.011033855046341167, regression losses: 0.0913478207265057, validation losses: 0.29687504443005003\n",
      "Epoch 4740, reconstruction losses: 0.011603709218890968, regression losses: 0.0956884773932558, validation losses: 0.2972885160324668\n",
      "Epoch 4741, reconstruction losses: 0.012619487682935256, regression losses: 0.09541794422698119, validation losses: 0.31034911128348913\n",
      "Epoch 4742, reconstruction losses: 0.011272640514901736, regression losses: 0.08702698470316048, validation losses: 0.3114386440362709\n",
      "Epoch 4743, reconstruction losses: 0.014431481819740567, regression losses: 0.14531519946588572, validation losses: 0.3256395020734101\n",
      "Epoch 4744, reconstruction losses: 0.011018405462904503, regression losses: 0.0851566851435037, validation losses: 0.3415287095331726\n",
      "Epoch 4745, reconstruction losses: 0.012085441035162577, regression losses: 0.08251048979152485, validation losses: 0.33850523522824877\n",
      "Epoch 4746, reconstruction losses: 0.011781211366434834, regression losses: 0.11354950855651799, validation losses: 0.3267902331163708\n",
      "Epoch 4747, reconstruction losses: 0.011464167751230301, regression losses: 0.10627962046100808, validation losses: 0.3215458691375579\n",
      "Epoch 4748, reconstruction losses: 0.01122013914093502, regression losses: 0.0913308211952443, validation losses: 0.32128877889705965\n",
      "Epoch 4749, reconstruction losses: 0.012689370206761249, regression losses: 0.08633513311654703, validation losses: 0.304974791785583\n",
      "Epoch 4750, reconstruction losses: 0.00947371219058761, regression losses: 0.0700569139728664, validation losses: 0.29287363197525534\n",
      "Epoch 4751, reconstruction losses: 0.010980449532446986, regression losses: 0.08482426594747015, validation losses: 0.28930920037568336\n",
      "Epoch 4752, reconstruction losses: 0.01125275197291177, regression losses: 0.08935498725403371, validation losses: 0.29212633412637623\n",
      "Epoch 4753, reconstruction losses: 0.012770036989196053, regression losses: 0.12320009452306777, validation losses: 0.285342522652118\n",
      "Epoch 4754, reconstruction losses: 0.014236235203003413, regression losses: 0.1133666645611557, validation losses: 0.2827714997271622\n",
      "Epoch 4755, reconstruction losses: 0.011116363214205791, regression losses: 0.09057919797106347, validation losses: 0.30983477999263764\n",
      "Epoch 4756, reconstruction losses: 0.01333536447995327, regression losses: 0.12788621062862596, validation losses: 0.29167863684990347\n",
      "Epoch 4757, reconstruction losses: 0.014484694643935184, regression losses: 0.21443036386449274, validation losses: 0.314768972654731\n",
      "Epoch 4758, reconstruction losses: 0.012792993463614587, regression losses: 0.15334773920979067, validation losses: 0.45127681817714327\n",
      "Epoch 4759, reconstruction losses: 0.01309738076307796, regression losses: 0.12618427417152364, validation losses: 0.3677991573475219\n",
      "Epoch 4760, reconstruction losses: 0.012451143106175403, regression losses: 0.11165718132909783, validation losses: 0.36118410385550376\n",
      "Epoch 4761, reconstruction losses: 0.016726249951942076, regression losses: 0.10368190167595792, validation losses: 0.4014518488847739\n",
      "Epoch 4762, reconstruction losses: 0.01688979804845389, regression losses: 0.11127566735392239, validation losses: 0.3713593428225307\n",
      "Epoch 4763, reconstruction losses: 0.009875963307473779, regression losses: 0.09011504003963268, validation losses: 0.3354436106706695\n",
      "Epoch 4764, reconstruction losses: 0.014400383819261266, regression losses: 0.12178955598624366, validation losses: 0.3209051026519796\n",
      "Epoch 4765, reconstruction losses: 0.012467097107137776, regression losses: 0.10532037143151626, validation losses: 0.30795263191280875\n",
      "Epoch 4766, reconstruction losses: 0.012624256264289063, regression losses: 0.11281351760789951, validation losses: 0.29173032517607167\n",
      "Epoch 4767, reconstruction losses: 0.013491120666209406, regression losses: 0.3854896203672633, validation losses: 0.28477147987924717\n",
      "Epoch 4768, reconstruction losses: 0.014987597288413711, regression losses: 0.0950116832588773, validation losses: 0.4697614863541493\n",
      "Epoch 4769, reconstruction losses: 0.016210116208600592, regression losses: 0.13942018491641345, validation losses: 0.5612882722902449\n",
      "Epoch 4770, reconstruction losses: 0.010155330599430436, regression losses: 0.0969774036255414, validation losses: 0.4447063421534136\n",
      "Epoch 4771, reconstruction losses: 0.01231446599897509, regression losses: 0.23486949978719304, validation losses: 0.43142945754733897\n",
      "Epoch 4772, reconstruction losses: 0.01200796695914719, regression losses: 0.10517470475289478, validation losses: 0.5478394472851396\n",
      "Epoch 4773, reconstruction losses: 0.012617697109415389, regression losses: 0.10010031755385798, validation losses: 0.5321110024959661\n",
      "Epoch 4774, reconstruction losses: 0.013867418658887815, regression losses: 0.1255243187053912, validation losses: 0.4024886812485173\n",
      "Epoch 4775, reconstruction losses: 0.011153275519614265, regression losses: 0.10397067073724474, validation losses: 0.34169360923127234\n",
      "Epoch 4776, reconstruction losses: 0.01090301767432069, regression losses: 0.08984859828198861, validation losses: 0.31813682452462916\n",
      "Epoch 4777, reconstruction losses: 0.012458404488954026, regression losses: 0.3449512698634055, validation losses: 0.31412273139478303\n",
      "Epoch 4778, reconstruction losses: 0.009302750311343684, regression losses: 0.0896751598233217, validation losses: 0.5306957913399992\n",
      "Epoch 4779, reconstruction losses: 0.010591919804401663, regression losses: 0.10607291727462705, validation losses: 0.5363802528487871\n",
      "Epoch 4780, reconstruction losses: 0.011831912651663825, regression losses: 0.09301195235763679, validation losses: 0.39673121748942636\n",
      "Epoch 4781, reconstruction losses: 0.011030242311990747, regression losses: 0.09584015925626865, validation losses: 0.33937943584165847\n",
      "Epoch 4782, reconstruction losses: 0.009892275921813524, regression losses: 0.08127131802146666, validation losses: 0.32476401588250653\n",
      "Epoch 4783, reconstruction losses: 0.010730651629784293, regression losses: 0.06416082619622959, validation losses: 0.33830622143581224\n",
      "Epoch 4784, reconstruction losses: 0.013299616696407841, regression losses: 0.14887183772956555, validation losses: 0.33581305900817093\n",
      "Epoch 4785, reconstruction losses: 0.013537749159430002, regression losses: 0.12222766947049155, validation losses: 0.3490743122182429\n",
      "Epoch 4786, reconstruction losses: 0.014285642770310827, regression losses: 0.17034910623386273, validation losses: 0.36452292495818306\n",
      "Epoch 4787, reconstruction losses: 0.011477895050872296, regression losses: 0.11141511779990801, validation losses: 0.40312766600789496\n",
      "Epoch 4788, reconstruction losses: 0.010872172853272237, regression losses: 0.0921754236602822, validation losses: 0.3613345685422868\n",
      "Epoch 4789, reconstruction losses: 0.010666663795036434, regression losses: 0.061541366201938195, validation losses: 0.3264120987272295\n",
      "Epoch 4790, reconstruction losses: 0.010361998402635792, regression losses: 0.09101903961111123, validation losses: 0.30591451526491464\n",
      "Epoch 4791, reconstruction losses: 0.011731498685784034, regression losses: 0.10579759698302679, validation losses: 0.300235515011059\n",
      "Epoch 4792, reconstruction losses: 0.013599757302941422, regression losses: 0.11204905716149152, validation losses: 0.2913429467759558\n",
      "Epoch 4793, reconstruction losses: 0.012207767975150073, regression losses: 0.08681992306272616, validation losses: 0.28495018630200386\n",
      "Epoch 4794, reconstruction losses: 0.01091763385403893, regression losses: 0.09830357979792977, validation losses: 0.2884993618440031\n",
      "Epoch 4795, reconstruction losses: 0.019382911011603367, regression losses: 0.4163336426984504, validation losses: 0.27371647536656907\n",
      "Epoch 4796, reconstruction losses: 0.013550330865473812, regression losses: 0.09565970994997511, validation losses: 0.4432750843450274\n",
      "Epoch 4797, reconstruction losses: 0.010944995336018115, regression losses: 0.08912395004080294, validation losses: 0.45135441937855614\n",
      "Epoch 4798, reconstruction losses: 0.01293081728751932, regression losses: 0.13484361202201708, validation losses: 0.3421917821021687\n",
      "Epoch 4799, reconstruction losses: 0.011074468589477169, regression losses: 0.0887511957579752, validation losses: 0.3456722494823196\n",
      "Epoch 4800, reconstruction losses: 0.011570991517185474, regression losses: 0.12954103761198535, validation losses: 0.3705694936171977\n",
      "Epoch 4801, reconstruction losses: 0.012151440431009712, regression losses: 0.11186750667070403, validation losses: 0.3137119463884656\n",
      "Epoch 4802, reconstruction losses: 0.011981055901934608, regression losses: 0.08213310397611134, validation losses: 0.2681765674330464\n",
      "Epoch 4803, reconstruction losses: 0.01002889444504347, regression losses: 0.09003946249322253, validation losses: 0.26792676518821396\n",
      "Epoch 4804, reconstruction losses: 0.00938135126623298, regression losses: 0.061394753793098375, validation losses: 0.28175798667025087\n",
      "Epoch 4805, reconstruction losses: 0.01460843252424715, regression losses: 0.11917357189876124, validation losses: 0.29798561773396715\n",
      "Epoch 4806, reconstruction losses: 0.011020629634318747, regression losses: 0.07944185531293478, validation losses: 0.28707834247537406\n",
      "Epoch 4807, reconstruction losses: 0.010231482420426267, regression losses: 0.07160343676999655, validation losses: 0.2733408693133307\n",
      "Epoch 4808, reconstruction losses: 0.010677530737964989, regression losses: 0.0998385117080173, validation losses: 0.2620456399294497\n",
      "Epoch 4809, reconstruction losses: 0.012727933368311947, regression losses: 0.10624463680029388, validation losses: 0.25597606875978207\n",
      "Epoch 4810, reconstruction losses: 0.01146308449614625, regression losses: 0.06838644869383129, validation losses: 0.25824249591098625\n",
      "Epoch 4811, reconstruction losses: 0.010706388699352205, regression losses: 0.09253186826752435, validation losses: 0.2588889388722083\n",
      "Epoch 4812, reconstruction losses: 0.010072584382559405, regression losses: 0.07953741710560336, validation losses: 0.26449779004705576\n",
      "Epoch 4813, reconstruction losses: 0.014821231325981033, regression losses: 0.11725958288786184, validation losses: 0.27267464565719096\n",
      "Epoch 4814, reconstruction losses: 0.010616191787146857, regression losses: 0.07479958592645818, validation losses: 0.2823645019507699\n",
      "Epoch 4815, reconstruction losses: 0.01004310314980962, regression losses: 0.06095380952437514, validation losses: 0.29821624413196635\n",
      "Epoch 4816, reconstruction losses: 0.010632688377539844, regression losses: 0.09221990764291534, validation losses: 0.2942967298613082\n",
      "Epoch 4817, reconstruction losses: 0.01267784401560817, regression losses: 0.10622531868033988, validation losses: 0.2921815138027693\n",
      "Epoch 4818, reconstruction losses: 0.012907082012926398, regression losses: 0.0985195111425614, validation losses: 0.29023987517594035\n",
      "Epoch 4819, reconstruction losses: 0.009889181007199042, regression losses: 0.07948761617459878, validation losses: 0.2938662710076325\n",
      "Epoch 4820, reconstruction losses: 0.01201906184168538, regression losses: 0.08556744271189833, validation losses: 0.31495520345592976\n",
      "Epoch 4821, reconstruction losses: 0.009980245133308021, regression losses: 0.10674475826536317, validation losses: 0.31700583352203593\n",
      "Epoch 4822, reconstruction losses: 0.008970752066976563, regression losses: 0.061556963495031765, validation losses: 0.26890092560315154\n",
      "Epoch 4823, reconstruction losses: 0.011610902569691583, regression losses: 0.07045140820356745, validation losses: 0.27467997676978945\n",
      "Epoch 4824, reconstruction losses: 0.01319491587353438, regression losses: 0.06580037450549267, validation losses: 0.31157540315172205\n",
      "Epoch 4825, reconstruction losses: 0.013113894472128493, regression losses: 0.10953593159092465, validation losses: 0.3013841814336629\n",
      "Epoch 4826, reconstruction losses: 0.010281608280821156, regression losses: 0.10645726570514587, validation losses: 0.3023295555472888\n",
      "Epoch 4827, reconstruction losses: 0.009844423561124067, regression losses: 0.07341911016076015, validation losses: 0.31580179806770703\n",
      "Epoch 4828, reconstruction losses: 0.01806980486123646, regression losses: 0.1278726437025497, validation losses: 0.2739996459960826\n",
      "Epoch 4829, reconstruction losses: 0.009446502825418222, regression losses: 0.0651263079876579, validation losses: 0.2959517013061486\n",
      "Epoch 4830, reconstruction losses: 0.013423570854419456, regression losses: 0.12481840768987487, validation losses: 0.28100753933814754\n",
      "Epoch 4831, reconstruction losses: 0.011012484414748053, regression losses: 0.08916908284608795, validation losses: 0.34232707749666014\n",
      "Epoch 4832, reconstruction losses: 0.011308450834040282, regression losses: 0.09902026584289508, validation losses: 0.3567659845171811\n",
      "Epoch 4833, reconstruction losses: 0.011153385271137291, regression losses: 0.11579088171775444, validation losses: 0.32517869757591034\n",
      "Epoch 4834, reconstruction losses: 0.014633694419460778, regression losses: 0.14230721226172333, validation losses: 0.28733468098373677\n",
      "Epoch 4835, reconstruction losses: 0.015700157590460485, regression losses: 0.09387091638626813, validation losses: 0.2766497400508524\n",
      "Epoch 4836, reconstruction losses: 0.011091856815138171, regression losses: 0.0705536380896677, validation losses: 0.2692749424917652\n",
      "Epoch 4837, reconstruction losses: 0.01231117173013484, regression losses: 0.07856450949448501, validation losses: 0.2606005818693685\n",
      "Epoch 4838, reconstruction losses: 0.011526317880186895, regression losses: 0.08441661191378748, validation losses: 0.2855376428520688\n",
      "Epoch 4839, reconstruction losses: 0.011448510140451637, regression losses: 0.08724287235466974, validation losses: 0.3117816601737938\n",
      "Epoch 4840, reconstruction losses: 0.01376704767774833, regression losses: 0.09355848894058792, validation losses: 0.3015578524248068\n",
      "Epoch 4841, reconstruction losses: 0.011749327679095686, regression losses: 0.09352480847091575, validation losses: 0.28554823328037193\n",
      "Epoch 4842, reconstruction losses: 0.012418906624096103, regression losses: 0.0779470307241095, validation losses: 0.2976014381666944\n",
      "Epoch 4843, reconstruction losses: 0.01372621282125684, regression losses: 0.08288314095586352, validation losses: 0.29215910176371823\n",
      "Epoch 4844, reconstruction losses: 0.010761840322804467, regression losses: 0.07121683787827693, validation losses: 0.2700345470515263\n",
      "Epoch 4845, reconstruction losses: 0.010821272334055502, regression losses: 0.08603876871390521, validation losses: 0.2601650267067032\n",
      "Epoch 4846, reconstruction losses: 0.010222106243992567, regression losses: 0.08565841287284795, validation losses: 0.2653498668130201\n",
      "Epoch 4847, reconstruction losses: 0.010145478951206353, regression losses: 0.08286624353929051, validation losses: 0.2803330696678245\n",
      "Epoch 4848, reconstruction losses: 0.011715992054094614, regression losses: 0.06755875155578718, validation losses: 0.30548512931640814\n",
      "Epoch 4849, reconstruction losses: 0.011455725022960666, regression losses: 0.12026144569088525, validation losses: 0.3050016639233819\n",
      "Epoch 4850, reconstruction losses: 0.009257533469439281, regression losses: 0.05917774113510956, validation losses: 0.3007121456695082\n",
      "Epoch 4851, reconstruction losses: 0.013990568156876687, regression losses: 0.09860682135625799, validation losses: 0.2945870841864595\n",
      "Epoch 4852, reconstruction losses: 0.010736561059627017, regression losses: 0.08421960705863966, validation losses: 0.28490918695857903\n",
      "Epoch 4853, reconstruction losses: 0.009863845306501954, regression losses: 0.07866487534402444, validation losses: 0.27370580547346196\n",
      "Epoch 4854, reconstruction losses: 0.012163956781252303, regression losses: 0.08216943252762418, validation losses: 0.270685565204524\n",
      "Epoch 4855, reconstruction losses: 0.009177321085923779, regression losses: 0.07124195315482909, validation losses: 0.2736501244373146\n",
      "Epoch 4856, reconstruction losses: 0.010181109529049062, regression losses: 0.16848225736658695, validation losses: 0.26948620051890504\n",
      "Epoch 4857, reconstruction losses: 0.011925275872863775, regression losses: 0.1352788868149286, validation losses: 0.32090824878077645\n",
      "Epoch 4858, reconstruction losses: 0.01139841124933746, regression losses: 0.12671580706280133, validation losses: 0.37488835118096375\n",
      "Epoch 4859, reconstruction losses: 0.011819247351364536, regression losses: 0.166398660983328, validation losses: 0.33389011680944886\n",
      "Epoch 4860, reconstruction losses: 0.013200412978451915, regression losses: 0.10607875096402321, validation losses: 0.3216594817388542\n",
      "Epoch 4861, reconstruction losses: 0.013415009726326591, regression losses: 0.1577217791354014, validation losses: 0.32446267243722826\n",
      "Epoch 4862, reconstruction losses: 0.010813619537970715, regression losses: 0.08068761259633507, validation losses: 0.33905227318748143\n",
      "Epoch 4863, reconstruction losses: 0.01283732178595757, regression losses: 0.10036956465916887, validation losses: 0.35264467376006037\n",
      "Epoch 4864, reconstruction losses: 0.010553302220041595, regression losses: 0.08043500210956342, validation losses: 0.37549584364629196\n",
      "Epoch 4865, reconstruction losses: 0.011239139475203056, regression losses: 0.09708463447443752, validation losses: 0.3171645928565587\n",
      "Epoch 4866, reconstruction losses: 0.011728192884020744, regression losses: 0.06385385100243722, validation losses: 0.2864407980826535\n",
      "Epoch 4867, reconstruction losses: 0.010587603919333164, regression losses: 0.0816281988238671, validation losses: 0.28740633602289106\n",
      "Epoch 4868, reconstruction losses: 0.01267852979530442, regression losses: 0.09701341702989769, validation losses: 0.29286762869637367\n",
      "Epoch 4869, reconstruction losses: 0.015205368046444196, regression losses: 0.11814218224850187, validation losses: 0.27426846809436356\n",
      "Epoch 4870, reconstruction losses: 0.01038022717767927, regression losses: 0.05887375127492217, validation losses: 0.27500464531913077\n",
      "Epoch 4871, reconstruction losses: 0.011202222351957473, regression losses: 0.062106900624421466, validation losses: 0.2866310651752897\n",
      "Epoch 4872, reconstruction losses: 0.010272312720681706, regression losses: 0.06793600158186125, validation losses: 0.28388129994314465\n",
      "Epoch 4873, reconstruction losses: 0.01064307091846196, regression losses: 0.0836602641714533, validation losses: 0.28193337590086803\n",
      "Epoch 4874, reconstruction losses: 0.01238332810529533, regression losses: 0.09926813340285587, validation losses: 0.29299155882796935\n",
      "Epoch 4875, reconstruction losses: 0.010315458778947293, regression losses: 0.07697190507143613, validation losses: 0.35309156808681225\n",
      "Epoch 4876, reconstruction losses: 0.012145461614016664, regression losses: 0.09073487029485823, validation losses: 0.351861656109449\n",
      "Epoch 4877, reconstruction losses: 0.015524058795681448, regression losses: 0.11943086188031522, validation losses: 0.32967425497857894\n",
      "Epoch 4878, reconstruction losses: 0.00956392600950294, regression losses: 0.0700681824510279, validation losses: 0.38131682752035284\n",
      "Epoch 4879, reconstruction losses: 0.01274167419371244, regression losses: 0.08329535730784766, validation losses: 0.3498648992626935\n",
      "Epoch 4880, reconstruction losses: 0.012107451882831292, regression losses: 0.08291233629593199, validation losses: 0.3065837931893391\n",
      "Epoch 4881, reconstruction losses: 0.011244693257175007, regression losses: 0.08197182850479118, validation losses: 0.2991656728945066\n",
      "Epoch 4882, reconstruction losses: 0.013924034962935537, regression losses: 0.10268656591720152, validation losses: 0.2825560013889793\n",
      "Epoch 4883, reconstruction losses: 0.011362626522289096, regression losses: 0.1121914540082141, validation losses: 0.2966939442406328\n",
      "Epoch 4884, reconstruction losses: 0.01257253354346841, regression losses: 0.1074243744701445, validation losses: 0.29800926047100434\n",
      "Epoch 4885, reconstruction losses: 0.01173340835871654, regression losses: 0.10579285518392602, validation losses: 0.2909274908008374\n",
      "Epoch 4886, reconstruction losses: 0.012136587731493464, regression losses: 0.13054164824149792, validation losses: 0.2903443843040615\n",
      "Epoch 4887, reconstruction losses: 0.008618294410140665, regression losses: 0.061456577684405954, validation losses: 0.3061514572303759\n",
      "Epoch 4888, reconstruction losses: 0.010711917502187855, regression losses: 0.09311457771281605, validation losses: 0.32000797199217507\n",
      "Epoch 4889, reconstruction losses: 0.00938288163388357, regression losses: 0.06548891272368078, validation losses: 0.32588196850577966\n",
      "Epoch 4890, reconstruction losses: 0.010617517767819084, regression losses: 0.08733498627449608, validation losses: 0.30983232894172863\n",
      "Epoch 4891, reconstruction losses: 0.009722760295872027, regression losses: 0.08363392967370767, validation losses: 0.2974771376292149\n",
      "Epoch 4892, reconstruction losses: 0.010893762697161188, regression losses: 0.10241812963858012, validation losses: 0.27190152230172776\n",
      "Epoch 4893, reconstruction losses: 0.010858519264448339, regression losses: 0.08656704803214778, validation losses: 0.2892666510039381\n",
      "Epoch 4894, reconstruction losses: 0.015109833577421076, regression losses: 0.15513221060239718, validation losses: 0.27504073041291205\n",
      "Epoch 4895, reconstruction losses: 0.012518525061272899, regression losses: 0.08085701413945122, validation losses: 0.26303611415867784\n",
      "Epoch 4896, reconstruction losses: 0.01192360407041391, regression losses: 0.0887502521417177, validation losses: 0.2562868487959557\n",
      "Epoch 4897, reconstruction losses: 0.011293328552641061, regression losses: 0.10764472636348366, validation losses: 0.3139312721488299\n",
      "Epoch 4898, reconstruction losses: 0.012078048029321243, regression losses: 0.09249094998487836, validation losses: 0.3496825412927684\n",
      "Epoch 4899, reconstruction losses: 0.010459885571922721, regression losses: 0.06716706805610209, validation losses: 0.3107132592583704\n",
      "Epoch 4900, reconstruction losses: 0.01894827626237308, regression losses: 0.32368285232506017, validation losses: 0.3038217326653542\n",
      "Epoch 4901, reconstruction losses: 0.0109032059166051, regression losses: 0.07910339407343683, validation losses: 0.4013422142425497\n",
      "Epoch 4902, reconstruction losses: 0.01103099457549626, regression losses: 0.07452139044064225, validation losses: 0.40043953437139174\n",
      "Epoch 4903, reconstruction losses: 0.015271961002252709, regression losses: 0.14229995650417251, validation losses: 0.3459871142224823\n",
      "Epoch 4904, reconstruction losses: 0.012368448987107534, regression losses: 0.1333790175180107, validation losses: 0.3341946918196471\n",
      "Epoch 4905, reconstruction losses: 0.013531490226734368, regression losses: 0.18739904195043688, validation losses: 0.35502463133144346\n",
      "Epoch 4906, reconstruction losses: 0.014125498858725678, regression losses: 0.1974623833821309, validation losses: 0.36637008394448034\n",
      "Epoch 4907, reconstruction losses: 0.012208908712099379, regression losses: 0.11250403926623896, validation losses: 0.3775534161964214\n",
      "Epoch 4908, reconstruction losses: 0.012412316978586444, regression losses: 0.10697484647014552, validation losses: 0.4407287003323071\n",
      "Epoch 4909, reconstruction losses: 0.01183574149066802, regression losses: 0.13724611984180066, validation losses: 0.4606936947542725\n",
      "Epoch 4910, reconstruction losses: 0.012035130666504763, regression losses: 0.10244902718284252, validation losses: 0.4370801466417412\n",
      "Epoch 4911, reconstruction losses: 0.010465569026180779, regression losses: 0.09300062834850005, validation losses: 0.3709809974847419\n",
      "Epoch 4912, reconstruction losses: 0.016081141203170526, regression losses: 0.20584554670744362, validation losses: 0.35361710955807113\n",
      "Epoch 4913, reconstruction losses: 0.009936627348814425, regression losses: 0.06371031662467563, validation losses: 0.4491031791222648\n",
      "Epoch 4914, reconstruction losses: 0.010838119410230159, regression losses: 0.1043398528059123, validation losses: 0.41999804765311366\n",
      "Epoch 4915, reconstruction losses: 0.009172957518494866, regression losses: 0.07005895205379516, validation losses: 0.33339242349407944\n",
      "Epoch 4916, reconstruction losses: 0.009513859815196053, regression losses: 0.07747341190559531, validation losses: 0.3092138247810732\n",
      "Epoch 4917, reconstruction losses: 0.012042634538984957, regression losses: 0.08803054333637052, validation losses: 0.3043125649086852\n",
      "Epoch 4918, reconstruction losses: 0.011691102084705019, regression losses: 0.09828374195433753, validation losses: 0.3081265674706304\n",
      "Epoch 4919, reconstruction losses: 0.011402755057979322, regression losses: 0.08851138969270902, validation losses: 0.30879215713017133\n",
      "Epoch 4920, reconstruction losses: 0.011250539547850682, regression losses: 0.0887332009996551, validation losses: 0.29007110821897963\n",
      "Epoch 4921, reconstruction losses: 0.01725389634141347, regression losses: 0.15003931684524757, validation losses: 0.32383827580320174\n",
      "Epoch 4922, reconstruction losses: 0.012227661631319246, regression losses: 0.08520486677493075, validation losses: 0.39603258108646905\n",
      "Epoch 4923, reconstruction losses: 0.012311761366185201, regression losses: 0.10467338519647532, validation losses: 0.36720934630945484\n",
      "Epoch 4924, reconstruction losses: 0.01474323232409602, regression losses: 0.09532699992504468, validation losses: 0.34324630874041406\n",
      "Epoch 4925, reconstruction losses: 0.012241355877294571, regression losses: 0.10660808891280038, validation losses: 0.33394149994818845\n",
      "Epoch 4926, reconstruction losses: 0.012730947322337996, regression losses: 0.11261824657734465, validation losses: 0.32292248146631997\n",
      "Epoch 4927, reconstruction losses: 0.01233688610264906, regression losses: 0.06804900237251045, validation losses: 0.3178222331030746\n",
      "Epoch 4928, reconstruction losses: 0.011868796460008314, regression losses: 0.10692757158411711, validation losses: 0.31690846175669635\n",
      "Epoch 4929, reconstruction losses: 0.011929246978551522, regression losses: 0.0826977915211572, validation losses: 0.3315211499247167\n",
      "Epoch 4930, reconstruction losses: 0.010286316977008766, regression losses: 0.07299752446226698, validation losses: 0.31544485896342234\n",
      "Epoch 4931, reconstruction losses: 0.011992759340371298, regression losses: 0.11024991498420306, validation losses: 0.2918335269340517\n",
      "Epoch 4932, reconstruction losses: 0.012739835317663902, regression losses: 0.11401744523347049, validation losses: 0.2895156019334609\n",
      "Epoch 4933, reconstruction losses: 0.010628432624767701, regression losses: 0.08444291413320726, validation losses: 0.292696377277445\n",
      "Epoch 4934, reconstruction losses: 0.010466794271891644, regression losses: 0.13665406904757116, validation losses: 0.3442183003354623\n",
      "Epoch 4935, reconstruction losses: 0.012233304051360009, regression losses: 0.08741912035178918, validation losses: 0.4545323734259355\n",
      "Epoch 4936, reconstruction losses: 0.01416481663448668, regression losses: 0.14344199235854635, validation losses: 0.37643624513066026\n",
      "Epoch 4937, reconstruction losses: 0.011085789931981291, regression losses: 0.12519055337652302, validation losses: 0.34037098001978827\n",
      "Epoch 4938, reconstruction losses: 0.011462876759599045, regression losses: 0.0913366065511229, validation losses: 0.32734374917267695\n",
      "Epoch 4939, reconstruction losses: 0.012049718405984332, regression losses: 0.09871049459538857, validation losses: 0.32029770959234766\n",
      "Epoch 4940, reconstruction losses: 0.015113682929751881, regression losses: 0.08828877465817586, validation losses: 0.3144575188332509\n",
      "Epoch 4941, reconstruction losses: 0.011067386263224965, regression losses: 0.1014878707354481, validation losses: 0.3140241634973581\n",
      "Epoch 4942, reconstruction losses: 0.01079863468011456, regression losses: 0.09061413855818645, validation losses: 0.3162072098719561\n",
      "Epoch 4943, reconstruction losses: 0.013419342359822055, regression losses: 0.07834271468932487, validation losses: 0.3147878496628604\n",
      "Epoch 4944, reconstruction losses: 0.00990973467869979, regression losses: 0.04972625337112611, validation losses: 0.31541426972420233\n",
      "Epoch 4945, reconstruction losses: 0.011945980308896873, regression losses: 0.09812175614589544, validation losses: 0.31695431073578767\n",
      "Epoch 4946, reconstruction losses: 0.009823245734643021, regression losses: 0.07123863258053562, validation losses: 0.3199014482322726\n",
      "Epoch 4947, reconstruction losses: 0.011071525629075102, regression losses: 0.0815493567343171, validation losses: 0.3348212201898923\n",
      "Epoch 4948, reconstruction losses: 0.01359158147830394, regression losses: 0.13208658188582323, validation losses: 0.32097510415588054\n",
      "Epoch 4949, reconstruction losses: 0.011383969243272937, regression losses: 0.07203415101449503, validation losses: 0.3140250200028204\n",
      "Epoch 4950, reconstruction losses: 0.013489730071300002, regression losses: 0.10141031302064377, validation losses: 0.31058445811006186\n",
      "Epoch 4951, reconstruction losses: 0.011390927203304452, regression losses: 0.0979575894691439, validation losses: 0.3007314084426259\n",
      "Epoch 4952, reconstruction losses: 0.012844436118810091, regression losses: 0.09909258984103556, validation losses: 0.2974102637486623\n",
      "Epoch 4953, reconstruction losses: 0.01363536459733079, regression losses: 0.11141486881028807, validation losses: 0.3104284243076052\n",
      "Epoch 4954, reconstruction losses: 0.010979329374755872, regression losses: 0.10269287504024427, validation losses: 0.3250672132141456\n",
      "Epoch 4955, reconstruction losses: 0.01295610152837884, regression losses: 0.14829543762151873, validation losses: 0.30737717174667484\n",
      "Epoch 4956, reconstruction losses: 0.011261687947241847, regression losses: 0.10989205983784203, validation losses: 0.2846892868908962\n",
      "Epoch 4957, reconstruction losses: 0.011627683053311282, regression losses: 0.14727319040565706, validation losses: 0.28354780006667446\n",
      "Epoch 4958, reconstruction losses: 0.020036838366163566, regression losses: 0.12675665812134695, validation losses: 0.29355787218141854\n",
      "Epoch 4959, reconstruction losses: 0.012461079101548478, regression losses: 0.09789626049142244, validation losses: 0.38381089555805403\n",
      "Epoch 4960, reconstruction losses: 0.016061502471633602, regression losses: 0.1297275153477677, validation losses: 0.3747951895103351\n",
      "Epoch 4961, reconstruction losses: 0.012024045641037972, regression losses: 0.08935247563928364, validation losses: 0.37764482527459214\n",
      "Epoch 4962, reconstruction losses: 0.01213121389953286, regression losses: 0.11631108579754715, validation losses: 0.3305152625026409\n",
      "Epoch 4963, reconstruction losses: 0.012084326029999318, regression losses: 0.09327852188405455, validation losses: 0.3196517724704879\n",
      "Epoch 4964, reconstruction losses: 0.011332744271305383, regression losses: 0.07416984349664792, validation losses: 0.3179233755568206\n",
      "Epoch 4965, reconstruction losses: 0.012621437053473674, regression losses: 0.09517679287867717, validation losses: 0.3067172983320616\n",
      "Epoch 4966, reconstruction losses: 0.011116514758820173, regression losses: 0.08227125442041769, validation losses: 0.3182122308230166\n",
      "Epoch 4967, reconstruction losses: 0.0126114852949107, regression losses: 0.09458500078327427, validation losses: 0.32537512707352534\n",
      "Epoch 4968, reconstruction losses: 0.010253731425518995, regression losses: 0.08755256662962631, validation losses: 0.3193406489933607\n",
      "Epoch 4969, reconstruction losses: 0.012090308615703415, regression losses: 0.10127393500838959, validation losses: 0.3114038885041179\n",
      "Epoch 4970, reconstruction losses: 0.011565012422823186, regression losses: 0.09203110904410018, validation losses: 0.3235716896294766\n",
      "Epoch 4971, reconstruction losses: 0.016328960356098845, regression losses: 0.10488245106511952, validation losses: 0.3100915728599357\n",
      "Epoch 4972, reconstruction losses: 0.010594670053963317, regression losses: 0.08628565112500418, validation losses: 0.31265200508936636\n",
      "Epoch 4973, reconstruction losses: 0.011124344999040508, regression losses: 0.07796801938748626, validation losses: 0.31152105092958055\n",
      "Epoch 4974, reconstruction losses: 0.014880718068358912, regression losses: 0.11272513726513857, validation losses: 0.3217804366390779\n",
      "Epoch 4975, reconstruction losses: 0.015917275578429743, regression losses: 0.09917150314431364, validation losses: 0.3542468259263276\n",
      "Epoch 4976, reconstruction losses: 0.010071341416947753, regression losses: 0.08598431520333635, validation losses: 0.30324169008522445\n",
      "Epoch 4977, reconstruction losses: 0.010555329590898915, regression losses: 0.08837708833506558, validation losses: 0.30164603858538014\n",
      "Epoch 4978, reconstruction losses: 0.012725730084401901, regression losses: 0.10012384011436677, validation losses: 0.3073411377074993\n",
      "Epoch 4979, reconstruction losses: 0.015086297205645138, regression losses: 0.257139331285778, validation losses: 0.2934142286646447\n",
      "Epoch 4980, reconstruction losses: 0.01139799679865268, regression losses: 0.12217773183137061, validation losses: 0.3199302569969054\n",
      "Epoch 4981, reconstruction losses: 0.011280592591683415, regression losses: 0.10013395257391887, validation losses: 0.3189740715666592\n",
      "Epoch 4982, reconstruction losses: 0.01082383444870948, regression losses: 0.12384523833341608, validation losses: 0.3172448211660493\n",
      "Epoch 4983, reconstruction losses: 0.016952055204686668, regression losses: 0.23466821208539373, validation losses: 0.3370473218649761\n",
      "Epoch 4984, reconstruction losses: 0.010918734554563716, regression losses: 0.08368240127944207, validation losses: 0.41249223212838665\n",
      "Epoch 4985, reconstruction losses: 0.011300530323511873, regression losses: 0.10909262655324711, validation losses: 0.41842113269184034\n",
      "Epoch 4986, reconstruction losses: 0.010044624528363234, regression losses: 0.10360336862115033, validation losses: 0.33682978779770173\n",
      "Epoch 4987, reconstruction losses: 0.010914067556239646, regression losses: 0.10234822877164136, validation losses: 0.2879353615098754\n",
      "Epoch 4988, reconstruction losses: 0.01312719345682839, regression losses: 0.08963144659520159, validation losses: 0.2927194237874905\n",
      "Epoch 4989, reconstruction losses: 0.012442062114429287, regression losses: 0.13024641762697306, validation losses: 0.3122919576105303\n",
      "Epoch 4990, reconstruction losses: 0.012393661736507303, regression losses: 0.05970877684973696, validation losses: 0.3526724583554444\n",
      "Epoch 4991, reconstruction losses: 0.010982988870121448, regression losses: 0.08883280084115866, validation losses: 0.32686661492437474\n",
      "Epoch 4992, reconstruction losses: 0.011873691746248437, regression losses: 0.09895145800836287, validation losses: 0.29763001631245484\n",
      "Epoch 4993, reconstruction losses: 0.014459315128433577, regression losses: 0.07394147789634589, validation losses: 0.3094888263251882\n",
      "Epoch 4994, reconstruction losses: 0.011166414581820116, regression losses: 0.10272942458954326, validation losses: 0.3222097247103737\n",
      "Epoch 4995, reconstruction losses: 0.011909137068242731, regression losses: 0.08978864998879339, validation losses: 0.3020136582091095\n",
      "Epoch 4996, reconstruction losses: 0.014822210416533003, regression losses: 0.11958199931485981, validation losses: 0.29974942463651644\n",
      "Epoch 4997, reconstruction losses: 0.012737722886225655, regression losses: 0.09795425748588886, validation losses: 0.3676008638862884\n",
      "Epoch 4998, reconstruction losses: 0.013318278618975436, regression losses: 0.09165649359624417, validation losses: 0.3190257203383725\n",
      "Epoch 4999, reconstruction losses: 0.013058118975714414, regression losses: 0.09304286059034976, validation losses: 0.2836526940026415\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_format()\n",
    "\n",
    "dataset, method = config.values()\n",
    "\n",
    "training_wifi_pos, testing_wifi_pos = load(dataset)\n",
    "\n",
    "boundary = get_boundary(training_wifi_pos[:, -2:], testing_wifi_pos[:, -2:])\n",
    "\n",
    "DSAR_training(dataset, training_wifi_pos, boundary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_pos, testing_err, rssi_reconst = DSAR_testing(testing_wifi_pos, dataset, boundary)\n",
    "avg_test_err= sum(testing_err) / len(testing_err)\n",
    "plot_wifi_pos(dataset, method, training_wifi_pos[:,-2:], testing_wifi_pos[:,-2:], testing_pos, testing_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label = [-1. 14.] -> predicted label = [-2.09986868 13.81645428], err = (1.1150785348964487+0j)\n",
      "original label = [-1. 20.] -> predicted label = [-2.09980446 20.11606396], err = (1.1059117016835738+0j)\n",
      "original label = [-10.  14.] -> predicted label = [-10.83162254  14.44535265], err = (0.9433636817969159+0j)\n",
      "original label = [-10.  16.] -> predicted label = [-9.74237739 17.85402425], err = (1.8718374168330927+0j)\n",
      "original label = [-10.  18.] -> predicted label = [-9.42107352 19.50644187], err = (1.6138534539936769+0j)\n",
      "original label = [-10.  20.] -> predicted label = [-9.85203365 20.03528288], err = (0.15211483479636043+0j)\n",
      "original label = [-10.  22.] -> predicted label = [-9.79271764 20.36111158], err = (1.651944682488057+0j)\n",
      "original label = [-11.  14.] -> predicted label = [-11.97386488  14.90720921], err = (1.3309550530403071+0j)\n",
      "original label = [-11.  20.] -> predicted label = [-10.23157095  20.32530128], err = (0.8344483980686628+0j)\n",
      "original label = [-13.  14.] -> predicted label = [-13.76876273  14.88226402], err = (1.1702076453691936+0j)\n",
      "original label = [-13.  20.] -> predicted label = [-13.04200239  20.67338029], err = (0.6746889752206091+0j)\n",
      "original label = [-14.  14.] -> predicted label = [-13.73316366  15.03244858], err = (1.0663731523893243+0j)\n",
      "original label = [-14.  16.] -> predicted label = [-14.21744008  14.70279094], err = (1.3153066327173304+0j)\n",
      "original label = [-14.  18.] -> predicted label = [-13.47882891  20.83326285], err = (2.880798095885307+0j)\n",
      "original label = [-14.  20.] -> predicted label = [-13.56112204  20.79523408], err = (0.9083012188409155+0j)\n",
      "original label = [-14.  22.] -> predicted label = [-13.60688032  21.56540065], err = (0.586020198426078+0j)\n",
      "original label = [-15.  14.] -> predicted label = [-15.82873189  13.98267783], err = (0.8289129031672788+0j)\n",
      "original label = [-17.  14.] -> predicted label = [-16.93854653  13.89240474], err = (0.12390830710605781+0j)\n",
      "original label = [-19.  14.] -> predicted label = [-17.0705132   13.95824441], err = (1.9299385564039115+0j)\n",
      "original label = [-3. 14.] -> predicted label = [-3.50282901 13.79539795], err = (0.5428618766565351+0j)\n",
      "original label = [-3. 20.] -> predicted label = [-3.74269758 20.16518693], err = (0.7608458591874928+0j)\n",
      "original label = [-5. 14.] -> predicted label = [-4.70026734 13.78276507], err = (0.37017655019738577+0j)\n",
      "original label = [-5. 20.] -> predicted label = [-5.80253329 20.33900337], err = (0.8711962861416624+0j)\n",
      "original label = [-7. 14.] -> predicted label = [-6.64032881 13.79280406], err = (0.415082547956901+0j)\n",
      "original label = [-7. 20.] -> predicted label = [-8.11508836 20.55162319], err = (1.244070015468579+0j)\n",
      "original label = [-9. 14.] -> predicted label = [-8.95115384 13.97647952], err = (0.054214019242866375+0j)\n",
      "original label = [-9. 20.] -> predicted label = [-9.60116115 20.40937861], err = (0.727313939550461+0j)\n",
      "testing avg error = 1.0033231310194437\n"
     ]
    }
   ],
   "source": [
    "#listing the difference of original label and predicted label\n",
    "import cmath\n",
    "testing_labels = testing_wifi_pos[:, -2:]\n",
    "for i, label in enumerate(testing_labels):\n",
    "    err = (label - testing_pos[i])\n",
    "    err = cmath.sqrt(err[0]**2 + err[-1]**2)\n",
    "    print(f\"original label = {label} -> predicted label = {testing_pos[i]}, err = {err}\")\n",
    "print(f\"testing avg error = {avg_test_err}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6ddf36f5b06b2d1dffbdce440328aa987a3baf133dab91692508e7a923335d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
